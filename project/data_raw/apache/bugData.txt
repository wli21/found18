7300	null	CLOSED		NickM	1016655420000	1040250787000		 HeaderName When making use of ReadmeName and HeaderName under Win2K I get strange usage,  not as documented.     ReadmeName README     HeaderName HEADER I expect to have either README or README.html for example to work this.   Instead none work and the only working file for this is: readme.txt or readme.htm (case sensitive still)  Apart from being undocumented (as far as I could see) it seems wrong to use non- internet standard extension .htm following in IIS's footsteps.  But Id also  expect any case to work but it doesnt, the addition of .txt (optionally) is  useful at least.  Nick	For whatever it is worth, this appears to work fine on Unix platforms.  I also would *not* expect readme.txt,readme.htm,readme.html variants to work.  But, that is my personal interpretation of the docs and my preference as well.  I'll leave this open in case it is determined that this is a Win32-specific thing. I know it works perfectly under UNIX, it IS a Win32 thing but surely that is  just as relevant.  Either to the docs or to the programming.  Ive not tested  this under Apache2 yet, but Im guessing you have due to upgrading its status -  if not I can if you wish?  IMO on Win32 the case shouldnt matter and extensions should be none .txt  and .html (not .htm).   --Nick The bug you describe applies to Apache 1.3.  It does not apply to 2.0.  However, if Multiviews is not on, automatic name 'prefixes' are no longer used on Apache 2.0.  With 2.0 you may need something as simple as  <Files 'README.*'>     Options +Multiviews </Files> <Files 'HEADER.*'>     Options +Multiviews </Files>  if you don't otherwise use Multiviews in the corresponding directory tree.    The fix is committed and will be available with the release of 1.3.28.  It does NOT work with 1.3.27 under Linux or BSD. I have confirmed this bug or one weth very similar behavior  on multiple installations running on multiple operating systems installed and tested by multiple people.  Please ignore my comments above. The issue I saw on Linux and BSD was a seperate issue  that at first appeared to have similar symptoms. 			Justin Erenkrantz	NickM	Ray Morris	Will Rowe
7441	null	CLOSED		Dinesh Patel	1017056460000	1018839571000		RFC 2616 - Apache incorrectly expects a non-empty Host header Running Apache 2.0.28 server on RedHat Linux Set up machine, OS and Apache for IPv6 networking Tried to download HTTP content by specifying the IPv6 numerical IP address The Apache server is not fully HTTP 1.1 compliant.   The server incorrectly expects a non-empty Host header even when the server is  specified by a numeric IP address e.g. 10.158.7.52.  The host header should be empty when the server IP address is specified using a  numerical address. Server incorrectly returns and 400 http server code.   rfc2616 - Hypertext Transfer Protocol -- HTTP/1.1 Section 14.23 Host  IPv6 browsers will not work on Apache if this is not fixed.	Confirmed.  And this is a regression from 1.3, which handles this correctly.  However, I don't think it has anything to do with IPv6.  The same issue is present with ordinary old IPv4 addresses.  Although this should be fixed, I'm not sure why this is causing you a problem. All the browsers that I've seen send the IP address in the Host: header when they don't have a name, and this works fine. This should be resolved in revision 1.73 of server/vhost.c.  This will be included in the next release of Apache httpd-2.0.  Thanks for using Apache! *** Bug 8422 has been marked as a duplicate of this bug. *** *** Bug 8604 has been marked as a duplicate of this bug. ***			Cliff Woolley	Joshua Slive	Justin Erenkrantz
7492	null	CLOSED		Yuriy Ryabikov	1017165300000	1049053041000		Rewritemap mismerges paths (c:/ not recognized as rooted) -begin----httpd.conf-----  <Directory 'C:/Program Files/Apache Group/Apache/htdocs'>     Options Indexes FollowSymLinks     AllowOverride All RewriteEngine on RewriteRule ^(.*)$ $1/%{REMOTE_ADDR} RewriteRule ^(.*)$ ${AntiLeech:$1|/leech2.html}     Order allow,deny     Allow from all </Directory>  <VirtualHost *:87>      ServerAdmin webmaster@localhost      DocumentRoot 'C:/Program Files/Apache Group/Apache/htdocs'      ServerName localhost  RewriteEngine on RewriteMap AntiLeech prg:C:/PROGRA~1/APACHE~1/APACHE/HTDOCS/1.pl RewriteLog 'C:/PROGRA~1/APACHE~1/APACHE/HTDOCS/rewrite.log' RewriteLogLevel 9 </VirtualHost>   --end-----httpd.conf-----  -begin----rewrite.log----- 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (2) init rewrite engine with requested uri /fgdfgdf 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (1) pass through /fgdfgdf 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (3) [per-dir c:/program files/apache group/apache/htdocs/]  strip per-dir prefix: c:/program files/apache group/apache/htdocs/fgdfgdf ->  fgdfgdf 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (3) [per-dir c:/program files/apache group/apache/htdocs/]  applying pattern '^(.*)$' to uri 'fgdfgdf' 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (2) [per-dir c:/program files/apache group/apache/htdocs/]  rewrite fgdfgdf -> fgdfgdf/10.1.1.2 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (3) [per-dir c:/program files/apache group/apache/htdocs/]  add per-dir prefix: fgdfgdf/10.1.1.2 -> c:/program files/apache  group/apache/htdocs/fgdfgdf/10.1.1.2 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (3) [per-dir c:/program files/apache group/apache/htdocs/]  add per-dir prefix: c:/program files/apache  group/apache/htdocs/fgdfgdf/10.1.1.2 -> c:/program files/apache  group/apache/htdocs/c:/program files/apache group/apache/htdocs/fgdfgdf/10.1.1.2 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (3) [per-dir c:/program files/apache group/apache/htdocs/]  strip per-dir prefix: c:/program files/apache group/apache/htdocs/c:/program  files/apache group/apache/htdocs/fgdfgdf/10.1.1.2 -> c:/program files/apache  group/apache/htdocs/fgdfgdf/10.1.1.2 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (3) [per-dir c:/program files/apache group/apache/htdocs/]  applying pattern '^(.*)$' to uri 'c:/program files/apache  group/apache/htdocs/fgdfgdf/10.1.1.2' 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (5) map lookup OK: map=AntiLeech key=$1 -> val= 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (2) [per-dir c:/program files/apache group/apache/htdocs/]  rewrite c:/program files/apache group/apache/htdocs/fgdfgdf/10.1.1.2 ->  10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (3) [per-dir c:/program files/apache group/apache/htdocs/]  add per-dir prefix:  -> c:/program files/apache group/apache/htdocs/ 10.1.1.2 - - [26/Mar/2002:19:52:15 +0200] [localhost/sid#8d7ab8] [rid#96d640/initial] (3) [per-dir c:/program files/apache group/apache/htdocs/]  add per-dir prefix: c:/program files/apache group/apache/htdocs/ -> c:/program  files/apache group/apache/htdocs/c:/program files/apache group/apache/htdocs/ --end-----rewrite.log-----	Could you please describe the exact problem you are experiencing?  Is it the  fact that the key is not getting substituted properly in the RewriteMap?  You obviously have problems with the per-dir prefix getting added more than once, but that is because you aren't using RewriteBase like you should be. Or alternatively, you should not place the RewriteRules inside a <Directory> section. Created an attachment (id=1431) httpd.conf  Created an attachment (id=1432) rewrite.log  Created an attachment (id=1433) perl CGI  Joshua,  Thank you for reply. Please take a look at the line from rewrite log:   map lookup OK: map=AntiLeech key=$1 -> val= 1. back-reference to pattern does is not resolved to URI as it should be, when used within rewrite-map reference   RewriteRule ^(.*)$ ${AntiLeech:$1|/leech2.html} 2. rewrite map program does not receive any input, as it's evident from empty perl log, which I forgot to mention, and turned off buffering in attached perl script. 3. This bug is exposed only under Win32. Under UNIX RewriteMap works ok, all vars are subsituted, and per-dir prefix is added only once (latter may be because of slightly different directory layout, but that's another issue. BTW, RewriteBase does not help).   OK.  I'm not sure if prg: rewritemaps have ever worked in win32.  I'm updating the summary to better direct attention. May be will fixed in next version? ^) This bug is difficult to address in Apache 1.3.x.  Not impossible, but difficult.  As guessed, this has never worked in the 1.3 series.  Apache 2.0.x introduced new APIs for determining fully qualified path names.  Mod_rewrite in Apache 2.0 was updated in v. 1.84 to accept  any rooted path (based on the filesystem convention, e.g. c:/foo for  win32, or foo/bar:bleh for Netware.)  http://cvs.apache.org/viewcvs/httpd-2.0/modules/mappers/mod_rewrite.c.diff?r1=1.83&r2=1.84&diff_format=h  There may also be thread saftey problems with the rewrite cache, introduced in Apache 2.0's v. 1.83, that would need backporting.  http://cvs.apache.org/viewcvs/httpd-2.0/modules/mappers/mod_rewrite.c.diff?r1=1.82&r2=1.83&diff_format=h  Finally, it seems that ap_pstrcat is still being used to merge paths in 1.3 and 2.0.  This should be fixed in 2.0 to use apr_filepath_merge, and there was a similar API in 1.3.  So this can be fixed, but someone needs to take the time to write and test the fixes.  I'd entertain applying a patch that was well thought out.      Patch applied, this report will be resolved in 1.3.26.  Thread saftey of   the rewrite cache remains an issue, creating a new incident for tracking   thread saftey.    Make that, fixed in the forthcoming 1.3.25. *** Bug 8424 has been marked as a duplicate of this bug. *** I stepped into this bug, too. Then I found this bug report, downloaded Apache 1.3.27, but I still have the same problem!   My .htaccess:  RewriteEngine On RewriteRule ^vpserve.php - [L] RewriteRule ^(.*) vpserve.php   The resulting rewrite log:  127.0.0.1 - - [30/Mar/2003:16:11:11 +0200] [vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir c:/themen/sss/htdocs/_tests/vistapoint/] add path-info postfix: c:/themen/sss/htdocs/_tests/vistapoint -> c:/themen/sss/htdocs/_tests/vistapoint/ 127.0.0.1 - - [30/Mar/2003:16:11:11 +0200] [vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir c:/themen/sss/htdocs/_tests/vistapoint/] strip per-dir prefix: c:/themen/sss/htdocs/_tests/vistapoint/ ->  127.0.0.1 - - [30/Mar/2003:16:11:11 +0200] [vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir c:/themen/sss/htdocs/_tests/vistapoint/] applying pattern '^vpserve.php' to uri '' 127.0.0.1 - - [30/Mar/2003:16:11:11 +0200] [vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir c:/themen/sss/htdocs/_tests/vistapoint/] add path-info postfix: c:/themen/sss/htdocs/_tests/vistapoint -> c:/themen/sss/htdocs/_tests/vistapoint/ 127.0.0.1 - - [30/Mar/2003:16:11:11 +0200] [vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir c:/themen/sss/htdocs/_tests/vistapoint/] strip per-dir prefix: c:/themen/sss/htdocs/_tests/vistapoint/ ->  127.0.0.1 - - [30/Mar/2003:16:11:11 +0200] [vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir c:/themen/sss/htdocs/_tests/vistapoint/] applying pattern '^(.*)' to uri '' 127.0.0.1 - - [30/Mar/2003:16:11:11 +0200] [vp.savignano.local/sid#5d82c8][rid#682450/initial] (2) [per-dir c:/themen/sss/htdocs/_tests/vistapoint/] rewrite  -> vpserve.php 127.0.0.1 - - [30/Mar/2003:16:11:11 +0200] [vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir c:/themen/sss/htdocs/_tests/vistapoint/] add per-dir prefix: vpserve.php -> c:/themen/sss/htdocs/_tests/vistapoint/vpserve.php 127.0.0.1 - - [30/Mar/2003:16:11:11 +0200] [vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir c:/themen/sss/htdocs/_tests/vistapoint/] add per-dir prefix: c:/themen/sss/htdocs/_tests/vistapoint/vpserve.php -> c:/themen/sss/htdocs/_tests/vistapoint/c:/themen/sss/htdocs/_tests/vistapoint/vpserve.php  For some reason, the directroy preix is still added twice.  I re-opened the bug, but a work-around hint would be helpful as well. Sorry, I missed the fact that the modules were changed from .dll to .so in some version, and did not update the httpd.conf accordingly.  I discovered this a few minutes ago and corrected the mistake. Now it works flawlessly.  Mea culpa!			Jeff Trawick	Joshua Slive	Metin Savignano	Will Rowe	Yuriy Ryabikov
7572	null	CLOSED		Brian Bothwell	1017318060000	1018206867000		mod_proxy does not reset timer when reading from client This bug was submitted by Martin Lichtin <martin@lichtin.net> to the old Apache bug system back in May 2000:  http://bugs.apache.org/index.cgi/full/6127  I discovered this issue when trying to upload large files over slow connections to our web application, which uses a light front-end mod_proxy server to pass requests to many heavy mod_perl server.  We were getting the following error on the mod_perl backend servers:  CGI.pm: Server closed socket during multipart read (client aborted?). [Tue Mar 26 16:44:59 2002] [error] [client 63.74.45.131] Premature end of script headers: /www/cgi-bin/test.cgi  Turned out the uploads would fail after 300 seconds, the 'Timeout' value on the mod_proxy server.  I confirmed this by setting the Timeout to 10 seconds as well as 10000 seconds, and the behavior was as exepected.  I found a link to Martin's bug report, and the included patch applied to both our 1.3.20 and 1.3.24 servers fixed the problem. For some reason this bug was missed or ignored, but it or something like it should be added the next Apache release in order to fix this issue.  the patch to the 1.3.9 tree  (proxy_http.c): *************** *** 355,362 ****   /* send the request data, if any. */        if (ap_should_client_block(r)) { !       while ((i = ap_get_client_block(r, buffer, sizeof buffer)) > 0)             ap_bwrite(f, buffer, i);       }       ap_bflush(f);       ap_kill_timeout(r); --- 338,347 ----   /* send the request data, if any. */        if (ap_should_client_block(r)) { !       while ((i = ap_get_client_block(r, buffer, sizeof buffer)) > 0) { !             ap_reset_timeout(r);             ap_bwrite(f, buffer, i); +         }       }       ap_bflush(f);       ap_kill_timeout(r);	Here's the patch for 1.3.24: (just a change of line #'s since 1.3.9) ---------------------------------------  *** proxy_http.c        Thu Mar 28 13:42:32 2002 --- proxy_http.c.patched        Thu Mar 28 13:42:17 2002 *************** *** 377,384 ****        /* send the request data, if any. */       if (ap_should_client_block(r)) { !         while ((i = ap_get_client_block(r, buffer, sizeof buffer)) > 0) !             ap_bwrite(f, buffer, i);       }       ap_bflush(f);       ap_kill_timeout(r); --- 377,386 ----        /* send the request data, if any. */       if (ap_should_client_block(r)) { !       while ((i = ap_get_client_block(r, buffer, sizeof buffer)) > 0) { !       ap_reset_timeout(r); !       ap_bwrite(f, buffer, i); !       }       }       ap_bflush(f);       ap_kill_timeout(r);  Patch applied. 			Brian Bothwell	Graham Leggett
7628	null	CLOSED		Jos Backus	1017448800000	1033759707000		daemontools patch no longer applies cleanly to 1.3.24 The daemontools patch posted at  \thttp://www.apache.org/dist/httpd/contrib/patches/1.3/daemontools.patch  no longer applies cleanly to 1.3.24. Please download the new patch from  \thttp://lizzy.dyndns.org/~jos/apache-1.3.24-daemontools.patch  and install it as  http://www.apache.org/dist/httpd/contrib/patches/1.3/apache-1.3.24-daemontools.patch  and remove the old patch. Thanks.  Jos	handled			Jim Jagielski
7764	null	CLOSED		Ranier Vilela Fonseca	1018014120000	1024240522000		tmpnam is dangerous Compiler GCC 2.95.3 Results of compilation:  .../htpassword.c:613 The use of tmpnam 'is dangerous, better use mkstemp  Have the possibility inclusion the argument: -Wall, in all rules for compilation?  Thanks.  Ranier.	This is a bogus warning.  Apache uses tmpnam in a safe way. Comment from Cliff Woolley (glad we have peer review ;-):  Actually, depending on how htpasswd is used, it might be possible to construct some sort of a symlink attack to have arbitrary files corrupted. It's not a bogus warning... it really should be fixed.  I've been meaning to do it for ages; htdigest was already fixed.  htpasswd is more difficult because the whole program needs to be APRized... there was a patch to do this at one point written by Mladen Turk, but the patch was overkill IMO (and that of the other people that reviewed it as I recall), so it never got committed.  If it were up to me, I'd leave this bug listed as open to remind us to get to this one day.  *** Bug 8197 has been marked as a duplicate of this bug. *** htpasswd has been re-written, and no longer uses tempnam.  Thank you for the bug report. 			Joshua Slive	Ryan Bloom
7791	null	CLOSED		octave klaba	1018098180000	1022402209000		mod_suexec problem I have just compiled 2.0.35 and some of cgi script does not word anymore. I used to have 1.3.24 (with suexec too). So, it should work with without any problem.  the problem is that the scripts do not take the variables in the right order: http://ping.ovh.net/traceroute_1.3.24.cgi works on 1.3.24 only and http://ping.ovh.net/traceroute_2.0.35.cgi works on 2.0.35 only  # diff -u traceroute_1.3.24.cgi traceroute_2.0.35.cgi  --- traceroute_1.3.24.cgi       Sat Apr  6 14:56:05 2002 +++ traceroute_2.0.35.cgi       Sat Apr  6 14:56:00 2002 @@ -49,7 +49,7 @@          else                   echo 'Result for <b>$1</b>:'                  echo /<PRE/> -                nice $TRACEROUTE '$1' 2>&1 +                nice $TRACEROUTE '$2' 2>&1                  echo /</PRE/>          fi  else  it is the same when you try to open a cgi with perl  # telnet ping.ovh.net 80 Trying 213.186.33.13... Connected to ping.ovh.net. Escape character is '^]'. HEAD / HTTP/1.0   ----> nothing with ps auxw I see this: ovh      28262  0.2  0.4  2244 1180 ?        S    14:59   0:00 perl index.cgi  index.cgi  (index.cgi 2 times ?) # kill 28262 and telnet ping.ovh.net 80 gives:  HTTP/1.1 200 OK Date: Sat, 06 Apr 2002 12:59:08 GMT Server: Apache/2.0.35 (Unix) Connection: close Content-Type: text/html; charset=ISO-8859-1  Connection closed by foreign host.  the configuration: # uname -a Linux ping.ovh.net 2.2.20ext3 #2 Mon Jan 21 23:37:49 CET 2002 i686 unknown  # /usr/local/apache/bin/httpd -V Server version: Apache/2.0.35 Server built:   Apr  6 2002 14:18:38 Server's Module Magic Number: 20020329:0 Architecture:   32-bit Server compiled with....  -D APACHE_MPM_DIR='server/mpm/prefork'  -D APR_HAS_SENDFILE  -D APR_HAS_MMAP  -D APR_HAVE_IPV6  -D APR_USE_SYSVSEM_SERIALIZE  -D APR_USE_PTHREAD_SERIALIZE  -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT  -D APR_HAS_OTHER_CHILD  -D AP_HAVE_RELIABLE_PIPED_LOGS  -D HTTPD_ROOT='/usr/local/apache'  -D SUEXEC_BIN='/usr/local/apache/bin/suexec'  -D DEFAULT_ERRORLOG='logs/error_log'  -D SERVER_CONFIG_FILE='conf/httpd.conf' # /usr/local/apache/bin/httpd -v Server version: Apache/2.0.35 Server built:   Apr  6 2002 14:18:38 # /usr/local/apache/bin/httpd -l Compiled in modules:   core.c   mod_access.c   mod_auth.c   mod_echo.c   mod_cache.c   mod_mem_cache.c   mod_include.c   mod_log_config.c   mod_env.c   mod_setenvif.c   prefork.c   http_core.c   mod_mime.c   mod_status.c   mod_autoindex.c   mod_asis.c   mod_suexec.c   mod_cgi.c   mod_negotiation.c   mod_dir.c   mod_imap.c   mod_actions.c   mod_speling.c   mod_userdir.c   mod_alias.c   mod_rewrite.c   mod_so.c  <VirtualHost *> DocumentRoot /home/ovh/www ServerName ping.ovh.net SuexecUserGroup ovh ovh </VirtualHost>  [2002-04-06 15:00:17]: uid: (500/ovh) gid: (500/500) cmd: traceroute.cgi [2002-04-06 15:00:23]: uid: (500/ovh) gid: (500/500) cmd: traceroute.cgi	I have tester this on Redhat Linux 7.2 with cvs head of both apache-1.3 and httpd-2.0. I get the same behavior from the identical cgi run on both versions of Apache. Parms $1, $2, and $3 all line up the same in my tests.  Could you retry your tests with the latest versions of Apache 1.3 and 2.0? If I don't hear from you to the contrary, I will close this in a couple of days since it works for me.  Thank you. I'm seeing this bug aswell in 2.036 and CVS. suexec is getting passed args  ala:     /path/to/suexec (~)uid gid cmdname argv0 argv1 argv2   and so on. Previously in 1.3 it was :      /path/to/suexec (~)uid gid argv0 argv1 argv2   and argv0 was assumed to == cmdname. This patch reverts to the previous behaviour.  Index: os/unix/unixd.c =================================================================== RCS file: /home/cvspublic/httpd-2.0/os/unix/unixd.c,v retrieving revision 1.52 diff -u -u -r1.52 unixd.c --- os/unix/unixd.c     17 May 2002 11:33:10 -0000      1.52 +++ os/unix/unixd.c     26 May 2002 00:47:29 -0000 @@ -350,16 +350,16 @@             }      }      /* allocate space for 4 new args, the input args, and a null terminator */ -    newargs = apr_palloc(p, sizeof(char *) * (i + 5)); +    newargs = apr_palloc(p, sizeof(char *) * (i + 4));      newprogname = SUEXEC_BIN;      newargs[0] = SUEXEC_BIN;      newargs[1] = execuser;      newargs[2] = execgroup;      newargs[3] = apr_pstrdup(p, progname);  -    i = 0; +    i = 1;      do { -        newargs[i + 4] = args[i]; +        newargs[i + 3] = args[i];      } while (args[i++]);       return apr_proc_create(newproc, newprogname, newargs, env, attr, p); patch works for me (2.0.35)  Octave thanks, I've committed the patch			Brian Pane	Colm	Paul J. Reder	octave klaba
7795	null	CLOSED		Dave Hodder	1018109760000	1018802718000		Support XHTML media type (RFC 3236) in default install Would it be possible for someone to add support for RFC 3236 (the 'application/xhtml+xml' media type registration) into the default Apache server installation?  It's missing in both version 1.3.x and 2.0.x.  Firstly, the registration should appear inside the mime.types file:      application/xhtml+xml\t\txhtml xht  Secondly the DirectoryIndex directive inside httpd.conf (or all the http*.conf* files) should have a reference to 'index.xhtml', e.g.:      DirectoryIndex index.xhtml index.html  ... or perhaps:      DirectoryIndex index.xhtml index.html index.xhtml.var index.html.var  Many thanks,  Dave	*** Bug 7796 has been marked as a duplicate of this bug. *** Created an attachment (id=1542) Test XHTML file (index.xhtml)  I've added the type to mime.types, but I'm not going to change the default DirectoryIndex.  I see no reason to do that unless we see this type becoming the predominant default type.  For now, people can edit their own config files, just like they do for php, etc.  Thanks for using Apache!			Dave Hodder	Joshua Slive
7802	null	CLOSED		Issac Goldstand	1018132620000	1018234602000		t compile Using: OpenSSL 0.9.7-dev 24 Sep 2000 built on: Sun Apr  7 01:17:42 IDT 2002 platform: linux-elf options:  bn(64,32) md2(int) rc4(idx,int) des(ptr,risc1,16,long) idea(int) blowfish(idx)  compiler: gcc -fPIC -DOPENSSL_THREADS -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H -DOPENSSL_NO_KRB5 -DL_ENDIAN -DTERMIO -O3 -fomit-frame-pointer -m486 -Wall -DSHA1_ASM -DMD5_ASM -DRMD160_ASM OPENSSLDIR: '/usr/local/httpd/ssl'  Configure line:  ./configure --prefix=/usr/local/apache2 --enable-so --enable-rewrite --enable-ssl --enable-http  --with-ssl=/usr/local/httpd  Error: /bin/sh /home/issac/httpd-2.0.35/srclib/apr/libtool --silent --mode=compile gcc  -g -O2 -pthread -DNO_DBM_REWRITEMAP    -DLINUX=2 -D_REENTRANT -D_XOPEN_SOURCE=500 -D_BSD_SOURCE -D_SVID_SOURCE -DAP_HAVE_DESIGNATED_INITIALIZER   -I. -I/home/issac/httpd-2.0.35/os/unix -I/home/issac/httpd-2.0.35/server/mpm/prefork -I/home/issac/httpd-2.0.35/modules/http -I/home/issac/httpd-2.0.35/modules/proxy -I/home/issac/httpd-2.0.35/include -I/home/issac/httpd-2.0.35/srclib/apr/include -I/home/issac/httpd-2.0.35/srclib/apr-util/include -I/usr/local/httpd/include/openssl -I/usr/local/httpd/include -I/home/issac/httpd-2.0.35/modules/dav/main -I/home/issac/httpd-2.0.35/srclib/apr-util/include  -c ssl_engine_kernel.c && touch ssl_engine_kernel.lo ssl_engine_kernel.c:1809: conflicting types for "ssl_callback_LogTracingState' mod_ssl.h:639: previous declaration of "ssl_callback_LogTracingState' make[3]: *** [ssl_engine_kernel.lo] Error 1 make[3]: Leaving directory "/home/issac/httpd-2.0.35/modules/ssl' make[2]: *** [all-recursive] Error 1 make[2]: Leaving directory "/home/issac/httpd-2.0.35/modules/ssl' make[1]: *** [all-recursive] Error 1 make[1]: Leaving directory "/home/issac/httpd-2.0.35/modules' make: *** [all-recursive] Error 1	this has been fixed in cvs. quick fix can be done by hand if you edit mod_ssl.h and change this line: #if SSL_LIBRARY_VERSION >= 0x00907000 to if 0 			Doug MacEachern
7803	null	CLOSED		Matthew Darwin	1018137000000	1024116149000		t work in 2.0.35 the root= paramter of make install install is ignored and the web server is installed in the real location instead.  This is inconvient for making packages.  See http://www.apacheweek.com/issues/98-05-01	I have made a DESTDIR patch (I'm attaching it). Created an attachment (id=1495) patch to allow for 'make DESTDIR=%{buildroot} install' in packages  Thanks for the patch!  It works great! Created an attachment (id=1880) This is a hand-editied version of Andreas' patch so it applies against 2.0.36. 2 Minor changes.  *** Bug 9792 has been marked as a duplicate of this bug. *** I have committed this patch, and it will either be in 2.0.38 or 2.0.39, depending on if the RM wishes to include it in a tag that is likely to be made sometime tonight or tomorrow. 			Andreas Hasenack	Juergen Strobel	Matthew Darwin	Ryan Bloom
7810	null	CLOSED		Colm	1018177020000	1034788510000		suexec + userdir non-functional in httpd 2.0.35 (possibly related to bug 7791) Possibly Related to Bug 7791. mod_cgid behaviour is a major security issue and should at least be documented.  using prefork mpm + mod_cgi : suexec is called with arguments 'uid gid binary ..' and NOT '~uid gid binary ..' which results in a not in docroot error. Hacky shell script to add ~ to the call and recall a real suexec binary results in correct operation.  Confirmed on FreeBSD 4.5 and Solaris 8 (sparc)  using worker mpm + mod_cgid :  suexec DOES NOT EVEN GET CALLED. userdir cgi run with the uid/gid of the  webserver.   Confirmed on FreeBSD 4.5 and Solaris 8 (sparc)  configure cmdlines:  ./configure --prefix=/local/apache-test / --enable-cgi / --enable-suexec --with-suexec-caller=www / --with-suexec-docroot=/local/web/htdocs / --with-suexec-bin=/local/apache-test/bin/suexec / --with-suexec-logfile=/local/apache-test/logs/suexec_log / --with-suexec-userdir=public_html / --with-suexec-uidmin=100 --with-suexec-gidmin=100 --with-suexec-umask=077   ./configure --prefix=/local/apache-test / --with-mpm=worker / --enable-cgid / --enable-suexec --with-suexec-caller=www / --with-suexec-docroot=/local/web/htdocs / --with-suexec-bin=/local/apache-test/bin/suexec / --with-suexec-logfile=/local/apache-test/logs/suexec_log / --with-suexec-userdir=public_html / --with-suexec-uidmin=100 --with-suexec-gidmin=100 --with-suexec-umask=077  relevant configuration directives:  UserDir public_html  ..  <Directory /home/*/*/public_html>      Options Indexes ExecCGI Includes SymLinksIfOwnerMatch      AllowOverride AuthConfig </Directory>  <Directory /home/*/*/*/public_html>      Options Indexes ExecCGI Includes SymLinksIfOwnerMatch      AllowOverride AuthConfig </Directory>  (we have a lot of users, hence nested /home)	Created an attachment (id=1580) PATCH os/unix/unixd.c for mpm=prefork  The Patch I've attachted fixes the first case, with mpm=prefork.  Still no fix for mpm=worker and likely other mpm's. Thanks for your patch!  I have committed a variant of your patch to HEAD.  Please try out a CVS snapshot or wait for the forthcoming Apache 2.0.36.  Thanks for using Apache! committed colm's patch that fixes suexec+userdir+cgid I am experiencing this problem on Solaris 8 and the latest version httpd 2.0.39.   Skimming through the source it seems the patches included in the bug report were applied before its release. It appears to be a problem with userdir, because apache will call suexec, but it does not recognize user directories (suexec is called with the target uid/gid of the httpd user/group and treats the CGI as if it were in the document root).    I have UserDir set to web in httpd.conf and am loading the following as DSOs:  access_module alias_module auth_module autoindex_module cgi_module dir_module env_module include_module log_config_module mime_magic_module mime_module negotiation_module setenvif_module suexec_module unique_id_module userdir_module vhost_alias_module  and the following compiled in:  # /usr/local/apache/bin/httpd -l Compiled in modules:   core.c   mod_ssl.c   prefork.c   http_core.c   mod_so.c  Hopefully I didn't miss something obvious!  Thanks in advance,  Dennis       Do you have any SuexecUserGroup Directives in your config files ?  Try removing them. Crossreference point: PR 9038 contains a discusion relevant to this issue. Without the SuexecUserGroup directive set, suexec is never called... nothing logged to cgi.log and CGIs (including ~user ones) are executed successfully as the httpd user. With the directive set, suexec is at least called, but it does not honor ~user... the target uid/gid are set to that of the httpd user and script execution fails because it is not in the document root.  I did check Bug 9038 before submitting, which states disabling cgid in the LoadModule should fix it.  I did this (noted in the modules I am loading) without success.  As I re-read 9038, Alex had success by disabling cgid at compile time.  Is that the ultimate fix (vs. at LoadModule time) ?  Thanks, Dennis  mod_cgid + userdir + suexec has been functional as of 2.0.39, I'm currently using that combination on several platforms.  Try reversing the order in which you load the userdir and suexec modules. Also, did you specify --enable-suexec at configure time? It's possible to have the suexec module built without that, so it may be an issue.  I did include that config option... pullled from config.log (minus the formatting for readability):  ./configure --with-layout=Apache / --prefix=/usr/local/apache / --enable-mods-shared=access actions alias asis auth auth_anon auth_dbm autoindex cache cern_meta cgi cgid charset_lite dav deflate dir env example expires ext_filter file_cache headers imap include info isapi log_config mime mime_magic negotiation proxy rewrite setenvif speling status suexec unique_id userdir usertrack vhost_alias / --enable-modules=ssl / --enable-so / --enable-ssl / --enable-suexec / --with-ssl=/opt / --enable-static-htpasswd / --disable-auth-digest / --with-suexec-caller=www / --with-suexec-docroot=/web / --with-suexec-userdir=web / --with-suexec-uidmin=10 / --with-suexec-gidmin=10 / --with-suexec-safepath=/usr/bin:/opt/bin  Any other ideas?  Your continued to help is appreciated.  Dennis Should have explicitly mentioned I did change the order in which suexec/userdir are loaded without success. It seems like this has been fixed at some point.  If not, please feel free to reopen the bug report.			Brian Pane	Colm	Dennis Kelly	Joshua Slive	Justin Erenkrantz
7812	null	CLOSED		Ralf Hildebrandt	1018179780000	1018209298000		t set permissions on cross-process lock I built Apache using: make distclean ./configure  --with-mpm=prefork --enable-speling --enable-dav --enable-headers --enable-mods-shared=max --enable-mime-magic make make install  and started it with:  /usr/local/apache2/bin/apachectl start  in the log I get: [Sun Apr 07 13:17:01 2002] [emerg] (22)Invalid argument: Couldn't set permissions on cross-process lock  and it doesn't run after that.	Please verify that the User and Group directives are valid for your system. These frequently have to be changed from the default (depending on the OS).  I think the failure is that Apache is trying to use an invalid user or group id when setting accessibility to the SysV semaphore used for accept serialization.  Alternatively, change from the default of using SysV semaphores to fcntl  locks by coding this in your config file:  AcceptMutex fcntl  Setting the User & Group to decent values (www:www) fixed it.The error message isn't really helpful, though. The error message has been changed to point the admin to the User and Group directives.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick	Ralf Hildebrandt
7818	null	CLOSED		Sander Temme	1018202040000	1018947146000		Stale config.guess in tarball While configuring apr-util:  checking for Expat in /usr... no checking for Expat in /usr/local... no checking for Expat in xml/expat-cvs... no checking for Expat in xml/expat... yes updating cache /Users/sctemme/projects/httpd-2.0.35/./config.cache configuring package in xml/expat now loading cache /Users/sctemme/projects/httpd-2.0.35/./config.cache checking host system type... configure: error: can not guess host type; you  must specify one configure failed for xml/expat configure failed for srclib/apr-util [monalisa:~/projects/httpd-2.0.35] sctemme%   The workaround is to find config.guess and config.sub in /usr/libexec on  the local machine and copy them over the offending ones.   We've been here before. The expat in CVS does not exhibit this problem.  The 2.0.32 tarball did not exhibit this problem. I don't know exactly what is  happening... maybe the action of rolling the tarball sucks in an expat from  outside CVS? I browsed the httpd_roll_release script in CVS and saw  nothing but a plain old checkout.	*** Bug 7970 has been marked as a duplicate of this bug. *** I copied config.guess and config.sub from my /usr/libexec/ to the following  locations:   /root/httpd-2.0.35/   /root/httpd-2.0.35/srclib/apr-util   /root/httpd-2.0.35/srclib/apr-util/xml/expat  Ran main configure, got same error as Sander. Ran apr-util configure,  same error. Ran expat configure, same error.  Ran expat configure as so: ./configure --host=powerpc-apple-darwin5.3  and got following: loading cache ./config.cache checking host system type... Invalid configuration "powerpc-apple- darwin5.3': system "darwin5.3' not recognized  checking target system type... Invalid configuration "powerpc-apple- darwin5.3': system "darwin5.3' not recognized  checking build system type... Invalid configuration "powerpc-apple- darwin5.3': system "darwin5.3' not recognized  checking for ranlib... ranlib checking for gcc... gcc checking whether the C compiler (gcc  ) works... yes checking whether the C compiler (gcc  ) is a cross-compiler... no checking whether we are using GNU C... yes checking whether gcc accepts -g... yes checking for ld used by GCC... /usr/bin/ld checking if the linker (/usr/bin/ld) is GNU ld... no checking for BSD-compatible nm... /usr/bin/nm -p checking whether ln -s works... yes updating cache ./config.cache loading cache ./config.cache within ltconfig ltconfig: you must specify a host type if you use "--no-verify' Try "ltconfig --help' for more information. configure: error: libtool configure failed  Re-Ran with following: ./configure --host=powerpc-apple-bsd and everything configured fine.  Matthew I have merged in the latest config.guess/config.sub from GNU.  I also explicitly added config.guess/config.sub for expat.  This should explain why our bundled expat is acting weird - it was using the config.guess from icarus rather than a recent one.  For more information, please see the commit log: http://cvs.apache.org/viewcvs.cgi/httpd-2.0/CHANGES?rev=1.709&content-type=text/vnd.viewcvs-markup  Please try a nightly build to see if your problem goes away.  I will close this PR for now.  If the problem remains with the next release (or a nightly), you may reopen it.  Thanks for using Apache! *** Bug 8405 has been marked as a duplicate of this bug. *** Verified with Apache 2.0.36 release. Closing... I assume as reporter it's  my prerogative/task to close.			Justin Erenkrantz	Matthew Boehm	Sander Temme
7822	null	CLOSED		Andreas Hasenack	1018215300000	1045066969000		small index.html.pt-BR fixes Attaching patch...	Created an attachment (id=1497) Small pt_BR fixes  I have a little problem which is, since I don't understand your language, I  really can't verify that this is an improvement.  If there is another person who is fluent in this language who could append a comment to this bug report verifying this patch, then I can commit it.  Thanks. Well, I can assure you that calling 'documenta????o' (which is pt_BR for documentation, which wasn't even translated) with a big 'O' in front if it is like referring to Sandra Bullock with a 'he' :) Created an attachment (id=1716) Really correct problems (small) in index.html.pr-br  Really was minor problems in language in index.html.pt-br. There is: 1. The word 'temporaria' in line 'substituir esta p??gina temporaria', the correct is 'tempor??ria' 2. The word 'apontar' in line 'ou apontar o servidor para o seu conte??do real', better 'ou configurar o servidor para o seu conte??do real', replace 'apontar' with 'configurar' 3. The prhase 'Esta p??gina est?? sendo carregada, pois o administrador...', better 'Esta p??gina foi carregada, pois provavelmente, o administrador...' 4. The word 'contacte' in line 'Por favor, contacte...', correct is 'contate' 5. The word 'a' in line 'e n??o poder?? ajudar a resolu????o...', better is 'na', correct is 'e n??o poder?? ajudar na resolu????o...' 6. The line 'O Apache documentation foi inclu??do com esta distribui????o', correct is 'A documenta????o do Apache foi inclu??da com esta distribui????o'.  Thanks.  P.S. My english is 'bad', but my portuguese is better ;)> Hi, I'm a brazilian portuguese native speaker. Rainer's suggestions are OK.  I have others, but since I'm translating all /htdocs and /htdocs/manual to portuguese, I think I'll commit them to CVS later (*when* I have commit access to CVS :)  Fabio. Hi, I'm a brazilian portuguese native speaker. Rainer's suggestions are OK.  I have others, but since I'm translating all /htdocs and /htdocs/manual to portuguese, I think I'll commit them to CVS later (*when* I have commit access to CVS :)  Fabio. Finally fixed. Thank you guys.			Andr?? Malo	Andreas Hasenack	Fabio Mengue	Joshua Slive	Ranier Vilela Fonseca
7832	null	CLOSED		Sven Neuhaus	1018270620000	1018804156000		missing colon in example The example states: <-- Error --> but it's supposed to be a proper HTML comment: <!-- Error -->	Created an attachment (id=1500) inserting the missing colon  There are more missing colons and one line with the colon in the wrong spot. Created an attachment (id=1501) fix missing/wrong colons  Thanks!  This will be fixed in the next release of the docs.			Joshua Slive	Sven Neuhaus
7840	null	CLOSED		Andreas Hasenack	1018277160000	1018831647000		apachectl: wrong dir for the httpd binary make install places 'httpd' in $(sbindir), and apachectl expects to find it in $(bindir): --- httpd-2.0.35/support/apachectl.in.orig      2002-04-07 18:11:08.000000000 -0300 +++ httpd-2.0.35/support/apachectl.in   2002-04-07 18:11:23.000000000 -0300 @@ -29,7 +29,7 @@  PIDFILE=@exp_runtimedir@/@progname@.pid  #  # the path to your httpd binary, including options if necessary -HTTPD='@exp_bindir@/@progname@' +HTTPD='@exp_sbindir@/@progname@'  #  # pick up any necessary environment variables  if test -f @exp_bindir@/envvars; then	Fixed in revision 1.12 of support/apachectl.in.  This will be included in the next release of Apache httpd-2.0.  Thanks for using Apache! *** Bug 8413 has been marked as a duplicate of this bug. ***			Justin Erenkrantz
7841	null	CLOSED		Andreas Hasenack	1018277340000	1018573812000		httpd.pid file placement in httpd-std.conf Should the PID file really be placed in the logdir?  --- httpd-2.0.35/docs/conf/httpd-std.conf.in.confvars   2002-04-04 06:15:43.000000000 -0300 +++ httpd-2.0.35/docs/conf/httpd-std.conf.in    2002-04-07 17:54:11.000000000 -0300 @@ -78,7 +78,7 @@  # identification number when it starts.  #  <IfModule !mpm_netware.c> -PidFile @rel_logfiledir@/httpd.pid +PidFile @rel_runtimedir@/httpd.pid  </IfModule>    #	This has been committed to the Apache httpd-2.0 CVS repository and will be included in the next release of Apache httpd-2.0.  docs/conf/httpd-std.conf.in revision 1.2 has this change.  Thanks for using Apache! *** Bug 7798 has been marked as a duplicate of this bug. ***			Cliff Woolley	Justin Erenkrantz
7882	null	CLOSED		David Hill	1018375260000	1078015011000		env LIBS ignored during build The documented method of adding extra libraries to the build process is broken.  Setting LIBS in the envrionment is the normal method of adding extra libraries to the link line. But with 2.0.35, this variable is not used during the build. Adding $(ALL_LIBRARIES) into build/programs.mk corrects the problem.  *** build/program.mk.orig       Tue Apr  9 13:55:09 2002 --- build/program.mk    Tue Apr  9 13:37:52 2002 *************** *** 57,60 ****   PROGRAM_OBJECTS = $(PROGRAM_SOURCES:.c=.lo)      $(PROGRAM_NAME): $(PROGRAM_DEPENDENCIES) $(PROGRAM_OBJECTS) !       $(LINK) $(PROGRAM_LDFLAGS) $(PROGRAM_OBJECTS) $(PROGRAM_LDADD) --- 57,60 ----   PROGRAM_OBJECTS = $(PROGRAM_SOURCES:.c=.lo)      $(PROGRAM_NAME): $(PROGRAM_DEPENDENCIES) $(PROGRAM_OBJECTS) !       $(LINK) $(PROGRAM_LDFLAGS) $(PROGRAM_OBJECTS) $(PROGRAM_LDADD) $(ALL_LIBS)	[This is a mass bug update.] This bug reports a problem in an older version of Apache 2. Could you please update to the most recent version and see if you can reproduce this problem.  If the bug still exists, please update the bug with the latest version number.  If  the bug no longer exists, please close the bug report.  Sorry for this impersonal response, but we get many more bug reports than our volunteers can keep up with. Thanks for using Apache! [This is a mass bug update.] [Resolve-20021102] No response from submitter; assuming issue is resolved. If the problem still exists in the lastest version, please reopen this report and update appropriately. This is still a bug in apache 2.0.43. I've tried the patch included here making  the changes by hand and they appear to solve the problem. Fixed in HEAD; thanks for the report.  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/Makefile.in?r1=1.138&r2=1.139 I see that the fix has been checked into HEAD. But when will this be rolled into an actual release? The buggy Makefile.in is still there as of 2.0.50. This has now been proposed for backport to 2.0.			Joe Orton	Joshua Slive	Kartik Subbarao	Noah Arliss
7930	null	CLOSED		Michael	1018467240000	1019244047000		Minor Bug w/ Apache Monitor in Sys Tray (v. 2.0) When you double click on the System Tray Apache Monitor, it opens up and you  can restart the server no problems, but if you single 'left' click on the icon  in the system tray and then highlight the server and then 'restart'.  The  Monitor program crashes and causes a 'send Microsoft an error report' and then  closes out of the system tray.  The server is not restarted at all.  Not a big bug.. and probably just XP specific (that's what I get for trying it  on something it may not have been intended for ;)  Great work on 2.0 ~!  Love it~!  - Michael	*** Bug 8147 has been marked as a duplicate of this bug. *** Created an attachment (id=1626) Patch.     Patch applied, for the next release (.36).  Thanks David!   *** Bug 8809 has been marked as a duplicate of this bug. *** *** Bug 8888 has been marked as a duplicate of this bug. ***			Cliff Woolley	David Shane Holden	Joshua Slive	Will Rowe
7966	null	CLOSED		Olav Kolbu	1018537680000	1019976451000		Wrong Content-Length when SSI used as DirectoryIndex In some cases, the Content-Length used remains the length of the file on disk, even though the  content of the file is changed by SSIs before transfer to client. This happens only when the file in  question is used as a DirectoryIndex, i.e. http://www.nanvaent.org:81/. If explicitly gotten, i.e.  http://www.nanvaent.org:81/oktest.shtml, it transfers fine (presumably because the server does not  include a Content-Length: header in that case).    The weird part is that _sometimes_ it actually works...    Example:    In httpd.conf:  DirectoryIndex oktest.shtml  AddType text/html .shtml  AddOutputFilter INCLUDES .shtml        File /cgi-bin/oktest.cgi  --- cut here ---  #!/bin/sh  echo Content-Type: text/html  echo  echo TeSt  --- cut here ---    File /oktest.shtml   (Note, 54 bytes long)  --- cut here ---  <html>  <!--#exec cgi='/cgi-bin/oktest.cgi'-->  </html>  --- cut here ---    Some tests with wget, the first one explicitly asking for the file:    strider tmp # wget -O - -S http://www.nanvaent.org:81/oktest.shtml  --16:57:45--  http://www.nanvaent.org:81/oktest.shtml             => "-'  Resolving www.nanvaent.org... done.  Connecting to www.nanvaent.org[194.70.3.222]:81... connected.  HTTP request sent, awaiting response...   1 HTTP/1.1 200 OK   2 Date: Thu, 11 Apr 2002 14:57:45 GMT   3 Server: Apache/2.0.35 (Unix) PHP/4.3.0-dev mod_ssl/2.0.35 OpenSSL/0.9.6a   4 Accept-Ranges: bytes   5 Connection: close   6 Content-Type: text/html; charset=ISO-8859-1        [<=>                                  ] 0             --.--K/s             <html>  TeSt    </html>      [ <=>                                 ] 21            20.51K/s    16:57:45 (20.51 KB/s) - "-' saved [21]      Second test, just asking for the directory:  strider tmp # wget -O - -S http://www.nanvaent.org:81/  --16:59:42--  http://www.nanvaent.org:81/             => "-'  Resolving www.nanvaent.org... done.  Connecting to www.nanvaent.org[194.70.3.222]:81... connected.  HTTP request sent, awaiting response...   1 HTTP/1.1 200 OK   2 Date: Thu, 11 Apr 2002 14:59:42 GMT   3 Server: Apache/2.0.35 (Unix) PHP/4.3.0-dev mod_ssl/2.0.35 OpenSSL/0.9.6a   4 Last-Modified: Thu, 11 Apr 2002 14:40:25 GMT   5 ETag: '364ce-36-65f60840'   6 Accept-Ranges: bytes   7 Content-Length: 54   8 Keep-Alive: timeout=15, max=200   9 Connection: Keep-Alive  10 Content-Type: text/html; charset=ISO-8859-1     0% [                                     ] 0             --.--K/s    ETA --:--<html>  TeSt    </html>  38% [=============>                       ] 21            20.51K/s    ETA 00:00    16:59:57 (20.51 KB/s) - Connection closed at byte 21. Retrying.    etc etc    Note the Content-Length header.	I'm experiencing problems with proxies that is probably related to this bug. The proxy cache is cutting the reply short if / is requested, but I get the full reply if /index.shtml is used. The same bug is under Windows 2000. This is seen on a bunch of different OSes, so change it to be All platforms and All OSes.  An email has been sent to dev@httpd.apache.org asking for people to look at this. There were lots of changes right before 2.0.35 regarding this code, so I think something may have snuck in.  If the filters were ordered right, the C-L should be correct, so this isn't obvious as to where the problem is and I'll let the people who worked on it pre-2.0.35 look at this since they were the last ones in the code. I cannot recreate this problem on Windows (haven't tried elsewhere).  Can  someone send me an httpd.conf (as simple as possible) that I can use to  recreate?  I can recreate this on 35/solaris 2.6 FWIW content-length and etags shouldn't be shown on a SSI page. mod_include ~line 3367    apr_table_unset(f->r->headers_out, 'Content-Length');      /* Always unset the ETag/Last-Modified fields - see RFC2616 - 13.3.4.      * We don't know if we are going to be including a file or executing      * a program which may change the Last-Modified header or make the      * content completely dynamic.  Therefore, we can't support these      * headers.      * Exception: XBitHack full means we *should* set the Last-Modified field.      */     apr_table_unset(f->r->headers_out, 'ETag');      /* Assure the platform supports Group protections */     if ((*conf->xbithack == xbithack_full)         && (r->finfo.valid & APR_FINFO_GPROT)         && (r->finfo.protection & APR_GEXECUTE)) {         ap_update_mtime(r, r->finfo.mtime);         ap_set_last_modified(r);     }     else {         apr_table_unset(f->r->headers_out, 'Last-Modified');     }  I'm thinking AutoIndex is the culprit  sorry about that Konqueror ate my line feeds. I just cut & pasted some some mod-include code from ~3767 showing it unsetting the Etag & Content-length fields I have exactly the same problem. I am using linux redhat. We use 'exec cgi' a lot and have this problem (incomplete  content is returned as a result), right now we are trying  to work-around it specifying 'index.html' at the end of our requests. This problem has been resolved in modules/http/http_request.c revision 1.141. (Gnarly to reproduce!)  This should be included in the forthcoming 2.0.36 or you can try out the latest CVS snapshots.  Thanks for using Apache! *** Bug 8141 has been marked as a duplicate of this bug. ***			Bill Stoddard	Christian Lemke	David Waring	Ian Holsman	Justin Erenkrantz	javier wilson
7969	null	CLOSED		Leon Bottou	1018540440000	1018802780000		File docs/conf/mime.types does not contain image/vnd.djvu Mime type image/vnd.djvu is now official. See http://www.iana.org/assignments/media-types/image/ It would be nice to include it in the mime.types file distributed with apache.  Thanks.  - Leon Bottou  See also: (misfiled bug report ?) http://citadelle.intrinsec.com/mailing/current/HTML/ml_apache-server-bugs/0338.html	This type has now been added in 1.3 and 2.0.  Thanks for using Apache.			Joshua Slive
7990	null	CLOSED		Paul J Murphy	1018566540000	1070520651000		AddDescription fails for directories (mod_autoindex) The AddDescription directive no longer works for directories.  Compare http://www.murph.org/photos/ (Apache 1.3.22) to  http://www.murph.org:81/photos/ (Apache 2.0.35 with my patch from bug #7988).  I will attach the .htaccess for that directory (it's the same directory served  by both servers).	Created an attachment (id=1530) .htaccess from directory which exhibits this bug  This works for me on cvs-head (2.0.36-dev). Make sure that you have your AllowOverride config for the directory set to allow the .htaccess 'IndexOptioons' and 'AddDescription' directives to work. I'm still seeing the problem with 2.0.37-dev pulled from CVS yesterday (built  at Apr 30 2002 08:53:58).  See http://www.murph.org:84/test/ for a better example of the behaviour under  2.0.37-dev. Ports 81, 82, 83 have the same directory available under 1.3.22 (patched), 2.0.35(patched), 2.0.35(unpatched) for easy comparison.  'AllowOverride FileInfo AuthConfig Limit Indexes' is specified in httpd.conf  for the parent directory on all 4 servers. I just tested it with 'AllowOverride FileInfo AuthConfig Limit Indexes' and it works fine for me with 2.0.37-dev as of about noon today.  What system are you running on? Can you post the full container config for the directory in question?  Thanks. www.murph.org is running Solaris 8 4/01, patched with the Mar/28/2002 recommended patch cluster:  \tSunOS salsa 5.8 Generic_108528-14 sun4m sparc SUNW,SPARCstation-5  Built with gcc-2.95.2, as supplied on the Solaris 8 4/01 freeware companion CD.  Here is the config for the parent directory (which is the DocumentRoot):  <Directory '/usr/local/apache2/htdocs'>     Options Indexes IncludesNoExec FollowSymLinks MultiViews     AllowOverride FileInfo AuthConfig Limit Indexes     Order allow,deny     Allow from all </Directory>  Ah. Well I can confirm that it works on Linux. :)  I will have to bow out at this point. Someone with an appropriate Sun box needs to pursue this further. Can someone else with Solaris confirm this? AddDescription works fine for me with 2.0.36 and CVS. Solaris 8/sparc,  same patch cluster.  SunOS prodigy 5.8 Generic_108528-13 sun4u sparc SUNW,Ultra-4   Try adding a slash to the end of the directory names?  AddDescription 'New York City, NY' 'New York/'                                             ^  I can hit the problem easily.  Comparing 1.3 behavior with 2.0.44-dev behavior on Solaris 8:  With 1.3, if I omit a trailing slash from the directory name on AddDescription, the description is applied to the directory, but if I add a trailing slash to the directory name on AddDescription, the description is not applied to the directory.  Apache 2.0 is just the opposite.  ----  With Apache 2.0.44-dev on Linux I see the same results as with Apache  2.0.44-dev on Solaris -- when the directory name specified on AddDescription has a trailing slash, it works; otherwise it doesn't work.   A fix has just been committed to 2.0.44-dev.  Thanks for your report, and thanks for using Apache!  AddDescription is broken for directories again in 2.0.48.  I don't know if this is the root cause, but commenting out the one-line change made since 2.0.47 in mod_autoindex.c (line 1364) fixes this particular problem.  Yep, sorry. The previous fix wasn't 100 percent correct either. And the combination broke it finally ;). It's fixed alrady in 2.1 and waiting for backport. fix for 2.0.48 regression has been merged into stable branch for 2.0.49			Andr?? Malo	Cliff Woolley	Colm	David Shane Holden	Jeff Trawick	Michael Fuhr	Paul J Murphy	Paul J. Reder
7991	null	CLOSED		Paul J Murphy	1018568160000	1067722272000		Enhance ExpiresByType to accept wildcards (mod_expires) It's useful to be able to set the Expires header according to just the major  (but not the minor) MIME type (ie Content-Type: major/minor), eg:      ExpiresByType image/* 'access plus 1 week'  The attached patch adds this behaviour, and has been successfully tested on  Solaris 8/SPARC with recent Sun patches.	Created an attachment (id=1531) Patch for this enhancement  There was change comitted into the 2.1 tree to solve your problem partially. It's proposed for backport. Marking it as fixed so far.			Andr?? Malo	Paul J Murphy
8014	null	CLOSED		sam morris	1018618920000	1050598614000		Apache cannot handle NTFS Junctions (Symlinks) For testing, I have an alias called /C that points to 'C:/Documents and Settings/'. I keep my  profile directory on a separate disk that is mounted under 'C:/Documents and Settings/Sam'.  However, the Sam/ folder does not appear in Apache's directory listing. Additionally, while the  directory listing is being generated, this appears in the error.log:  [Fri Apr 12 14:33:05  2002] [error] [client 127.0.0.1] symlink doesn't point to a file or directory: C:/Documents and  Settings/Sam  Asking for anything under 'http://localhost/C/Documents and  Settings/Sam' manually throws a 403 back to the client, with the same error in the event  log.  If I remove the 'FollowSymLinks' option for the directory then the error message is  instead:  [Fri Apr 12 14:41:29 2002] [error] [client 127.0.0.1] Symbolic link not allowed:  C:/Documents and Settings/Sam  and a 403 is still returned to the browser.	Please don't submit to the bug database and post to the newsgroup at the same time.  You may reopen this report if you don't get a response within a few days on the newsgroup. Reopening, with more information:  Snippet from httpd.conf:    Alias /C 'C:/'    <Directory  'C:/'>       Options Indexes FollowSymLinks MultiViews       AllowOverride None       Order  allow,deny       Allow from all    </Directory>  Requesting  http://localhost/C/Documents%20and%20Settings/ returns a listing of the directory, but  with the expected 'Sam/' entry (C:/Documents and Settings/Sam/ is actually a mount point)  omitted. Instead, '[error] [client 127.0.0.1] symlink doesn't point to a file or directory:  C:/Documents and Settings/Sam' appears in the error log.  Requesting  http://localhost/C/Documents%20and%20Settings/Sam/, or anything inside of it, returns a  403 error and likewise adds '[error] [client 127.0.0.1] symlink doesn't point to a file or  directory: C:/Documents and Settings/Sam' to the error log.  Requesting  http://localhost/C/Documents%20and%20Settings/All%20Users/ or any of the other links  from the directory listing works as it should.  After doing some reading, it appears that what  Apache calls symlinks on Windows are actually NTFS Junctions; most junctions have a target of  a regular pathname (such as 'C:/Target/'), but the mount point junctions Windows uses have a  target in the form of '//?/Volume{90b9a960-b928-11d5-bbf2-806d6172696f}/' (the classid is  the volume's unique identifier).  The error message suggests that Apache is checking the  junction target to see if it is a valid path (which the mount point junction target is not)  and throwing the error. So it seems the problem lies within the code that Apache uses to check the  symlink/juntion target.    This is fixed in the current 2.0.36-dev tree, and will be part of the   next 2.0.36 release we expect to roll out within a week or so.    Thanks for your report, your detailed examples, and for adopting Apache 2.0!   The precise behavior noted in the original bug still occurs in 2.0.44 on UNC  (remote share) paths under Win2K Server or Win2K3RC2:  Alias /nas/junction/dir1/dir2/ '//192.168.0.10/nas/junction/dir1/dir2/' <Directory '//192.168.0.10/nas/junction/dir1/dir2'>     Options Indexes FollowSymLinks     AllowOverride None     Order allow,deny     Allow from all </Directory>  [Thu Mar 27 22:24:03 2003] [error] [client 67.67.67.117]  Forbidden: //192.168.0.10/nas/junction doesn't point to a file or directory  If FollowSymLinks is turned off, then:  [Thu Mar 27 23:24:07 2003] [error] [client 67.67.67.117] Symbolic link not  allowed: //192.168.0.10/nas/junction  Either way, with indexing turned on and using the following mapping, Apache  browses the directory fine, and generates an index, but does not see ANY of  the junctions:  Alias /nas/ '//192.168.0.10/nas/' <Directory '//192.168.0.10/nas'>     Options Indexes FollowSymLinks     AllowOverride None     Order allow,deny     Allow from all </Directory>  It sees regular folders and files just fine.  NFTS can create at least two common types of junctions.  One is the MountVol  target format shown in Sam's bug report, and the other is a path reference as  created with 'linkd.exe' from Win2K Resource Kit.  The above behavior is  observed with BOTH types.    I have rated this as MAJOR because without fixing this, Apache cannot be used  to serve content from servers in a web farm that all work from a NAS server  that mounts many RAID arrays using the 'MountVol' or 'LinkD' method.  While  the LinkD method is uncommon, the MountVol method is offered in default  Windows GUI Drive Management on volume creation, and is a common way to add  new volumes into an existing path structure.      I'm not 100% this fixes the issue mentioned at  http://nagoya.apache.org/bugzilla/show_bug.cgi?id=8014 though I tried to  reproduce the issue as I understood it.  If one of the bug submitters could  test it that would be great.  Bill, if you could verify that this change is  reasonable I would appreciate it, the 'wanted' thing is a little vague to me.  --- filestat.c.orig     Fri Mar  7 14:21:29 2003 +++ filestat.c  Fri Mar 28 07:16:02 2003 @@ -363,7 +363,8 @@          finfo->size = 0x7fffffff;  #endif   -    if (wininfo->dwFileAttributes & FILE_ATTRIBUTE_REPARSE_POINT) { +    if (wanted & APR_FINFO_LINK && +        wininfo->dwFileAttributes & FILE_ATTRIBUTE_REPARSE_POINT) {          finfo->filetype = APR_LNK;      }      else if (wininfo->dwFileAttributes & FILE_ATTRIBUTE_DIRECTORY) {      /kristofer Reopen to get this on the radar. Bill? your turn ;-)    This was fixed in 2.0.45.  Please upgrade, and if the problem persists, please   reopen the bug with the new error log entries and observations.    I stand corrected; that patch wasn't committed.    Now committed as of apr/file_io/win32/filestat.c revision 1.79,   and I expect you will see this in the forthcoming Apache 2.0.46.			Andr?? Malo	Joshua Slive	Kristofer Spinka	Skeuomorph	Will Rowe	sam morris
8045	null	CLOSED		Arthur I.	1018702560000	1024120271000		Apache 2.0.35 compile without mod_autoindex I'm a trying compile light build of apache 2.0.35, without some useless modules. when i disable mod_autoindex, and mod_dir still active.. i set up DirectoryIndex index.htm index.html if directory don't have this files ... when i get url like / -  http://domain.com/ apache response error - 500 ! ...  1.3 version in this case show 404 error ... in error_log i get strange message about handler httpd/unix-directory bla-bla.. how fix it ? ..  if i enable autoindex -> error code is 503 Forbidden  how disable autoindex and get 404 like a 1.3 version ? ..  config: <Directory /var/www/htdocs > Options None AllowOverride All </Directory>	Action httpd/unix-directory /directory-not-allowed  Redirect 403 /directory-not-allowed  might be a gross, dirty hack, but it just might work for the moment.  I suppose the default-handler should be taught to recognize and fail httpd/unix-directory requests with a 404.  My only concern is that this is -not- a 404, that level of the heirarchy -is- found, but can't be processed in any meaningful way.  Implies a 401 or 403.  The processing schema's changed enough that you tickled this oversight. In fact, we are erroring out far more often (even in late 1.3.x builds) due to the possibility of one module being tricked into failure, and having another module pick up the request.  E.g. some folks used multiview matching on index documents, but those could (in some very bizare and tangled circumstances) be evaded, and autoindex was picking up the slack when the admin didn't intend for that to happen.  We now avoid Not Found as a 'catch all' if resources exist, otherwise such potentials will always exist.  Thanks for the report, and let us know about the gross hack! This has been fixed in CVS, and will be available in a later release.  The default_handler wasn't catching cases where all of the previous modules had declined to serve the request. 			Ryan Bloom	Will Rowe
8122	null	CLOSED		Martin Kutschker	1018898820000	1048538311000		SSLMutex option settings not honoured With the SSLMutex option the user could (in 1.3.x) ask for file based or semaphore based locking. Now mod_ssl asks apr for the default mechanism. Which is not a bad thing, but the option values should reflect what is provided.  I suggest using the same options as for the AcceptMutex option or using a backward compatible style:  sem = sysvsem file: = flock | fcntl (whatever is preferred on the platform)	Created an attachment (id=1794) new config behaviour  The patch changes the SSLMutex command and offers these options:  default | yes none | no fcntl flock sysvsem posixsem pthread sem = sysvsem | posixsem file: = fcntl | flock  The meaning of 'yes' changes to 'default', 'sem' will use either Sys V or Posix semaphores (the former are preferred) and file will use either Fcntl or Flock (preferring Fcntl).  The command remains (reasonably) backward compatible and is now in sync with the AcceptMutex command. Created an attachment (id=1801) Remove debug output in ssl_engine_config.c else same as the previous which is btw a proposed fix.  [This is a mass bug update.] This bug reports a problem in an older version of Apache 2. Could you please update to the most recent version and see if you can reproduce this problem.  If the bug still exists, please update the bug with the latest version number.  If  the bug no longer exists, please close the bug report.  Sorry for this impersonal response, but we get many more bug reports than our volunteers can keep up with. Thanks for using Apache! [This is a mass bug update.] [Resolve-20021102] No response from submitter; assuming issue is resolved. If the problem still exists in the lastest version, please reopen this report and update appropriately.    This is a behavior change.  I don't see where we have considered this   patch yet, so reopening the report.  Thanks for keeping up with the stale   reports, Joshua!  S'funny. I didn't even see this (old) 'bug' and had just send email to dev@ proposing the  same sort of thing.  I'm a very big +1 on this. Can you please verify the options available now in the latest source base (HEAD  includes Jim's patch), and close the PR if you think the problem is resolved.  Thanks -Madhu Sounds ok looking at the code.  In ssl_engine_mutex.c it would have been nice to us verbose eror reporting in ssl_mutex_init and friends. See below for the relevant code of my original patch (it did help a lot while tracking bugs):  +    status = apr_global_mutex_create(&mc->pMutex, mc->szMutexFile, mc->nMutexMech, p); +    if (status != APR_SUCCESS) { +        char buf[120]; + +        apr_strerror(status, buf, sizeof(buf)); +        if (mc->szMutexFile) +            ssl_log(s, SSL_LOG_ERROR, +                       'Failed to create global mutex lock using file "%s': %s', +                        mc->szMutexFile, buf); +        else +            ssl_log(s, SSL_LOG_ERROR, +                       'Failed to create global mutex lock: %s', buf);    Ok, the patch is backported to 2.0.45 to honor the full range of SSLMutex   flavors, mirroring the AcceptMutex core directive.  Please look at bug 19182, ssl.conf needs to be updated.			Jim Jagielski	Joshua Slive	Madhusudan Mathihalli	Martin Kutschker	Will Rowe	askme
8170	null	CLOSED		Michael D. Risser	1018976340000	1020460989000		LoadModule lines not modified when libexecdir changed When configured using --enable-layout=RedHat, the httpd.conf file does not get  changed in the LoadModule directives. When using the RedHat layout, modules are  placed in $prefix/lib/apache, the ServerRoot is set to /usr and the LoadModules  directives are set to modules/mod_foo.so. Manually changing the LoadModule  directives to lib/apache/mod_foo.so results in the module(s) being loaded.  If possible the Makefile should be modified to take care of this, or at least it should  be included in the documentation ;-)	I've seen that this confuses many people, and a quick look at Makefile.in shows me that it hasn't been fixed yet. A fix was submitted by Thom May and has been committed to httpd-2.0/Makefile.in revision 1.108.  This will be included in a forthcoming release of Apache 2.0 (but did not make it in time for inclusion into 2.0.36).  Thanks for using Apache!			Joshua Slive	Justin Erenkrantz
8176	null	CLOSED		David Winterbourne	1018994040000	1019499828000		logic error in reclaim_child_processes function called during shutdown This function is called at shutdown to kill off all of the children processes  that were spawned during startup and runtime. The bug is around line 2742 where  ap_select is called. It seems that the intention was to use the select command  as a precision sleep mechanism. As the comment indicates, some time needs to be  allowed for children processes to do their termination stuff. The problem was  that ap_select was returning prematurely as a result of a signal interupt  (errno = EINTR), and therefore was never really sleeping for the expected  amount of time. This didn't allow enough time for my children process to clean  themselves up and resulted in various resource leaks. I changed the line from:   ap_select(0, NULL, NULL, NULL, &tv);   to:   while(ap_select(0, NULL, NULL, NULL, &tv) == -1) {}   And while I am not saying that this code is the best way to do this, it did  work, allowing my children to die a natural death.	null	
8223	null	CLOSED		Anthony Best	1019072160000	1019713251000		mime types code case sensitive. image.JPG gets the mime type text/plain while image.jpg gets image/jpeg.  This was produced with the default config, I've check the mime type file no problems there that I could see.   An example: http://zerospace.org:8080/zs10.JPG http://zerospace.org:8080/zs10.jpg	 This is the correct behavior.  All filename and uri parsing semantics are case sensitive on Unix, except where noted in the documentation.  Hmmm... Are you sure about this Will?  I haven't tried to see how this works in 1.3, but the docs for TypesConfig seem to imply that this is supposed to be case-insensitive.  (They aren't clear, but they use the term 'extension', which we almost always mean to be case-insensitive, and they say 'The extensions are lower-cased.'  I don't know what that is supposed to mean.  Joshua may be right ... if you can reproduce that .JPG worked in 1.3 please reopen this report and we can get the situation corrected. Yes it works in Apache 1.3.22  http://zerospace.org:80/zs10.JPG http://zerospace.org:80/zs10.jpg  Also adding JPG to the mime types does nothing.  Same mime config. Yes, I've confirmed with 1.3 as well.  It makes sense to me that way.  All extension matching should be case-insensitive. This has been resolved in modules/http/mod_mime.c revision 1.82.  This will be included in the forthcoming Apache 2.0.36 release.  Thanks for using Apache! *** Bug 8567 has been marked as a duplicate of this bug. ***			Anthony Best	Joshua Slive	Justin Erenkrantz	Will Rowe
8227	null	CLOSED		Eric Kilfoil	1019080860000	1019601766000		t built properly when using the following configure statement:  ./configure --prefix=/usr --datadir=/var/www'  The document root in the httpd.conf file is set to:  DocumentRoot: '/usr//var/www/htdocs'  Instead of the expected:  DocumentRoot '/var/www/htdocs'	This should be resolved in docs/conf/httpd-std.conf.in revision 1.3.  This fix will be included in the next release of Apache httpd-2.0.  Thanks for using Apache! *** Bug 7979 has been marked as a duplicate of this bug. ***			Cliff Woolley	Justin Erenkrantz
8234	null	CLOSED		Simon Wheeler	1019096820000	1019462952000		AcceptPathInfo ignored AcceptPathInfo set to on or default does not appear to work as expected (at  all) on win32/2k/xp this is on a default win32 binary install with standard  config wherever/ however it is used it is ignored a 404 is generated rather than the  expected lookback in the REQUEST_URI   i.e. somehost.com/this.htm/var1/var2/ results in a 404 rather than this.htm+PATH_INFO	I just tried this on FreeBSD (daedalus to be specific) and I get the same thing. Here is what I did: placed an .htaccess file in my public_html directory containing only AcceptPathInfo On then requested the file http://www.apache.org/~slive/index.html/path_info which gives a 404 even though index.html exisists.  Perhaps I missunderstand this directive entirely, but I thought it should allow the request in that case. This has been fixed for 2.0.36.  Thanks for using Apache!			Cliff Woolley	Joshua Slive
8314	null	CLOSED		Robert La Ferla	1019250780000	1019251714000		MMapFile directive in httpd.conf generates a segfault. MMapFile directive in httpd.conf generates a segmentation fault.  /usr/local/my_apache2/bin/apachectl: line 192: 23669 Segmentation fault       $HTTPD -DSSL /usr/local/my_apache2/bin/apachectl startssl: httpd could not be started	Environment:  Apache 2.0.35 on RH 7.2 (i386)  Created an attachment (id=1640) fix for bug 8314  I was able to quickly reproduce it (need some regression test for this :) ). The patch I just attached gets me past initialization and I'm able to serve the cached file.  Your feedback would be appreciated.  I just now see that Paul Reder committed a fix for this earlier today. His fix is the same as the patch I just posted. 			Jeff Trawick	Robert La Ferla
8357	null	CLOSED		David Barnes	1019445480000	1019600186000		t work Hi, I'm trying to force Apache to use http 1.0 regardless of what the client supports. I've tried various configurations that I confirmed word in Apache 1.3, but I'm still getting http 1.1 when using Apache 2. Here is my http.conf section:  BrowserMatchNoCase 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:0.9.9+) Gecko/20020419' downgrade-1.0 force-response-1.0 BrowserMatchNoCase '.*' nokeepalive downgrade-1.0 force-response-1.0     SetEnvIfNoCase User-Agent '.*ozilla.*' /              downgrade-1.0 force-response-1.0  SetEnv force-no-vary SetEnv downgrade-1.0 SetEnv force-response-1.0  I set Mozilla up to log the HTTP headers and this is what I get: 0[234180]: http request [ 0[234180]:   GET / HTTP/1.1 0[234180]:   Host: algonquin.tzo.com:8080 0[234180]:   User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:0.9.9+) Gecko/20020419 0[234180]:   Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,video/x-mng,image/png,image/jpeg,image/gif;q=0.2,text/css,*/*;q=0.1 0[234180]:   Accept-Language: en-us, en;q=0.50 0[234180]:   Accept-Encoding: gzip, deflate, compress;q=0.9 0[234180]:   Accept-Charset: ISO-8859-1, utf-8;q=0.66, *;q=0.66 0[234180]:   Keep-Alive: 300 0[234180]:   Connection: keep-alive 0[234180]: ] 1948[ff79d8]: http response [ 1948[ff79d8]:   HTTP/1.1 200 OK 1948[ff79d8]:   Date: Mon, 22 Apr 2002 03:11:43 GMT 1948[ff79d8]:   Server: Apache/2.0.35 (Win32) 1948[ff79d8]:   Last-Modified: Mon, 22 Apr 2002 03:00:31 GMT 1948[ff79d8]:   Etag: '0-5-e72f61a1' 1948[ff79d8]:   Accept-Ranges: bytes 1948[ff79d8]:   Content-Length: 5 1948[ff79d8]:   Connection: close 1948[ff79d8]:   Content-Type: text/html; charset=ISO-8859-1 1948[ff79d8]: ]  You can look at my config yourself if you wish: http://algonquin.tzo.com:8080 for a test page and look at how it is set up here: http://algonquin.tzo.com:8080/server-info	Confirmed this also happens on freebsd.  But we are having a hard time figuring out why you need this. Note that the repsponse returned by Apache is doing downgrade-1.0 and force-no-vary correctly: it is using only HTTP/1.0 features.  The actual version number in the HTTP response status line shouldn't matter for any reasonably sensible client.  On the other hand, it is a documented feature, that should work. This is due to a reversed check in http_protocol.c.  A fix has been committed in modules/http/http_protocol.c revision 1.415.  This will be included in the next release of Apache!  Thanks for using Apache!			Joshua Slive	Justin Erenkrantz
8388	null	CLOSED		Ching Wan	1019523720000	1037056228000		Long running CGI script cannot terminated by browser When a CGI script runs for a long time and the user clicks the 'Stop' or 'Back'  button in the browser before it ends, the server fails to terminate the CGI  process on the server, even if the CGI script is frequently writing back  lines.  Here's a sample partial CGI script:  $| = 1; print '<pre>/n': foreach (1 .. 50) {     print 'line $_/n';     sleep (1); }  This script continues to run even if the user has clicked 'Stop' in the browser  5 seconds into the process.  I remember fixing this problem in Apache 1.3 by closing the right process  handle.  But since 1.3 was not able to have unbuffered I/O to write back to the  HTTP server process immediately, the fix was not useful for 1.3 anyway.  Now  that 2.0 seems to be able to have unbuffered IO for CGI output (finally!),  fixing this bug would be extremely helpful, especially in defeating MS.  This  is a killer shortcoming of IIS where a run-away CGI script can never be  terminated except the pre-defined 'cut-off' time for all scripts.	I wonder if this is caused by the same thing as bug 8253 (r->connection->aborted not set)? [This is a mass bug update.] This bug reports a problem in an older version of Apache 2. Could you please update to the most recent version and see if you can reproduce this problem.  If the bug still exists, please update the bug with the latest version number.  If  the bug no longer exists, please close the bug report.  Sorry for this impersonal response, but we get many more bug reports than our volunteers can keep up with. Thanks for using Apache! With some fixes committed this morning to mod_cgi.c and server/protocol.c, the CGI script is normally terminated when using mod_cgi.  There may be some paths in mod_cgi that aren't fixed, and mod_cgid is definitely still broken.  I don't know why this bug is not being considered. I now try to post it as a Linux/Apache 2.0 bug, since it is to be found there too, in case that will draw more interest. I would think it is a major problem that Apache can not run cgi-scripts with keep-alive, and I would like our technical department to be able to upgrade our apache installations (for security fixes etc) without me having to patch it first. I am not sufficiently aware of the purpose of the problematic code to propose a final solution - in my own case, it is quite OK to just throw it out, but I would think it serves some purpose - perhaps to stop faulty cgi-scripts from running endlessly. Perhaps it could be specified in the configuration file whether this action is wanted or not. In general you can't assume that a PR is not being considered if there is no update in the last several days.  As already noted in the PR, it now works with mod_cgi with current code from CVS.  I am still working on getting it working with mod_cgid.  (I have it working in a patch posted to dev@httpd yesterday, but the patch needs  some further work before committing.)  I'm confused about your statement    'Apache can not run cgi-scripts with keep-alive'  What is the connection between keep-alive and this PR?  looks like bo@kase.se complained on the wrong PR by mistake...  ignore the last two updates :) A fix has just been committed to mod_cgid to terminate scripts which the connection drops.  Hopefully it will be in the next stable Apache 2 release (2.0.x).  The mod_cgi fixes will almost definitely be in the next stable Apache 2 release.   			Bengt 	Jeff Trawick	Joshua Slive
8449	null	CLOSED		Masao Takaku	1019631240000	1019761250000		'  	Is 'ctime a typo of 'strftime' in the following text:  http://httpd.apache.org/docs/howto/ssi.html.en#whenwasthisdocumentmodified    For more details on the timefmt format, go to your favorite search site and look for ctime. The syntax is the same.  You are indeed correct.  Thanks for the catch.			Joshua Slive	Masao Takaku
8453	null	CLOSED		Stephan W	1019639100000	1023278473000		apxs uses wrong path-variable for build-dir I am trying to install php 4.2.0 as a DSO-modul for apache 2.0.35. The  configure-script of php fails with  cannot open /usr/local/build/config_vars.mk: No such file or directory at  ./apxs line 248.  I tracked the error down to the apxs script. In line 69:  get_config_vars('$prefix/build/config_vars.mk',/%config_vars);  I am using the GNU layout. In this layout the build-directory is under  '/usr/local/share/apache2/build' and the prefix is '/usr/local/'  If I change that to the right path (/usr/local/share/apache2/build/' it works  and I can compile php. But when i try to make 'make install' I get the  following:  /usr/local/sbin/apxs -i -a -n php4 libphp4.la /usr/local/build/instdso.sh SH_LIBTOOL='/usr/local/build/libtool' libphp4.la  /usr/local/libexec sh: /usr/local/build/instdso.sh: No such file or directory apxs:Error: Command failed with rc=8323072  It seems thap apxs uses in the lines 418, 443 and 474 the wrong path-variable.  I think it should be the variable (or path) '$installbuilddir' from the file  config.layout  in case of '$prefix/build' ??? I do not know how to access that  variable or how I should do it right, because I am not so familiar with the  code-structurof apache.  I configured php with following command:  ./configure --with-tsrm-pthreads --with-mysql=/usr/local  --with-imap-ssl=/usr/local --with-gettext --with-imap=/Source/imap-2001a  --with-gd --with-openssl=/usr/local --with-apxs2=/usr/local/sbin/apxs  and apache 2.0.35 with the following:  ./configure --enable-layout=GNU  --enable-info --with-ssl=/usr/local  --enable-so	After a few tries, I changed all the $prefix/build to  /usr/local/share/apache2/build and compiled and installed php. This time the  installation was ok. The script copied libphp4.so to the right place and  inserted the LoadModuledirective in http.conf.  Now there is another error when I start apache:  Syntax error on line 218 of /usr/local/etc/apache2/httpd.conf: Cannot load /usr/local/libexec/libphp4.so into server:  /usr/local/libexec/libphp4.so: undefined symbol: ssl_onceonlyinit sbin/apachectl start: httpd could not be started   I don't have time left for today but I think this is another problem  (hopefully). I will work on this tomorrow. Maybe there is another point in  somewhere.  *** Bug 8678 has been marked as a duplicate of this bug. *** I think that this was fixed in 2.0.36.  You can try a prelease version here: http://httpd.apache.org/dev/dist/  If that doesn't fix it, please reopen this report and up the version number.  Thanks for using Apache. I'm still seeing this in 2.0.36. In my case, apxs contained    my $prefix         = '/software/stow/apache-2.0.36';  and    get_config_vars('$prefix/build/config_vars.mk',/%config_vars);  when that second line should have been    get_config_vars('$prefix/share/apache/build/config_vars.mk',/%config_vars);  Also, apxs later contained    my $envvars = get_vars('bindir') . '/envvars';  which should have been    my $envvars = get_vars('sbindir') . '/envvars';  Those two changes allowed me to configure and build PHP 4.2.0.  I use a custom layout in config.layout, but it's very similar to the GNU layout; I can send along the details if they'd help. I spoke too soon: There are other instances of $prefix/build in apxs, As the original reporter mentioned, and they should all probably be fixed.  It doesn't look like this is fixed in CVS either (looking via ViewCVS at http://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/apxs.in, which seems to be at version 1.37). I also ran into this, with an Apache build I did on a Debian system from  latest sources. I'm trying to build Subversion, and its configuration script  fails due to this bug. I've fixed support/apxs.in on my system, sort of. I've  just subscribed to the developers list so that I can discuss it there. In the  meantime, if someone's interested in the diffs, send me an email at  dmuller@spookydistance.com. A fix for this was just committed to CVS.  I'm pretty sure that it will be in 2.0.37 (or whatever version comes next).  Thanks for your report, and thanks for using Apache! 			Dan Muller	Jeff Trawick	Josh Smith	Joshua Slive	Stephan W
8462	null	CLOSED		Dipl.-Inform. Kai Hofmann	1019651280000	1020493655000		 missing <!--#elif expr='($SERVER_PORT = 443) && ($p_ssl = 1)' --> produces a 'Unmatched '('' error which is wrong. Under Apache 1.3.x this code runs without any problems.	I agree this looks like a bug.  But which version of 1.3 is this working with?  From  looking at the CVS history, it seems like 2.0's mod_include is almost identical to  1.3.25-dev's as far as parsing the expressions goes.  The parsing code in 2.0 was misplacing the character after the '443'... this was harmless if the character was whitespace, but bad if the character was a parenthesis.  I just committed a change to fix this.			Brian Pane	Cliff Woolley
8464	null	CLOSED		James Tait	1019652120000	1022642978000		mod_rewrite not executing external rewriting engine if args are supplied NOTE: This bug has been reproduced on Solaris 8 as well.  I have the following working config for Apache 1.3.24:  RewriteMap DAAC 'prg:/usr/j2se/bin/java -classpath /usr/apache/libexec/rewrite:/usr/apache/libexec/rewrite/jlog.jar DAAC 550 /var/apache/logs/daac_log' RewriteRule ^/Prot([^/]*)/(.+)     /${DAAC:Prot$1/$2|DENIED} [C] RewriteRule ^/DENIED$              - [F]  The config is simple enough, if the incoming request is for a file within a directory named, for example, /Protected, then the external rewrite engine gets called to perform authorisation (in reality there'd be an auth token or something in the URI).  However, transferring this configuration to 2.0.35 does not have the desired effect -- in fact, the external rewrite engine is never exec'd.  This has been tested with the above command line, a very basic shell script, a Perl script and a natively compiled binary -- none of them ever appear to get called (they should all touch a file in the filesystem when they are run, and do so when run from the command line).  The C program I used is as follows:  #include <stdio.h> #include <sys/time.h>  int main(int argc, char *argv[]) {   char input[1024];   FILE *error_log;   struct timeval tv;   long delay;    if(argc < 2) {     printf('Usage: %s <millisecond delay>/n', argv[0]);     printf('Defaulting to 500ms/n');     delay = 500000;   } else {     delay = (atol(argv[1]) * 1000);   }   if (delay < 0) {     printf('Delay must be a positive integer/n');     return 1;   }    if((error_log = fopen('/tmp/DAAC.log', 'a')) == NULL) {     printf('Unable to open logfile/n');     return 2;   }    while (scanf('%1023s', input)) {     tv.tv_sec = 0;     tv.tv_usec = delay;     fprintf(error_log, '%s/n', input);     fflush(error_log);     select(0, NULL, NULL, NULL, &tv);     printf('%s/n', input);     fflush(stdout);   }   fclose(error_log);   return 0; }	Created an attachment (id=1814) Output of strace -f httpd -X  I've looked into this a bit further with 2.0.36, and also compared to 1.3.24.  In 1.3.24, mod_rewrite execl's a shell process itself in the function rewritemap_program_child(), passing the user-supplied config line as an argument:  execl(SHELL_PATH, SHELL_PATH, '-c', (char *)cmd, NULL);   This works, even if you supply arguments to the program to be run.  In 2.0.36 it leaves the exec to APR:      if (((rc = apr_procattr_create(&procattr, p)) != APR_SUCCESS) ||         ((rc = apr_procattr_io_set(procattr, APR_FULL_BLOCK,                                   APR_FULL_NONBLOCK,                                   APR_FULL_NONBLOCK)) != APR_SUCCESS) ||         ((rc = apr_procattr_dir_set(procattr,                                    ap_make_dirstr_parent(p, progname)))          != APR_SUCCESS) ||         ((rc = apr_procattr_cmdtype_set(procattr, APR_PROGRAM)) != APR_SUCCESS)) {         /* Something bad happened, give up and go away. */     }     else {         procnew = apr_pcalloc(p, sizeof(*procnew));         rc = apr_proc_create(procnew, progname, NULL, NULL, procattr, p);   This works when the program doesn't have arguments to be passed, but fails if there are arguments.  Looking at the apr_proc_create() function:          else if (attr->cmdtype == APR_PROGRAM) {             if (attr->detached) {                 apr_proc_detach(APR_PROC_DETACH_DAEMONIZE);             }              execve(progname, (char * const *)args, (char * const *)env);         }   NERK!  The whole user-supplied string is passed as progname, with args and env empty.  I can get around this by running a shell script that runs my program with arguments, but that's kinda messy.  I'd prefer to see mod_rewrite handle this correctly and pass in the args.  If I get time, I'll settle down and fix this.  If anyone wants to beat me to it.... I committed the revised patch you posted to dev@httpd, with one change, which  was that I had to disable the stat of the program to avoid having to duplicate  the apr_tokenize_to_argv() call.  If the program doesn't exist, it will fail to  startup anyway, so this should still be fine.  Thanks! Okay, so the apr_stat() thing wasn't *quite* that easy... apr_proc_create() does not necessarily return an error if the program specified doesn't exist...  on Unix, it only returns an error if the fork() call itself failed.  Bah.  So I  added another apr_stat() call just after the apr_tokenize_to_argv() call has already happened.  Anyway, consider it fixed.  :)			Cliff Woolley	James Tait
8472	null	CLOSED		Oliver Humpage	1019660520000	1019715423000		 is left blank, apache can hang Really little bug this, but if you load mod_userdir, and then change the  'Userdir' directive (in httpd.conf) from its default of 'public_html' to simply  be blank*, apache *will* start, but as soon as you load something from  http://www.domain.com/~userdir, apache will hang horribly.  * in order to simply let pages be served straight from ~userdir.  I compiled from the FreeBSD port, with mod_suexec.  OK, so just putting 'Userdir' without a folder to map to in httpd.conf is a  silly thing to do, but perhaps it's worth not letting apache start if that's the  case.	No denying that the behavior you describe is a bug, but let me just note for the record that UserDir with no argument is not correct.  What you want is UserDir disabled (Although I'm not sure if that will just pass through ~ requests, or if it will return 'forbiden'.  In the latter case, the only solution is to remove mod_userdir.) Yes, I know just putting 'Userdir' is a stupid thing to do: in fact, you get the  'take pages straight from ~userdir/' effect by never having a 'Userdir' line.  At least, that worked for me...  I just reckoned that if something eaily-spottable in the httpd.conf file could  make apache hang, it should be checked for before loading. Minor bug..... Wouldn't    userdir .  accomplish what you are trying to do?  In any case, Apache should provide more intellegent feedback. Re: 'Userdir .'  Fair point. It does work. In fact, leaving out the Userdir line altogether as I  previously suggested seems to make apache revert to its default of  public_html (hadn't *quite* tested things properly). Thanks for your  suggestion.  Sorry, it's the end of a long, hot day (am in the UK). Brain gone walkies. Leaving it blank doesn't cause a hang here - it doesn't do anything either.  However, so that people don't get any ideas on what this means, I have committed a change that makes UserDir with no arguments be invalid and rejected (with an appropriate message).  This fix is in modules/mappers/mod_userdir.c revision 1.44.  This will be included in the next release of Apache 2.0.  Thanks for using Apache!			Joshua Slive	Justin Erenkrantz	Oliver Humpage	Will Rowe
8482	null	CLOSED		zapp	1019671860000	1055988152000		nph- CGIs and/or server-pushed methodes not working properly i'm using a nph- CGI, which isn't working properly with apache 2.0.35, although  the changelog says, that nph- is working again!  description: after starting the nph- CGI, any browser receives some data (no prob so far) but after a certain (almost everytime the same) amount, the browers stops  getting data. the more strange thing is .. the cgi (cgi-irc) still works! and after quiting that CGI, the browers receives the rest of the data-packets.  so i assume, that the server-pushed method gets a kind of overflow ..	forget to say: that script worked on apache 1.3.19 I am also experiencing this with a nph- cgi.  It seems to be after 64K-128K of  data the remainder is corrupted when sent through to the requesting web  browser.  The data is clean FOR SURE when it is issued by the cgi.  Do you have a sample which exhibits the problem?  How is the data generated?   Slowly over time?  In one burst?  This nph- script works for me (all data  received by browser): #!/bin/sh  echo 'HTTP/1.1 200 OK' echo 'Date: Thu Nov 29 16:22:33 CET 2001' echo 'Server: Apache' echo 'Connection: close' echo 'Content-Type: text/html' echo cat /home/trawick/apacheinst/manual/mod/mod_ssl.html cat /home/trawick/apacheinst/manual/mod/mod_ssl.html  well, i'm not using such a simple one. i'm using cgi-irc  (http://cgiirc.sourceforge.net). it's a chat skript, so the data is generated  slowly over time. anonther point maybe could be the multipart content-type:  #!/usr/bin/perl    print 'HTTP/1.0 200 OK/n';    print 'Cache-Control: no-cache/nExpires: -1/nPragma: no-cache/n';    print 'Content-type: multipart/x-mixed-replace;boundary=BOUNDARY/n/n';  still the same problem in version 2.0.36  still not working in 2.0.39  the problem, that the browsers gets only a certain amount of data, seems to  fixed, but now it looks like the connection isn't a keep-alive one.  as mentioned, the problem apears using the cgi-irc (cgiirc.sourceforge.net). while the browser still can send data to the server (which this cgi is handling  properly), the data which should be sent from the cgi, never reaches the  browser.  it's working on apache 1.3.19 .. but not on apache 2.0.39 if you wish to take a look:  http://www.galgenberg.net/cgi-bin/cgiirc/irc.cgi <-- apache 2.0.39  http://132.187.222.249/cgi-bin/cgiirc/irc.cgi <-- apache 1.3.19 Hi, i'm the author of CGI:IRC - thanks to zapp for pointing me at this bug.  I've now written a test-case that shows this working on apache 1.3 but not  apache 2.  It doesn't seem to be related to nph scripts, just anything sending content  that shouldn't be buffered.  The test makes use of javascript in the stream and for me works fine on apache  1.3 (two installs tested).  Apache 2: http://cgiirc.blitzed.org/teststream.cgi Apache 1.3: http://dgl.cx/test/teststream.cgi (Also nph- scripts at same locations as above to show it affects both nph and  non-nph scripts). Source code: http://cgiirc.sourceforge.net/files/teststream.cgi  Hope this helps. (Note that if the test fails but these values only differ by a second then it's  likely to be a laggy connection). On apache 2 they nearly all appear at the  same time. Also I know CGI:IRC has problems with opera and konqueror so don't  test on those browsers). And sourceforge appear broken for serving scripts so use  http://cgiirc.sourceforge.net/files/teststream.pl.txt and rename it.. Thanks for the recent updates.  Just to avoid wasting anybody's time:  this is an acknowledged problem that multiple developers have been able to reproduce  it is considered high-priority (tracked in STATUS file)  hopefully this will be resolved before long  Originally I said non-nph scripts had problems too, this doesn't seem to be the case and i've now got cgiirc.blitzed.org working on apache 2.0 by not using an nph script.  I think this problem might be related to bug number 8388? As The only thing remaining is the script doesn't always seem to be correctly killed by apache when the connection terminates, on apache 1.3 I'm quite sure it used to send a SIGINT (or similar) to the cgi script when the connection was closed, but apache 2 doesn't appear to be doing that?  We have a CGI script which works fine in 1.3.20 (and on the command line: 'su - nobody -c '/opt/bin/perl /blah/cgi-bin/dpradm page=18.html/&arg1=val1/&arg2=val2'') but never returns all the data to the browser (or telnet port80 session).  This is on Solaris 2.6.  As a result, it looks like our only Apache 2 box is going to roll back to 1.3.26. I believe that Apache 2.0.40 has fixed this bug for me. (only build difference being: --disable-threads). Bug still exists in 2.0.40  Agreed - bug still exists (but occurs less). I dont think this is limited to NPH either. [This is a mass bug update.] This bug reports a problem in an older version of Apache 2. Could you please update to the most recent version and see if you can reproduce this problem.  If the bug still exists, please update the bug with the latest version number.  If  the bug no longer exists, please close the bug report.  Sorry for this impersonal response, but we get many more bug reports than our volunteers can keep up with. Thanks for using Apache! sry guys, but it's still not working in 2.0.43 I haven't had chance to try apache 2 recently, but people are still reporting this and asking about it. Any chance of some sort of update about when it might be fixed?  Zapp, were you using mod_cgi or mod_cgid when you tried with 2.0.43?  2.0.43 has some fixes to help streaming in general (nph or not).  A problem specific to mod_cgid which broke streaming with wasn't fixed  until right after 2.0.43 was released.   hi trawick  LoadModule cgi_module libexec/apache2/mod_cgi.so  we're going to update to the latest CVS version this (maybe tomorrow)  afternoon. keep u informed!  any ideas, when v2.0.43++ will be released? If you were using mod_cgi with 2.0.43, you have all the fixes that are available.  Here is teststream.pl on cvs HEAD with mod_cgid:  --------- Testing streaming of content (with scripting) If most of the tests below succeed then it is likely streaming of content works fine. If they fail then either the webserver, a proxy between you and the webserver or your browser is having problems with streams (and sometimes scripts embedded inside streams). If the difference in any failed tests is only a second then it is more likely that your internet connection to the server is slow.  Test 0: OK Test 1: Failed: 1035460289 != 1035460288 Test 2: Failed: 1035460294 != 1035460293 Test 3: Failed: 1035460299 != 1035460298 Test 4: Failed: 1035460304 != 1035460303 Test 5: Failed: 1035460309 != 1035460308 Less than 4 tests were successful. You probably have a problem with streaming of content (or a slow internet connection) End of test. ------------  Note that the failures were all only 1 second too late.  Here is teststream.pl on cvs HEAD with mod_cgi:  ------ Testing streaming of content (with scripting) If most of the tests below succeed then it is likely streaming of content works fine. If they fail then either the webserver, a proxy between you and the webserver or your browser is having problems with streams (and sometimes scripts embedded inside streams). If the difference in any failed tests is only a second then it is more likely that your internet connection to the server is slow.  Test 0: OK Test 1: OK Test 2: OK Test 3: OK Test 4: OK Test 5: OK 6 out of 6 tests were OK, looks like streaming is working End of test. -----  Should I assume that there is a functional problem with mod_cgid based on this test, or perhaps it is just a bit slower than mod_cgi?  weird..  testing with CGI:IRC v0.5  2.0.43: client receives an exact number of bytes, then nothing for about 10 secs. after  that, CGI:IRC connects to the IRC-Server and the client completely receives the  rest. the connection is now closed. (data can be sent to (irc-)server, but  cannot be received)  2.0.44-dev: (httpd-2.0_20021024101256.tar.gz) client receives exact number of bytes, too. no waiting. CGI:IRC starts  immediately. BUT the client doesn't receive the all the data. the amount of  bytes, received by the client after CGI:IRC has connected to IRC-Server, is  changing from time to time; after a dozen tests, the data hasn't been fully  received one single time. the connection stays alive till termination (by user =) (same as above: data sending, not receiving...)  maybe david can provide some more details, what's going on that could terminate  the data-flow. I've just installed apache 2.0.43 to test with - using mod_cgi and prefork (default ./configure options).   teststream works fine -but- if it is called nph-teststream.cgi all but one of the tests fail (and it's out by much more than a second).  So, the first problem is fixed by renaming it something not beinging with nph- (I don't understand that - I thought the idea was to do less processing on nph- scripts). For CGI:IRC renaming nph-irc.cgi to something like irc-main.cgi and updating config (and removing the 'HTTP/1.0 200 OK' line on non-CVS versions) fixes it.   The other problem briefly mentioned above is still present, no signal is sent to the process to terminate it when the user stops the request, Apache 1.3 does, although I can't find this in any CGI specification, but it's a very useful feature. Thanks for the reminder about calling the script nph-...  Nothing written to the network in that case, so I'll start debugging that.  The nph flavor of teststream.pl works fine for me with this patch.  Wanna try the patch with the more complicated test (irc script)?  Index: server/core.c =================================================================== RCS file: /home/cvs/httpd-2.0/server/core.c,v retrieving revision 1.213 diff -u -r1.213 core.c --- server/core.c       14 Oct 2002 20:08:15 -0000      1.213 +++ server/core.c       24 Oct 2002 17:26:10 -0000 @@ -3653,6 +3653,7 @@      conn_rec *c = f->c;      core_net_rec *net = f->ctx;      core_output_filter_ctx_t *ctx = net->out_ctx; +    apr_read_type_e eblock = APR_NONBLOCK_READ;       if (ctx == NULL) {          ctx = apr_pcalloc(c->pool, sizeof(*ctx)); @@ -3728,7 +3729,16 @@                  const char *str;                  apr_size_t n;  -                rv = apr_bucket_read(e, &str, &n, APR_BLOCK_READ); +                rv = apr_bucket_read(e, &str, &n, eblock); +                if (APR_STATUS_IS_EAGAIN(rv)) { +                    /* send what we have so far since we shouldn't expect more +                     * output for a while...  next time we read, block +                     */ +                    more = apr_brigade_split(b, e); +                    eblock = APR_BLOCK_READ; +                    break; +                } +                eblock = APR_NONBLOCK_READ;                  if (n) {                      if (!fd) {                          if (nvec == MAX_IOVEC_TO_WRITE) {  The last patch posted to this PR has been tested successfully and will be in the next release of Apache.  There is still a concern about the issue described in PR 8388, but the issue of server-pushed output for nph- and non-nph- seems to be resolved.  Apache/2.0.46 (Unix) mod_perl/1.99_09 Perl/v5.6.1 mod_ssl/2.0.46 OpenSSL/0.9.6c Server at valk.ath.cx Port 443  Using https connection it not work... with http it work some helps? Valk: your question would appear to be unrelated to this bug report.  And it doesn't  appear to be a bug report of its own, but rather a user-support question.  Please  email your question to modssl-users@modssl.org.  They will, no doubt, want more  details on your configuration in order to help diagnose your problem. 			Andy Green	Cliff Woolley	David Leadbeater	Jeff Trawick	Joshua Slive	Nic Doye	ValK	zapp
8491	null	CLOSED		Axel Loewe	1019680500000	1037499769000		mistake in the german translation of error docs when authentication fails the caption is 'Authentikation fehlgeschlagen'. it should be  something like 'Authentifizierung' or 'Authentifizierung fehlgeschlagen'. that's not bad,  but i thought it would be good to correct this little mistake because 'Authentikation' isn't a  proper german word ;-)	Babelfish and Google both say Authentication is Authentisierung in German.  I don't know German, but your spelling might be correct.  Authentikation surely isn't correct.  =)  We will wait until a committer who speaks German can review the spelling (we have a bunch, so it shouldn't be much of a delay).  Thanks for using Apache! Let's call this 'documentation', since it is under the 'docs' directory in the source distribution. Thanks. This is fixed and will be included in the next release.			Erik Abele	Joshua Slive	Justin Erenkrantz
8493	null	CLOSED		Jon Ribbens	1019692860000	1074040778000		mod_rewrite does not try index.html like it used to My DOCUMENT_ROOT/.htaccess file looks like this:  RewriteEngine on RewriteBase / RewriteCond %{DOCUMENT_ROOT}/wt/$1.py -f RewriteRule ^(.*)$ /wt/$1.py  Under Apache 1.3, when you try the URL http://www.example.com/ then mod_rewrite  will try running 'index.html' through the rewrite rules. Under Apache 2.0, it  does not, it just tries ''. How do I get the old behaviour?	Is there any danger of this bug report ever being addressed?    Try using rewritelog and rewriteloglevel 9     http://httpd.apache.org/docs-2.0/mod/mod_rewrite.html#rewritelog    to create a snapshot of the rewrite parsing of this request, and then   attach that to this bug.  Only then might we be able to determine what   mod_rewrite is doing (correctly or incorrectly.) Created an attachment (id=3792) RewriteLog file showing problem  OK I have attached a log file showing this, I'm not sure how it helps since it  doesn't really show anything not described in my original report, but here it  is ;-) It showed one -very- interesting thing, an empty URI.  The only way to get an empty URI is a file redirect (as opposed to a uri redirect.)  I'll ponder this and throw you more questions later.  Any 'interesting' (non-standard) modules loaded?  Any interesting things you've done in the corresponding <Location > or <Directory > blocks, or the core config? The configuration was completely standard. I downloaded a brand new copy of  apache 2.0.43 for this test. It was configured and installed with ./configure -- prefix=/tmp --enable-rewrite and the httpd.conf was unchanged from the  distribution except for changing the listen port, adding 'AllowOverride all' so  the .htaccess file would work, and adding the RewriteLog[Level] lines.  The htdocs directory was unchanged from the distribution except for adding a  trivial index.html file, creating a 'wt' directory under the htdocs directory,  creating an empty file 'wt/index.html.py', and creating a '.htaccess' file in  the htdocs directory whose contents were identical to that shown in the  original bug report. I've seen this problem, too, with 2.0.40 (RH Linux 8.0 distribution).  I checked an old copy  of 1.3.26 for comparison.  I made a simple rule for testing: RewriteRule ^index/.html$ rewritten.html  The internal redirects do not appear to be going through mod_rewrite.  See attachment  for a comparison of the rewrite_log between 2.0.40 and 1.3.26 Created an attachment (id=4024) rewrite_log comparison between 1.3.26 and 2.0.40  I also ran in to this problem when migrating from 1.3.27 to 2.0.40-11 (Red Hat 8 RPM). When ever / is requested (ie: http://www/example.com/ or http://www.example.com/foobar/) mod_rewrite doesn't resolve it to a DirectoryIndex file. This happens with REQUEST_FILENAME as well as SCRIPT_FILENAME.  RewriteEngine On  RewriteCond %{REQUEST_FILENAME} -f RewriteRule /* /cgi-bin/script.cgi [T=application/x-httpd-cgi,L] Created an attachment (id=4708) rewrite_log file illustrating the problem.  > RewriteEngine On  > RewriteCond %{REQUEST_FILENAME} -f > RewriteRule /* /cgi-bin/script.cgi [T=application/x-httpd-cgi,L]  This cannot work. /* matches only slashes. You probably want something like /.*  The other problem (DirectoryIndex doesn't apply): IMHO, This is not a mod_rewrite bug. It seems, that we have more and more issues, comin' up with the new 2.0 internal_fast_redirect stuff, used, for example, by mod_dir. That means especially that there is no longer a real internal redirect from / to /index.html, so it cannot apply.  Jon, you may try RewriteCond %{LA-U:REQUEST_FILENAME} -f ...  Bug 13211 suffers from the same function (fast_redirect).  Either we have to document it, or we should change it back to a normal internal redirect (or spend some time in reworking and rethinking that fast_redirect function). Opinions? What does internal_fast_redirect exactly do/mean (since it is not documented, I  have to ask).  My personal opinion is that the rewrite-stuff should be better documented. I  use Apache (2) for quite a while now, but I simply cannot get certain rewrite- rules to work. Not because they aren't correct, but I always have problems  getting mod_rewrite to work at the right time (in comparison to other  directives). But I'm not sure if this related? the fast internal redirect doesn't do a real internal redirect (which would repeat most of the request handling for the new url) instead of only merging the data from a previous subrequest with the current request data at the point of calling. mod_dir uses that for redirecting / to /index.html (or whatever).  The relation to this bug is: in 1.3 mod_dir causes an internal redirect, which processes all the api phases again, so mod_rewrite gets a chance to match the new stuff. In 2.0 there's no redirect, so no chance for mod_rewrite (simple, eh? ;-)  Your rewrite problems... perhaps you should look in the bug database for similar bugs or create a new entry? I was wondering if there was any update for this bug report? I've been watching the version changelog and the status of this page, but haven't seen anything.  Thanks much! Please try the LA-U flag as already suggested.  I'm changing the component to docs, since the new behaviour simply needs to be documented. I wish I could Andr??, but LA-F doesn't work and LA-U returns strange results. I'm using Red Hat's build (httpd-2.0.40-11.3) so I don't know off hand if this would be an issue with the virgin distribution or not.  Is this really a 'feature' and not a bug in 2.x? Created an attachment (id=6393) rewrite_log file for LA-F/LA-U.  Boomer, you are absolutely right. I was convinced it worked for me sometime, but there was mod_negotiation involved...  However, mod_rewrite has a bug, that LA-U in directory context doesn't work. Just fixed it in HEAD (and proposed for backporting to the stable trees).  After fixing it, %{LA-U:REQUEST_URI) results in the actual delivered URI (e.g. /index.html) and %{LA-U:REQUEST_FILENAME} in the resulting /path/to/filename.  If you want to test it, the patch is here (the line numbers will differ for the 2.0 branch, but that shouldn't be a problem): <http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/mappers/mod_rewrite.c.diff?r1=1.150&r2=1.151>.  (leaving in documentation category, because it's still new behaviour) In 2.1 it's fixed, since rewrite rules work also in subrequests there.  Unfortunately it's not likely to be backported, because it may lead to unexpected results in existing configurations.			Andr?? Malo	Derek Chee	Jon Ribbens	No Spam	Sander Holthaus	Will Rowe
8544	null	CLOSED		Carlo Marcelo Arenas Belon	1019807880000	1020288016000		ab is not reporting the right mean time on the load tests From 1.3 ab, the code has been changed to have a better granularity and the  time reported is on uS with the APR constant APR_USEC_PER_SEC used to get the  real elapsed time on seconds.  sadly ab reports on 'ms' and therefore the printed number on seconds doesn't  match the real time measured.  the easiest solution is to multiply the expression used times 1000 on  both 'Time per request' printings	Created an attachment (id=1713) an explicative diff of the solution  Created an attachment (id=1720) a context diff patch (finally)  A fix has been committed to correct this which will be included in a future release. Please see revision 1.100 of the file ab.c. Thank you for your submission.			Carlo Marcelo Arenas Belon	Paul J. Reder
8569	null	CLOSED		Joshua Slive	1019849760000	1020350088000		t match against the query string The documentation should be much more specific about what Location matches against.  People are often confused because they try to match against something in the query string.	Done.			Joshua Slive
8625	null	CLOSED		Jonathan Layes	1020094800000	1046482330000		ProxyPassReverse uses ServerName rather than requested host in ServerAliases Not sure if this is a bug or a feature but, from my perspective, it is a bug....  When mod_proxy rewrites the header of a redirect, it uses the defined ServerName to accomplish this.  IMHO, this behaviour is incorrect if there are one or more ServerAliases and the request comes in via one of those aliases.  The proper behaviour, I believe, would be to have mod_proxy remember the Host: line for the original request and use that hostname (rather than ServerName) to rewrite the redirect.    So as not to break the current behaviour, perhaps an option could be added to selectively enable this correct behaviour?	Have you checked the effect of the usecanonicalname directive on this behavior?  'UseCanonicalName off' in the VirtualHost did give the expected behaviour.  Perhaps a note should go in the mod_proxy documentation to refer to the UseCanonicalName directive?  Thanks for pointing out the oversight. Accept this as a documentation bug. Reopen to assign. added to the docs.			Andr?? Malo	Jonathan Layes	Will Rowe
8643	null	CLOSED		Nelson Arzola	1020158100000	1020176573000		Online docs have incorrect link In the online manual, on this page:   http://httpd.apache.org/docs-2.0/server- wide.html  Clicking on the link for 'CoreDumpDirectory', under the 'File Locations'  section takes you to a page that has no informaiton about 'CoreDumpDirectory'.	The links are now fixed on httpd.apache.org and in the library, so a future release of Apache will have the fixes.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
8696	null	CLOSED		Laurent Marcoux	1020261300000	1020349781000		Links to oreilly dead Document tutorials links to O'Reilly Network Apache DevCenter (2) are dead.	Thanks.  I've brought the page up-to-date with the 1.3 version.  Of course, these are all 1.3 tutorials anyway.  Thanks for using Apache!			Joshua Slive
8726	null	CLOSED		Jerry Baker	1020313260000	1021503607000		s to any utility are Incompatible With Apache Build The Cygwin installation installs awk.exe, but it is not a real executable, but  rather a symlink pointing to gawk.exe. Since there aren't symlinks on Windows,  all references to awk by the Apache build script fail. Changing the Cygwin  gawk.exe to awk.exe seems to fix things.  Not sure how this could be addressed, but it should be mentioned in release  notes or something.	   One final observation; you can always use NTFS 5.0 junctions (in XP)   [which ARE real symlinks] or NTFS hard links in place of cygwin's    inventive but back-asswards faux symlinks.    Jerry, I believe you know how to author a patch ... feel free to offer   up a patch to win_compiling.html, and submit it to docs@httpd.apache.org   ... but it is good to have the citation in the bug database :-) As far as I know, junctions are only for directories. You can make a junction so  that C:/directory-a is a 'junction' to C:/directory-b. I do not believe you can  do it with individual files.  I sure would like to author a patch. No problem. Very busy with some summer  classes. Please ping me if you haven't heard back in a while.    Thanks for the offer Jerry... reopening as a doc bug. Adding patch here in addition to sending to docs@httpd.apache.org Created an attachment (id=1875) Patch for win_compiling.html to add note about Cygwin's symlinked awk.exe  Reopening to really close    Doc committed, thanks Jerry!			Jerry Baker	Will Rowe
8740	null	CLOSED		Jiri Novak	1020347220000	1021440801000		t send lower characters then 20h ASCII? WriteClient can't send lower characters then 20h ASCII?  This code return nothing:  CString header('Content-type: text/plain/r/n'); DWORD dwSize = header.GetLength(); pCtxt->ServerSupportFunction( HSE_REQ_SEND_RESPONSE_HEADER, NULL, &dwSize, (unsigned long *)(LPCTSTR)header );  DWORD len = 3; pCtxt->WriteClient( '/x00zz', &len, 0 );    If you send 32 and more characters >= 20h before sending character < 20h you can see result:  CString header('Content-type: text/plain/r/n'); DWORD dwSize = header.GetLength(); pCtxt->ServerSupportFunction( HSE_REQ_SEND_RESPONSE_HEADER, NULL, &dwSize, (unsigned long *)(LPCTSTR)header );  #define ALEN 32 char acka[ALEN]; memset( acka, 'A', ALEN ); len = ALEN; pCtxt->WriteClient( acka, &len, 0 ); DWORD len = 3; pCtxt->WriteClient( '/x00zz', &len, 0 );   Send me reply, where in code is error please and when can I download corrected  version from your web site. Thank you Jiri Novak	But it's no rule 32 characters before . If I use real binary data, I need for  example 200 bytes before, 500 bytes before and so on... otherwise there is NULL  result...    Nope, any characters are acceptable.    It seems we didn't flush for the response correctly, therefore you had some   very bogus results.  So could any ISAPI script.    In the next couple of days, I will make available a test build under 2.0.36   that should work under that version.  Am attaching you to another incident   so I can send that announce to all at the same time.    Presuming this solves all your problems, you will see this fix will appear   in release 2.0.37. 			Jiri Novak	Will Rowe
8789	null	CLOSED		Tim	1020451020000	1033170176000		SuExec Log File does not get created by default when suexec is enabled The documentation at the url http://httpd.apache.org/docs-2.0/suexec.html  mentions  '--suexec-logfile=FILE  This defines the filename to which all suEXEC transactions and errors are  logged (useful for auditing and debugging purposes). By default the logfile is  named 'suexec_log' and located in your standard logfile directory (-- logfiledir).'  When i ran:  ./configure --prefix=/usr/local/apache2 --enable-auth-anon --enable-auth-dbm -- enable-so --enable-speling --enable-dav --enable-dav-fs --enable-suexec --with- suexec-caller=99 --with-suexec-docroot=/domains --with-suexec-uidmin=500 --with- suexec-gidmin=500 --enable-static-support --enable-static-htpasswd --enable- static-htdigest --enable-static-rotatelogs --enable-static-logresolve --enable- static-htdbm --enable-static-ab --enable-static-checkgid --enable-ssl --with- ssl=../openssl-0.9.6c  the suexec logfile didnot get created by default. Each time suexec wants to log  an error it gives another error in the log files as below: [Fri May 03 23:54:53 2002] [error] [client 192.168.1.38] failed to open log file [Fri May 03 23:54:53 2002] [error] [client 192.168.1.38] fopen: No such file or  directory	The default logfile for suexec was in /usr/local/apache, instead of /usr/local/apache2.  I have committed a fix for that.			Ryan Bloom
8841	null	CLOSED		Anthony Schorer	1020720120000	1020730833000		ScriptAlias and mod_userdir conflict Setup: mod_userdir enabled userdir set to public_html (/home/user/public_html) cgi directory scriptaliased (see below) (/home/user/cgi)  Description: Prior to upgrading to 2.0.* (2.0.35 was my first step), ScriptAlias didn't have a problem with the use of ~'s in the alias'd path (ex: ScriptAlias /~user/cgi/ /home/user/cgi) In 2.0.35/36 though, apache's error log turns up this:  [error] [client 129.74.157.255] File does not exist: /home/user/public_html/cgi  For some reason, it thinks the cgi dir should be under the document root for  that user.  If I remove the ~, all functions as I would expect. (Configuration file available at http://warpedlight.com/~aschorer/httpd.conf)  Independently confirmed by at least 1 other user.	Created an attachment (id=1796) Proposed patch: Reverse the ordering of the mod_userdir and mod_alias hooks  If you can, please give the attached patch a go and see if it fixes your problem. After applying the patch and recompiling...  -=# ./apachectl start httpd: apr_hooks.c:162: tsort: Assertion "0' failed. ./apachectl: line 192:   719 Aborted                 (core dumped) $HTTPD ./apachectl start: httpd could not be started  If you want the core, let me know :o Created an attachment (id=1797) Second part of patch  Sorry, my fault.  You also need to patch mod_userdir as I do in the second patch. Give that a shot. Appears to work 'correctly' now. Thanks :-) OK.  Thanks very much for the report.  This will be fixed in 2.0.37.			Anthony Schorer	Joshua Slive
8853	null	CLOSED		Jason	1020759840000	1027275029000		mod_vhost_alias and Aliases Using any of the mod_vhost_alias directives causes the Alias(Match) and ScriptAlias(Match)  directives to cease functioning.  The moment I uncomment a line containing a  VirtualDocumentRoot /www/%0, my server-wide ScriptAliases stop working, as well as All errors  saying that a 404 was encountered trying to handle the error, since the Alias to /error stops  working. (And so does the /icons alias).  Not sure if this is an issue with mod_vhost_alias or  mod_alias, but I'm trying it here.	Created an attachment (id=1803) Make mod_alias run before mod_vhost_alias  It looks like the ordering of the translate_name hook has not been very well thought-out.  Could you please try the attached patch and see if it fixes your problem. Created an attachment (id=1804) corrected patch  Woops.  Sorry, but I'm not in a position to compile apache at the moment, so I can't test these.  The second patch should be better. Patching with stock 2.0.36 did not work for me. Tried editing the changes in manually and  resulted in an assertion error in apr_hooks.c. Should I try it with a CVS snapshot or? Yes, you should try it with the CVS snapshot.  There was another ordering change with respect to mod_alias that went in a couple days ago, and without that change, you will get conflicts.  Sorry I didn't think of this before.  So you will either need to work from CVS and apply this patch, or work from 2.0.36 and apply the patches from bug 8841 before this one.  Let us know the results. Any luck with this patch?  It looks right to me, but I'm not going to commit it because I don't have a mod_vhost_alias setup to test it. *** Bug 10503 has been marked as a duplicate of this bug. *** An updated version of this patch was committed.			Jason	Joshua Slive
8869	null	CLOSED		Andreas Sundstr	1020778920000	1021310290000		apxs: wrong dir for inclusion of envvars make install places the envvars and envvars-std files in $(sbindir) but apxs tries to find it in $(bindir)  --- httpd-2.0.36/support/apxs.in~       Mon Apr 29 20:09:02 2002 +++ httpd-2.0.36/support/apxs.in        Tue May  7 15:33:42 2002 @@ -223,7 +223,7 @@  my $httpd = get_vars('sbindir') . '/' . get_vars('progname');  $httpd = eval qq('$httpd');  $httpd = eval qq('$httpd'); -my $envvars = get_vars('bindir') . '/envvars'; +my $envvars = get_vars('sbindir') . '/envvars';  $envvars = eval qq('$envvars');  $envvars = eval qq('$envvars');	Your change will be in Apache 2.0.37.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
8927	null	CLOSED		Brian Tkatch	1020903960000	1020965900000		 as per the documentation When the DefaultType directive is not in the httpd.conf file, pages are sent with the Content-Type header set to text/plain. The documentation <URL:http://httpd.apache.org/docs/mod/core#defaulttype> says 'Default: DefaultType text/html'.	Thanks for the report!  This is now fixed.			Joshua Slive
8934	null	CLOSED		Sebastian Hantsch	1020943740000	1021423466000		GetServerVariable returns wrong lpdwSizeofBuffer According to the MSDN at  http://msdn.microsoft.com/library/default.asp?url=/library/en-us/iisref/html/psdk/asp/isre504l.asp  the parameter 'lpdwSizeofBuffer' should be set to 'the size of bytes transferred into the buffer, including the null-terminating byte' on successful completion.  Currently in mod_isapi.c, line 629, the null-terminating byte is not taken into account, so the value of 'lpdwSizeofBuffer' is too small by one.  This breaks ISAPI-dlls based on Borland Delphi 6.0, as these dlls use the value of 'lpdwSizeofBuffer' to determinate the length of the server variable.  Suggested fix: Replace line 629:  *lpdwSizeofBuffer = len; with *lpdwSizeofBuffer = len + 1;	   Fixed in CVS this morning... the fix will be available in .37 and an   interim test mod_isapi.so I will be making available this week that   will be build for .36.  Will let you know when that test version is   available [we have refactored the code significantly, and will want   to get it in as many hands as possible.    There were a few more instances where we needed to count the trailing   NULL, but I think I caught them all (and credited you with the patch   in CHANGES.)    Thanks for the report and analysis!     Adding Jira for notification of test release this week.     There is a test module of mod_isapi.c cvs version 1.73 now available from      http://www.apache.org/~wrowe/mod_isapi.so    Please feel free to test (within Apache 2.0.36) and report back with   any success or hassles you encounter.  The source code is available;      http://cvs.apache.org/viewcvs.cgi/*checkout*/httpd-2.0/modules/arch/win32/mod_isapi.c?rev=1.73     http://cvs.apache.org/viewcvs.cgi/*checkout*/httpd-2.0/modules/arch/win32/mod_isapi.h?rev=1.1    All ISAPI directives are now per-directory, except for ISAPICacheFile (which   remains global.)  A new  ISAPIFakeAsync on  will allow modules to believe that   mod_isapi is an async server, and respond to the async requests and invoke   the module's completion callbacks.    Unless problems are identified, this is the code expected to be released   with Apache 2.0.37.    TIA  *** Bug 9421 has been marked as a duplicate of this bug. ***			Will Rowe
8938	null	CLOSED		Alex BATKO	1020958320000	1020961049000		ScriptSock missing from index The ScriptSock directive (of mod_cgid) is missing from the Directive Index, whereas the mod_cgi directives are listed.  Please add ScriptSock and the corresponding link to mod_cgid.	This was actually an error in the XSLT we use to auto-generate the directive index.  Thanks for pointing out the problem!			Joshua Slive
8943	null	CLOSED		Alex BATKO	1020967020000	1020967486000		' Original text: These elements allow conditional text, the inclusion other files or programs, as well as  Please add 'of' following 'inclusion': These elements allow conditional text, the inclusion of other files or programs, as well as  ps. i appologize if this is my second submission of this typo - i felt that something went wrong with my first attempt (plus i didn't get an email confirmation from bugzilla for over 10 minutes).	Thanks.  Fixed.  (And I only got it once.)			Joshua Slive
8944	null	CLOSED		Alex BATKO	1020969480000	1020970452000		typo: unintended spacing Please remove the extra spaces (or tabs) from the front of the #if line, so that the block lines up nicely.  Original text: The structure of this conditional construct is:          <!--#if expr='test_condition' -->     <!--#elif expr='test_condition' -->     <!--#else -->     <!--#endif -->	Hmmm... Me thinks your browser is a little wacky.  This looks fine to me.  By the way, if you are interested in helping out in a more efficient way, you might like to visit the documentation project: http://httpd.apache.org/docs-project/ nope, it really did have extra whitespace.  :)  fix committed.  thanks!  Ahh, sorry, I was looking at an almost identical example in mod_include. I should read more carefully.			Cliff Woolley	Joshua Slive
9003	null	CLOSED		Alex BATKO	1021164300000	1021273074000		typo: bracket It seems that <VirtualHost< should have been <VirtualHost>.  Original text: Special note: Use of this directive in <VirtualHost< is no longer supported	This has been fixed in CVS and will be included in the next release!  Thanks for using Apache!			Justin Erenkrantz
9011	null	CLOSED		Erich Prchal	1021213920000	1062790856000		t exit With Worker-MPM on Solaris (both 2.6 and 8) I get error messages '[crit] the listener thread didn't exit' every few minutes.  The system was under heavy load (10-18 child processes) with (intentionally) non-keepalive requests.  By adding traces I found that the dummy_signal_handler in worker.c  does get called 10 times for the correct thread,  but the function apr_proc_mutex_lock never returns.  I think this behaviour does not deserve a LOG_CRIT  which might unneccessarily alert the administrator as it can occur quite normally:  According to the man page for pthread_mutex_lock:  'If a signal is delivered to a thread waiting  for  a  mutex,  upon return from the signal handler the thread resumes wait-  ing for the mutex as if it was not interrupted.'  And for other lock types which do not behave the same way proc_mutex.c simulates this behaviour by making a loop over EINTR.  By the way, should proc_mutex.c set PTHREAD_MUTEX_RECURSIVE if such is defined on the system? The man page says the behaviour is undefined for default.	Note: this PR is very similar though not identical to PR9169.   [This is a mass bug update.] This bug reports a problem in an older version of Apache 2. Could you please update to the most recent version and see if you can reproduce this problem.  If the bug still exists, please update the bug with the latest version number.  If  the bug no longer exists, please close the bug report.  Sorry for this impersonal response, but we get many more bug reports than our volunteers can keep up with. Thanks for using Apache! The problem did no longer occur since 2.0.39 This bug still occurs to me with version 2.0.44 at this configuration:  StartServers        64 ServerLimit         96 MinSpareThreads 256 MaxSpareThreads 512 ThreadsPerChild 24 MaxRequestsPerChild  0  I don't have to get any load into the system. Just after start apache with this  configuration this message starts do fill the log file.  Also having this problem on 2xP3-1.4GHz + Linux 2.4.20 + httpd 2.0.45 + openssl 0.9.7b + PHP 4.3.1, using  MPM worker (threadpool).   Definitely vote for dropping this from ""crit''; system still seems to  operate fine, except for filling up my error log.     Configuration:      ServerLimit         200   StartServers        1   MaxClients          250   MinSpareThreads     5   MaxSpareThreads     10   ThreadsPerChild     5   MaxRequestsPerChild 0            Sorry if this is bothersome, but looking at the code, I'm not sure I understand this properly, maybe  this is a bug?  I'm probably misunderstanding this..  pthread_kill() and kill() both return 0 on  success; shouldn't this loop be in a success condition if it successfully kills the thread?  Isn't  that the point of the loop?  If I interpreted it correctly, then this loop will always trigger the  error unless pthread_kill() or kill() fails, no?                iter = 0;           while (iter < 10 &&   #ifdef HAVE_PTHREAD_KILL                  pthread_kill(*listener_os_thread, 0)   #else                  kill(ap_my_pid, 0)   #endif                  == 0) {               /* listener not dead yet */               apr_sleep(apr_time_make(0, 500000));               wakeup_listener();               ++iter;           }      \t if (iter >= 10) {              ap_log_error(APLOG_MARK, APLOG_CRIT, 0, ap_server_conf,                           'the listener thread didn't exit');          }         passing 0 as the signal to kill() or pthread_kill() is just a check to see if the process or thread is still alive  the purpose of that loop is to keep telling the listener thread to go away until either it goes away or we give up trying Severity of the message has been changed to debug in 2.1-dev, and change will be proposed for merge into 2.0.48-dev.  The message is of interest to developers only, and while it does represent a glitch (listener thread not terminating in the cleanest possible way), there  is no known impact of the glitch.  Sounds great, thanks!			Cliff Woolley	Eider Oliveira	Erich Prchal	Jeff Trawick	Jordan Ritter	Joshua Slive
9012	null	CLOSED		Peter Hicks	1021216020000	1045666710000		 tags when placing LoadModule lines When the last LoadModule entry in httpd.conf is enclosed in an <IfDefined> tag, apxs will blindly insert another LoadModule directly after, which is bad behavoir.  Better behaviour would be for apxs to parse httpd.conf and only insert LoadModule and AddModule lines after any <IfDefined> tags.	It's fixed in 2.1 and proposed for backport. apxs checks the last LoadModule line on being within section(s) and puts the new line after that section(s) then. (AddModule will be treated similar in 1.3).  Thanks for your report and thanks for using Apache! *** Bug 8712 has been marked as a duplicate of this bug. *** This bug will be fixed in 1.3.28 and 2.0.45.			Andr?? Malo
9014	null	CLOSED		ASADA Kazuhisa	1021217520000	1023297317000		mod_deflate generates corrupted result at large data. mod_deflate module generates corrupted result with large data (over 200kbytes). deflate_out_filter deflate input buckets into output bucket, but output buffer information reset every input bucket, it means waste partial deflated data at process next input bucket. Output buffer must initialize before BRIGADE_FOREACH loop.  --- mod_deflate.c.org   Tue May  7 09:35:16 2002 +++ mod_deflate.c       Mon May 13 00:32:18 2002 @@ -328,4 +328,8 @@      }   +    /* initialize deflate output buffer */ +    ctx->stream.next_out = ctx->buffer; +    ctx->stream.avail_out = c->bufferSize; +      APR_BRIGADE_FOREACH(e, bb) {          const char *data; @@ -437,6 +441,4 @@                                                        * trust zlib */          ctx->stream.avail_in = len; -        ctx->stream.next_out = ctx->buffer; -        ctx->stream.avail_out = c->bufferSize;            while (ctx->stream.avail_in != 0) {	Woo-hoo!  I was tracking this down last week, but I had to leave for WWDC and didn't follow up.  Your patch is right and has been committed in revision 1.4 of modules/filters/mod_deflate.c.  It will be included in the next release of Apache 2.0!  Thanks for using Apache (and keep the patches coming)! I am still seeing these symptoms in the httpd-2.0_20020530221254.tar.gz snapshot. The difference may be that for the files having problems the output is generated by a cgi script and then fed through INCLUDES and then DEFLATE. 50KB files work OK. 450KB files fail to be uncompressed using lynx 2.5-dev, Netscape 4.08 and IE 5.?. I am running this under linux 2.2.16 (Redhat) on a Athlon Tbird. I tested things a bit more and found that if I am just using the DEFLATE filter things work OK. But when I use DEFLATE after INCLUDES then they don't. I also tried just INCLUDES and the only differences were the expected ones. Is there any chance that you can provide a sample CGI script that  generates the right include tags to causes mod_include to create  a sequence of data that mod_deflate can't handle?  Thanks! A CGI-BIN script isn't needed to duplicate the problem. A sample broken link is at: http://wolff.to/area/test.html Source to the actual files is available at: http://wolff.to/area/test.txt http://wolff.to/area/sig.txt http://wolff.to/area/links.txt The .txt files are sym links to the .html files. INCLUDES and DEFLATE filters are run on .html files, but not on .txt files. Justin Erenkrantz committed a patch to mod_deflate earlier today that might  fix this problem.  Try out the CVS version of mod_deflate.c (rev 1.16) and see  if that fixes your problem.    Thanks!  I tried 1.16 in a CVS snapshot from a few days ago and the problem appears to be fixed. I will be removing the test files shortly. Thanks for fixing this.			Bruno Wolff III	Cliff Woolley	Jeff Trawick	Justin Erenkrantz
9061	null	CLOSED		Max Dittrich	1021364400000	1021384363000		' The file 'config.layout' notes to use the configure-switch '--with-layout' to select an installation layout. Instead this has to be done by using '--enable-layout'.	This is now fixed in CVS.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
9065	null	CLOSED		Sergi	1021375020000	1021930343000		 welcome page in Catalan language Hi,  The file 'docroot/index.html.ca' has some errors (mostly missing letters and  missing tildes). Besides, it was a translation of an old welcome page which did  not match the English one in the 2.0.36 release. I translated myself the English 2.0.36 into Catalan just in case you find it  worth enough to update future Apache releases. In case you're interested, you  can download the Catalan page from:  http://www.geocities.com/chavalpk/index-ca.zip  Greetings,   - Sergi -	Could you please do us a favor and find another fluent Catalan speaker to review your work and post here confirming that your new translation is accurate.  We are trying to avoid the crappy translations we have had in the past.  Thanks! Hi,  I contacted a professional translator to get my Catalan page reviewed and she  did some rework on it... but now it looks great and should be 100% accurate :)  You can download it from http://www.geocities.com/chavalpk/index-html-ca.zip  Greetings,   - Sergi -   OK.  I'll take your word for it and commit this.  In general, though, we prefer to have an independent person actually post here to confirm.  Thanks for your contribution!			Joshua Slive	Sergi
9076	null	CLOSED		Michael King	1021396500000	1043980139000		 without AuthType set causes 500 Server Version: Apache/1.3.24 (Unix) Server Built: May 1 2002 10:07:09 API Version: 19990320:11 Run Mode: standalone  From the httpd.conf:   <IfModule mod_info.c>   <Location /server-info>       SetHandler server-info       Order deny,allow       Deny from all       Allow from 127 10 192.168       Satisfy any   </Location>   </IfModule>  This is a LOCATION directive, which processes after the .htaccess directives  have occurred. For my docroot directory, I've got an 'AllowOverride All' in  place. However, in that root directory, I do *not* have an .htaccess file.  I get a Server Error 500, and it generates an access_log entry, but no  error_log entry.  access_log: 10.X.X.X - - [14/May/2002:11:40:20 -0500] 'GET /server-info HTTP/1.1' 500 630  If I remove the 'Satisfy any' clause, operation is normal. The issue is that I don't know in advance if the user will put a .htaccess file in place to pre-determine if I need to put a 'Satisfy any' clause in the LOCATION blocks.  I don't know if 'Satisfy any' requires an .htaccess file and a 'Require' clause  in it before it will work.  I think the behaviour should be that 'Satisfy any' doesn't care if there is  a .htaccess file or not (implies no condition, but not satisfied). Using  a 'Satisfy any' should always allow access if not specified by either  .htaccess or 'Allow from'  Michael.	Same behaviour with 1.3.26 on Windows 2000 Professional. (even with simpler test-case, i.e.  normal directory, only 'Satisfy') I wonder whether this should be split into two bugs: - one  documentation bug to make it clearer that access restrition by client host address AND  username/password ist _required_ if you want to use 'Satisfy'. (It only states 'is only  useful') - one bug, because Apache should log something like this in its error log.  Well, it's a broken logic in 'satisfy any' handling. Bug is fixed in 2.1.0-dev and proposed for backport.  Thanks for using Apache! It's fixed now and will be available in the next release (1.3.28).			Andr?? Malo	Psychopath
9181	null	CLOSED		Sander van Zoest	1021582500000	1033737051000		Unable to set headers on non-2XX responses. It is common practice to set Cookie's to pass along on HTTP redirects for 'login' authentication.   When implementing P3P <http://www.w3.org/P3P/> using  mod_headers.c the Header directive only sets r->headers_out  and does not pass the headers along for non-2XX responses  such as error pages and redirects.  To provide this functionality we added the ErrorHeader  directive which populates r->err_headers_out instead.  A patch for 1.3.X by Michael Radwin is available at the specified URL.	Created an attachment (id=1883) Patch: Adds ErrorHeader Directive  This has been added in apache 1.3.27.  Dw. --  Dirk-Willem van Gulik			Dirk-Willem van Gulik	Sander van Zoest
9187	null	CLOSED		Max Dittrich	1021594800000	1021659867000		[docs/manual/stopping.html] broken link for PidFile the link for 'PidFile' in 'docs/manual/stopping.html' targets 'mod/core.html#pidfile', but PidFile has moved to mod_mpm_common.  The correct target should be 'mod/mpm_common.html#pidfile'  BTW the modules mpm_common and mod_cache aren't listed in docs/manual/mod/index-bytype.html but in docs/manual/mod/index.html	Fixes committed, thanks. 			Cliff Woolley
9222	null	CLOSED		ASADA Kazuhisa	1021728900000	1021853291000		mod_deflate should check Content-Encoding header Content with 'Content-Encoding' header, content is encoded. But mod_deflate does not check it. It cause to encode content twice.  This problem is reproduceible by get encoded content via mod_proxy.   Following is my trivial patch: ------------------------------------------------------------ --- mod_deflate.c\t17 May 2002 11:33:09 -0000\t1.5 +++ mod_deflate.c\t17 May 2002 16:16:49 -0000 @@ -274,4 +274,11 @@          }   +        /* encoded yet? */ +        accepts = apr_table_get(r->headers_out, 'Content-Encoding'); +        if (accepts) { +     ap_remove_output_filter(f); +     return ap_pass_brigade(f->next, bb); + } +          /* if they don't have the line, then they can't play */          accepts = apr_table_get(r->headers_in, 'Accept-Encoding'); ------------------------------------------------------------  Workaround for existing environment: ------------------------------------------------------------ <IfModule mod_deflate.c>     SetEnvIf Content-Encoding '.*' no-gzip </IfModule> ------------------------------------------------------------   Thanks for read my broken English.	fixed in current CVS tree Thanks Kazuhisa.			Ian Holsman
9233	null	CLOSED		Jonathan Knispel	1021812540000	1021981908000		t create runtimedir When installing the 'opt' layout from config.layout, the runtimedir is not  created.  As a result when httpd is started for the first time the PID file  cannot be created.  This is reported in the error log.  If I create the  runtimedir by hand and start httpd again, it works.      On a vaguely related note, I also have an FHS 2.2 (Filesystem Hierarchy  Standard) layout you can add to config.layout.  If you send me an email  address I'll forward it to you.  I'll include a helpful description of what  files go where and why, with cross references to the FHS 2.2 standard.  The  description might provide a useful basis for developer discussion or perhaps  inclusion in some Apache documentation.    Regards,                                             Jonathan Knispel	The runtimedir creation problem is now fixed in CVS and will be in the next release of Apache.  If you wish to pursue adding the FHS layout to config.layout, either post it  to the dev@httpd.apache.org mailing list or open a separate PR  (enhancement request) to track that issue.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
9244	null	CLOSED		Robin Johnson	1021883160000	1021927935000		--enable-http --enable-mods-shared=most causes link failure 2.0.36 fails to compile on a RedHat 7.0 box I was upgrading for a friend. Initially the compiler was egc-2.91.6 with binutils-2.5. After I got the error,  I checked on the version of the compiler and binutils, and upgraded those to  gcc-3.1 and binutils 2.12. It appears that something is not getting linked  properly. I have 2.0.36 compiled perfectly on my Slackware 8 box that has the  same release of gcc and binutils, so I think that can be ruled out. This will  be a mainstream production system, so I am reluctant to use the CVS HEAD branch  for this system.  /bin/sh /root/new/httpd-2.0.36/srclib/apr/libtool --silent --mode=link gcc  -g - O2 -pthread -DNO_DBM_REWRITEMAP    -DLINUX=2 -D_REENTRANT -D_XOPEN_SOURCE=500 - D_BSD_SOURCE -D_SVID_SOURCE -DAP_HAVE_DESIGNATED_INITIALIZER   -I. - I/root/new/httpd-2.0.36/os/unix -I/root/new/httpd-2.0.36/server/mpm/prefork - I/root/new/httpd-2.0.36/modules/http -I/root/new/httpd-2.0.36/modules/proxy - I/root/new/httpd-2.0.36/include -I/root/new/httpd-2.0.36/srclib/apr/include - I/root/new/httpd-2.0.36/srclib/apr-util/include -I/root/new/httpd- 2.0.36/modules/dav/main -I/root/new/httpd-2.0.36/srclib/apr-util/xml/expat/lib - export-dynamic    -o httpd  modules.lo   modules/mappers/mod_so.la  server/mpm/prefork/libprefork.la server/libmain.la  os/unix/libos.la /root/new/httpd-2.0.36/srclib/pcre/libpcre.la /root/new/httpd- 2.0.36/srclib/apr-util/libaprutil.la /root/new/httpd- 2.0.36/srclib/apr/libapr.la -lm -lcrypt -lnsl -lresolv -ldl -lz -lgdbm - ldb /root/new/httpd-2.0.36/srclib/apr-util/xml/expat/lib/libexpat.la server/.libs/libmain.al(config.lo): In function "ap_method_is_limited': /root/new/httpd-2.0.36/server/config.c:389: undefined reference to  "ap_method_number_of' server/.libs/libmain.al(exports.lo)(.data.rel+0x1f8): undefined reference to  "ap_send_error_response' server/.libs/libmain.al(exports.lo)(.data.rel+0x200): undefined reference to  "ap_set_keepalive' server/.libs/libmain.al(exports.lo)(.data.rel+0x20c): undefined reference to  "ap_make_etag' server/.libs/libmain.al(exports.lo)(.data.rel+0x210): undefined reference to  "ap_set_etag' server/.libs/libmain.al(exports.lo)(.data.rel+0x218): undefined reference to  "ap_meets_conditions' server/.libs/libmain.al(exports.lo)(.data.rel+0x224): undefined reference to  "ap_method_register' server/.libs/libmain.al(exports.lo)(.data.rel+0x228): undefined reference to  "ap_method_registry_init' server/.libs/libmain.al(exports.lo)(.data.rel+0x22c): undefined reference to  "ap_make_method_list' server/.libs/libmain.al(exports.lo)(.data.rel+0x230): undefined reference to  "ap_copy_method_list' server/.libs/libmain.al(exports.lo)(.data.rel+0x234): undefined reference to  "ap_method_list_do' server/.libs/libmain.al(exports.lo)(.data.rel+0x238): undefined reference to  "ap_method_list_vdo' server/.libs/libmain.al(exports.lo)(.data.rel+0x23c): undefined reference to  "ap_method_in_list' server/.libs/libmain.al(exports.lo)(.data.rel+0x240): undefined reference to  "ap_method_list_add' server/.libs/libmain.al(exports.lo)(.data.rel+0x244): undefined reference to  "ap_method_list_remove' server/.libs/libmain.al(exports.lo)(.data.rel+0x248): undefined reference to  "ap_clear_method_list' server/.libs/libmain.al(exports.lo)(.data.rel+0x24c): undefined reference to  "ap_set_content_type' server/.libs/libmain.al(exports.lo)(.data.rel+0x26c): undefined reference to  "ap_index_of_response' server/.libs/libmain.al(exports.lo)(.data.rel+0x270): undefined reference to  "ap_get_status_line' server/.libs/libmain.al(exports.lo)(.data.rel+0x274): undefined reference to  "ap_setup_client_block' server/.libs/libmain.al(exports.lo)(.data.rel+0x278): undefined reference to  "ap_should_client_block' server/.libs/libmain.al(exports.lo)(.data.rel+0x27c): undefined reference to  "ap_get_client_block' server/.libs/libmain.al(exports.lo)(.data.rel+0x280): undefined reference to  "ap_discard_request_body' server/.libs/libmain.al(exports.lo)(.data.rel+0x2a0): undefined reference to  "ap_method_number_of' server/.libs/libmain.al(exports.lo)(.data.rel+0x2a4): undefined reference to  "ap_method_name_of' server/.libs/libmain.al(exports.lo)(.data.rel+0x2e0): undefined reference to  "ap_byterange_filter' server/.libs/libmain.al(exports.lo)(.data.rel+0x2e4): undefined reference to  "ap_http_header_filter' server/.libs/libmain.al(exports.lo)(.data.rel+0x310): undefined reference to  "ap_internal_redirect' server/.libs/libmain.al(exports.lo)(.data.rel+0x314): undefined reference to  "ap_internal_redirect_handler' server/.libs/libmain.al(exports.lo)(.data.rel+0x318): undefined reference to  "ap_internal_fast_redirect' server/.libs/libmain.al(exports.lo)(.data.rel+0x328): undefined reference to  "ap_allow_methods' server/.libs/libmain.al(exports.lo)(.data.rel+0x32c): undefined reference to  "ap_allow_standard_methods' server/.libs/libmain.al(exports.lo)(.data.rel+0x330): undefined reference to  "ap_die' server/.libs/libmain.al(exports.lo)(.data.rel+0xd08): undefined reference to  "ap_basic_http_header' server/.libs/libmain.al(exports.lo)(.data.rel+0xd0c): undefined reference to  "ap_send_http_trace' server/.libs/libmain.al(exports.lo)(.data.rel+0xd10): undefined reference to  "ap_send_http_options' server/.libs/libmain.al(protocol.lo): In function "read_request_line': /root/new/httpd-2.0.36/server/protocol.c:671: undefined reference to  "ap_method_number_of' server/.libs/libmain.al(protocol.lo): In function "ap_read_request': /root/new/httpd-2.0.36/server/protocol.c:819: undefined reference to  "ap_make_method_list' /root/new/httpd-2.0.36/server/protocol.c:913: undefined reference to  "ap_send_error_response' /root/new/httpd-2.0.36/server/protocol.c:941: undefined reference to  "ap_http_input_filter_handle' /root/new/httpd-2.0.36/server/protocol.c:945: undefined reference to "ap_die' /root/new/httpd-2.0.36/server/protocol.c:934: undefined reference to  "ap_send_error_response' /root/new/httpd-2.0.36/server/protocol.c:935: undefined reference to  "ap_discard_request_body' server/.libs/libmain.al(core.lo): In function "ap_custom_response': /root/new/httpd-2.0.36/server/core.c:1106: undefined reference to  "ap_index_of_response' server/.libs/libmain.al(core.lo): In function "set_error_document': /root/new/httpd-2.0.36/server/core.c:1129: undefined reference to  "ap_index_of_response' /root/new/httpd-2.0.36/server/core.c:1134: undefined reference to  "ap_index_of_response' server/.libs/libmain.al(core.lo): In function "ap_limit_section': /root/new/httpd-2.0.36/server/core.c:1477: undefined reference to  "ap_method_number_of' /root/new/httpd-2.0.36/server/core.c:1486: undefined reference to  "ap_method_register' server/.libs/libmain.al(core.lo): In function "core_override_type': /root/new/httpd-2.0.36/server/core.c:3098: undefined reference to  "ap_set_content_type' server/.libs/libmain.al(core.lo): In function "default_handler': /root/new/httpd-2.0.36/server/core.c:3159: undefined reference to  "ap_allow_standard_methods' /root/new/httpd-2.0.36/server/core.c:3166: undefined reference to  "ap_discard_request_body' /root/new/httpd-2.0.36/server/core.c:3178: undefined reference to  "ap_send_http_options' /root/new/httpd-2.0.36/server/core.c:3208: undefined reference to "ap_set_etag' /root/new/httpd-2.0.36/server/core.c:3211: undefined reference to  "ap_meets_conditions' server/.libs/libmain.al(request.lo): In function "make_sub_request': /root/new/httpd-2.0.36/server/request.c:1525: undefined reference to  "ap_make_method_list' /root/new/httpd-2.0.36/server/request.c:1528: undefined reference to  "ap_copy_method_list' server/.libs/libmain.al(request.lo): In function "ap_sub_req_method_uri': /root/new/httpd-2.0.36/server/request.c:1622: undefined reference to  "ap_method_number_of' server/.libs/libmain.al(util_script.lo): In function  "ap_scan_script_header_err_core': /root/new/httpd-2.0.36/server/util_script.c:574: undefined reference to  "ap_set_content_type' /root/new/httpd-2.0.36/server/util_script.c:496: undefined reference to  "ap_meets_conditions' server/.libs/libmain.al(util_xml.lo): In function "ap_xml_parse_input': /root/new/httpd-2.0.36/server/util_xml.c:75: undefined reference to  "ap_setup_client_block' /root/new/httpd-2.0.36/server/util_xml.c:85: undefined reference to  "ap_should_client_block' /root/new/httpd-2.0.36/server/util_xml.c:106: undefined reference to  "ap_get_client_block' collect2: ld returned 1 exit status	I forget to add my configure options:  ./configure --enable-deflate --enable-mime-magic / --enable-expires --enable-headers / --enable-unique-id --enable-http --enable-dav / --enable-info --enable-cgi --disable-cgid / --enable-speling --enable-rewrite / --enable-so --enable-mods-shared=most What do you get for ./httpd -l and ./httpd -V ?      With your ./configure arguments, configure says:      checking which MPM to use... prefork   checking whether to enable mod_http... shared (most)   checking whether to enable mod_mime... shared (most)      mod_http should never be shared!!      What's happened is that by explicitly specifying --enable-http, you've tricked  it into allowing --enable-mods-shared=most to cause mod_http to be built as a  shared module (DSO), which you can't do.  The link failures are because the  symbols exported from mod_http are missing.  Get rid of the --enable-http  from the ./configure line and then mod_http will go back to being statically  compiled like it's supposed to be and it will work.  We should try to find  some way to detect this misconfiguration and either fix it automatically or  at least fail more gracefully.      Here is a patch that seems to work for me: It is patterned after a similar fragment for the mod_so DSO.  --- httpd-2.0.36/modules/http/config2.m4        Wed Oct  3 10:47:51 2001 +++ httpd-2.0.36-new/modules/http/config2.m4    Mon May 20 13:14:41 2002 @@ -4,8 +4,15 @@   http_objects='http_core.lo http_protocol.lo http_request.lo'  +dnl mod_http should only be built as a static DSO +if test '$enable_http' = 'yes'; then +    enable_http='static' +elif test '$enable_http' = 'shared'; then +    AC_MSG_ERROR([mod_http can not be built as a shared DSO]) +fi +  dnl mod_http freaks out when built as a DSO -APACHE_MODULE(http, HTTP protocol handling, $http_objects, , static) +APACHE_MODULE(http, HTTP protocol handling, $http_objects, , $enable_http)  APACHE_MODULE(mime, mapping of file-extension to MIME, , , yes)   APACHE_MODPATH_FINISH  yeah, I was actually just now working on a patch almost identical, also based on the one  from mod_so.  you actually don't need the:  -APACHE_MODULE(http, HTTP protocol handling, $http_objects, , static)  +APACHE_MODULE(http, HTTP protocol handling, $http_objects, , $enable_http)  part, since by now you've guaranteed that $enable_http == 'static'.    I'll commit this change in a few minutes.    Thanks! 			Cliff Woolley	Robin Johnson
9299	null	CLOSED		jay ball	1022041500000	1033193478000		t allow alternate dirs in some cases In the source to mod_userdir, the usage comments says that you may  combine UserDir entries to allow alternates.  The given example is:  UserDir public_html /usr/web http://www.xyz.com/users  which says to search for ~username/public_html then /usr/web/ username and finally do a redirect to http://www.xyz.com/users/username.   However, this example does not work in Apache 2.0.36.  Imagine that we have 'real' users of aaa and bbb (that is, with a login/ homedir), a set of 'fake' users yyy and zzz with only a directory under /usr/ web, and a set of redirected users mmm and nnn.  Now, using the above  configuration, point a browser to http://host/~aaa and ~bbb - it works.   However ~yyy ~zzz ~mmm ~nnn do not work.  If you swap /usr/web and  public_html, now ~yyy and ~zzz work, yet ~mmm and ~nnn do not work.   Thus, there is no way to make all three alternates work on the same  system and no way to do preference of order of search either.  The solution is to change the 'return DECLINED' in the #if  APR_HAS_USER section of mod_user to a 'continue'.  The diff -u is:  --- mod_userdir.c.orig  Tue May 21 16:03:22 2002 +++ mod_userdir.c       Tue May 21 16:03:50 2002 @@ -330,10 +330,10 @@                  filename = apr_pstrcat(r->pool, homedir, '/', userdir,                          NULL);              }              else {                  -                return DECLINED;                  +                continue;                               }  #else -            return DECLINED; +            continue;  #endif          }  -----end-diff----  Currently, /usr/web or /web/*/html style UserDir entries will search for the  exact file for the username+dir and if it is not found, it move on to the next  entry on the UserDir line.  However, for the 'public_html' style UserDir entry, if we do not find  ~username/public_html then we decline to process this request and do  not go to the next entry on the UserDir line.  So, end of request, 404.  If we  change the 'return DECLINED' to 'continue' as above, then we can move on to the next UserDir entry.  Entries in the form of http:// are redirects and must come last.  Apache does not know if the user exists on the remote machine, thus it must come last on the line.  This fact should be mentioned in the docs and source.  Yet, the ability to even use alternates in not mentioned in the docs, only in the source.  This needs to be added too.  I can write a paragraph if  someone wants  (oh, and while we're working on mod_userdir.c, around line 351, can we  change the tabs to spaces?  ;-)	Yes I have set UserDir to public_html but in order the access the users web site  you must add a / at the end line ~user/ instead of just ~user  Bug or my fault? rea: Please don't modify someone else's bug unless you are sure you are adding useful information.  The problem you are reporting has nothing to do with the original bug and is answered at http://httpd.apache.org/docs/misc/FAQ.html#set-servername I have committed the patch below with a slight modification, along with some documentation.  Thank you for the bug report, and thank you for using Apache 2.0.			Joshua Slive	Ryan Bloom	rea
9316	null	CLOSED		Jonathan Knispel	1022077560000	1023451443000		' If I build apache 2.0.36 with a custom config.layout entry, the  apxs script doesn't use it.  The layout I'm using specifies:        prefix:        /opt/apache-httpd-2_0_36      #...      datadir:         /var${prefix}/share      installbuilddir: ${datadir}/build    The apxs script ends up with this in it:        my $prefix         = '/opt/apache-httpd-2_0_36';      my $CFG_PREFIX     = $prefix;        # read the configuration variables once      my %config_vars = ();      get_config_vars('$prefix/build/config_vars.mk',/%config_vars);    The first parameter to 'get_config_vars' should be the  installbuilddir from the 'config.layout' entry.      Here's the full config.layout entry I'm using in case you need to  run some more tests on it, but note my remarks afterwards.    #   According to the Linux Filesystem Hierarchy Standard 2.2 (FHS) with  #   the full product name and version in the directory names.  For more  #   information see the specification at http://www.pathname.com/fhs/.  #  <Layout LinuxFHSFullName>      prefix:        /opt/apache-httpd-2_0_36      exec_prefix:   ${prefix}      bindir:        ${exec_prefix}/bin      sbindir:       ${exec_prefix}/sbin      libdir:        ${exec_prefix}/lib      libexecdir:    ${exec_prefix}/libexec      mandir:        ${prefix}/man      sysconfdir:    /etc${prefix}      datadir:       /var${prefix}/share      installbuilddir: ${datadir}/build      errordir:      ${datadir}/error      iconsdir:      ${datadir}/icons      htdocsdir:     ${datadir}/htdocs      manualdir:     ${prefix}/manual      cgidir:        ${datadir}/cgi-bin      includedir:    ${prefix}/include      localstatedir: /var${prefix}      runtimedir:    /var/run/apache-httpd-2_0_36      logfiledir:    /var/log/apache-httpd-2_0_36      proxycachedir: /var/cache/www/apache-httpd-2_0_36/proxy  </Layout>    Here's the configure command line I used:        $ ./configure --enable-layout=LinuxFHSFullName /        --enable-modules='rewrite auth-dbm so ssl'    Unless you're working with a later version than 2.0.36, you'll need  to create 'runtimedir' by hand after installing (bug #9233).    Hope that helps,                                            Jonathan Knispel	  Here are some additional path corrections for the apxs script:        my $envvars = get_vars('bindir') . '/envvars';    should use 'sbindir' instead of 'bindir'.  Or perhaps replace the  get_vars() call with $CFG_SBINDIR.      There are a few other references to '$prefix/build' or variants.  They should be replaced with references to 'installbuilddir', or a  new variable $CFG_INSTALLBUILDDIR, defined in the same way as  $CFG_SBINDIR.  Don't forget this one:        include %PREFIX%/build/special.mk      If it was just a matter of changing the script I'd offer a patch,  but I'm an Apache novice and I don't have time to figure out how  to get the config_vars.mk path into the apxs script.  I'm just hacking  it in by hand.    Regards,                                            Jonathan Knispel    Just looking at building mod_webapp for Tomcat, it would be very  useful if they could 'apxs -q installbuilddir'.  The installbuilddir problem is a duplicate report (see 8453).  That problem is now fixed.  The sbin/envvars problem has been fixed for some time.  I'll change this to an enhancment request to track your suggestion to support 'apxs -q installbuilddir'.  fix the severity (now 'Enhancement') 'apxs -q installbuilddir' now works with the current code in CVS. 			Jeff Trawick	Jonathan Knispel
9319	null	CLOSED		Sander	1022081640000	1024124560000		t honor ServerSignature if i set serversignature off in the httpd config file server sigature does'nt work, still when people tries to get a page that does not exist  the followwing data is being showed, but normaly version info, etc. should not be showed when serversginature is off  Object not found! The requested URL was not found on this server. If you entered the URL  manually please check your spelling and try again.  If you think this is a server error, please contact the webmaster  mailto:webmaster@satmarkt.nl Error 404 www.satmarkt.nl  05/22/02 17:30:51  Apache/2.0.36 (Win32)	That is not an internal apache error message.  That is a custom multi-lingual error  message that comes distributed with the server.  See the ErrorDocument directives in httpd.conf for instructions on how to modify these.    Frankly, Josh, that's a bogus answer.  We distribute those error docs, not   some third party we can blame :-)    I believe we were looking at this issue, it may already be resolved in .37,   the question was whether we should be changing the SERVER_STRING variable or   adding another variable to be used by the error docs.  This may be a duplicate   report, as well, we need to tie out this report if that is the case.  Well, ServerSignature works as documented.  Personally, I don't see a need to provide two different ways to configure the sample errordocuments.  You can already simply go and edit the include file to get rid of the info that you don't want.  Or if that is too complicated, comment out those ErrorDocuments and use the internal ones.  The only way I see to get what you want is to add a SERVER_SIGNATURE environment variable and then go test for that in a bunch of places in the error docs.  It won't be that easy.   Just changing the SERVER_SOFTWARE variable won't be sufficient because there is also SERVER_NAME and SERVER_ADMIN used in various places that would be need to be controlled by ServerSignature to make things consistent. I have commented out the offending variable.  If users want to add it back, they can uncomment it.  Regardless, we shouldn't be including this information by default. 			Joshua Slive	Ryan Bloom	Will Rowe
9410	null	CLOSED		Vasiliy Gagin	1022305680000	1022357282000		Broken registry.c Service failing to read parameters supplied through  HKEY_LOCAL_MACHINE/SYSTEM/CurrentControlSet/Services/Apache2/ImagePath  registry key. Problem is in registry.c file, method ap_registry_get_array. It used to read  HKEY_LOCAL_MACHINE/SYSTEM/CurrentControlSet/Services/Apache2 /Parameters/ConfigArgs value, which in my case is empty. But original  implementation failing to recognize empty array and is returning array with  one empty element. This empty element is inserted into argument list before  user arguments during arguments rewriting. Becouse of that user arguments are  getting ignored.  Here is simple patch: --- registry-old.c\tFri May 17 11:11:40 2002 +++ registry.c\tSat May 25 05:21:54 2002 @@ -266,26 +266,21 @@  \t\t\t     pValue,        /* for value */  \t\t\t     &nSize);\t/* for size of 'value' */   -        nSize = 1;    /* Element Count */ -        tmp = pValue; -        while (tmp[0] || tmp[1]) -        { -            if (!tmp[0]) -                ++nSize; -            ++tmp; +        nSize = 0;    /* Element Count */ +        for (tmp = pValue; *tmp; ++tmp) { +            ++nSize; +            while (*tmp) { +                ++tmp; +            }          } -     +          *parray = apr_array_make(p, nSize, sizeof(char *)); -        tmp = pValue; -        newelem = (char **) apr_array_push(*parray); -        *newelem = tmp; -        while (tmp[0] || tmp[1]) -        { -            if (!tmp[0]) { -                newelem = (char **) apr_array_push(*parray); -                *newelem = tmp + 1; +        for (tmp = pValue; *tmp; ++tmp) { +            newelem = (char **) apr_array_push(*parray); +            *newelem = tmp; +            while (*tmp) { +                ++tmp;              } -            ++tmp;          }      }	Created an attachment (id=1939) Bug fix     Applied, and further protected from unterminated or single null terminated   REG_MULTI_SZ data.  Thanks for your report and patch!			Vasiliy Gagin	Will Rowe
9413	null	CLOSED		Tsuyoshi SASAMOTO	1022314620000	1022337584000		apr_pool_userdata_set() should be used in mod_auth_digest.c, mod_suexec.c, ssl_scache.c. To use apr_pool_userdata_setn() in post_config functions of DSO modules is not good. I experienced SEGV at httpd startup.  --- httpd-2.0.36/modules/aaa/mod_auth_digest.c.org      Sun Apr 28 18:02:19 2002 +++ httpd-2.0.36/modules/aaa/mod_auth_digest.c  Fri May 24 21:39:42 2002 @@ -384,7 +384,7 @@       * set up our static data on the second call. */      apr_pool_userdata_get(&data, userdata_key, s->process->pool);      if (!data) { -        apr_pool_userdata_setn((const void *)1, userdata_key, +        apr_pool_userdata_set((const void *)1, userdata_key,                                 apr_pool_cleanup_null, s->process->pool);          return OK;      } --- httpd-2.0.36/modules/generators/mod_suexec.c.org    Thu Apr 25 16:18:39 2002 +++ httpd-2.0.36/modules/generators/mod_suexec.c        Sat May 25 13:56:59 2002 @@ -141,7 +141,7 @@          ap_log_error(APLOG_MARK, APLOG_NOERRNO|APLOG_NOTICE, 0, s,                       'suEXEC mechanism enabled (wrapper: %s)', SUEXEC_BIN);   -        apr_pool_userdata_setn((void *)1, SUEXEC_POST_CONFIG_USERDATA, +        apr_pool_userdata_set((void *)1, SUEXEC_POST_CONFIG_USERDATA,                                 apr_pool_cleanup_null, s->process->pool);      }   --- httpd-2.0.36/modules/ssl/ssl_scache.c.org   Thu Mar 28 08:25:58 2002 +++ httpd-2.0.36/modules/ssl/ssl_scache.c       Fri May 24 22:15:04 2002 @@ -94,7 +94,7 @@            apr_pool_userdata_get(&data, userdata_key, s->process->pool);          if (!data) { -            apr_pool_userdata_setn((const void *)1, userdata_key, +            apr_pool_userdata_set((const void *)1, userdata_key,                                     apr_pool_cleanup_null, s->process->pool);              return;          }	Right you are... Brad Nicholes had already caught one of these after 2.0.36 was  released.  Justin Erenkrantz caught a similar one in PHP4 not long ago as  well.  I've committed your patch for the two remaining modules that were doing  this.  Thanks for using Apache! *** Bug 7992 has been marked as a duplicate of this bug. *** *** Bug 7635 has been marked as a duplicate of this bug. ***			Cliff Woolley
9424	null	CLOSED		Artjom Grudnitsky	1022414520000	1023413985000		Typo in the Auth Howto http://httpd.apache.org/docs/howto/auth.html has a (possible) typo in Line 263 (html-source). The example uses /usr/local/apache/passwd/password as the password file in the mentioned line; however /usr/local/apache/passwd/passwords is used throughout the rest of the howto.	Thanks.  This will be fixed in the next update.			Joshua Slive
9446	null	CLOSED		Stanislav Brabec	1022516220000	1023414172000		Cosmetical fix of httpd.conf comments Patch to point to exact location of files in comments: ftp://ftp.penguin.cz/pub/users/utx/MY/apache_1.3.9.diff	This is a patch against 1.3.9, which is very old.  I believe this issue has been fixed in more recent versions. This path is agains 1.3.9--1.3.24. There was no need to update my patch. But I am not updating my Apache activelly. Thanks! It's really fixed now for the next release (1.3.28).  And sorry for the long delay ;-)			Andr?? Malo	Joshua Slive	Stanislav Brabec
9469	null	CLOSED		Erich Prchal	1022620140000	1022622587000		localtime not thread safe I had problems with localtime in another connection, so I looked through the Apache code and found some of these in ssl_engine_vars.c. I suggest to replace localtime with localtime_r if the server is multithreaded, like in apr/time/unix/time.c	I've fixed this by apr-izing the time functions in that file.  (It's better to use  apr_time_exp_lt() than to proliferate localtime() vs. localtime_r() everywhere... that's  the whole point of APR.)  Thanks for the report! 			Cliff Woolley
9534	null	CLOSED		Bruno Wolff III	1022816400000	1029952155000		rewritemap using external map program gets out of sync I am using an external rewritemap program (in perl with STDOUT getting flush by each print statement) with a prefork mpm and I am seeing the returned values be returning to the wrong requests. Often the first one or two lookups return no value (from rewritelog) and after that the returned values often seem to be offset by this amount with respect to request. Logs from the program indicate that it is returning the correct value based on the input it is receiving. I have seen this occur in several 2.0.37 snapshots, the latest being httpd-2.0_20020530221254.tar.gz . The following rewrite directives are being used: Rewritelock /home/httpd/html/robot/lock Rewritemap blocked prg:/home/httpd/html/robot/check.pl A current copy of the program can be found at: http://wolff.to/robot/check.pl I have played with the lockfile (ownership, access rights and existence) and haven't seen any differences in behavior.	Created an attachment (id=2167) Working Fix against 2.0.39, but still needs some work (uses Non-Apache-Constant EAGAIN)  I tried this using the current CVS after receiving the update message and I am still seeing the problem. I am including an extract from my rewrite log. I changed the script to return the IP address it was asked to lookup which should match that of the request. The log makes it clear that it doesn't. I also included part of my httpd.conf file relating to the external map. I am running a 2.2 linux kernel. If you need other information, I should be able to probably help. I really would like to see this issue fixed. Thanjs for working on this issue. RewriteLock /home/httpd/html/robot/lock Rewritemap blocked prg:/home/httpd/html/robot/check.pl 127.0.0.1 - - [24/Jun/2002:12:02:03 --0500] [localhost/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=127.0.0.1 -> val= 127.0.0.1 - - [24/Jun/2002:12:02:05 --0500] [localhost/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=127.0.0.1 -> val=OK-127.0.0.1 64.24.12.167 - - [24/Jun/2002:12:02:11 --0500] [wolff.to/sid#81a6cc0][rid#8247138/initial] (5) map lookup OK: map=blocked key=64.24.12.167 -> val=OK-127.0.0.1 64.24.12.167 - - [24/Jun/2002:12:02:13 --0500] [wolff.to/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=64.24.12.167 -> val=OK-64.24.12.167 64.24.12.167 - - [24/Jun/2002:12:02:14 --0500] [wolff.to/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=64.24.12.167 -> val=OK-64.24.12.167 127.0.0.1 - - [24/Jun/2002:12:02:18 --0500] [localhost/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=127.0.0.1 -> val=OK-64.24.12.167 This issue is not yet fixed in CVS.  The patch attached to this PR has not yet  been committed.  I've reviewed it, though, and it seems quite on-target.  I'll  commit a variant of it (fixing it to use APR_EAGAIN) sometime tonight.    --Cliff  Sorry this took a while. I managed to miss that you had included the patch in the bugzilla entry so that I could use it before it was committed to CVS. I just tried out the patch applied to the current CVS (about two hours old) and it seemed to fix my problem. Thanks. Just adding: it is not fixed in apache 2.0.40, the same ugly patch from 2.0.39 is still needed.  Okay, upon further investigation, I believe the correct fix is actually this:    line 3463:    -        ((rc = apr_procattr_io_set(procattr, APR_FULL_BLOCK,  -                                  APR_FULL_NONBLOCK,  -                                  APR_FULL_NONBLOCK)) != APR_SUCCESS) ||  +        ((rc = apr_procattr_io_set(procattr, APR_FULL_BLOCK, APR_FULL_BLOCK,  +                                   APR_NO_PIPE)) != APR_SUCCESS) ||      It's because reads are set to nonblocking mode that we're getting hosed here.   You shouldn't have to check for APR_EAGAIN from apr_file_read()... it's only  getting returned because we told it to (by setting nonblocking mode).  Oops!    Please let me know if this fixes it and I'll commit the change.    --Cliff  I tested the suggestion to change the read to blocking and it seemed to work correctly. (I had also removed the previous fix for this test.) Fixed for 2.0.41.    Thanks for your feedback!  *** Bug 12175 has been marked as a duplicate of this bug. ***			Bruno Wolff III	Cliff Woolley	Joshua Slive	Sven Koch
9587	null	CLOSED		Timo Weing	1023133920000	1058275902000		Wrong icon with FancyIndexing If a directory contains a file listet in the DirectoryIndex directive, the  folder icon is replaced by the icon for the DirectoryIndex file,  e.g. /icons/layout.gif if there is a file named index.html.	Created an attachment (id=2021) Removes the filename mod_dir attaches to the request_rec before find_icon receives it.     An extra stat()?  (and in the wrong place, at that.)  ICK.    The essentials are that we already stat()ed this somewhere    in the way-back machine, and then ran it through to discover   that it is really something else [e.g. requesting /foo/ will   return an html document ... index.html in that directory.]   That means it is -more- than just another folder.    The correct fix is probably deeper in the code.  I expect we   will need to determine the stat() just a little bit earlier.   If I can prove the stat() always occurs, and that dir_walk   and file_walk will just borrow the pre-existing stat, then   noone should shoot us for requesting more detailed information   from apr_dir_read().    In any case, this should NOT BE OCCURING on Win32 unless some   patch to dir_walk, autoindex, or sub_req_lookup_dirent has it   borked.  Win32 apr_dir_read() already returns much more fileinfo   than most Unix platforms.    I will look at it, though I can't promise a fix in the 2.0.37   timeframe.  Certainly by 2.0.38.         The problem arises when mod_autoindex calls ap_sub_req_lookup_dirent on each of the sub directories.  The returned request_rec.filename has the DirectoryIndex file attached to it.  So, I figured it was best to strip that file off the end of the rr.filename before passing it to find_icon.  The ap_is_directory call is far from necessary... all that's needed is     rr->filename = ap_make_dirstr_parent (rr->pool, rr->filename);      'The problem arises when mod_autoindex calls ap_sub_req_lookup_dirent    on each of the sub directories.'    This is why the code once relied on dirent->type instead of rr->finfo->type.   However, some folks pointed out that Unix doesn't determine the filetype on   a dirread() call, and we would have to beg unix to do so.  However, if we   did that, we would want to prove we aren't wasting extra stats, and that   ap_sub_req_lookup_dirent will pass that info on to rr->finfo, which dir_walk   will actually consume.    If that code works correctly, it's just a matter of passing APR_FINFO_MIN   along with APR_FINFO_DIRENT switches to apr_dir_read.   i had to tweak the mod_autoindex.c in the latest version of apache to get it to work right.  here are my work arounds:           //if (!(p->icon = find_icon(d, rr, 1))) {                 // was getting wrong icons on folders                 p->icon = find_default_icon(d, '^^DIRECTORY^^');             //}             if (!(p->alt = find_alt(d, rr, 1))) {                 if (!(p->alt = find_default_alt(d, '^^DIRECTORY^^'))) {                     p->alt = 'DIR';                 }             }         }         else {             p->icon = find_icon(d, rr, 0);             p->alt = find_alt(d, rr, 0);             p->size = rr->finfo.size;         }           p->desc = find_desc(d, rr->filename);          if ((!p->desc) && (autoindex_opts & SCAN_HTML_TITLES)) {                 //added this check -- was getting garbage description on folder            if (dirent->filetype != APR_DIR)                   p->desc = apr_pstrdup(r->pool, find_title(rr));         } Commenting out 'if (!(p->icon = find_icon(d, rr, 1)))' breaks the ability to specify an icon for a directory with an AddIcon directive .  I've walked through this code a ton of times and the simplest patch i've come up with is...  Index: modules/generators/mod_autoindex.c =================================================================== RCS file: /home/cvspublic/httpd-2.0/modules/generators/mod_autoindex.c,v retrieving revision 1.119 diff -u -r1.119 mod_autoindex.c --- modules/generators/mod_autoindex.c  2 Mar 2003 18:06:16 -0000       1.119 +++ modules/generators/mod_autoindex.c  15 Jul 2003 07:28:50 -0000 @@ -1361,6 +1361,7 @@              if (autoindex_opts & FOLDERS_FIRST) {                  p->isdir = 1;              } +            rr->filename = ap_make_dirstr_parent (rr->pool, rr->filename);              if (!(p->icon = find_icon(d, rr, 1))) {                  p->icon = find_default_icon(d, '^^DIRECTORY^^');              }  which removes the appended filename added by mod_dir, if any, from rr->filename which results in find_icon seeing the correct filename.  this looks reasonable to me. Committed in 2.1 and proposed for backport.  Thanks for patch (and your patience :), Shane. *** Bug 23050 has been marked as a duplicate of this bug. ***			Andr?? Malo	David Shane Holden	Will Rowe	andy d
9644	null	CLOSED		Bruno Wolff III	1023302460000	1023735439000		error logs entries for external filter, but page served ok I am seeing error logs like the following when using a filter program (a 10 line perl program included below): [Wed Jun 05 13:12:39 2002] [error] [client 127.0.0.1] (9)Bad file descriptor: apr_file_close(child input) I get a log entry whenever a page to which this filter is applied gets included (by INCLUDES) in another document. If the document has three includes I get three error messages for each reference. I don't get an error message if I access the file directly instead of including it. I use the virtual= clause to specify the document. This is occuring in the httpd-2.0_20020605161218.tar.gz snapshot with apr and apr-util from about the same time. I also had the problem with the previous snapshot I was using from a few days ago. The perl program is as follows: #!/usr/bin/perl print '/n<pre>/n'; while (<STDIN>) {   s/&/&amp;/;   s/</&lt;/;   s/>/&gt;/;   print; } print '</pre>/n'	This is now fixed in CVS and will be in the next release of Apache. You can use this patch if you want:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/protocol.c.diff? r1=1.105&r2=1.106  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
9673	null	CLOSED		Christian Kohlsch	1023391320000	1045439339000		Conditional GET requests not handled properly with filtered content Apache2 does not pay attention to dynamic PHP scripts configured by   SetInputFilter/SetOutputFilter PHP, as it still checks the modification   date of the plain .php file.      This leads to caching problems, when the user's browser sends a   'If-Last-Modified' request. Apache returns '304 Not Modified', as the  PHP file itself has not changed, although the dynamic content may have  changed!    The problem is in modules/http/http_protocol.c, line 386+  Hotfix: I have commented out line 393 (return HTTP_NOT_MODIFIED), so that this  feature is totally disabled.    Is there a chance to check for an Input/OutputFilter set? That way, we could  deactivate the feature for PHP pages only.	I'm fairly sure that it is the filter itself that should be removing the last-modified.  There are many filters that do not affect caching, so apache should not be removing last-modified for every filter.  So, the punch line is, you should file this bug report with PHP. The problem is that the PHP filter is not called. Here is a dump of the  client-server communication:    ---------> from Client to Server  GET / HTTP/1.1  Accept: */*  If-Modified-Since: Thu, 06 Jun 2002 17:47:44 GMT; length=17947  Host: www.newsclub.de  Connection: Keep-Alive    <-------- Reply from Server to Client    HTTP/1.1 304 Not Modified  Date: Thu, 06 Jun 2002 17:50:08 GMT  Server: Apache/2.0.36 (Unix) DAV/2 PHP/4.2.1  Connection: Keep-Alive  Keep-Alive: timeout=15, max=100  ETag: '66ab2-4ef-63a14340'    --------- End of reply, that's it - no content!    So, there is neither PHP output nor the PHP source code at all, Apache seems  to block further processing of the request.    Still a PHP problem.  Content is never returned on a 304 response.  That is the point of the response. What is happening is that Apache is running the request, seeing the  last-modified information, and deciding that the client already has up-to-date content, so it doesn't need to send it again.  It is the responsibility of the PHP filter to remove the last-modified information so that apache always serves fresh content.  Oops.  I take it all back.  I just tried with mod_include's INCLUDES filter, and even though it strips Last-Modified, Apache still serves conditional GET requests.  Ouch.  Here's an example: ab26[joshua]59% telnet httpd.apache.org 80 Trying 63.251.56.142... Connected to httpd.apache.org. Escape character is '^]'. GET /docs/vhosts/index.html HTTP/1.1 Host: httpd.apache.org If-Modified-Since: Thu, 06 Jun 2002 20:58:16 GMT  HTTP/1.1 304 Not Modified Date: Thu, 06 Jun 2002 21:01:29 GMT Server: Apache/2.0.37-dev (Unix) ETag: 'ea72a-b3f-f3b22680;2434f440' Content-Location: index.html.en Vary: negotiate,accept-language,accept-charset   And what the heck is that ETag doing in the 304 response?  It is not in there for a normal response: HEAD /docs/vhosts/index.html HTTP/1.1 Host: httpd.apache.org  HTTP/1.1 200 OK Date: Thu, 06 Jun 2002 21:09:12 GMT Server: Apache/2.0.37-dev (Unix) Content-Location: index.html.en Vary: negotiate,accept-language,accept-charset TCN: choice Accept-Ranges: bytes Content-Length: 3158 Content-Type: text/html Content-Language: en  And what the heck is the Content-Length doing in the normal response?  Both Content-Length and ETags are explicitly unset by mod_include.  I'm afraid I'm out of my league here, so I'll need to leave this to others. The If-Modified-Since and If-Unmodified-Since logic uses r->mtime as the time of the entity being served, not the Last-Modified header.  I assume this is an optimization to avoid reparsing Last-Modified.  So either stripping Last-Modified is not enough (also set r->mtime to 0), or we need to change the logic on line 316 of http_protocol.c.  Note though that this is also how Apache 1.3 deals with it, so I'm not sure I see what the problem is.  Sounds like a bug (misunderstanding?) in mod_include and mod_php4.  --Cliff  The Content-Length is probably being generated by the content length filter  (that's its job).  Not sure about the etag, but I do remember some discussion  about that recently I think...  As I understand, the problem is the filter concept itself.     Filters are applied on data that is already processed by http_protocol.c          What http_protocol.c checks is the modification time of a file, ie.     'index.php'. The script has been written in 2001, for example, but it produces     new content from a database every minute.          So, the PHP code gets only executed, if Apache decides to pass the data to the     filter. Here Apache decides not to, because it thinks that the file has not     changed.          The ETag is probably generated because Apache looks at the program code of     index.php itself, not at the content the PHP script produces.         I suggest to add an Apache directive to disable If-Modified-Since processing    for Filtered files, for example:        <FilesMatch '/.php$'>        SetInputFilter PHP        SetOutputFilter PHP        CheckIfModifiedSince off    </FilesMatch>        PHP itself could then automatically set this directive.       I disagree.  It should be the filter's responsibility to decide if it modifies the data, not the administrator.  If the filter wants to deligate that job to the administrator (like mod_include does with XBitHack full) then it can do so. But somehow, http_protocol.c must get that information.    Is there a way to check for a certain filter in http_protocol.c?  That would enable me to write a quick hack for PHP.    Currently, I have disabled 'not modified' replies at all, which is  no good idea...    This is due to a bug in PHP and in the httpd-2.0 core.  default_handler shouldn't be calling ap_meets_condition().  As I posted to dev@httpd, this decision should most likely be delayed until the ap_http_header_filter() is called.  However, PHP's use of filters is completely and totally broken in many ways.  =)  First off, it doesn't unset Last-Modified which it needs to do.  There's a lot of bogosity in how it deals with buckets.  I've posted before to php-dev@ about this. Can someone give me a hint how to write a quick fix for it?  I would just need to check if PHP is in the filter chain.    That's easier said than done.  Easier is the seemingly 'right' fix that Justin  proposed: move the ap_meets_conditions() call from the default_handler to the  ap_http_header_filter.    --Cliff   I'd like to post a workaround without patching apache or PHP....  Just edit your script(s) to send a 'header('Last-Modified: Mon, 26 Jul 1997 05:00:00 GMT');' or just some other date older than the mdate of your script file. This solves the problem.  Reason: The bug causes Apache2 to look for the mdate of the .php file to determine if it has been modified. If the browser first gets a header like above, it next time asks for the page with an 'If-Modified-Since: Mon, 26 Jul 1997 05:00:00 GMT'. Then, the httpd looks at the mdate of your script, which is always newer and says: Yes, it has been modified, '200 OK'. The script will be served and it will response again with the header line from above. Round and round the story goes. :))  Greets, and have fun!  Daniel Daniel: Your workaround solves the problem, but creates another one.  Searching engines that spider the pages would see 'old' Last-Modified headers  and therefore will not index them.    At NewsClub.de, the pages are updated at least every 30 minutes, so this  fix is at least not good for me.    Maybe the bug is even fixed in the current CVS versions of apache2 and php4?    Hmm, the actual Changelog contains:    *) Add a filter_init parameter to the filter registration functions      so that a filter can execute arbitrary code before the handlers      are invoked.  This resolves a problem where mod_include requests      would incorrectly return a 304.  [Justin Erenkrantz]  Is this the solution to our problem? I'm compiling httpd-2.0_20020723101312 at the moment and will try it. I'm sorry, problem not solved yet using the latest unstable cvs code of both  php4 and httpd-2.0.  ...but they are compiling and running fine :)))) This should be fixed in Apache 2.0.42 and later.  Unknown when exact fix was committed (probably much earlier than 2.0.42), but the behavior works as expected for filtered content now. I'm still having this bug, even with the 'short fix' Daniel Eckl posted. :-/  Running Apache 2.0.43 for Windows with php-4.2.3-Win32. Try PHP 4.3.0 BETA, it seems to be working now. This bug has been closed but appears to still persist.  I'm running Apache  2.0.43 with PHP 4.3 and I still have this issue.  Has it been decided wether  this is legitimately a bug in Apache or PHP yet?  I have heard it thrown around  as a PHP bug by Apache and an Apache bug by PHP and was wondering if either  side has given in and said where the bug really is.  Thank you, Steve The problem can be worked around in php.  See http://bugs.php.net/bug.php?id=17098  Daniel Yes, the filter_init hook resolved this.  See how mod_include and mod_php (in their CVS tree) do it.  It should be included in the next PHP release if it isn't already, but there isn't anything more we can do with this issue.  The API is there.  Thanks for using Apache HTTP Server!			Christian Kohlsch	Cliff Woolley	Daniel Eckl	Erlend Stromsvik	Joshua Slive	Justin Erenkrantz	Sascha Kulawik	stephen fox
9729	null	CLOSED		Matthew Brecknell	1023632520000	1023728449000		httpd -V gives TYPES_CONFIG_FILE instead of AP_TYPES_CONFIG_FILE A small oversight, liable to cause minor confusion during configure & build:  httpd -V reports the value of TYPES_CONFIG_FILE, if defined, though this macro  does not seem to be used anywhere else in the code.  AP_TYPES_CONFIG_FILE, as defined in httpd.h and used in mod_mime.c, seems to be  a more useful value to report.   --- server/main.c       Wed Apr 17 17:36:28 2002 +++ /tmp/main.c Fri Jun  7 19:34:58 2002 @@ -229,8 +229,8 @@      printf(' -D DEFAULT_ERRORLOG=/'' DEFAULT_ERRORLOG '/'/n');  #endif  -#ifdef TYPES_CONFIG_FILE -    printf(' -D TYPES_CONFIG_FILE=/'' TYPES_CONFIG_FILE '/'/n'); +#ifdef AP_TYPES_CONFIG_FILE +    printf(' -D AP_TYPES_CONFIG_FILE=/'' AP_TYPES_CONFIG_FILE '/'/n');  #endif   #ifdef SERVER_CONFIG_FILE	Your fix has been committed to Apache 2.0.  Thanks for your patch, and thanks for using Apache! 			Jeff Trawick
9770	null	CLOSED		Francesco Russo	1023800460000	1023807426000		 not working [Previous ref: PR 10090 - Pablo Delgado -]   I compiled Apache 2.036 using: ./buildconf ./configure --with-mpm=worker / / --enable-access / --enable-alias / --enable-auth / --enable-cgi / --enable-rewrite / / --disable-actions / --disable-cgid / --disable-asis / --disable-auth_anon / --disable-autoindex / --disable-env / --disable-imap / --disable-include / --disable-isapi / --disable-status / --disable-userdir  make make install  Then I configured a Virtual Host like this:  <VirtualHost 123.123.123> RewriteEngine on RewriteMap random rnd:/home/httpd/randomrew.txt RewriteRule ^/testrnd/index.html$  http://${random:tot1} [R] </VirtualHost>  'randomrew.txt' contains: tot1 www.site1.com/|www.site2.com/|www.site3.com/  Only happen the redirect to 'www.site1.com' [the first in the list].  The same rewrite worked without any problem in all Apache 1.3.1x versions.	This has now been fixed.  We just missed the cutoff for 2.0.37, so expect the fix in 2.0.38.  For now, you can use this small patch to mod_rewrite:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/mappers/mod_rewrite.c.diff? r1=1.121&r2=1.122  Thanks for your report, and thanks for using Apache!  *** Bug 9783 has been marked as a duplicate of this bug. ***			Jeff Trawick	Joshua Slive
9787	null	CLOSED		Dave Dyer	1023824460000	1024125579000		initial config should be augmented for SSI to enable server side includes, AddType text/html .shtml must also be added to the config file.  This should be added to the comment/examples right next to the AddOutputFilter line for .shtml	I have committed this to CVS, and it will be available in the next release. 			Ryan Bloom
9858	null	CLOSED		Vasiliy Gagin	1024022880000	1024131674000		ApacheMonitor can not start service due to bug in service.c or ApacheMonitor.c My service.c revision is 1.53. ApacheMonitor passes to StartService array of argv with argv[0]  == '...Apache2.exe'. SCM inserts additional argument ('service name') before  argv[0], and this extra argument causes service to fail during startup.  Last 1.53 revision of fixes same issue for '-k start' argument, but I have '-k  runservice' and it is not working.	This has been fixed in CVS and will be good to go in 2.0.38.  Thanks for your  report!			Cliff Woolley
9866	null	CLOSED		Ping Xiao	1024061220000	1024120374000		apache 2.0.36 mod_include seems to have flow control problem The flow control doesn't seem to skip the else section. For example, if true1   do 1 else   do 2   if true2      do 22   else      do 3   endif endif  In my case, when 'true1' instead of perform 'do 1' and then finish, it keeps on  performing 'do 2' and the condition tset 'if true2', and so on.	Don't know how to correct original description, so I add my correction here:  It didn't actually perform the 'do 2' but it performed the 'if true 2'  when 'true 1' was satisfied.  Thanks for catching this.  I've just committed a fix for inclusion in 2.0.38 (which hopefully will be tagged tomorrow).			Brian Pane	Ping Xiao
9977	null	CLOSED		Dai Sato	1024454460000	1045945614000		suexec uses strerror(), which is not in SunOS4 in support/suexec.c, strerror() is used without any care for NEED_STRERROR. so, it should have it's own strerror() like discribed bellow (the code is from main/util.c):  --- suexec.c.org        Wed Jun 19 11:02:21 2002 +++ suexec.c    Wed Jun 19 11:02:21 2002 @@ -103,6 +103,19 @@   ***********************************************************************   */  +#ifdef NEED_STRERROR +char * +     strerror(int err) +{ + +    char *p; +    extern char *const sys_errlist[]; + +    p = sys_errlist[err]; +    return (p); +} +#endif +  #if defined(NEED_INITGROUPS)  int initgroups(const char *name, gid_t basegid)  {	It's fixed in 2.1 (using the patch provided in http://bugs.apache.org/index.cgi/full/5913) and proposed for backport.  Thanks for the report and thanks for using Apache! Finally fixed in 1.3 and 2.0 branch. It will appear in the next releases (1.3.28 and 2.0.45).			Andr?? Malo
9989	null	CLOSED		Christian Hammers	1024483680000	1024929359000		t give -n) Stupid mistake, '1 & (1 | 2) == 1 & (3) == 1' where as it must be 3 to fullfill the condition. 1 sadly is enough to fullfill the if() condition..   --- support/htpasswd.c.orig     Wed Jun 19 12:41:26 2002 +++ support/htpasswd.c  Wed Jun 19 12:40:55 2002 @@ -375,7 +375,7 @@          }      }  -    if (*mask & (APHTP_NEWFILE | APHTP_NOFILE)) { +    if ((*mask & (APHTP_NEWFILE | APHTP_NOFILE)) == (APHTP_NEWFILE | APHTP_NOFILE)) {          apr_file_printf(errfile, '%s: -c and -n options conflict/n', argv[0]);          exit(ERR_SYNTAX);      }	AWWWW MAN!!! Sorry, my fault.  The logic before said :    if (*mask & (APHTP_NEWFILE & APHTP_NOFILE)) {    which was visibly broken, so I changed it without actually testing to what it  is now, which is also wrong.  ;(    Anyway, I'm officially changing it to:    if ((*mask & APHTP_NEWFILE) && (*mask & APHTP_NOFILE)) {    I'll place a patch in  http://www.apache.org/dist/httpd/patches/apply_to_2.0.39/    Thanks for your report!  *** Bug 10075 has been marked as a duplicate of this bug. *** *** Bug 10014 has been marked as a duplicate of this bug. *** This bug is back in 2.0.39:      if (*mask & (APHTP_NEWFILE | APHTP_NOFILE)) {         apr_file_printf(errfile, '%s: -c and -n options conflict/n', argv[0]);         exit(ERR_SYNTAX);     }  Yes, I know the bug is in 2.0.39.  That's why I gave a URL for a patch that  is /dist/httpd/patches/apply_to_2.0.39/.  :)  The first version released with  the patch incorporated will be 2.0.40.  --Cliff *** Bug 10309 has been marked as a duplicate of this bug. *** *** Bug 11173 has been marked as a duplicate of this bug. ***			Cliff Woolley	David Shane Holden	David Tonhofer	Will Rowe
10074	null	CLOSED		James Dugal	1024600200000	1024657339000		apachectl invokes httpd with -k option For some reason I can't find a report on this ... so here goes! apachectl is built to invoke httpd with the -k option to do a start, stop, restart or graceful, eg, httpd -k start But the -k option is not supported (in main.c).  I reverted to using the 1.3.x version of apachectl as a bypass.	The code is not in main.c; it is called before the normal cmd-line processing in main.c runs.  What is the symptom when you use apachectl from 2.0.39?  What is the output of 'apachectl -V'? Created an attachment (id=2144) script demonstrating the problem, and httpd -V, -l report  Oh, the perchild MPM :)  If I can get it to build I'll make the minor change necessary to get it to support -k.  Thanks for the extra doc!   This problem with the perchild MPM as been fixed in CVS and will be in the next release.  In the meantime, you can use this patch:  Index: server/mpm/experimental/perchild/mpm.h =================================================================== RCS file: /home/cvs/httpd-2.0/server/mpm/experimental/perchild/mpm.h,v retrieving revision 1.16 diff -u -r1.16 mpm.h --- server/mpm/experimental/perchild/mpm.h      1 Apr 2002 08:27:42 -0000       1.16 +++ server/mpm/experimental/perchild/mpm.h      21 Jun 2002 10:53:29 -0000 @@ -76,6 +76,7 @@  #define AP_MPM_WANT_SET_MAX_REQUESTS  #define AP_MPM_WANT_SET_COREDUMPDIR  #define AP_MPM_WANT_SET_ACCEPT_LOCK_MECH +#define AP_MPM_WANT_SIGNAL_SERVER  #define AP_MPM_USES_POD   #define MPM_CHILD_PID(i) (ap_scoreboard_image->parent[i].pid) Index: server/mpm/experimental/perchild/perchild.c =================================================================== RCS file: /home/cvs/httpd-2.0/server/mpm/experimental/perchild/perchild.c,v retrieving revision 1.126 diff -u -r1.126 perchild.c --- server/mpm/experimental/perchild/perchild.c 13 Jun 2002 16:36:19 -0000      1.126 +++ server/mpm/experimental/perchild/perchild.c 21 Jun 2002 10:53:30 -0000 @@ -1999,7 +1999,7 @@   module AP_MODULE_DECLARE_DATA mpm_perchild_module = {      MPM20_MODULE_STUFF, -    NULL,                       /* hook to run before apache parses args */ +    ap_mpm_rewrite_args,        /* hook to run before apache parses args */      NULL,                       /* create per-directory config structure */      NULL,                       /* merge per-directory config structures */      perchild_create_config,     /* create per-server config structure */  Apply the patch, then 'make clean && make && make install'.  Thanks for your report, and thanks for using Apache! 			James Dugal	Jeff Trawick
10130	null	CLOSED		Dustin Cavanaugh	1024675320000	1026100608000		d packages Compilation with VC6 results in the following error: Error scanning file  C:/Download/Temp/httpd-2.0.39/support/win32/ApacheMonitorVersion.rc for  dependencies.  A search for the reference yields: C:/Download/Temp/httpd-2.0.39/support/win32/ApacheMonitor.rc(67):#include  'ApacheMonitorVersion.rc'	   Please describe     1. how you invoked the build (in the studio ide?  which target project?       command line?  what command?)    2. is awk correctly installed on your machine?    3. which package you obtained (-win32-src.zip?  .tar.gz?  CVS checkout?)    4. what Visual Studio 6.0 service pack you have installed.  Built with /VS C++ 6.0/sp5. Target project InstallBin - Win32Release. Build command line: 'NMAKE /f makefile.win INSTDIR='/Apache2' SHORT=R  LONG=Release _install'.  awk: From command line: C:/>awk --version GNU Awk 3.0.6 Copyright (C) 1989, 1991-2000 Free Software Foundation.  Source: httpd-2.0.39-win32-src.zip downloaded from mirror.    Since I can reproduce this on DevStudio 7.0 (missing the #include clue that we   better generate ApacheMonitorVersion.rc in order to compile ApacheMonitor.rc)   I'm leaving this report open.    However, I expect the problem lies in GNU 3.06 built under [???  cygwin?]   Can you share where you obtained that, if it is cygwin (perhaps the command   depends awk.exe  will reveal which clib and other .dll's it's bound to.)    cygwin does it's own thing with pathnames and so forth, and cannot handle   win32 backslash path delimiters and the like.  It's very possible that your   problem is isolated to this issue.    Please track further discussion with your GNU [cygwin?] awk on bug 10131.   This indicent will track DevStudio's unwillingness to grok #include in   .rc source files. i'd like to grab this bug if no-one objects...    Please do James... see the microsoft.public.vc.ide_general list for some    observations, just search for .rc and #include and you will see others have   observed this same behavior and some [not many] have worked around it on   Visual Studio 7.0.  I suspect the user's problems in VS6.0 were phantoms of   not having a working awk.    After you create an account on this bugzilla, you might want to see yourself   to this bug.  I have committed a fix for this.  Please test the latest CVS and let us know if it solves your problem. I don't know what you mean, 'test the latest CVS'. I pulled httpd-2.0_20020708101252.tar.gz and httpd-2.0_20020708041218.tar.gz, but neither Apache.dsw would load anything into VC++ 6.0.  Are you referring to other code somewhere else? OK, i fixed this and the patch was committed by Ryan yesterday into CVS. You  may wish to check a snapshot from today, and make sure your env is extraclean.   -- james			Dustin Cavanaugh	James Cox	Ryan Bloom	Will Rowe
10146	null	CLOSED		Kozin Maxim	1024743000000	1026111835000		2.0.39 DoS Hello.  Some time ago in different maillist was post: ------------------------------------------------------ Date: Wed, 19 Jun 2002 12:45:24 -0700 From: gobbles@hushmail.com To: vulndev@vulndev.org, submissions@packetstormsecurity.org,      bugs@securitytracker.net, bugtraq@securityfocus.com,      vuln-dev@securityfocus.com Subject: Remote Apache 1.3.x Exploit ---------------------------------------------------------------- Mail has attachment, which 'exploit for openbsd' code. But 'exploit' has one side effect  - for apache 2.0.39 it make DoS. Child eat all memory, swap and die with diagnostic '. Jun 20 11:16:39 solo /kernel: pid 49564 (httpd), uid 65534, was killed: out of swap space ' In gdb we can see, that child loop in  modules/http/http_protocol.c in function: ap_discard_request_body(): 1962        } while (!seen_eos); (gdb) n 1920            rv = ap_get_brigade(r->input_filters, bb, AP_MODE_READBYTES, (gdb) n 1923            if (rv != APR_SUCCESS) { (gdb) n 1939            APR_BRIGADE_FOREACH(bucket, bb) { (gdb) n 1961            apr_brigade_cleanup(bb); (gdb)   And 2.0.40-dev from cvs DoS-ed too.  p.s.  OS: FreeBSD 4.5 and 4.6 releases  b.r.  Kozin Maxim	Created an attachment (id=2156) code for DoS 2.0.39 on FreeBSD 4.[56]  Fixed in CVS.  Will be included in next release (2.0.40).  Thanks for using Apache httpd!			Justin Erenkrantz	Kozin Maxim
10147	null	CLOSED		Christoph Vogel	1024753320000	1025121675000		Broken ExtFilterOptions DebugLevel Actually I tried to find out how to escape ExtFilterDefine commands correctly.  I defined  ExtFilterDefine sed-replace cmd='/bin/sed s/verdana/arial/g'  as an example (the actual problem was that cmd='/bin/sed 's/verdana/arial/g''  doesn't work). This external filter works okay with Set/AddOutputFilter. To debug the command I added  ExtFilterOptions DebugLevel=9  to the corresponding <Directory> context. But then the ExtFilter stops working  and gives me  [error] couldn't find definition of filter 'sed-replace'  in my error_log and a related error is given back to UA. Nothing else has been  changed after adding the ExtFilterOptions directive.	I wasn't able to reproduce the lost filter definition when using this configuration:  <Directory /photo> DirectoryIndex index.cgi Options Indexes ExecCGI AddHandler cgi-script .cgi  SetOutputFilter sed-replace ExtFilterOptions DebugLevel=9 </Directory>  ExtFilterDefine sed-replace cmd='/bin/sed 's/photos/picurs/g''  (I didn't see any output at the client because sed got confused by the single quotes.  When I remove the single quotes it works fine.)  Can you spot something about my testcase which is inconsistent with your description, or can you perhaps supply a set of minimal changes to the default httpd-std.conf which would expose the problem?  Thanks so much!  (Certainly I need to update the doc to describe quoting issues like this!!)  I did it the other way 'round and tried to reproduce your situation :) It does work if the ExtFilterDefine and the ExtFilterOptions statement are  located _within the same VH_. In my configuration ExtFilterDefine is located in the main config (so I can  reuse it otherwhere) and ExtFilterOptions + SetOutputFilter in a directory  context within a VH. Contrarily the ExtFilter works fine in this situation if  ExtFilterOptions is not set. So the bahaviour is inconsistent and I think one  should have the possibility to split Define and Options for ExtFilter just like  I did. Apart from that - wouldn't it be nice to have a separate logfile for ExtFilters  just like with CGIs oder URL rewriting? I dunno if it's a enough for a formal  feature request. Thanks for the update...  I was able to reproduce and am working on a change to mod_ext_filter so that filter definitions can be used across multiple servers/vhosts.  (I'm ignoring your feature request for the moment :) )  Thanks again!  mod_ext_filter has been changed to find filter definitions in the main server in case they weren't defined in the vhost...  the patch as committed is below, and will be in the next release of Apache:  http://cvs.apache.org/viewcvs.cgi/httpd- 2.0/modules/experimental/mod_ext_filter.c.diff?r1=1.29&r2=1.30  I tweaked the documentation to try to clarify how parameters to the external program are specified.  In addition, I added a new example which you might recognize.  If you really want to have stderr from the filter written to a file, please write another PR for the feature request.  I don't personally plan on doing anything about that unless it is clear that there is a widespread desire for it.  (Other folks may be interested however.) Note that the LogStderr option (on the ExtFilterOptions directive) can  be used to capture the external filter's stderr in the Apache error log.  Thanks again for your report! 			Christoph Vogel	Jeff Trawick
10216	null	CLOSED		Jiri Novak	1025016060000	1036417929000		ISAPI + SSL = status 200 as 500 after correct reply When I use ISAPI Extenstion and SSL, Apache attach after correct ISAPI reply  page with title: 200 OK  ------------------------------------------------------------------------ OK The server encountered an internal error or misconfiguration and was unable to  complete your request.  Please contact the server administrator, jira.novak@gecapital.com and inform  them of the time the error occurred, and anything you might have done that may  have caused the error.  More information about this error may be available in the server error log.  Apache/2.0.39 Server at ssl666cgcfge Port 443 ------------------------------------------------------------------------  This is message for status 500, but it is status 200!  Any idea? Thanx Jiri	Primary, I need load and CACHE any cgi script (windows library) without  unloading. I'm windows programer so I don't know other option except ISAPI...  Any help please? I traced SSL is without influence... Hi again boys.  I changed line 1532 in 'mod_isapi.c' from       /* Set the status (for logging) */     if (cid->ecb->dwHttpStatusCode) {         cid->r->status = cid->ecb->dwHttpStatusCode;     }  to      /* Set the status (for logging) */     if (cid->ecb->dwHttpStatusCode && cid->ecb->dwHttpStatusCode!=200) {         cid->r->status = cid->ecb->dwHttpStatusCode;     }  I don't check what you do with 'cid->r->status' variable, but it resolve my problem.  Ave, GeniuZ     Have just committed a bugfix for this report.    Rather than Status!=200 tests, we will simply track response_sent, and   once it has been sent, we will return 0 (assuring the server core module   that it's been handled.)  This also assures that if the ISAPI module wants   to return the 200, or 500, or redirect, and completely handles it internally,   that this bug won't appear again.			Jiri Novak	Will Rowe
10259	null	CLOSED		Rodent of Unusual Size	1025116380000	1029783405000		charset always being added to Content-Type on redirects The Content-Type of a redirection response appears to always have a charset parameter added, even if 'AddDefaultCharSet Off' is in effect.  This confuses some browsers when they try to use the META tags in the target document.	It is supposed to have a charset param when not using custom errordocuments beca use we output a response body with HTML in it, and we are specifying what charse t that response body has.  This is not a 'default' charset, it is the charset th at we wrote the document in.  Since the generated page uses ISO-8859-1 the charset parameter is allowed but  not required on the redirect response. Removing the charset attribute will have  no effect on compliant browsers, and resolve the issue for non-compliant  browsers. The current Apache behaviour is correct but breaks some older versions of  Netscape. I suggest code be added to enable a BrowserMatch directive to  selectively disable adding the charset (specifically on redirects?). The suppress-error-charset variable is now available for this purpose.			Bill Stoddard	Joshua Slive	Klaus Johannes Rusch	marcs@znep.com
10324	null	CLOSED		Stephan Austerm	1025277600000	1028130308000		typo prevents 2.0.39 w/ cvs ldap modules to build --- /home/au/src/ldap/httpd-ldap/ldap-cache/util_ldap.c Tue May 28 21:32:30 2002 +++  util_ldap.c Fri Jun 28 17:14:02 2002 @@ -274,7 +274,7 @@    #ifdef  APU_HAS_LDAP_NETSCAPE_SSL          if (ldc->netscapessl) { -            if (!ldc->certdb) { +            if (!ldc- >certtdb) {                 /* secure LDAP requested, but no CA cert defined */                  ldc->reason = 'secure LDAP  requested, but no CA cert defined';                  return -1;	I renamed the field certtdb to certdb in util_ldap.h (part of httpd-2.0 distribution).  I don't see the word 'certtdb' being used anywhere else in the world :)  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
10422	null	CLOSED		William Campbell	1025638320000	1025639416000		htpasswd overwrites last user, no more users can be added htpasswd in 2.039 does not add new users, it just replaces the last one (from the command line).  This occurs both before and after applying the (-c -n  patch).      htpasswd from 1.3.24 can be used successfully with httpd 2.0.39	Fixed in CVS, we weren't adding a newline at the end of each record. *** Bug 10221 has been marked as a duplicate of this bug. *** Why did no one look at bug 10221?  I had this issue fixed via an attached patch  on 6/27, while it was fixed in CVS until 7/2.  Basically, I'm just wondering  what, if anything, I need to do differently to be heard. I searched the database for this problem and saw nothing similar, otherwise I  would not have posted it.  Just a word. People actually try to track the bug db, but it's mostly done in their spare time, which is quite limited, as you may guess.  Thanks for your reports and for using Apache.			Andr?? Malo	Cliff Woolley	Jon Noack	Ryan Bloom	William Campbell
10424	null	CLOSED		Jens Kubieziel	1025641200000	1025646768000		' The word 'privileges' is on certain places in the docu misspelled. The wrong word is  'privilages'.	Thanks for your report.  This has now been fixed in CVS and updated on httpd.apache.org.  			Jeff Trawick
10430	null	CLOSED		Phil Almquist	1025657520000	1037796781000		highperformance-std.conf and manual inconsistant with worker mpm <IfModule worker.c> MaxClients       8 StartServers     3 MinSpareThreads  5 MaxSpareThreads 10 ThreadsPerChild 25 </IfModule>  [root@kote k0te]# /www/bin/apachectl startssl WARNING: MaxClients (8) must be at least as large  large as ThreadsPerChild (25). Automatically  increasing MaxClients to 25. [root@kote k0te]#	The doc was fixed some time ago.  The config in highperformance-std.conf was just now fixed and will be in the next release.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
10449	null	CLOSED		Alex D. Baxter	1025719560000	1045690988000		suexec allows environment variables not in the safe list Due to the way suexec checks environment variables in the environment against the compiled-in safe list to decide if variables should be allowed through to the executed CGI program, environment varibles *not* explicitly defined in the safe list are allowed through if the beginning of the variable name matches a variable in the safe list.  This may be by design, in which case the suexec documentation should be amended appropriately.  I cannot see how this could ever be a security problem.  The 'problem' appears in both the 1.3.26 and the 2.0.39 versions of suexec.c, and I have verified it at runtime in Apache 1.3.26.  The problematic code appears in apache_1.3.26/src/support/suexec.c, function clean_env():  static void clean_env(void) {     char pathbuf[512];     char **cleanenv;     char **ep;     int cidx = 0;     int idx;       if ((cleanenv = (char **) calloc(AP_ENVBUF, sizeof(char *))) == NULL) {         log_err('emerg: failed to malloc memory for environment/n');         exit(120);     }      sprintf(pathbuf, 'PATH=%s', SAFE_PATH);     cleanenv[cidx] = strdup(pathbuf);     cidx++;      for (ep = environ; *ep && cidx < AP_ENVBUF-1; ep++) {         if (!strncmp(*ep, 'HTTP_', 5)) {             cleanenv[cidx] = *ep;             cidx++;         }         else {             for (idx = 0; safe_env_lst[idx]; idx++) {                 if (!strncmp(*ep, safe_env_lst[idx],                              strlen(safe_env_lst[idx]))) {                      ^^^^^^^^^^^^^^^^^^^^^^^^                      ! note only checked to length safe_env_lst[idx] variable!                     cleanenv[cidx] = *ep;                     cidx++;                     break;                 }             }         }     }      cleanenv[cidx] = NULL;      environ = cleanenv; }  I suppose one way of fixing this to do exact comparisions would be (avoiding calling strlen() on an 'untrusted' environment variable):              for (idx = 0; safe_env_lst[idx]; idx++) {                 if (!strncmp(*ep, safe_env_lst[idx],                              strlen(safe_env_lst[idx])                      && *ep[strlen(safe_env_lst[idx])]=='/0')) {                     cleanenv[cidx] = *ep;                     cidx++;                     break;                 }             }  Alternatively this could just be described as a feature, in which case this paragraph in htdocs/manual/suexec.html.html should be amended appropriately:        <li>         <strong>Can we successfully clean the process environment         to ensure safe operations?</strong>           <blockquote>           suEXEC cleans the process' environment by establishing a           safe execution PATH (defined during configuration), as           well as only passing through those variables whose names           are listed in the safe environment list (also created           during configuration).         </blockquote>       </li>	hmm, shouldn't one check for a '=' sign?  (or alternatively append a '=' to the variable names within the 'safe' list?) Options? I guess it could be fixed with just a quick strlen comparison.  But note that this is probably not a security risk.  The point of cleaning down the environment is to prevent unsafe env variables from being passed (think LD_LIBRARY_PATH, etc).  It is HIGHLY unlikely that an attacker would be able to construct an unsafe env variable using a prefix of a safe env variable. strlen doesn't work here, because the env array consists of enties ala 'PATH=/foo/bar'.  But you're right, it's not really a security risk. But I'm pedantic ;-)) I found, however, <http://bugs.apache.org/index.cgi/full/2790> and I think, most of the stuff suggested there is worth to be patched. (the current problem is also described there - with the same solution, I proposed here 5 years later ;-) Well, it's fixed in 2.1 and proposed for backport.  Thanks for the report and thanks for using Apache! The fix will appear in 1.3.28 and 2.0.45.			Andr?? Malo	Joshua Slive
10460	null	CLOSED		Tamer Abdelgawad	1025740260000	1029704290000		Service Monitor reports wrong service state On Win2kPro with one administrator and two superuser accounts, the Apache Service Monitor (tray) in the superuser accounts reports incorrectly that the Apache2 service is not running, when in fact it is.  It does report the correct status in the administrator account, which was used to install the Apache2 service.  In the superuser accounts, the 'Stop' button is grayed out, and the 'Start' button doesn't do anything.  'net stop apache2' and 'net start apache2' work fine from the command line in the superuser accounts, but have no effect on the Server Monitor status.	   I believe we have addressed this in Apache 2.0.40 - please upgrade   and check out the new behavior.  There were several bogus permission   assumptions that -have- been fixed. Done and done.  Service monitor now works correctly with 2.0.40.  Thanks.			Tamer Abdelgawad	Will Rowe
10574	null	CLOSED		Phil Almquist	1026178140000	1029944730000		mod_include exec requires mod_cgi, just a documentation problem? -nt- mod_include's exec directive requires mod_cgi, this probably isnt a bug but it's undocumented.	*** Bug 10514 has been marked as a duplicate of this bug. *** I'll take this as a documentation bug. Thanks.  This will be fixed in the next release.			Joshua Slive	Phil Almquist
10575	null	CLOSED		Phil Almquist	1026178320000	1089427557000		no option to autoindex auth protected files/folders nt	To be a bit more verbose -   mod_autoindex hides directories and files that require authentication, which leads to a catch-22; how does someone find the file to log in if they can't see that it exists?  It's very nifty that it can hide authentiated resources *if* the site requires users to log in earlier; however, this doesn't work in all situations.  Therefore, it's necessary to have an option where this behaviour is turned off.  [changing the severity, as this isn't an enhancement; it's a bug in a 2.0 enhancement ] I know It's silly to argue over the serverity level, but this was a deliberate design decision,  and hence can't be classified as a bug.  It was considered unsafe to give un-authenticated users information on areas of the server to which they don't have access.  Yes, it would be nice to be able to turn this off.  But it's not a bug. wow i forgot this bug report even existed since ive stopped using autoindex (due to this problem actually).  this might only be an enhancement but it is very necessary for doing seemingly simple things like indexing userdirs and forces the user to create their own custom cgi or similar autoindex which is not at all an ideal solution.  other than requiring auth in the root directory which is not an option there is currently no possible way to have a completely autoindexed site that uses any sort of authentication.  with the new header / footer options and other enhancements mod_autoindex is becoming much more useable and more integrated in websites structures; it would be very nice if it wasnt incompatable with authentication.  i had to tweak the mod_autoindex.c in the latest version of apache to get it to work right.  here are my work-arounds:           //if (!(p->icon = find_icon(d, rr, 1))) {                 // was getting wrong icons on folders                 p->icon = find_default_icon(d, '^^DIRECTORY^^');             //}             if (!(p->alt = find_alt(d, rr, 1))) {                 if (!(p->alt = find_default_alt(d, '^^DIRECTORY^^'))) {                     p->alt = 'DIR';                 }             }         }         else {             p->icon = find_icon(d, rr, 0);             p->alt = find_alt(d, rr, 0);             p->size = rr->finfo.size;         }           p->desc = find_desc(d, rr->filename);          if ((!p->desc) && (autoindex_opts & SCAN_HTML_TITLES)) {                 //added this check -- was getting garbage description on folder            if (dirent->filetype != APR_DIR)                   p->desc = apr_pstrdup(r->pool, find_title(rr));         }  This patch doesn't solve the problem of hiding directories with authenticated access does it? Is there any patch which does this work? Or any other workaround? I need it very much...  Thanks, Martin Created an attachment (id=11165) Finally I found a workaround - this dirty hack disables directory hiding feature.  Can this feature be brought back?  Perhaps be default, auth protected dirs files can be hidden, but allow to specify to display hidden directories and files with IndexOptions?   Incoming Patch adds a new IndexOptions Command 'ShowForbidden'.  This will list directories or files that normaly wouldn't be shown because the subrequest returns  forbidden.  This patch is against 2.1-CVS Head. Created an attachment (id=11890) Adds 'ShowForbidden' to IndexOptions  Oooh, nice, +1.  Watch the code style though:  +    if((autoindex_opts & SHOW_FORBIDDEN) &&  +       (rr->status == HTTP_UNAUTHORIZED || rr->status == HTTP_FORBIDDEN)) {  should be:     if ((blah)        && (blee)) {  (I also detest the (1 == foo) style rather than (foo == 1) but that's not in the style guide :) Patch Commited to 2.1.  Thanks for the feature request!  -Paul Querna *** Bug 30854 has been marked as a duplicate of this bug. *** *** Bug 35443 has been marked as a duplicate of this bug. ***			Joe Orton	Jose de Leon	Joshua Slive	Mark Nottingham	Martin Horak	Paul Querna	Phil Almquist	andy d
10617	null	CLOSED		Arthur P. Smith	1026253200000	1026302387000		SegFault in mod_ext_filter when content_type is null This happens when a filtered URL returns a Location: redirect (the example I looked at was the Zope management console) - the bucket-brigade for the (non-existant) body is forwarded to the external filter, but no content_type is set (and there is no content). You obviously don't want to filter a content-less body. The following is a patch to mod_ext_filter.c that fixes the problem:  *** mod_ext_filter.c    Tue Jul  9 18:01:47 2002 --- mod_ext_filter.c_orig       Tue Jul  9 17:57:05 2002 *************** *** 491,499 ****           return APR_EINVAL;       }       ctx->p = f->r->pool; !     if ((f->r->content_type == NULL) || !       (ctx->filter->intype && ctx->filter->intype != INTYPE_ALL && !         strcasecmp(ctx->filter->intype, f->r->content_type))) {           /* wrong IMT for us; don't mess with the output */           ctx->noop = 1;       } --- 491,499 ----           return APR_EINVAL;       }       ctx->p = f->r->pool; !     if (ctx->filter->intype && !         ctx->filter->intype != INTYPE_ALL && !         strcasecmp(ctx->filter->intype, f->r->content_type)) {           /* wrong IMT for us; don't mess with the output */           ctx->noop = 1;       }	Note this was for a location also serviced by mod_proxy - I haven't tried it for CGI or other ways you could get a Location: directive returned, so it could be really a problem in mod_proxy. I'd suspect mod_ext_filter though first. mod_ext_filter definitely needs to watch out for NULL content_type. At the very least, the if statement should be changed to:       if (ctx->filter->intype &&          ctx->filter->intype != INTYPE_ALL &&          (!f->r->content_type ||           strcasecmp(ctx->filter->intype, f->r->content_type))) {  So if the user specifies a certain content_type to process we'll make certain that there is a content_type associated with the response. I do not know whether or not a NULL content_type always implies that there  is no actual response body.  I doubt that it is true in general.    mod_ext_filter should already handle an empty response okay (or that is another  bug :) ), so the fix above should be sufficient for your problem and we don't worry about whether or not there is a response body to filter.  Good point - your fix is definitely the right one. Thanks! The fix has been committed and will be in the next release of Apache.  Thanks for your report/patch, and thanks for using Apache! 			Arthur P. Smith	Jeff Trawick
10644	null	CLOSED		Carsten Gaebler	1026312240000	1034821164000		no support for dbm rewrite maps configure sets -DNO_DBM_REWRITEMAP regardless of any installed (n|g)db(m) libraries and header files.	Applies to 2.0.40 too. Dirty hack for me was comment the following section in  configure:    if test 'x$CFLAGS' = 'x'; then     echo '  setting CFLAGS to /'-DNO_DBM_REWRITEMAP/''     CFLAGS='-DNO_DBM_REWRITEMAP'   else     apr_addto_bugger='-DNO_DBM_REWRITEMAP'     for i in $apr_addto_bugger; do       apr_addto_duplicate='0'       for j in $CFLAGS; do         if test 'x$i' = 'x$j'; then           apr_addto_duplicate='1'           break         fi       done       if test $apr_addto_duplicate = '0'; then         echo '  adding /'$i/' to CFLAGS'         CFLAGS='$CFLAGS $i'       fi     done   fi  /modules/mappers/config9.m4 makes configure always set NO_DBM_REWRITEMAP. mod_rewrite has just been changed to use the apr-util dbm interface. This change will be in the next release of Apache 2.0.x.  For now, the SDBM dbm flavor is always used.  It won't be compatible with dbm rewrite maps built for Apache 1.3 until apr-util supports ndbm and mod_rewrite is changed to prefer ndbm over the built-in sdbm.   Someone has expressed to work on ndbm support soon, so  hopefully that change will be in the next Apache 2.0.x release too.  The PR should be kept open until the ndbm support is available.  Thanks for your report, and thanks for using Apache.  ndbm support is now in.  This is fixed.			Christoph Vogel	Ian Holsman	Jeff Trawick	Joshua Slive
10678	null	CLOSED		Thomas K	1026380700000	1058217047000		Several .htaccess files are consulted, REMOTE_USER gets dropped Hello,  I am using Apache 2.0.39, but unfortunately the REMOTE_USER environment  variable gets lost, when limiting access by means of .htaccess. In  contrast to this it is possible to limit the access in the httpd.conf file.  works:   Virtual Host Config:     <Location /dir>         AuthType Basic         AuthName Test         AuthUserFile /path/to/file         Require valid-user     </Location>  doesn't work:   .htaccess:         AuthType Basic         AuthName Test         AuthUserFile /path/to/file         Require valid-user  Is there a special reason, why the REMOTE_USER variable is dropped in the second case and how can I avoid this behaviour? When trying to access a Document in '/dir' one is asked for password as usual, but even a simple Shell-script just writing the environment to a file, does not show the REMOTE_USER variable. The script was configured using AddHandler and Action.  AddHandler testhandler .test Action testhandler /cgi-bin/testscript  'testscript' contains:  #!/bin/sh echo -e 'Content-Type: text/plain/n/nhello world/n'; set > /tmp/testscript-output  Thanks in advance!  Ciao, Thomas	It works with Apache 1.3.26 so it's not an usage problem. .htaccess isn't the problem.  It seems more to be in the use of AddHandler and  Action.  If a similar simple script exists in the directory and is executable under the  ExecCGI rules, then REMOTE_USER is passed: .htaccess:     AuthType Basic     AuthName Test     AuthUserFile /path/to/password/file      Require valid user (or Require user name)  Then a script in that directory like this shows the environment variable:  test.cgi: #!/bin/sh echo 'Content-Type: text/plain' echo echo 'Remote User: $REMOTE_USER'  However, identifying such a script in an Action or Script directive causes the  variable to be lost somewhere, as in this as well as the case originally  outlined:  httpd.conf: Script PUT /path/to/the/above/script  .htaccess:    AuthType Basic    AuthName 'no REMOTE_USER'    AuthUserFile /path/to/password/file     <Limit PUT>       Require user name    </Limit>  and the variable REMOTE_USER does not appear.     A further interesting effect occurs when using two .htaccess files.  1.)  htdocs/.htaccess: AuthType Basic AuthName Test AuthUserFile /home/test/htdocs/.htpasswd Require user b AddHandler test-script .sh Action  test-script /cgi-bin/test.cgi  cgi-bin/.htaccess: #empty  When trying to access a document test.sh. The server asks for user b's  password, but the REMOTE_USER variable doesn't exist.   2.)  htdocs/.htaccess: AddHandler test-script .sh Action  test-script /cgi-bin/test.cgi  cgi-bin/.htaccess: AuthType Basic AuthName Test AuthUserFile /home/test/.htpasswd Require user a  The server asks for user a's password and the REMOTE_USER variable is shown.  To my mind this behavious is wrong because two .htaccess files are consulted, but not fully applied.  This may be the same bug as #11602.  I encountered the same problem when moving from 1.3.12 to 2.046. As suggested  by Joseph M. Hinkle, this has to do with mod_action, NOT .htaccess.   My config is as follows (Apache 2.046, Windows NT 4.0)  Action etat-ge-tdb /cgi-bin/tdb.cgi AddHandler etat-ge-tdb .tdb  In my Apache 1.3.12 config, there was no access limit on the script 'tdb.cgi'. Some of my *.tdb files had access limits, and in those cases the REMOTE_USER  was appropriately passed to tdb.cgi. Now it now longer works with Apache 2. My  workaround was to add a 'require valid-user' directive for /cgi-bin/tdb.cgi,  but this is not fully satisfactory since it is no longer possible to have  anonymous access for some of my *.tdb files.  Note : in Apache 1.3.12, I used MIME types instead of AddHandler; but this is  not the cause of the problem (Action with MIME types in Apache 2.046 still  does not transmit the REMOTE_USER). The problem is fixed in 2.1. The remote user of the original request will be passed via REDIRECT_REMOTE_USER to the script, which is even more logical than the old behaviour. If you want to get REMOTE_USER direcly, you should protect the script itself (which works already fine).  I'll propose it for backport to 2.0 stable branch.  Thanks for using Apache! *** Bug 11602 has been marked as a duplicate of this bug. *** *** Bug 21927 has been marked as a duplicate of this bug. *** This was fixed in 2.0.48-dev. If the target script is not protected, it will get the REDIRECT_REMOTE_USER env variable, containing the original user. Supplying r->user to an unprotected script is wrong (even in 1.3.x) and therefore not supported. *** Bug 29812 has been marked as a duplicate of this bug. ***			Andr?? Malo	Christian Hammers	Joseph M. Hinkle	Mark Jason Dominus	Thomas K	laurent dami
10773	null	CLOSED		Hunter Peress	1026580860000	1044887679000		Acccess warning is not informative when trying to run cgi the permissions of this cgi are such that there is an access violation. It was 777, and I was getting: ------------------------------- Server error! Error message: Premature end of script headers: t.cgi  If you think this is a server error, please contact the webmaster Error 500 Apache/2.0.36 (Unix) PHP/4.2.1 -------------------------------  a different error message would be more useful.	so whe  I changed the code to 755, the cgi executed fine. If you are using suexec, then the security restrictions prevent more info from being passed back to apache.  But you will find a more detailed error report in the suexec log file.  Thanks for using Apache! suexec now (in 2.1) sends a message to stderr, that something within suexec happened. The actual information is still available in suexec's log. And therefore I'll mark this bug as fixed.			Andr?? Malo	Hunter Peress	Joshua Slive
10920	null	CLOSED		Bjoern A. Zeeb	1026937620000	1028058444000		http-ldap / util_ldap.h only working with threads enabled As suggest first posted to apache users but go no answer so here we go ...  was just looking at http-ldap CVS checkout from 2002-07-12 and httpd-2.0.39.  When compiling on FreeBSD threads are disabled by default in apache2 as stated in INSTALL.  compiling --with-ldap will fail because include/util_ldap.h uses apr_thread_mutex_t but as APR_HAS_THREADS is defined 0 that struct (typedefed somewhere else) from         srclib/apr/include/arch/unix/thread_mutex.h is not known.  ldap-aaa and ldap-cache also seem to depend on threads.  My question now is:  a) ldap stuff should also work without threads ? so can someone who    knows the code please have a look at and change it to also work    without threads.  b) please check for threads in configure when you need    them and do not allow the user to compile without; I am not    talking about -lpthread, which will also be found on FreeBSD,    but --{enable,disable}-threads.    [ ok, this may be tricky within actual build framework but      this should no longer be necessary if a) is done ;-) ]	The ldap code now supports a non-threaded environment such as APR-on-FreeBSD.  util_ldap.h was updated in httpd-2.0 CVS and various pieces were updated in  httpd-ldap CVS.  Your point about checking for features at configure time and disabling function as necessary is well taken.  Various such checks are present. There aren't too many people using the ldap code yet so it fell through the cracks.  Thanks for your report, and thanks for using Apache!  			Jeff Trawick
10946	null	CLOSED		m wolf	1027001520000	1028651502000		redundant slashes in urls cause 403 Forbidden errors Trying to retrieve http://foo.ximian.com/bar.html will work, but trying to retrieve http://foo.ximian.com//bar.html (note the redundant slashes) fails with a 403.  For what it's worth, http://foo.ximian.com/baz//baz.html works OK.    As a workaround, I used mod_rewrite in a manner similar to this:     RewriteEngine On     RewriteRule ^//(.*$) /path/to/docroot/$1 This works, and the performance hit doesn't seem to be especially great, but it isn't ideal.	I'm suffering from the same problem, but in my (a bit more) complex server  setup the rewrite rule would have to be split up in multiple rules.  To clearify the things I tried to get some output in the error log, but even  in 'LogLevel debug' I don't get any message there. It is only noted in the  access log as 'GET //file'.  I'm not sure if this is expected or even allowed behavior, but the following patch should allow you to use redundant slashes.  Created an attachment (id=2475) patch     This bug is fixed in CVS, and that patch will hopefully be included    in the forthcoming Apache 2.0.40 release.    Thanks for the detailed reports, and the suggested patch, David.   I had to attack it a bit differently, there were actually two code   paths to be dealt with, your patch fixed one of them.  Co-credit and   kudos anyways for hacking in a fix! 			David Shane Holden	Stefan Steinbeck	Will Rowe
10961	null	CLOSED		Sean M. Alderman	1027018740000	1051201325000		 does not pass environment back to the browser The following configuration example causes loss of the query string...  Servername xxx.xxx.com #ScriptAlias /cgi-bin/ /usr/local/apache/cgi-bin <Directory /> Redirect /cgi-bin/ http://yyy.xxx.com/cgi-bin/  ...  </Directory>  ----- With the above config - Browser is pointed to http://xxx.xxx.com/cgi-bin/some.cgi?q=abc Browser is sent a 302 with new location at http://yyy.xxx.com/cgi-bin/some.cgi -----  Using the redirect outside of the <Directory XYZ> block functions properly  ServerName xxx.xxx.com #ScriptAlias /cgi-bin/ /usr/local/apache/cgi-bin/ Redirect /cgi-bin/ http://yyy.xxx.com/cgi-bin/ <Directory /> ... </Directory>  ---- Browser points to http://xxx.xxx.com/cgi-bin/some.cgi?q=abc Browser is sent a 302 with location of http://yyy.xxx.com/cgi-bin/some.cgi?q=abc ----  I have tested this repeatedly on RedHat 7.3 and Solaris 8.  Verifying both visually with the browser and a network sniff.	The problem is fixed in main dev branch (2.1) and proposed for backport.  Thanks for your report and thanks for using Apache! FYI: Finally merged into the 1.3 and 2.0 stable trees (1.3.28 and 2.0.46 will include the fix).			Andr?? Malo
10993	null	CLOSED		Peter Bieringer	1027103580000	1031065396000		Missing MIME type image/x-icon MIME type image/x-icon for the shortcut icon is missing, wrong MIME type is  sent, even if mime_magic was enabled.  Also happen on 1.3.x series.  Fix:  --- mime.types.orig     Fri Jul 19 20:13:46 2002 +++ mime.types  Fri Jul 19 20:14:51 2002 @@ -380,6 +380,7 @@  image/vnd.wap.wbmp             wbmp  image/vnd.xiff  image/x-cmu-raster             ras +image/x-icon                   ico  image/x-portable-anymap                pnm  image/x-portable-bitmap                pbm  image/x-portable-graymap       pgm	Hmmm... We have a policy of only adding officially-registered MIME types to our mime.types file.  This one may be common enough to warrent an exception.  Other opinions? *** Bug 12241 has been marked as a duplicate of this bug. *** done. this should be in 2.0.41 done for 2.0.41			Ian Holsman	Joshua Slive
11030	null	CLOSED		Frodo Looijaard	1027327980000	1028119625000		: double bind "Listen IPADDR' works fine; "Listen HOSTNAME' not. It seems Apache tries to  bind twice in this last case, and crashes without even writing something to the  Errorlog (it seemt to try to write to stderr, though).  See the attached output of "truss -f -a -e -vall -rall -wall bin/apachectl  start > /tmp/out.txt 2>&1'. Line 1774 and line 2989 try the same bind; the  second one fails of course.  We use Solaris 2.8 (it also occurred for 2.0.36 in Solaris  2.6); /etc/nsswitch.conf contains "hosts: files dns' and the problem occurs  both when the hostname aplux11-a is in /etc/hosts and when it is not (it is  always in DNS).	Created an attachment (id=2435) Truss log  Created an attachment (id=2461) patch  A fix for this was just committed and will be in the next release of Apache.  Thanks for the report, and thanks for using Apache!  Thanks especially to Mr. Holden, whose debugging and initial patch pointed out the problem. 			David Shane Holden	Frodo Looijaard	Jeff Trawick
11041	null	CLOSED		Erik Sj	1027347600000	1027359158000		' The text at http://httpd.apache.org/docs-2.0/mod/core.html#usecanonicalname  'if ServerName is set to www.example.com and Port is set to 9090'  where 'Port' is marked as though it was a d??rective, is misleading because Port is in httpd 2.0 no longer a directive.  A suggestion how it could be stated instead:  'if ServerName is set to www,example.com:9000'	You are, indeed, correct.  But I find the whole paragraph irrelevant now that the ServerName and Port are unified, so I'll just delete it.  Thanks for your help!  Meant to close this...			Joshua Slive
11212	null	CLOSED		Marcus Leon	1027701900000	1040386977000		Apache2 apxs still adds the AddModule statement to httpd.conf This is a bug as AddModule is no longer suported in Apache 2, I believe.	Created an attachment (id=3989) Remove AddModule support from apxs  A fix has been submitted to the black hole known as dev@httpd. This patch was committed to HEAD.			Joe Orton
11213	null	CLOSED		Ian Darwin	1027704720000	1029789655000		Inadequate message when module is rejected. Fix attache; please commit The version number message when a module is rejected due to incompatibility should print the actual version number of the failed module and the server.  A patch will be attached to this bug number.	Created an attachment (id=2500) Patch to provide better error message.  Commited.. Thanks for the patch!			Ian Darwin	Ian Holsman
11310	null	CLOSED		Charles Reitzel	1028067480000	1049783484000		> The VC6 mod_ssl build doesn't work unless I do one of two things:  1) Place both D:/code/3rdParty/openssl-0.9.6c/include AND D:/code/3rdParty/openssl-0.9.6c/include/openssl in my include path.  or   2) Update mod_ssl.h as follows:  /* OpenSSL headers */ #include <openssl/ssl.h> #include <openssl/err.h> #include <openssl/x509.h> #include <openssl/pem.h> #include <openssl/crypto.h> #include <openssl/evp.h> #include <openssl/rand.h> #ifdef SSL_EXPERIMENTAL_ENGINE #include <engine.h>   /* Not sure, <openssl/engine.h>? #endif  #include 'ssl_toolkit_compat.h'  #ifdef HAVE_SSL_X509V3_H #include <openssl/x509v3.h> #endif  Recommend the latter (#2) as this is the convention used by OpenSSL itself and,  therefore, most OpenSSL apps.  Thanks, Charlie	Hi Charlie,   Although I'd like to do this, I'm curious to know if there any specific  reason why you want it to be done ?.  -Madhu Hi Mahdu,  The convention with OpenSSL and many other packages is to have a top-level  include directory.  It avoids file name conflicts and just makes the code  clearer.  Thus, the appropriate directory to have in the INCLUDE path is  $OPENSSL_HOME/include and the syntax in your source code should be  #include <openssl/somefile.h>  NOT  #include <somefile.h>  This way a) it will build on MSVC and b) I can use the same INCLUDE setting for  my own OpenSSL code as Apache 2.  Thanks Charlie I've committed the changes to HEAD. Can you please verify (if possible) and  close the bug ?.  Thanks -Madhu    No response from reporting - I've verified this myself and am   tagging the report fixed. 			Charles Reitzel	Madhusudan Mathihalli	Will Rowe
11428	null	CLOSED		Brian Gallew	1028305920000	1068402244000		mod_auth_anon and many userids In the past, mod_auth_anon allowed you to configure things such that any  userid was valid.  Here is a patch which will re-implement that behaviour.   Once this patch is applied an 'Anonymous *' stanza will allow any userid to  match.  *** mod_auth_anon.c.old Fri Aug  2 12:22:07 2002 --- mod_auth_anon.c     Fri Aug  2 12:14:38 2002 *************** *** 240,245 **** --- 240,247 ----         while ((res == DECLINED) && (p != NULL)) {             if (!(strcasecmp(c->user, p->password)))                 res = OK; +           if (p->password[0] == '*') +               res = OK;             p = p->next;         }       }	In the past? NCSA? couldn't find it in CVS down to apache 1.2 ;-)  But, ehm, how is it useful? If one can supply any uid with any password... why the effort? It's extremely useful in a two-tiered authentication system.  Let's say, for instance, that you have a firewall.  Further, that your business application lives 'inside' the firewall, while the authentication system is only operative 'outside' the firewall.  Apache on the firewall machines can do authentication just fine.  Apache on the internal machine cannot.  Instead, they have to believe that anything that gets through has already been authenticated.  This is exactly what I use this for. I hope, you're checking the anon uids in any other way. Otherwise everybody behind the firewall is granted access to the system...  I have, however, another security problems in my mind, because one can easily compromise the log files (by using weird user ids). Hmm. I'm changing this to WONTFIX for 1.3 (maintenance mode) but consider this to be an enhancement for 2.1.  Thanks for using Apache. Reopen to resolve FYI: Applied the enhancement to the 2.1 branch. As said before, it probably won't backported.			Andr?? Malo	Brian Gallew
11467	null	CLOSED		Steve Holden	1028559720000	1029008593000		Typo in htdocs/index.html.var The (Dutch?) content is incorrectly encoded in the htdocs/index.html.var file as  URI: index.html.nl Content-language: nl Contenty-type: text/html  The last line should, of course, begin with 'Content-Type:'	null	
11475	null	CLOSED		Chris Darroch	1028566320000	1073954071000		t contain cookies If the CookieStyle configuration directive is set to Cookie2 or RFC2965, then mod_usertrack sets dcfg->style = CT_COOKIE2.  In turn, the spot_cookie() function will then parse the Cookie2: request header, looking for the Apache cookie:      cookie = apr_table_get(r->headers_in,         (dcfg->style == CT_COOKIE2 ? 'Cookie2' : 'Cookie'))  However, reading the RFC 2965 specification, specifically section 3.3.5, it appears to me that the Cookie2: header is only used to indicate the highest version of the cookie specification that the client understands. Per 3.3.4, the actual cookie values are still sent in the Cookie: header. (See also 9.1 and the examples under 4.1 and 4.2.)  As a further note, it seems to me -- I could be reading the spec or code incorrectly, of course -- that the cookie parsing code in spot_cookie() may not really work with RFCs 2109 or 2965, because it doesn't accept commas as cookie delimiters, nor the whitespace or double-quote (') quoted-strings allowed by those RFCs.  See 10.1.3 in RFC 2109, as well as 4.1 and 4.3.4 in RFC 2109, and 3.1 and 3.3.4 in RFC 2965. My apologies if I've misread something!	Looking at the spot_cookie() code a bit more, I'm also suspicious that it may be confused by both RFC 2965-style cookies (which can have quoted-string values, with escaped characters).  Further, I think it will also be confused just by old-style cookies where the string 'Apache' (or whatever the cookie name it's looking for is) appears in a cookie name or value somewhere before the actual cookie name/value pair in the header.  For example, I suspect 'Apache2=foo; Apache=bar' or 'foo=Apache; Apache=bar' would both cause the apr_strstr_c() call to find the first, incorrect, occurance of 'Apache'.  Or, if the client has two valid 'Apache' cookies for the server, with different paths, it may send them both, with the more-specific path first ... but since we always set the path=/, our cookie will be the last one, not the first one.  if ((value = ap_strstr_c(cookie, dcfg->cookie_name))) {     char *cookiebuf, *cookieend;      value += strlen(dcfg->cookie_name) + 1;  /* Skip over the '=' */     cookiebuf = apr_pstrdup(r->pool, value);     cookieend = strchr(cookiebuf, ';');     if (cookieend)         *cookieend = '/0';      /* Ignore anything after a ; */  I don't know if this helps or not, but since I don't have time right now to implement a complete fix, I will attach a file that parses a Cookie: header into an APR hash of cookies, where each hash value is an APR array of 'string' structures.  The first structure in an array is the first cookie we found with the given name (the name is the hash key that points to the array), which should be the most-specific cookie of that name, assuming the client is working correctly.  The last structure in an array is the last cookie -- which is the one mod_usertrack would want, because it would have to be the path=/ cookie.  The 'string' structure contains both the string itself, null-terminated, and the string length, which is useful for avoiding additional strlen() calls. The cookie_get() function returns the string of the first cookie, or NULL if there is more than one cookie with the same name.  This obviously isn't useful for the mod_usertrack situation, where we want the last cookie in an array.  For that, you want to do something like (assuming you know there's at each one element in the array):  /**** DEBUG: watch out for nelts == 0 !! ****/ string = ((struct string*) val_arr->elts) + val_arr->nelts - 1; str = string->ptr; str_len = string->str_len;  When parsing the Cookie: header, if a $Version=1 cookie is detected at the start (or some legal RFC 2965 variation), then the code parses according to RFCs 2965 and 2616 (mostly); otherwise, it parses according to the old Netscape specification.  When parsing in RFC 2965-mode, cookie names are flattened to lowercase, since the spec calls for case-insensitive cookie names.  Quoted strings are de-quoted and escaped characters in quoted strings are un-escaped (except for some dubious values that RFC 2616 allows).  Unquoted cookie values must be RFC 2616 tokens, and all cookie names must be tokens as well. Both commas and semicolons are legal delimiters.  When parsing in Netscape-mode, cookie names and values are not altered, except that we ignore internal whitespace and commas, because the spec doesn't allow those at all.  Only semicolons are legal delimiters.  In general, high-bit-set octets and ASCII control characters are stripped out, despite what RFC 2616 allows, because -- well, because applications really shouldn't be using such stuff in an HTTP header, should they?  The code also imposes its own #defined limits on name and value lengths. This probably overkill given that the header is normally limited to about 8 Kb by the DEFAULT_LIMIT_REQUEST_FIELDSIZE #define, but this code came from another application where we didn't have such external limits.  Plus, it's worth noting that both the Netscape and RFC 2965 specs allow clients to send 20 cookies where each one's name/value pair is 4 Kb ... but any application that actually relied on that many large cookies would cause Apache errors for its clients, once they exceeded the 8 Kb header limit.  Maybe someday Cookie: headers should be allowed to exceed the DEFAULT_LIMIT_REQUEST_FIELDSIZE?  Or else, at least a warning about this conflict with the specs should maybe go in the docs.  The code tries hard to avoid excess strlen()-type calls and multiple passes over the data.  Although it would be more elegant to allocate key[] and val[] buffers off the stack for the maximum, dump characters into them as we find them, and then apr_palloc() just enough space for the resultant strings, that requires at least two passes over all the data.  Instead, this code starts by allocating a small buf_size buffer from apr_palloc(), and then, once it's filled up, allocating double that amount of space for the next buffer.  The doubling continues until a reasonable maximum is reached that can always contain the largest string we need to handle (ideally, several large strings). This does involve memcpy() calls when we have to reallocate in the middle of a name or value, and some wasted space, but we should avoid a full 2* pass over all the data, and not waste too much more space than we need.  Like I said, it's a bit of overkill just for the Cookie: header, but I had the code on hand.  The attached code should compile, but it differs slightly from our actual implementation usage, so I can't guarantee that it's bug-free.  Perhaps something like this might form part of an APR-util cookie library?  Or not ... Created an attachment (id=2624) Netscape and RFC 2695 compliant cookie parser  Oops, two extra comments: the last line of the cookie_parse_header() function should 'return APR_SUCCESS', not 'return OK', and this code simply skips over any cookies whose names start with $ when parsing in RFC 2965-mode. An enhancement would be to put those $name values into a fancier 'struct cookie' that contains the 'struct string', and push those structures onto the APR arrays. regarding the spotcookie problem misrecogonizing cookies: that was fixed recently...  no comment from me on your rfc compliance comment RFC issue Fixed in 2.1 and proposed for backport into the 2.0 and 1.3 stable branches.  Thanks for the report and thanks for using Apache.			Andr?? Malo	Chris Darroch	Jeff Trawick
11521	null	CLOSED		TAKAHASHI Makoto	1028700540000	1105131531000		Addition of  Japanese error message I added Japanese error messages to /error directory. Because charset is different, I had to separate files. First I only separate Japanese modules, but $HTTP_REFERER variable became wrong. And in httpd.conf files like       ErrorDocument 400 /error/HTTP_BAD_REQUEST.html.var  are changed to      ErrorDocument 400 /error/HTTP_BAD_REQUEST.html  zipped file is in location of url.	Created an attachment (id=2607) proposed error messages  Thanks for the contribution.  We really would prefer not to go back to multiviews for the error messages if we can avoid it.  I'll look into the issue of charset in typemaps and get back to you.   OK.  What we'll do is, rather than using MultiViews, simply use the URL: field of the typemap files to point to the correct document.  But before we can commit these, we need them to be read by another fluent  Japanese speaker.  If you can have someone do that and post here, that would be great.  Otherwise, someone from the documentation project may get to it.  I'm going through the bug db to make sure patches are findable.  Please see  http://httpd.apache.org/dev/patches.html  Thank you for the contribution. I added them with some enhancement.  http://cvs.apache.org/viewcvs.cgi?root=Apache-SVN&rev=124566&view=rev 			Hiroaki KAWAI	Jeff Trawick	Joshua Slive	TAKAHASHI Makoto
11540	null	RESOLVED		Christoph Vogel	1028755260000	1185368498000		ProxyTimeout ignored Actually I tried to figure out what results when a configured ProxyTimeout has  expired. My testcase was as follows:  - a nVH with a working ProxyPass and ProxyPassReverse set - low ProxyTimeout (2) setting within the nVH - iptables rule to simply drop incoming proxied host's traffic  The connection hangs until Apache's main Timeout value (default setting) from  UAs point of view and it doesn't matter if ProxyTimeout was set or not. Additionally I tried to set ProxyTimeout in the main config with identical  behaviour (leaving ProxyPass(Reverse) in its place). I didn't try ProxyTimeout within a configuration for Apache as regular client  proxy, so it might be entailed with ProxyPass(Reverse) merely.	Same behaviour with 2.0.40 From investigating this, ProxyTimeout only applies after the connection is successfully established, which won't happen if the packets are dropped. Will check further to see if this is correct behaviour or not.  *** Bug 23122 has been marked as a duplicate of this bug. *** Confirmed - the ProxyTimeout applies after a successful connection. To test this, you need to convince your test connection to connect successfully, but then not send any data. The proxy should wait the timeout length for a response, and give up if this time is reached.  I'm closing this bug for now, if you have further problems, reopen it.   I'm facing this problem with IHS2.042.2 (Apache/2.0.46) on AIX.  Simply put, I have an upstream application server that takes about 15mins to  generate a large report. The reverse proxy returns a 502 error to the client  after the connection timeout period elapses (which is normal). I can overcome  the problem by increasing the Timeout directive, but believe it would be more  appropriate to use the ProxyTimeout directive. This does not, however, produce  the desired effect.  Perhaps the last comment 'ProxyTimeout applies after a successful connection'  could be clarified in more detail? My observation is ProxyTimeout (by 2.0.51) rather sets the Connect timeout, not the read timeout. Another bug regarding ProxyTimeout is, that neither Timeout nor ProxyTimeout apply when an SSL proxy connection ('CONNECT') is established. These connections never time out. Timeout for socket in case of proxy request set in modules/proxy/mod_proxy.c     by function ap_proxy_connect_to_backend():          /* Set a timeout on the socket */         if (conf->timeout_set == 1) {             apr_socket_timeout_set(*newsock, conf->timeout);         }         else {              apr_socket_timeout_set(*newsock, s->timeout);         }  GDB show, that conf->timeout_set is 0, and timeout get from global config (from 'Timeout' directive).  Note, that other *_set variable never used in mod_proxy* for check something.  I don't know why conf->timeout_set is zero in ap_proxy_connect_to_backend().  May be need compared 2 functions from modules/proxy/mod_proxy.c: create_proxy_config and merge_proxy_config  Check this: ps->timeout= (overrides->timeout_set == 0) ? base->timeout : overrides->timeout; If overrides->timeout_set equal 0, than ps->timeout setted, but may be we need set too :    ps->timeout_set = 1;    /* because timeout set always, timeout_set is always setted */ ?  But probably we don't need use *_set variable anywhere in proxy_utils to check.  next patch work in my environment: diff -u  modules/proxy/proxy_util.c.save  modules/proxy/proxy_util.c --- modules/proxy/proxy_util.c.save     Tue Nov 23 14:47:48 2004 +++ modules/proxy/proxy_util.c  Tue Nov 23 14:48:46 2004 @@ -1128,7 +1128,7 @@  #endif            /* Set a timeout on the socket */ -        if (conf->timeout_set == 1) { +        if (conf->timeout != 0) {              apr_socket_timeout_set(*newsock, conf->timeout);          }          else {   Created an attachment (id=15511) ensures <opt>_set properties are set correctly in merge_proxy_config  ProxyTimeout directive is ignored because the timeout_set property gets cleared in merge_proxy_config.\tAttached patch resolves this problem Created an attachment (id=15512) 2.1.3-beta: ensures <opt>_set properties are set correctly in merge_proxy_config  This bug just bit me too. The patch in attachment 15511 looks good to me, applies cleanly (once it's been dos2unix'd) to 2.0.54, and I can confirm fixes the bug. I'd certainly like this to be applied.  I would also suggest that the documentation is updated to clarify that this timeout is for *establishing* the connection only (at least that's what the code and my tests show); and that the core Timeout directive will affect the timeout for an established connection. I'm happy to knock up a patch with suitable text - just say the word. So this bug is still in both 2.0.55 and the trunk. I am confirming that the already supplied attachments are still good for the respective (2.0 and 2.1) HEADs in SVN. Could we please get these applied? Bumping because this bug *still* exists in 2.0.58 and 2.2.4 and trunk. Will attach an updated patch against trunk. This should also apply against the HEAD of 2.2.x branch (bar lines numbers being slightly off, but given the context it should apply). Created an attachment (id=19589) patch against current trunk  (In reply to comment #13) > Created an attachment (id=19589) [edit] > patch against current trunk >   I've just applied that one to trunk (with your tabs/indentation fixed).  Stuart, from memory I think I've seen your name on quite a few bugs, and they tend to be of the kind that look valid but need some effort to check.  These may tend to pass under the radar here.  Maybe it would be more productive for you to participate in dev@httpd with such points. (In reply to comment #14) > I've just applied that one to trunk (with your tabs/indentation fixed).  Great, thank you. Apologies for indentation, I based it off a patch we've been using for a while on a local build and totally forgot to check for tabs<->spaces.  > Stuart, from memory I think I've seen your name on quite a few bugs, and they > tend to be of the kind that look valid but need some effort to check.  These > may tend to pass under the radar here. Maybe it would be more productive for > you to participate in dev@httpd with such points.  I'm already a subscriber. In fact, I brought this bug up there before: http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=113257650709794&w=2 - but got no response. I actually asked yesterday on Freenode's #apache what the best method to push bugs was, but people only seemed to be dealing with user queries. Is there a more developer-centric channel? I was planning to make another post to the mailing list after resubmitting these patches.  I certainly appreciate that patches aren't always obvious in their effect; and it's good that commiters don't just apply them without thought. :) I'm more than happy to help out and give examples/explain my working. If you'd like to continue the discussion on how reporters/developers without commit access can get their bugs (valid ones and not) dealt with more readily, let's take if off this bug. Please feel free to email me directly, or bring it up on dev@ and I'll join in. Created an attachment (id=19602) patch against current 2.2.x HEAD  Created an attachment (id=19606) patch against current 2.0.x HEAD  I had applied the patch in 2.0.59 and 2.2.4 versions, and doesn't work. I try in Solaris and Linux environment. What exactly doesnt work? (In reply to comment #19) > What exactly doesnt work?  I guess he is hit by  http://mail-archives.apache.org/mod_mbox/httpd-dev/200705.mbox/%3c464F4E80.9020202@apache.org%3e The ProxyTimeout setting for mod_proxy is not working as described. According to the documentation, ProxyTimeout should 'fail gracefully instead of waiting however long it takes the server to return.'  This means that ProxyTimeout setting should cause mod_proxy to return an error back to the user instead of waiting until the Server's main Timeout value is reached, which it is doing now. It seems the ProxyTimeout is currently ignored as everyone else here describes.  For example if Apache has a Timeout of 60 seconds and ProxyTimeout is 10 seconds, then mod_proxy should return an error message back to the user if after 10 seconds it did not receive a response to the server it connected to.   Please fix.   Thanks. Fixed in trunk as r546128, r550514. Backported to 2.2.x as r556972 (http://svn.apache.org/viewvc?view=rev&rev=556972).			Alon Dakik	Anthony Pahitas	Christoph Vogel	Dave Lee	Davi Arnaut	Georg v. Zezschwitz	Graham Collinson	Graham Leggett	Jordi Garcia	Maxim Kozin	Nick Kew	Ruediger Pluem	Stuart Children
11626	null	CLOSED		Edwin Martin	1029140880000	1029162204000		Bug report URL incorect The README file for apache_1.3.26-sun4u-sun-solaris2.280 (and maybe other binaries) mentions a wrong URL for bug-reports.  The URL, 'http://www.apache.org/bug_report.html', does not exist.	Thanks.  This will be fixed in future binary builds, and I'll see what I can do about getting a redirect put in at the old address.			Joshua Slive
11637	null	CLOSED		Rob Owen	1029168300000	1051873283000		PROPFIND returns invalid XML After the following PROPPATCH, a PROPFIND on these new properties returns a  response with invalid XML - 'DOM Error: NAMESPACE_ERR: Attempt to create or  change an object in a way which is incorrect with regard to namespaces'.   This bug could be a duplicate of 11468, but the strange namespace prefixes  (ns272756832 and ns272756832 in this example (which should just be ns1)) are  never declared (as opposed to declared too late in 11468).  PROPPATCH <?xml version='1.0' encoding='utf-8' ?> <D:propertyupdate xmlns:D='DAV:'>    <D:set>       <D:prop>          <YY:type xmlns:YY='http://www.sas.com/rnd/itech/WebDAV'>             <YY:p1>event</YY:p1>             <YY:p2>high</YY:p2>          </YY:type>          <Z:Color  xmlns:Z='http://www.sas.com/rnd/itech/WebDAV/'>Yellow</Z:Color>       </D:prop>    </D:set> </D:propertyupdate>   PROPFIND <?xml version='1.0' encoding='utf-8'?> <D:multistatus xmlns:D='DAV:'> <D:response xmlns:ns0='DAV:' xmlns:ns1='http://www.sas.com/rnd/itech/WebDAV'  xmlns:ns2='http://www.sas.com/rnd/itech/WebDAV/'> <D:href>/davdigest/Tests/mpptest/</D:href> <D:propstat> <D:prop> <ns1:type><ns272756832:p1>event</ns272756832:p1><ns272756832:p2>high</ns2727568 32:p2></ns1:type> <ns2:Color>Yellow</ns2:Color> </D:prop> <D:status>HTTP/1.1 200 OK</D:status> </D:propstat> </D:response> </D:multistatus>	Assigning to the proper component (mod_dav). [This is a mass bug update.] This bug reports a problem in an older version of Apache 2. Could you please update to the most recent version and see if you can reproduce this problem.  If the bug still exists, please update the bug with the latest version number.  If  the bug no longer exists, please close the bug report.  Sorry for this impersonal response, but we get many more bug reports than our volunteers can keep up with. Thanks for using Apache! I have reproduced this bug using the latest Apache 2.0.44 (Win32). Below is the communication protocol. There are three requests. The first one is a OPTION request showing server info:  HTTP/1.1 200 OK Content-Type: text/plain; charset=ISO-8859-1 MS-Author-Via: DAV Date: Thu, 06 Feb 2003 13:11:47 GMT Allow: OPTIONS,GET,HEAD,POST,DELETE,TRACE,PROPFIND,PROPPATCH,COPY,MOVE,PUT,LOCK,UNLOCK DAV: 1,2 Content-Length: 0 Server: Apache/2.0.44 (Win32) DAV/2   The second one sets a DAV:link property on some resource. Request: <?xml version='1.0' encoding='utf-8' ?> <D:propertyupdate xmlns:D='DAV:'> <D:set> <D:prop  xmlns:ns0='TENT:'> <ns0:parent><D:link xmlns:D='DAV:' xmlns:user='TENT:'><D:src>http://thrud:8080/webdav/blubber</D:src><D:dst>http://thrud:8080</D:dst></D:link></ns0:parent> </D:prop> </D:set> </D:propertyupdate>  Response: HTTP/1.1 207 Multi-Status Content-Type: text/xml; charset='utf-8' Date: Thu, 06 Feb 2003 13:11:49 GMT Content-Length: 280 Server: Apache/2.0.44 (Win32) DAV/2  Response data: <?xml version='1.0' encoding='utf-8'?> <D:multistatus xmlns:D='DAV:' xmlns:ns1='TENT:' xmlns:ns0='DAV:'> <D:response> <D:href>/webdav/blubber</D:href> <D:propstat> <D:prop> <ns1:parent/>  </D:prop> <D:status>HTTP/1.1 200 OK</D:status> </D:propstat> </D:response> </D:multistatus>   The third one reads this property with a PROPFIND. The final response shows that the namespaces within the property value are wrong. Request: <?xml version='1.0' encoding='utf-8' ?> <D:propfind xmlns:D='DAV:'> <D:prop  xmlns:ns0='TENT:'> <ns0:parent /> </D:prop></D:propfind>  Header Depth: 0 Response: HTTP/1.1 207 Multi-Status Content-Type: text/xml; charset='utf-8' Date: Thu, 06 Feb 2003 13:11:49 GMT Content-Length: 435 Server: Apache/2.0.44 (Win32) DAV/2  Response data: <?xml version='1.0' encoding='utf-8'?> <D:multistatus xmlns:D='DAV:'> <D:response xmlns:ns0='DAV:' xmlns:ns1='TENT:'> <D:href>/webdav/blubber</D:href> <D:propstat> <D:prop> <ns1:parent><ns9107104:link><ns9107104:src>http://thrud:8080/webdav/blubber</ns9107104:src><ns9107104:dst>http://thrud:8080</ns9107104:dst></ns9107104:link></ns1:parent> </D:prop> <D:status>HTTP/1.1 200 OK</D:status> </D:propstat> </D:response> </D:multistatus>    *** Bug 15728 has been marked as a duplicate of this bug. *** A fix for this from Amit Athavale has been committed to Apache 2.1-dev. *** Bug 14969 has been marked as a duplicate of this bug. ***			Greg Stein	Jeff Trawick	Joe Orton	Joshua Slive	Roland Betz
11791	null	CLOSED		Tim Hurman	1029603060000	1030215895000		NULL pointer dereference in merge_env_dir_configs in merge_env_dir_configs the following code exists:      arr = apr_table_elts(add->unsetenv);     elts = (const apr_table_entry_t *)arr->elts;  however the definition of apr_table_elts just returns what is passed. This means that arr is set to NULL if add->unsetenv is NULL. At this point arr->elts causes a dereference through a NULL pointer and segfaults the server. from dbx:  (/tool/lang8.1/SUNWspro/bin/../WS6U1/bin/sparcv9/dbx) where                  current thread: t@5 =>[1] merge_env_dir_configs(p = 0x1b0d68, basev = 0x1239d0, addv = 0x1b88f8), line 114 in 'mod_env.c'  (/tool/lang8.1/SUNWspro/bin/../WS6U1/bin/sparcv9/dbx) print *add *add = {     vars     = 0x1b8900     unsetenv = (nil) }   This only seems to occour when a .htaccess contains a SetEnv directive or any of the subdirectories contain a .htaccess with a SetEnv directive, ie:  if SetEnv foo bla exists in /foo/.htaccess GET /foo/ HTTP/1.0 segfaults  SetEnv foo bla exists in /foo/bla/.htaccess GET /foo/ HTTP/1.0 segfaults  SetEnv foo bla exists in /foo/bla/a/.htaccess GET /foo/ HTTP/1.0 succeeds.  however if there is no SetEnv in /foo/.htaccess GET /foo/ HTTP/1.0 succeeds. /foo/.htaccess may contain other directives and remains unaffected.  this also only seems to apply if an index doesnt exist, ie mod_autoindex will return a directory index.  this was tested under solaris 8, SUN cc: cc: Sun WorkShop 6 update 1 C 5.2 2000/09/11  I have server configs, binaries and core files of this in action that I am able to provide.	a fix seems to be replacing  res->unsetenv = NULL; with res->unsetenv = apr_table_make(p, 10);  This PR has been fixed in the latest CVS HEAD. A check was put in to avoid accessing the structure if the value was NULL.  Thank you for reporting this issue.			Paul J. Reder	Tim Hurman
11793	null	CLOSED		Sebastian Wolfgarten	1029607440000	1029959842000		Parse error in ExtFilterDefine Hello,  I'm currently playing with output filters. I thought of using awk to print out the number of each line. In my bash shell I used this:  echo '<html>' | awk '{print NR ':' $N}'  I add the following lines to my httpd.conf:  ExtFilterDefine awk_line_numbering mode=output outtype=text/html  cmd='/bin/awk '{print NR/': /' $N}''  <Location />  SetOutputFilter awk_line_numbering  </Location>  Now when I start the apache I get a syntax error.   Unexpected parameter: ": /' $N}'''  I suppose this is a bug because some external programs like awk need to use quotation marks in order to work. A workaround is to put the awk command in an extra shell script but I assume this to be a bug.  My friend Werner Schalk has already posted this to the users mailing list of apache but they said I should use back-slashes (what I did anyway) or to report a bug. Here it is :-)  Bye and thanks, Sebastian Wolfgarten	Did you try   ExtFilterDefine awk_line_numbering mode=output outtype=text/html       cmd='/bin/awk '{print NR///': ///' $N}''  In case the '/' escaping is eating the second double quote?  If that's not the workaround, there is a bug in the parser.  This indeed seems to be a bug. parse_cmd in mod_ext_filter.c does not process escaping characters. It sees the first ' and scans till it finds the next '. No checks for escape chars.  I'll have a fix shortly. If you need a line numbering ExtFilter urgently you can use pr without getting  into escaping issues:  ExtFilterDefine pr_line_numbering cmd='/usr/bin/pr -n -t'  This was fixed earlier today (go Paul!).  I just verified that this  cmd= parameter yields a filter that prefixes the response with line  numbers:  cmd='/bin/awk '{print NR/': /' $N}''  To pick up the fix, you need a new modules/experimental/mod_ext_filter.c  and a new srclib/apr/strings/apr_cpystrn.c.  This will all be in the  next release of Apache 2.0.x.  Thanks for your report, and thanks for using Apache.  *** Bug 11794 has been marked as a duplicate of this bug. ***			Christoph Vogel	Jeff Trawick	Paul J. Reder	Will Rowe
11854	null	CLOSED		Moran Zaltsman	1029848940000	1029856809000		Unable to Start Apache2 (exits in 1/2 second after start, leaving [crit] errors in Log) I'm Unable to Start Apache2 - It Exists in 1/2 Second after i Start it ! and this is What I've Found in the Log :  /// [Tue Aug 20 15:54:39 2002] [crit] (22)Invalid argument: Parent: Failed to  create the child process. [Tue Aug 20 15:54:39 2002] [crit] (22506)The handle is invalid.  : master_main:  create child process failed. Exiting. [Tue Aug 20 15:54:39 2002] [notice] Parent: Forcing termination of child  process 3121056  ///  my Box is a 950Mhz Athlon w/256MB RAM, Running Win2K.Prof w/SP3 - and not any  Firewall.  if you need my httpd.conf or any other Info. - just Ask !  P.S. : Apache2 (with the current config.) used to Run on my System just 2 days  ago !	P.S. II : this is not the Downloadable Binary from httpd.apache.org - but a one that i've  compiled myself (using VC++ 6 w/SP5)  this is FYI only : as i've tried the Binary also - but incurred with the Same  result. Created an attachment (id=2775) Patch to call apr_initialize prior to checking if utf-8 fixups are required    This is a bug.  You mention you can compile apache yourself, please try the   attached patch.  Apache calls apr_app_initialize, which checks if it has   started on a WinNT-flavor Unicode-enabled platform.  But it hadn't called   apr_initialize to set up the oslevel flag before checking the platform.    If you report this clears up your bug, I'll commit, fix will be in the    2.0.41 release.      Created an attachment (id=2776) Small problem, apr_app_init can be called multiple times, this patch also resets the initialized flag to prevent double-initialization.  That was Fast man !  Thanks ! :]  It've Solved my Problem - Apache2 now Starts OK.  Thanks for your Dedication.    Yup... this will become an FAQ till .41 is in user's hands.  Fix committed. 			Moran Zaltsman	Will Rowe
12011	null	CLOSED		Psychopath	1030198860000	1034638358000		t apply when restarting the Apache service When I restart the Apache (2.0.40) service on Windows 2000 Pro with 'apache -k restart' changes  made to the httpd.conf file don't apply, Apache uses the old settings, though the configuration  file is reparsed (i.e. Apache tells me any syntax errors in it - it doesn't shutdown in this  case) Easy workaround is to use 'apache -k stop' and 'apache -k start'.  It is also notable that  'apacke -k stop' usually takes some seconds while 'apache -k restart' returns immediately.	Created an attachment (id=3469) Patches fixes the problem with sending a user define code (restart) to the service. This is causing the service not to restart properly.     Fix committed, this will be included in Apache 2.0.44 once released. *** Bug 12652 has been marked as a duplicate of this bug. ***			Juan Rivera	Will Rowe
12091	null	CLOSED		Jess Holle	1030469520000	1030562327000		Apache 2 httpd-ldap modules crash on Windows on startup The Apache 2 modules in the httpd-ldap sub-project (which should be moved  into 'experimental' in my opinion and have standard MSVC++ projects created,  etc -- though I have no vote) crash on Windows 2000 in Apache 2.0.40.  The issue is use of uninitialized memory in util_ldap_cache_init() [in  util_ldap_cache.c].  This routine declares a variable on stack, 'rmm_lock', and  passes it to apr_rmm_init() without initializing it.  apr_rmm_init() expects  this argument to be initialized and causes a later crash on Windows as a result  of finding random gargly-gook in this structure and interpretting it in such a  way that does not match the reality of the situation.  My patch (sorry I'm new at this and don't know how to generate proper patches :- (  ) is to no longer declare this variable and pass NULL to apr_rmm_init() in  its place -- as apr_rmm_init() can take a NULL for this argument.  This seems  to work fine on Windows and Solaris -- though I can't get this module to load  on AIX (no, I've not yet tried the original code....)  The line are (in patch pseudo-syntax):  Lines 293-297:   apr_status_t util_ldap_cache_init(apr_pool_t *pool, apr_size_t reqsize)   { -     apr_anylock_t rmm_lock;    #if APR_HAS_SHARED_MEMORY  and lines 305-308:       /* This will create a rmm 'handler' to get into the shared memory area */   -    apr_rmm_init(&util_ldap_rmm, &rmm_lock,   +    apr_rmm_init(&util_ldap_rmm, NULL,               (void *)apr_shm_baseaddr_get(util_ldap_shm), reqsize, pool);   #endif  The only alternative that I see is to add a call to initialize 'rmm_lock', but  from my brief (and possibly completely wrong) scan of the code it would appear  that passing null is a more efficient way of accomplishing the same thing.	Your fix has been committed.  Thanks for your report and thanks for using Apache!			Jeff Trawick
12132	null	CLOSED		Rob Cromwell	1030554840000	1030661636000		mod_rewrite Set-Cookie bug There is a bug in mod_rewrite that prevents you from setting the expiration date of a cookie using the cookie|CO flag in the RewriteRule directive.  The documentation states that the flag uses the following fields:  'cookie|CO=NAME:VAL:domain[:lifetime]' (set cocookie)    The optional parameter 'lifetime' is the lifetime of the cookie in minutes.  Currently, when you provide this field with any positive integer, it appears to be ignored by rewrite.  The cookie's expiration date is always set to the server's current time in GMT.  Here is an example that *should* set the cookie lifetime to be one day.   RewriteRule .* - [CO=MyCookie:1:mydomain.com:1440]   The root of the problem can be found on line 4159 of mod_rewrite.c, the 'lifetime' in seconds of the cookie is added to the request time to get the expiration date.  Currently, the 'lifetime' in seconds is being added as a long. The seconds should be transformed into apr_time before being added to the request time.  r->request_time + (60 * atol(expires))  Should be changed to   r->request_time + apr_time_from_sec((60 * atol(expires)))	I'll do this soon also need to fix the same spot to set it so it will be in err_headers out Fixed in current CVS. also.. the Cookie is now being sent out in err_headers_out so it should show up in stuff like 302's and 404's			Ian Holsman
12151	null	CLOSED		Dmitriy Smirnov	1030614000000	1030620187000		Very misleading typo in the docs on 3rd-party DSO compilation. An example of third-party DSO module installation in the documentation page  found at http://httpd.apache.org/docs-2.0/dso.html lists the following command as  the one needed to install a compiled DSO module:  $ apxs -i -a -n foo mod_foo.so  I believe it should be:  $ apxs -i -a -n foo mod_foo.la  Cost me an hour of my work type. Argh!	 Your fix has been committed and is reflected on the web site now.  Thanks for your report, and thanks for using Apache!  			Jeff Trawick
12172	null	CLOSED		Rob Cromwell	1030643640000	1030663138000		Path specification when setting a cookie with mod_rewrite Currently, when setting a cookie using the cookie|CO RewriteRule flag there is  no ability to specify the path of the cookie.  'cookie|CO=NAME:VAL:domain[:lifetime]' (set cocookie)  I suggest adding a second optional parameter to specify the path of the  cookie.  By adding it as an optional parameter, there won't be any conflicts  with existing cookie RewriteRules.  'cookie|CO=NAME:VAL:domain[:lifetime][:path]' (set cocookie)  I've modified the add_cookie function below to work with the new path field. ======================================================================= static void add_cookie(request_rec *r, char *s) {     char *var;     char *val;     char *domain;     char *expires;     char *path;      char *tok_cntx;     char *cookie;      if (s) {         var = apr_strtok(s, ':', &tok_cntx);         val = apr_strtok(NULL, ':', &tok_cntx);         domain = apr_strtok(NULL, ':', &tok_cntx);         expires = apr_strtok(NULL, ':', &tok_cntx);         path = apr_strtok(NULL, ':', &tok_cntx);          if (var && val && domain) {             /* FIX: use cached time similar to how logging does it */             cookie = apr_pstrcat( r->pool,                                   var,                                   '=',                                   val,                                   '; path=',                                   (path)? path : '/',                                   '; domain=',                                   domain,                                   (expires)? '; expires=' : NULL,                                   (expires)? ap_ht_time(r->pool,                                                         r->request_time +                                                         apr_time_from_sec(60 *  atol(expires)),                                                          '%a, %d-%b-%Y %T GMT',  1)                                            : NULL,                                   NULL);               /*              * XXX: should we add it to err_headers_out as well ?              * if we do we need to be careful that only ONE gets sent out              */             apr_table_add(r->headers_out, 'Set-Cookie', cookie);             rewritelog(r, 5, 'setting cookie '%s' to '%s'', var, val);         }     } }	Not sure why I'm cc'ed here.  Remove it and note that a fix is proposed in the bug. Thanks once again Rob. for my sanity, can you mention the other bugs you have open on the same piece of functionality ;-)  save me 3 seperate commits Works great! Sorry for the trouble :/ just me bitching.. take no heed			Ian Holsman	Joshua Slive	Rob Cromwell
12181	null	CLOSED		Rob Cromwell	1030656000000	1030662000000		Improved cookie logging in mod_rewrite The current entries to the rewrite log only include the name and value of the  cookie.  This should be changed to include all fields from the cookie for  easier debugging.    Current log writer call on line 4171 of mod_rewrite.c  rewritelog(r, 5, 'setting cookie '%s' to '%s'', var, val);  Should be changed to:  rewritelog(r, 5, 'setting cookie '%s'', cookie );	done. if you can check the latest version of CVS to confirm that it is working for you Works great!			Ian Holsman	Rob Cromwell
12202	null	CLOSED		Andrew Ho	1030752780000	1030906037000		If-None-Match requests always return 304 with FileETag None directive If Apache has the FileETag directive set to 'None' and an If-None-Match header  is sent in a request, Apache always sends back a 304 Not Modified response,  regardless of the content of the ETag(s) sent in the If-None-Match header.  This bug is pretty high priority, because it means that if a site running  Apache normally serves ETags but then stops serving them by setting FileETag  None, any downstream caches which understand ETags and send If-None-Match  requests will stop getting updated content.  How to reproduce:      1. Make a regular HTTP request to Apache for any static file,        and note its ETag.      2. Make another HTTP request for that file, sending an If-None-Match        header (for example, if the ETag from step 1 is 'abcdef', send        the header If-None-Match: 'abcdef'). Apache should correctly        return a 304 Not Modified response.      3. Make a new If-None-Match request with a bogus ETag, for example        by sending If-None-Match: 'xxx'. Apache should correctly return        a 200 OK and include an entity body.      4. Add a FileETag None directive to the Apache configuration,        and restart Apache.      5. Make the same If-None-Match request as in step 2. Again, Apache        should correctly return a 304 Not Modified response.      6. Make the same bogus If-None-Match request as in step 3 (or any        other If-None-Match request with a bogus ETag). Apache will        incorrectly return a 304 Not Modified response.  Steps 4 and 6 are enough to reproduce the bug but the other steps give a little  context by showing the correct behavior.  We have reproduced this bug with Apache 1.3.23 on OpenBSD and Apache 1.3.26 on  Solaris x86. We strongly suspect the bug to be platform independent; a quick  perusal of the code makes it look like the culprit is the strstr() inside  ap_meets_conditions() in src/main/http_protocol.c (line 612 of the Apache  1.3.26 distribution):      if_nonematch = ap_table_get(r->headers_in, 'If-None-Match');     if (if_nonematch != NULL) {         if (r->method_number == M_GET) {             if (if_nonematch[0] == '*')                 return HTTP_NOT_MODIFIED;             if (etag != NULL) {                 if (ap_table_get(r->headers_in, 'Range')) {                     if (etag[0] != 'W' &&                         ap_find_list_item(r->pool, if_nonematch, etag)) {                         return HTTP_NOT_MODIFIED;                     }                 }    /* here */   else if (strstr(if_nonematch, etag)) {                     return HTTP_NOT_MODIFIED;                 }  The problem appears to be that when FileETag None is set, the If-None-Match  header is set to '' because ap_make_etag() returns '' in that case.  Unfortunately, strstr(str, '') always returns true, so Apache incorrectly  returns 304 Not Modified for all requests.  A quick hack would be to have ap_make_etag() return an impossible sentinel  value instead of '' when FileETag None is set. A better fix would be to ignore  the If-None-Match logic altogether if FileETag None is set, as there is no  other sensible behavior.	I have confirmed that the bug exists in the current CVS HEAD. Simple one-line patch is coming... Created an attachment (id=2879) Patch against apache-1.3/src/main/http_protocol.c  Fixed in revision 1.327 of http_protocol.c			Andrew Ho	Justin Erenkrantz
12207	null	CLOSED		Andrew Ho	1030777740000	1030906090000		If-None-Match requests always return 304 with FileETag None directive If Apache has the FileETag directive set to 'None' and an If-None-Match header  is sent in a request, Apache always sends back a 304 Not Modified response,  regardless of the content of the ETag(s) sent in the If-None-Match header.  This bug is pretty high priority, because it means that if a site running  Apache normally serves ETags but then stops serving them by setting FileETag  None, any downstream caches which understand ETags and send If-None-Match  requests will stop getting updated content.  How to reproduce:      1. Make a regular HTTP request to Apache for any static file,        and note its ETag.      2. Make another HTTP request for that file, sending an If-None-Match        header (for example, if the ETag from step 1 is 'abcdef', send        the header If-None-Match: 'abcdef'). Apache should correctly        return a 304 Not Modified response.      3. Make a new If-None-Match request with a bogus ETag, for example        by sending If-None-Match: 'xxx'. Apache should correctly return        a 200 OK and include an entity body.      4. Add a FileETag None directive to the Apache configuration,        and restart Apache.      5. Make the same If-None-Match request as in step 2. Again, Apache        should correctly return a 304 Not Modified response.      6. Make the same bogus If-None-Match request as in step 3 (or any        other If-None-Match request with a bogus ETag). Apache will        incorrectly return a 304 Not Modified response.  Steps 4 and 6 are enough to reproduce the bug but the other steps give a little  context by showing the correct behavior.  I have reproduced this bug with Apache 2.0.40 on Solaris x86. I strongly  suspect the bug to be platform independent, as it is a simple missing check in  http_protocol.c for an empty ETag. Apache 1.3 has an identical bug, for which  details can be found in Bug 12202.	Created an attachment (id=2880) Patch against httpd-2.0/modules/http/http_protocol.c  Still a problem in HEAD. The attached patch fixes the problem. Fixed in revision 1.455 of http_protocol.c.			Andrew Ho	Justin Erenkrantz
12340	null	RESOLVED		Chris Ward	1031245920000	1191776362000		WindowsXP proxy, child process exited with status 3221225477 I'm using Apache as a cacheing proxy on a WindowsXP system (the upstream link is Starband satellite, the downstream link is a wireless LAN around my house). Apache2 breaks with messages below in the log; the web browsers get some rather disjointed sessions. Apache1 works fine. I get notices about Apache wanting to notify Microsoft about the problem, which I duly allow it to do. I'm not sure whether the problem is related to Apache on WindowsXP, or 'mod_proxy' etc. I am running without any upstream proxies. Starband have a strange scheme involving running half the TCP stack on my computer and the other half back that their satellite base station, but it works most of the time. [Tue Aug 27 08:33:11 2002] [notice] Parent: child process exited with status 3221225477 -- Restarting. [Tue Aug 27 08:33:11 2002] [notice] Parent: Created child process 4684 [Tue Aug 27 08:33:11 2002] [notice] Child 4684: Child process is running [Tue Aug 27 08:33:11 2002] [notice] Child 4684: Acquired the start mutex. [Tue Aug 27 08:33:11 2002] [notice] Child 4684: Starting 250 worker threads. [Tue Aug 27 08:33:15 2002] [notice] Parent: child process exited with status 3221225477 -- Restarting. [Tue Aug 27 08:33:15 2002] [notice] Parent: Created child process 3768 [Tue Aug 27 08:33:15 2002] [notice] Child 3768: Child process is running [Tue Aug 27 08:33:15 2002] [notice] Child 3768: Acquired the start mutex. [Tue Aug 27 08:33:15 2002] [notice] Child 3768: Starting 250 worker threads. [Tue Aug 27 08:33:19 2002] [notice] Parent: child process exited with status 3221225477 -- Restarting. [Tue Aug 27 08:33:19 2002] [notice] Parent: Created child process 5728	 Proxy crash in mod_proxy.c, function proxy_map_location():    +--- mod_proxy.c --------------------------------------------    |static int proxy_map_location(request_rec *r)    |{    |    int access_status;    |  ->|    if (!r->proxyreq || strncmp(r->filename, 'proxy:', 6) != 0)    |        return DECLINED;    +------------------------------------------------------------ r->filename points to NULL, cause strncmp access to violation exception (0xC0000005).  Bug also in apache 2.0.39 in same place.  Can you please attach your httpd.config file, and the actual URL requested which gives the crash ?  if this is a forward proxy, the r->filename should already by mapped to proxy:http://foobar/uri by the time it gets into this function (or else it would be breaking for >every< request anyone does, so there is something funky about your config I'm thinking Here proposed patch for fixing this bug (maked by 'diff mod_proxy.c fixed/mod_proxy.c' command):  255,256c255,256 <     if (!r->proxyreq || strncmp(r->filename, 'proxy:', 6) != 0) <         return DECLINED; --- >     if (!r->proxyreq) return DECLINED; >     if (strncmp(r->filename, 'proxy:', 6) != 0) return DECLINED;    It seems that in 'if' operator (in compiled code) both condition are checked even though first already truly. Thanks for high-speed fix. I take it that you don't need my config file any more; if you want it, let me know. Executing code to evaluate 'b' in (a || b) when it is not logically needed sounds like a compiler bug. Whose compiler do you build Apache for Windows with ? Would they be interested in a bug report ?  The oddity in my configuration is that I run an Apache proxy on Windows.  I am running 2.0.42 now, and the problem is fixed. Thanks ! This is giving me the same breakage again in 2.0.47; has the broken code crept back in ? *** Bug 18963 has been marked as a duplicate of this bug. ***   I'm running Win2K Advanced Server, Apache 2.0.47 with PHP 4.3.3 and NO  mod_proxy loaded, and I'm reporting the same problems. Some of the times the  service actually stops (it's automaticaly restarted by Win 60 s latter), the  rest of the times Apache seems to handle it on his own . I have a low thread  count (15) because of persistent connections do the database and the server is  pretty much exclusive.    Before I had 2.0.39 and all was fine, I tried downgrading to 2.0.46 and the  problem persisted. Didn't really wanted to downgrade much further, so I'll wait  for the outcome of this 'bug' :).    Further log details in :    http://nagoya.apache.org/bugzilla/show_bug.cgi?id=23300 I'm using 'squid' as cacheing proxy now (under WindowsXP Home). Works fine, and the license terms are just as good. Apache good web server, squid good proxycache, XMail good mailrouterthing ... I'm experiencing the same problem with Apache 2.0.54 with PHP 5.0.4 on WinXP  SP1, mod_proxy is not loaded. The error occurs sporadically, sometimes with the page partly sent to the  client. After Apache has automatically restarted, reloading the page does not  reproduce the error. I also receive this error on using phpmyadmin. Here is one of the URLs causing the error:  http://localhost/phpmy/sql.php?lang=de-utf-8&server=1&collation_connection=utf8_general_ci&db=phpbb&table=phpbb_auth_access&sql_query=SELECT+%2A+FROM+%60phpbb_auth_access%60&pos=0&goto=tbl_properties_structure.php (In reply to comment #0) I'm using XAMPP 1.5.1 on Windows XP Home with SP1 and SP2. No other server running.  I have the error, too. I'm not using Perl when it's running.I did not compile, I used the .zip version, unzipped in top-level directory.I've read all the bug reports here, and it seems this bug dissappeared, then reappeared again.  I have the following in my httpd-mpm.conf  <IfModule mpm_winnt_module>     ThreadsPerChild     250     MaxRequestsPerChild   0     Win32DisableAcceptEx </IfModule>  and httpd.conf has the appropriate line uncommented to Apache will read httpd-mpm.conf.  That was the suggested fix for problem when CPU usage maxes out on XP Home. Proposed fix does not work. When I attempt to view an HTML page that processes a PHP script (whether hard-coded in the HTML or called via SSI virtual), very often the CPU usage goes to 100%, Windows gives me an error 'Apache has encountered a problem and needs to close', and the page never loads.  There is no port conflict, but I tried changing to port 8080 just to see if that helped, and it doesn't. My firewall is not blocking anything, the first time I started Apache I chose to allow Apache to run as a server and to have the firewall remember this answer.  Appropriate section of log file:  [Wed Feb 22 16:36:47 2006] [notice] Apache/2.2.0 (Win32) DAV/2 mod_ssl/2.2.0 OpenSSL/0.9.8a mod_autoindex_color PHP/5.1.1 configured -- resuming normal operations [Wed Feb 22 16:36:47 2006] [notice] Server built: Dec  1 2005 18:36:53 [Wed Feb 22 16:36:47 2006] [notice] Parent: Created child process 3416 [Wed Feb 22 16:37:21 2006] [notice] Child 3416: Child process is running [Wed Feb 22 16:37:22 2006] [notice] Child 3416: Acquired the start mutex. [Wed Feb 22 16:37:22 2006] [notice] Child 3416: Starting 250 worker threads. [Wed Feb 22 16:37:22 2006] [notice] Child 3416: Starting thread to listen on port 8080. [Wed Feb 22 16:37:22 2006] [notice] Child 3416: Starting thread to listen on port 443. [Wed Feb 22 16:42:43 2006] [notice] Parent: child process exited with status 3221225477 -- Restarting. [Wed Feb 22 16:42:55 2006] [crit] (22)Invalid argument: unable to replace stderr with error_log [Wed Feb 22 16:42:55 2006] [crit] (2)No such file or directory: unable to replace stderr with /dev/null [Wed Feb 22 16:42:59 2006] [notice] Apache/2.2.0 (Win32) DAV/2 mod_ssl/2.2.0 OpenSSL/0.9.8a mod_autoindex_color PHP/5.1.1 configured -- resuming normal operations(In reply to comment #0) > I'm using Apache as a cacheing proxy on a WindowsXP system (the upstream > link is Starband satellite, the downstream link is a wireless LAN around my > house). Apache2 breaks with messages below in the log; the web browsers get > some rather disjointed sessions. Apache1 works fine. I get notices about Apache > wanting to notify > Microsoft about the problem, which I duly allow it to do. > I'm not sure whether the problem is related to Apache on WindowsXP, or > 'mod_proxy' etc. > I am running without any upstream proxies. Starband have a > strange scheme involving running half the TCP stack on my computer and the > other half back that their satellite base station, but it works most of the > time. > [Tue Aug 27 08:33:11 2002] [notice] Parent: child process exited with > status 3221225477 -- Restarting. > [Tue Aug 27 08:33:11 2002] [notice] Parent: Created child process 4684 > [Tue Aug 27 08:33:11 2002] [notice] Child 4684: Child process is running > [Tue Aug 27 08:33:11 2002] [notice] Child 4684: Acquired the start mutex. > [Tue Aug 27 08:33:11 2002] [notice] Child 4684: Starting 250 worker > threads. > [Tue Aug 27 08:33:15 2002] [notice] Parent: child process exited with > status 3221225477 -- Restarting. > [Tue Aug 27 08:33:15 2002] [notice] Parent: Created child process 3768 > [Tue Aug 27 08:33:15 2002] [notice] Child 3768: Child process is running > [Tue Aug 27 08:33:15 2002] [notice] Child 3768: Acquired the start mutex. > [Tue Aug 27 08:33:15 2002] [notice] Child 3768: Starting 250 worker > threads. > [Tue Aug 27 08:33:19 2002] [notice] Parent: child process exited with > status 3221225477 -- Restarting. > [Tue Aug 27 08:33:19 2002] [notice] Parent: Created child process 5728   This seems anything but a httpd bug. could you try to reproduce the issue and get a backtrace? Thanks. Instructions at http://httpd.apache.org/dev/debugging.html#backtrace-win No response to davi's request for detail.  And if there is a bug, it's clearly NOT the one originally reported, which is long-since fixed.			Chris Ward	Christian Kuhlmann	Davi Arnaut	David Ramalho	Ian Holsman	Nick Kew	Nico Haase	Semenov Innokentiy	cp_coder_2006@yahoo.com
12353	null	CLOSED		Owen Rees	1031298120000	1044108784000		Server creates empty meta files where MetaFiles on In directories where I have 'MetaFiles on', if 'file.meta' does not exist, the  server creates an empty 'file.meta' when 'file' is accessed. If 'file.meta'  exists, the server creates 'file.meta.meta' when 'file' is accessed and so on  adding a new file with an extra '.meta' each time.  Problem first seen after upgrading from 1.x to 2.0.39 on an HP-UX 10.20 system.  Currently running 2.0.40 built after deleting '| APR_CREATE' from the call of  apr_file_open in mod_cern_meta.c (line 383). This seems to fix the problem with  no obvious side effects seen with a few simple tests.	Thanks for your report/patch, and thanks for using Apache!  Your fix has just been committed to 2.1-dev and proposed for merging back to 2.0.45-dev.  FYI... the fix has been merged back to the stable tree for inclusion in 2.0.45			Jeff Trawick
12355	null	RESOLVED		samuel ball	1031307540000	1181296780000		POST incompatible w/ renegotiate https: connection when configuring SSLVerifyClient directive from global none to location  require, php scripts inside location are no more able to receive post data.   Error Method Not Allowed then occurs. error log shows '[error] SSL Re-negotiation in conjunction with POST method not  supported!' when SSLVerifyClient is set to 'required' but not when set to 'none'  this configuration inside ssl virtualhost section activate the bug : ---- SSLEngine on SSLVerifyClient none SSLVerifyDepth  1 SSLOptions +OptRenegotiate <location /consultation/ >         SSLVerifyClient require </location> ---- this configuration does not activate the bug : SSLEngine on SSLVerifyClient require SSLVerifyDepth  1 SSLOptions +OptRenegotiate <location /consultation/ >         SSLVerifyClient require </location>	[This is a mass bug update.] This bug reports a problem in an older version of Apache 2. Could you please update to the most recent version and see if you can reproduce this problem.  If the bug still exists, please update the bug with the latest version number.  If  the bug no longer exists, please close the bug report.  Sorry for this impersonal response, but we get many more bug reports than our volunteers can keep up with. Thanks for using Apache! This bug exists also in Apache/2.0.43 (WIN32) mod_ssl/2.8.11 OpenSSL/0.9.6g. This bug appears when runnimg under both Windows NT4.0 and XP(NT5.1). Addition to last comment:  Sorry, it must read Apache/2.0.43 (WIN32) mod_ssl/2.0.43 OpenSSL/0.9.6g I observe the same bug with Apache 2.0.43 running on Linux 2.4.19 box, but  with proprietary script handler.  Also observed on a Linux RedHat 8.0 (2.4.18-17 kernel) box running apache 2.0.43-1, mod_ssl-2.0.43-1 and php 4.2.2-8.   After setting up SSL to require client authentication and importing the  certificates into browsers, it works with Netscape 4.79 but not MSIE6  (6.0.2800.1106.xpsp1.020828-1920).  The https error file says: [error] SSL handshake failed (server myserver.com:443, client 192.168.1.2) [error] SSL Library Error: 336105671 error:140890C7:lib(20):func(137):reason (199) The first time I also get the spurious SSL handshake interrupt message.  Server config: Apache/2.0.43 (Unix) mod_ssl/2.0.43 OpenSSL/0.9.7 PHP/4.3.0 Kernel 2.4.8-26mdk When configured for client certificate authentication, POST method fails after KeepAlive timeout - if KeepAlive is disabled, POST method always fails.  SSLOptions +OptRenegotiate does not fix the problem.  Server: Apache/2.0.45 (Unix) mod_ssl/2.0.45 OpenSSL/0.9.7a AIX 4.3.3  I have tested IE 5.5, Netscape 4.8, Netscape 7, and Mozilla 1.3 - All browsers seem to be affected.  Log files can be found below.  IE 5.5 generates a segfault of the child and a 302 error along with the general symptoms - details of this can be found in the logs below.  -------------------------------------------------------------------------------------------------- Configuration excerpts:  KeepAlive On KeepAliveTimeout 15  SSLSessionCache dbm:/var/adm/httpd.ssl.cache SSLSessionCacheTimeout 300 SSLMutex file:/var/adm/httpd.ssl.mutex  <Directory /docs/clientcert> \tSSLOptions +StdEnvVars +ExportCertData +OptRenegotiate \tSSLVerifyClient require \tSSLVerifyDepth 2 \tSSLRequire %{SSL_CLIENT_CERT} eq file('<certfile>') / \t\tor %{SSL_CLIENT_CERT} eq file('<certfile>') \tOrder Deny,Allow \tDeny from all \tAllow from 1.1.1.1 </Directory>  -------------------------------------------------------------------------------------------------- HTML files used for testing:  $ cat index.html <HTML> <BODY> Hello client cert  <FORM action=index2.html method=post> <INPUT value='Post to index2.html' type=submit> </FORM>  </BODY> </HTML>  $ cat index2.html <HTML> <BODY> Hello client cert - index2  <FORM action=index.html method=post> <INPUT value='Post to index.html' type=submit> </FORM>  </BODY> </HTML>  -------------------------------------------------------------------------------------------------- VH access log: 2.2.2.2 - - [07/Apr/2003:14:23:57 -0700] 'GET /clientcert/index.html HTTP/1.1' 200 140 '-' 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' GET /clientcert/index.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:14:24:03 -0700] 'POST /clientcert/index2.html HTTP/1.1' 200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index2.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:14:24:03 -0700] 'POST /clientcert/index.html HTTP/1.1' 200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:14:24:04 -0700] 'POST /clientcert/index2.html HTTP/1.1' 200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index2.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:14:24:05 -0700] 'POST /clientcert/index.html HTTP/1.1' 200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:14:24:06 -0700] 'POST /clientcert/index2.html HTTP/1.1' 200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index2.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:14:24:07 -0700] 'POST /clientcert/index.html HTTP/1.1' 200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:14:25:12 -0700] 'POST /clientcert/index2.html HTTP/1.1' 405 244 'https://test.domain.com/clientcert/index.html' 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index2.html - 'HTTP/1.1' (-)  VH error log: [Mon Apr 07 14:25:12 2003] [error] SSL Re-negotiation in conjunction with POST method not supported! hint: try SSLOptions +OptRenegotiate  -------------------------------------------------------------------------------------------------- With Internet Explorer 5.5:  VH access log: 2.2.2.2 - - [07/Apr/2003:15:46:15 -0700] 'GET /clientcert/ HTTP/1.1' 302 227 '-' 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' GET /clientcert/ - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:15:46:16 -0700] 'GET /clientcert/ HTTP/1.1' 200 140 '-' 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' GET /clientcert/index.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:15:46:24 -0700] 'POST /clientcert/index2.html HTTP/1.1' 200 144 'https://test.domain.com/clientcert/' 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index2.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:15:46:25 -0700] 'POST /clientcert/index.html HTTP/1.1' 200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:15:46:26 -0700] 'POST /clientcert/index2.html HTTP/1.1' 200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index2.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:15:46:27 -0700] 'POST /clientcert/index.html HTTP/1.1' 200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:15:46:28 -0700] 'POST /clientcert/index2.html HTTP/1.1' 200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index2.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:15:46:29 -0700] 'POST /clientcert/index.html HTTP/1.1' 200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index.html - 'HTTP/1.1' (-) 2.2.2.2 - - [07/Apr/2003:15:46:58 -0700] 'POST /clientcert/index2.html HTTP/1.1' 405 244 'https://test.domain.com/clientcert/index.html' 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index2.html - 'HTTP/1.1' (-)  VH error log: [Mon Apr 07 15:46:15 2003] [error] Re-negotiation handshake failed: Not accepted by client!? [Mon Apr 07 15:46:58 2003] [error] SSL Re-negotiation in conjunction with POST method not supported! hint: try SSLOptions +OptRenegotiate  Server error log: [Mon Apr 07 15:46:16 2003] [notice] child pid 28262 exit signal Segmentation fault (11) The existance of this 'bug' is documented in modules/ssl/ssl_engine_kernel.c line 525. But it would really be nice to reimplement this feature. Created an attachment (id=9626) diff against httpd-2.0.48  Fixed the problem in the following way: Before the renegotiation is starting the body of the POST request will be readed via ap_get_client_block().(So content-length, chunking etc. is handeld correctly.)  The data will be stored in a brigade and an input filter will be added just after the http_header_filter. That input filter has the data from it's ctx.  So in any subsequent read call that input filter will be invoked and  can return the stored data.   P.S. Im not sure if the upload of the diff is ok, so I paste it to be sure   *** mod_ssl.h.patched\tThu Dec 18 13:11:48 2003 --- mod_ssl.h\tThu Dec 18 13:13:19 2003 *************** *** 709,714 **** --- 709,715 ----   void         ssl_io_filter_init(conn_rec *, SSL *);   void         ssl_io_filter_register(apr_pool_t *);   long         ssl_io_data_cb(BIO *, int, MODSSL_BIO_CB_ARG_TYPE *, int, long, long); + long         ssl_io_suck(request_rec *);      /*  PRNG  */   int          ssl_rand_seed(server_rec *, apr_pool_t *, ssl_rsctx_t, char *); *** ssl_engine_kernel.c.patched\tThu Dec 18 13:11:39 2003 --- ssl_engine_kernel.c\tThu Dec 18 13:15:04 2003 *************** *** 583,596 ****        *        * !! BUT ALL THIS IS STILL NOT RE-IMPLEMENTED FOR APACHE 2.0 !!        */ !     if (renegotiate && !renegotiate_quick && (r->method_number == M_POST)) {           ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server,                        'SSL Re-negotiation in conjunction '                        'with POST method not supported!/n'                        'hint: try SSLOptions +OptRenegotiate'); !            return HTTP_METHOD_NOT_ALLOWED;       }          /*        * now do the renegotiation if anything was actually reconfigured --- 583,602 ----        *        * !! BUT ALL THIS IS STILL NOT RE-IMPLEMENTED FOR APACHE 2.0 !!        */ ! \tif (renegotiate && !renegotiate_quick && (r->method_number == M_POST)) { ! #ifdef SSL_CONSERVATIVE \t\t           ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server,                        'SSL Re-negotiation in conjunction '                        'with POST method not supported!/n'                        'hint: try SSLOptions +OptRenegotiate'); ! \t\t           return HTTP_METHOD_NOT_ALLOWED; + #else\t\t + \t\tif( ssl_io_suck(r) != OK) { + \t\t\treturn HTTP_METHOD_NOT_ALLOWED; + \t\t}       } + #endif /* SSL_CONSERVATIVE */          /*        * now do the renegotiation if anything was actually reconfigured *** ssl_engine_io.c.patched\tThu Dec 18 13:12:02 2003 --- ssl_engine_io.c\tThu Dec 18 13:21:31 2003 *************** *** 897,902 **** --- 897,987 ----   }      static const char ssl_io_filter[] = 'SSL/TLS Filter'; + static const char ssl_buff_filter[] = 'SSL/TLS Buffering Filter'; + /* +  * reads the buffered data during a POST request with renegotiation +  * will be registere at runtime. +  * NOTE: we try to buffer the complete body. Use the attribute 'LimitRequestBody' +  * preventing DOS attacks. +  */ + long ssl_io_suck(request_rec *r) + { + \tapr_bucket *bucket; + \tapr_bucket_brigade *bb = apr_brigade_create(r->pool,r->connection->bucket_alloc); +  + \tint readed = 0; + \tint len = 0; + \tint toRead= 0; + \tchar *buffer = NULL; + \tchar *pos = NULL; + \t + \tif(ap_setup_client_block(r,REQUEST_CHUNKED_DECHUNK) !=OK) { + \t\treturn HTTP_METHOD_NOT_ALLOWED;  + \t} +  + \tif(!ap_should_client_block(r)) { + \t\treturn OK; + \t} + \t + \tdo { + \t\tbuffer = apr_pcalloc(r->pool,HUGE_STRING_LEN); + \t\ttoRead = HUGE_STRING_LEN; +  + \t\t/* check malloc */ + \t\tif(buffer == NULL) { + \t\t\tap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server, +                      'SSL Re-negotiation in conjunction ' + \t\t\t\t     'with POST (buffering body failed)!/n'); + \t\t\tapr_brigade_destroy(bb); + \t\t\treturn HTTP_METHOD_NOT_ALLOWED;\t\t\t + \t\t} + \t\t + \t\t/* fill the bucket */ + \t\tpos = buffer; + \t\tlen = 0; + \t\tdo { + \t\t\treaded  = ap_get_client_block(r,pos,toRead); +  + \t\t\tif(readed <=0) { + \t\t\t\tbreak; + \t\t\t} + \t\t\t + \t\t\ttoRead  -= readed; + \t\t\t + \t\t\t/* sanity */ + \t\t\tif(toRead<0) { + \t\t\t\treturn HTTP_METHOD_NOT_ALLOWED; + \t\t\t} +  + \t\t\tpos += readed; + \t\t\tlen += readed;\t + \t\t} + \t\twhile(toRead>0); +  + \t\t/* check last read result */ + \t\tif(readed<0) { + \t\t\tap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server, +                      'SSL Re-negotiation in conjunction ' + \t\t\t\t     'with POST (reading body failed)!/n'); + \t\t\tapr_brigade_destroy(bb); + \t\t\treturn HTTP_METHOD_NOT_ALLOWED;  + \t\t} + \t\t + \t\t/* check if we have readed everything */ + \t\tif(len == 0) { + \t\t\tbreak; + \t\t} + \t\tbucket = apr_bucket_pool_create(buffer,len,r->pool,r->connection->bucket_alloc); + \t\t +         APR_BRIGADE_INSERT_TAIL(bb, bucket); + \t}  + \twhile(1); + \t + \t//add the ssl_buff_filter_input + \tap_add_input_filter(ssl_buff_filter, bb, r, r->connection); + \t + \treturn OK;\t\t\t\t\t\t\t\t\t   + }      /*    *  Close the SSL part of the socket connection *************** *** 1361,1366 **** --- 1446,1529 ----       return status;   }    + static apr_status_t ssl_buff_filter_input(ap_filter_t *f, +                                         apr_bucket_brigade *bb, +                                         ap_input_mode_t mode, +                                         apr_read_type_e block, +                                         apr_off_t readbytes) + { + \tapr_bucket_brigade *aa = f->ctx; + \tapr_status_t  rv; + \t + \tif(aa && !APR_BRIGADE_EMPTY(aa)) { +  + \t\tif(mode == AP_MODE_READBYTES) { + \t\t\tapr_bucket *b; + \t\t\tapr_off_t missing = readbytes; + \t\t\tapr_size_t len; + \t\t\tconst char *tmp; + \t + \t\t\twhile (!APR_BRIGADE_EMPTY(aa)) { + \t\t\t\tb = APR_BRIGADE_FIRST(aa); + \t\t\t + \t\t\t\trv = apr_bucket_read(b, &tmp, &len, APR_BLOCK_READ); + \t\t\t\tif (rv != APR_SUCCESS) { + \t\t\t\t\treturn rv; + \t\t\t\t} + \t\t\t\t + \t\t\t\t/* consume whole bucket */ + \t\t\t\tif(missing >= len) { + \t\t\t\t\tAPR_BUCKET_REMOVE(b); + \t\t\t\t\tAPR_BRIGADE_INSERT_TAIL(bb,b); + \t\t\t\t} + \t\t\t\t/* comsume only a part */  + \t\t\t\telse{ + \t\t\t\t\trv = apr_bucket_split(b, missing); + \t\t\t\t\tif (rv != APR_SUCCESS) { + \t\t\t\t\t\treturn rv; + \t\t\t\t\t} + \t\t\t\t\t + \t\t\t\t\tAPR_BUCKET_REMOVE(b); + \t\t\t\t\tAPR_BRIGADE_INSERT_TAIL(bb, b); + \t\t\t\t\tbreak; + \t\t\t\t} + \t\t\t\t + \t\t\t\tmissing -= len; + \t\t\t\t + \t\t\t\tif (missing = 0) { + \t\t\t\t\tbreak; + \t\t\t\t} +  + \t\t\t\tif(missing<0) { + \t\t\t\t\treturn AP_FILTER_ERROR; + \t\t\t\t} + \t\t\t} + \t\t\treturn APR_SUCCESS; + \t\t} + \t\telse if (mode == AP_MODE_READBYTES) { + \t\t\tapr_bucket_brigade *nb = apr_brigade_create(f->r->pool,f->c->bucket_alloc); + \t\t\t + \t\t\t/* split */ + \t\t\trv = apr_brigade_split_line(nb,aa,block,readbytes); + \t\t\tif( rv != APR_SUCCESS) {\t\t\t\t + \t\t\t\treturn rv; + \t\t\t}  +  + \t\t\t/* concatinate */ + \t\t\tAPR_BRIGADE_CONCAT(bb,aa); + \t\t\t + \t\t\t/* remember the rest */ + \t\t\tf->ctx = nb; + \t\t\t + \t\t\treturn APR_SUCCESS;\t + \t\t} + \t\t + \t} + \t + \t + \treturn ap_pass_brigade(f->next, bb); + } +    static void ssl_io_input_add_filter(ssl_filter_ctx_t *filter_ctx, conn_rec *c,                                       SSL *ssl)   { *************** *** 1417,1422 **** --- 1580,1586 ----   {       ap_register_input_filter  (ssl_io_filter, ssl_io_filter_input,  NULL, AP_FTYPE_CONNECTION + 5);       ap_register_output_filter (ssl_io_filter, ssl_io_filter_output, NULL, AP_FTYPE_CONNECTION + 5); +     ap_register_input_filter  (ssl_buff_filter, ssl_buff_filter_input,  NULL, AP_FTYPE_PROTOCOL - 1);       return;   }        Just adding the PatchAvailable keyword. Hartmut, to keep bugs in the loop please don't resolve  them as fixed until they're reviewed and/or committed at least to one dev-tree. Anyway, thanks for  the patch. Also, this configuration does not activate the bug : SSLEngine on SSLVerifyClient optional SSLOptions +OptRenegotiate <location /location/ >         SSLVerifyClient optional         SSLVerifyDepth 10 </location> I was having a similar problem with per-directory SSL authentication with DAV. (Note that the patch posted earlier does not fix the problem for DAV.)  I have worked around the problem by having a global 'SSLVerifyClient optional' directive.  The per-directory 'SSLVerifyClient required' is then processed properly.  This seems to preserve all of the behavior that I need.  Those without a certificate can still access the site via SSL, and the entire site, including the portions using SSL authentication, work for those with proper certificates. This may need no more than clarification in the documentation.  I have attempted usage of all posts in this bug to date.  I have used the patch, no dice.  I have altered my configurations as noted by the posts mentioning that the bug will not be enabled with a configuration change, again no dice.  I have also used several configurations noted in errors by the apache software and nothing works.  I always get 'SSL Re-negotiation in conjunction with POST method not supported!' when the SSL is renegotiated and the next method is a POST instead of a GET.  I find it hard to swallow ('because I am a huge fan of Apache and mod_ssl'), that Apache organization would make such a glaring flaw in the 2.0 builds considering all this worked great in the 1.3 builds.  My final resolution because I am in a production environment (until Apache org. fixes the problem).  Go back to the 1.3 build ASAP. Hello,  I also applied all 'remedies' so far mentioned by others (including patching),  to no avail, the problem is still alive and healthy.  As a consequence, we are  considering going back to 1.3 as well.  I'm reluctant to go in this direction,  but without progress for months now, there seems to be no perspective for 2.0  within environments requiring client certs and the POST method....  BTW: You should remove the 'PatchAvailable' keyword.  No offense for the creator  of the patch, but it simply doesn't work.   Regards,  Birger *** Bug 21167 has been marked as a duplicate of this bug. *** Created an attachment (id=11681) patch for 2.0 to fix #12355  *Experimental* patch attached above for 2.0, this is closer to fixing the issue properly, without buffering the entire request body in memory.  (it makes one bogus assumption about the filter interfaces but seems to work OK)  This approach also needs careful checking bugs may allow clients to bypass the access control checks. Created an attachment (id=11736) proposed fix  Second patch attached is the fix I have proposed for this issue, which has no issues that I'm currently aware of, and could do with some wider testing. *** Bug 18395 has been marked as a duplicate of this bug. *** Created an attachment (id=11745) proposed fix for 2.0 branch  Proposed patch, rediffed for 2.0, attached above. Hi,  when patching the apache2-2.0.48 source RPM for Mandrake 10 (and  rebuilding the binaries), the SSL service crashes immediately upon the use of client certificates:  [Sat Jun 05 12:30:50 2004] [notice] LDAP: Built with OpenLDAP LDAP SDK [Sat Jun 05 12:30:50 2004] [notice] Digest: generating secret for digest authentication ... [Sat Jun 05 12:30:50 2004] [notice] Digest: done [Sat Jun 05 12:30:51 2004] [notice] Apache-AdvancedExtranetServer/2.0.48 (Mandrake Linux/6.2.100mdk) mod_ssl/2.0.48 OpenSSL/0.9.7a DAV/2 PHP/4.3.1 configured -- resuming normal operations   - service is now working and delivers ordinary pages successfully,    including PHP and MySQL_over_PHP operations and SSL (without client    certs) -  [Sat Jun 05 12:32:21 2004] [notice] child pid 29488 exit signal Segmentation fault (11)   - that was the child that dealt the first time with a     client certificate -   Without the patch (but same source) and without using POST, the  site works 'perfectly' using client certificates.     Birger *** Bug 29569 has been marked as a duplicate of this bug. *** Please don't mark bugs as fixed without adding a comment, and please don't mark bugs as fixed if they aren't really fixed! Have there been any updates on this issue since the last comment filed on July 8th of this year?  No; I'm not really convinced the solution I was working on can be made to be secure.  Note that for many configurations, there is a simple workaround: add    SSLVerifyClient optional  to the SSL vhost config, as well as the 'SSLVerifyClient require' in whatever Location/Directory context. I was reminded privately that the other workaround for this bug is of course to ensure that the first access the browser makes to the SSLVerifyClient-protected location uses a GET request rather than a POST request. *** Bug 31314 has been marked as a duplicate of this bug. *** Some general comments;  HTTP/1.0    the 'classic' HTTP/1.0 handling -must- buffer the body if the connection   will be renegotiated.  This should no longer be handled inside the mod_ssl   module itself, by itself.  With the advent of filters, either apreq2 or   another 'client buffer' module must be implemented.  The logic looks like;      brigade read loop       mem_body > max_memory_body ?         create tmpfile if tmpfile isnull         response 'failure' if total_body > max_buffer_body         write body -> tmpfile     reopen tmpfile read-only     insert tmpfile bucket of tmpfile prior to remaining mem_body buckets.    now we have two controls that would prevent DoS attacks present in the   original fix proposed (unbounded growth of the body.)  Remember, the   renegotiation would NOT determine the client certificate is valid until   after these resources had been consumed by a nefarious client.    I rather like the idea of apreq2 doing this work, and actually, integrating   apreq2 as a 'stock' apache module.  apreq2 does nothing until some module   in the server configuration wants to use its services.  HTTP/1.1 + client Expect: 100-continue    http://rfc.net/rfc2616.html#s8.2.3    Clients which truly pause for 100-continue could be satisfied with no   buffering of the body.  Schedule the renegotation prior to sending the   100 CONTINUE response.  Finally note that this is not specific to POST, it's generic to all HTTP methods which contain a client body.  The headers may be inspected to determine if the client is attempting to push a body with the request.   Isn't there any way to suppress renegotiation ? Workaround!!!  Following configuration works fine (optional for any except with CA  certificate, and required to an especific location):  SSLEngine on SSLVerifyClient optional_no_ca SSLVerifyDepth  2 SSLOptions +OptRenegotiate <location /any_location/ >         SSLVerifyClient require </location>  Regards,  Bruno Santiago 'SSLVerifyClient optional' seems also safe. Is 'SSLOptions +OptRenegotiate' really needed, or is it an optimisation ? Is it totally safe ? The doc states to use this carefully. (In reply to comment #34) > 'SSLVerifyClient optional' seems also safe. > Is 'SSLOptions +OptRenegotiate' really needed, or is it an optimisation ? > Is it totally safe ? The doc states to use this carefully.   The workaround explained above is not safe at least for apache 2.0.52. ' RE: [users@httpd] Bug or Feature : global SSLVerifyClient in <VirtualHost> overrides the same in  <Location>?  Simple test scenario is : 1. access document root location - 'SSLVerifyClient optional' ,  cancel certificate choice window. 2. access location <Location '/auth'> with  'SSLVerifyClient require' - no triggered SSL negotiation - access without certificate granted.  Correct should be the following behaviour, but there is no re-negotiation: >SSLVerifyClient is documented as working in directory context, so it should also work in <Location> context. The manual page for mod_ssl does  >explicitly say that a SSL renegotiation is triggered if a request for the location is received.    config sample:  <VirtualHost>  SSLVerifyClient optional   Alias /auth   /htdocs/access  <Location '/access'>  SSLVerifyClient require  SSLOptions +ExportCertData +StdEnvVars +OptRenegotiate SSLVerifyDepth 5  Options None  </Location>   </VirtualHost>   '       Proposed workaround is to add an additional <VirtualHost> and  configure in its context SSLVerifyClient require.   In my particular case creating webapi virtualhost suppose to fix problems with axis.           The problem mentioned in comment 35 is a separate issue from the bug covered here, and is fixed by: http://svn.apache.org/viewcvs?rev=264800&view=rev I was told to use something like this:  <VirtualHost ...>    ...    SSLVerifyClient none    ...    <Location /plop>       ...       SSLVerifyClient require       ...    </Location> </VirtualHost>  And this seems to work fine. Can someone confirm this is working correctly and I'm not missing some 'feature' for this bug ? Thanks If the bug isn't fixed, the issue is that the Location-specific renegotiation fails on a POST. If you're testing with GET, that's not a useful test. Created an attachment (id=16491) backport of patch from trunk  This is a backport of the patch from the trunk which was committed to fix this issue.\tAny results from testing are welcome. Created an attachment (id=16495) patch for 2.0.54  This patch can be applied to 2.0.54.  Now fixed for 2.1.8-beta and later.  http://svn.apache.org/viewcvs?rev=290965&view=rev  Given sufficient testing of the patch from comment 41, this could get a backport to 2.0.x. (In reply to comment #41)  > This patch can be applied to 2.0.54.  The patch can be applied to 2.0.55 aswell, and it allows using the following setup:    SSLVerifyClient optional   <Location /subversion>     DAV svn     SVNParentPath /path/to/reps     AuthzSVNAccessFile /path/to/accessfile     SSLVerifyClient require     SSLUserName SSL_CLIENT_S_DN_CN     SSLOptions +StrictRequire   </Location>  I used Subversion 1.2.3 clients on Linux and Windows for successful testing.  It is important to note that with the above configuration, access to the Subversion repository requires a client certificate, while other areas of the server can be accessed without certificates (i.e. webmail via HTTPS). Judging from my tests, this desired behaviour can not be achieved based on vanilla 2.0.55 sources, so I strongly welcome Joe's patch and hope it will be included as a 2.0.x backport in the future. (In reply to comment #43) > (In reply to comment #41) >  > > This patch can be applied to 2.0.54. >  > The patch can be applied to 2.0.55 aswell, and it allows using the > following setup: >  >   SSLVerifyClient optional >   <Location /subversion> >     DAV svn >     SVNParentPath /path/to/reps >     AuthzSVNAccessFile /path/to/accessfile >     SSLVerifyClient require >     SSLUserName SSL_CLIENT_S_DN_CN >     SSLOptions +StrictRequire >   </Location> >  > I used Subversion 1.2.3 clients on Linux and Windows for successful > testing. >  > It is important to note that with the above configuration, access to > the Subversion repository requires a client certificate, while other > areas of the server can be accessed without certificates (i.e. webmail > via HTTPS). Judging from my tests, this desired behaviour can not be > achieved based on vanilla 2.0.55 sources, so I strongly welcome Joe's > patch and hope it will be included as a 2.0.x backport in the future.    The problem is still not fixed. Was tested for apache 2.0.55 : there is still post method not allowed message described by you and other guys in this topic.  After patching apache it still doesn"t work, only the message is different.   We tried with apache_2.0.55 with unofficial patch from bugzilla (No.:12355) and got the following messages in logfiles.  access_log:  85.115.6.202 - - [17/Mar/2006:13:13:50 +0000] 'POST /webservice/services/SessionManagement HTTP/1.0' 403 - '-'  '-'  error_log with debug level in http.conf:  [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1738): OpenSSL: Handshake: start [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop: SSL renegotiate ciphers [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop: SSLv3 write hello request A [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop: SSLv3 flush data [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop: SSLv3 write hello request C [Fri Mar 17 13:32:54 2006] [info] Awaiting re-negotiation handshake [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1738): OpenSSL: Handshake: start [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop: before accept initializati on [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1697): OpenSSL: read 0/5 bytes from BIO#83a24b8 [mem : 842d708] (BIO dump follows) [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1644): +-------------------------------------------- -----------------------------+ [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1675): +-------------------------------------------- -----------------------------+ [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1770): OpenSSL: Exit: failed in SSLv3 read clien t hello B [Fri Mar 17 13:32:54 2006] [error] Re-negotiation handshake failed: Not accepted by client!? [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1488): [client 85.115.6.202] read from buffered SSL brigade, mode 0, 8192 bytes [Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1550): [client 85.115.6.202] buffered SSL brigade no w exhausted; removing filter [Fri Mar 17 13:33:07 2006] [debug] ssl_engine_io.c(1708): OpenSSL: I/O error, 5 bytes expected to read on BIO#83a24b8 [mem: 842d708] [Fri Mar 17 13:33:07 2006] [info] (70007)The timeout specified has expired: SSL input filter read faile d. [Fri Mar 17 13:33:07 2006] [debug] ssl_engine_kernel.c(1756): OpenSSL: Write: SSL negotiation finished successfully [Fri Mar 17 13:33:07 2006] [info] Connection to child 2 closed with standard shutdown(server drecord.de .something.com:443, client 85.115.6.202)  --------------------------------------------------------------------------------   P.S. We have additional virtualhost configured that is responsible for certificate authentication and session management with axis, there it works perfectly. So the problem occures only for <location> that doesn"t have a globaly set <SSLVerifyClient> to optional or required  P.P.S.  <SSLVerifyClient> optional in a global context fix the problem , but this solution is not acceptable because it enforce the browser to show the popup with installed certificates.(sure it is a browser issue and probably could be configured on the client side, but this is not the way it should work in productive env.)  Regards, Yefym If you have any problems using this patch, please upgrade to 2.2.0 instead, and file bugs giving the error_log output from 2.2.0. *** Bug 39154 has been marked as a duplicate of this bug. *** *** Bug 39243 has been marked as a duplicate of this bug. *** *** Bug 39705 has been marked as a duplicate of this bug. *** I couldn't understand why this bug is not fix by Apache team since the release  of Apache2. I really need this features to be enabled as what we have in  mod_ssl for version for apache1.3.x. It is fixed in 2.2.x, but has not been backported to 2.0.x yet. There is a patch against 2.0.54 attached to this report for those who need to fix this immediately for 2.0.x.    First this IS fixed in 2.2.0.  Backports aren't discussed on Bugzilla, this   issue has been raised in our 2.0.x STATUS file.  And given a more accurate name. this bug is always present with Apache/2.2.4.  You can't mixed SSLVerifyClient optinal and SSLVerifyClient requierd part To allow some Location for non SSL valid Client.   NOT WORKING ======== ------------------------ SSLVerifyClient optional SSLVerifyDepth  1 SSLOptions +OptRenegotiate <Location /Album> SSLRequireSSL SSLVerifyClient      require SSLCACertificateFile conf/ssl.crt/Root_Certificat.crt SSLCACertificatePath conf/ssl.crt SSLRequire  (%{SSL_CLIENT_S_DN_OU} eq 'Portable' || %{SSL_CLIENT_S_DN_OU} eq 'Personnal') SSLVerifyDepth       3 #FIX ANOTHER BUG SetEnv REMOTE_USER ${SSL_CLIENT_S_DN_CN} SSLUserName SSL_CLIENT_S_DN_CN </location>   WORKING == --------- Sorry ... I forgot to say .. that the bug is only with php. CGI perl work fine .. It's working fine when the certificat private key is <= 512. 2048b not working 1024b not working. But I don't understand why  If it's can help coders.  (In reply to comment #54 and previous ones) > It's working fine when the certificat private key is <= 512. > 2048b not working > 1024b not working. > But I don't understand why >  > If it's can help coders. >   This looks like an unrelated problem, could you open a new issue for it? Thanks. (In reply to comment #52) > this bug is always present with Apache/2.2.4. >  > You can't mixed SSLVerifyClient optinal and SSLVerifyClient requierd part > To allow some Location for non SSL valid Client. >   This was fixed in Apache 2.0.55, changelog:    *) SECURITY: CVE-2005-2700 (cve.mitre.org)      mod_ssl: Fix a security issue where 'SSLVerifyClient' was not      enforced in per-location context if 'SSLVerifyClient optional'      was configured in the vhost configuration.  [Joe Orton]  *** Bug 42625 has been marked as a duplicate of this bug. *** *** Bug 42625 has been marked as a duplicate of this bug. *** Backported to 2.0.x as r536373 (http://svn.apache.org/viewvc?view=rev&revision=536373)			Birger Toedtmann	Bruno Santiago	Davi Arnaut	David A. Desrosiers	Derrier Dominique	Eric Kraar	Erik Abele	Joe Orton	Joshua Slive	Marc Poulhi	Marc Stern	Marcin	Matthias Wimmer	Mohamed Sadok MOUHA	Pascal AUBRY	Ralph Seichter	Rob Riggs	Ruediger Pluem	Scott Cantor	Serge Dubrouski	Sushil Kambampati	Will Rowe	William J Dennison	Wolf-Dietrich Moeller	Yefym	keilh	richard chen
12395	null	CLOSED		Dr. Georg Czedik-Eysenberg	1031484300000	1041126732000		' 'Options -FollowSymLinks' combined with 'RewriteEngine on' (in '.htaccess')  results in the error message 'Options FollowSymLinks or SymLinksIfOwnerMatch is  off which implies that RewriteRule directive is forbidden'.  I suppose, that this is o.k., although I did not find it specified  in 'http://httpd.apache.org/docs/mod/mod_rewrite.html'.  But also 'Options -FollowSymLinks' combined with 'RewriteEngine off' results in  this error message and I this, that this is a bug.  Now you might ask, why I want to use 'RewriteEngine off', although this is the default, but I have a reason for this:  In the root directory of my (virtual) server I have 'Options +FollowSymLinks'  and I want to use 'RewriteEngine on' (this is no problem).  But in the subdirectory 'cgi-bin' there seems to be implicitly 'Options -FollowSymLinks' and even an explicit 'Options +FollowSymLinks' does not work (WHY???) and therefore I want to set 'RewriteEngine off' there,  in order to be able to use the 'cgi-bin' directory without getting the above- mentioned error message.	Hi,  is there really nobody out there, who is interested in this bug, which I reported 8 weeks ago and is still in the status NEW? :-(  Or do you need any additional information from me?  Regards, Georg Sorry for the long delay. It's fixed now in HEAD (i.e. httpd-2.1.0-dev) and will probably be backported to 1.3 and 2.0.  Thanks for using Apache! (and thanks for your patience...) *** Bug 16526 has been marked as a duplicate of this bug. *** Has this been resolved in Apache 1.3 yet? I notice it was originally logged in this bug against 1.3.23. I use 1.3.26 (Debian Packages) and it hasn't been resolved. Skimming the 1.3.27 CHANGES file I can see no mention of it being fixed there either... Ah, sorry, perhaps I should mention the state ;-) It's resolved for the next releases of 2.0.45 and 1.3.28. If I use this      RewriteEngine on     RewriteCond %{HTTP_REFERER} ^(.*)$     RewriteRule ^(.*)     -       [CO=referrer:%1:.domain.com]  in combination with -FollowSymLinks, I also get the error:   'Options FollowSymLinks or SymLinksIfOwnerMatch is  off which implies that RewriteRule directive is forbidden'  I'm not rewriting any URL, I just want to write out a coookie. Is this fixed in  this bugfix too? No. Options -FollowSymlinks means that you can't have any RewriteRules active. You may use mod_headers for only setting headers...			Andr?? Malo	Dr. Georg Czedik-Eysenberg	Sander Holthaus	Trevor Phillips
12483	null	CLOSED		Jess Holle	1031669340000	1043231865000		auth_ldap does not handle non-ASCII characters in auth name If a user name contains a non-ASCII (e.g. a Latin 1 high-byte like ??)  character, the httpd-ldap LDAP authentication modules do not properly encode  this when communicating with LDAP (at least with v3 LDAP).  It appears that the ldap authentication modules are essentially passing the  authentication name bytes along exactly as received, rather than re-encoding  them in UTF-8 as required by the RFC.  This appears to apply regardless of  which LDAP libraries are used (iPlanet/Netscape or OpenLDAP).  This severely limits this module for any locale outside the US.  [This issue also applies to the www.rudedog.org module upon which the httpd- ldap modules are based.]	   If you modify your httpd.conf file in utf-8, providing a legit non-ASCII, utf-8   encoded AuthName string, what happens?   A new directive AuthLDAPCharsetConfig was added which specifies a charset conversion file to fix this problem.  Patch was applied to v2.1.0-dev in December, and to v2.0.45-dev in January. 			Graham Leggett	Will Rowe
12596	null	CLOSED		Andr?? Malo	1031863860000	1046629557000		t unescape the pattern from query string if you use the form example from the mod_autoindex docs, opera (5&6  tested) escapes a '*' to %2A (yes: 42 ;-)  (At least) the P query parameter should be unescaped in general by  mod_autoindex.	Fixed in 2.1 and proposed for backport. Thanks, Andr??, for your report ;-)			Andr?? Malo
12655	null	CLOSED		William Drury	1032055320000	1118788952000		 sometimes causing QUERY_STRING variable to be garbage. I have run into this problem in both 2.0.39 and 2.0.40.  Using httpd 2.0.40 in Linux Mandrake 8.2, compiled without any external modules (but with --enable-rewrite), I have set the following things in httpd.conf:  AddHandler cgi-script .sgi AddOutputFilter INCLUDES .sgi  My intent is to server-parse the output of cgi scripts whose filename ends with .sgi.  This seems to work, if I print '<!--set VAR=/'FOO/' VALUE=/'bar/' -->/n' ; in the script, it is indeed set, so that code like:  <!--#include virtual='/cgi-bin/foo.sgi?$QUERY_STRING' --> <!--#if expr='$FOO' --> Foo is set. <!--#else --> Foo is not set. <!--#endif -->  produces the expected final output 'Foo is set.'.  However, if I have several 'include virtual' statements in the same .shtml file, there appears to be a problem.  If I add more include virtual statements to this file, like:  <!--#include virtual='/cgi-bin/foo.sgi?$QUERY_STRING' --> <!--#include virtual='/somefile.html' --> <!--#include virtual='/another_existing_file.html' --> <PRE> <!--#include virtual='/cgi-bin/printenv?$QUERY_STRING' --> </PRE>  ... printenv will show QUERY_STRING to be an empty string, and QUERY_STRING_UNESCAPED to be a disturbingly different line of garbage each time.  I'm available to test fixes on my example setup.  William Drury	This is probably related to bug 12542. This behaviour is still occurring in 2.0.42 It works for me with HEAD. Can you please test the current version with your setup and confirm?  Thanks! No further response. Assuming issue resolved.  Please reopen the bug if this is not the case and you can provide additional information.  Thanks for using Apache.  the bug still exists in 2.0.54.  the problem is that during subrequest processing, QUERY_STRING is allocated from subrequest's own r->pool that gets destroyed later, invalidating the table entry in the global suprocess_env.  apr_pool_join(r->main->pool, r->pool); which, if i'm correct, is supposed to take care of subrequest's pool lifetime, is effectively a nop when compiled without APR_POOL_DEBUG (--enable-pool-debug).  there might be other consequences of assuming extended lifetime of subrequest's pool, but in regard to QUERY_STRING i have made a small patch that i attach to this bug.  having investigated this i find the issue obvious enough, but i can arrange a testcase if requested. Created an attachment (id=15216) the patch for QUERY_STRING case  Hmmm, interesting.  Do you have a simple test case which reliably reproduces the issue, I can't get the examples above to fail?  But I don't disagree with your analysis, though I'm not convinced your fix is sufficient.  Are there other places where r->main->subprocess_env will get populated from r->pool during the subrequest?  I think there are: e.g.,  handle_set().  The apr_pool_join() call isn't supposed to actually do anything for non-debug builds; it just says 'I guarantee that this subpool won't be destroyed before its parent'.  But in fact that guarantee is not really given: the subrequest r->pool *is* destroyed, when ap_destroy_sub_req is called.  So a possibly more correct fix would be to just remove the call to ap_destroy_sub_request.  Does that fix your case, also? i have even shorter test case.  http://testcase12655.rbc.ru:88/?testQS - non-patched 2.0.54, QS3 should contain garbage.  http://testcase12655.rbc.ru/?testQS - patched, should be ok.  you can browse the source here: http://testcase12655.rbc.ru/index.txt http://testcase12655.rbc.ru/q.txt http://testcase12655.rbc.ru/empty.txt (every .shtml has a corresponding .txt symlink)  i don't normally hack apache, so i can't say if there are other places to fix pool usage in subrequests... i'm glad that i brought your attntion to this issue so it can be fixed thoroughly :) Thanks a lot, that was a great help.  I've committed a fix for this to the trunk and will propose it for backport to 2.0.x.  http://svn.apache.org/viewcvs?rev=179763&view=rev Now merged for 2.0.55.  http://svn.apache.org/viewcvs?rev=264762&view=rev *** Bug 36452 has been marked as a duplicate of this bug. ***			Andr?? Malo	Deomid Ryabkov	Joe Orton	Joshua Slive	William Drury
12660	null	CLOSED		Thomas Bader	1032093060000	1032094864000		wrong url in default httpd.conf See the default httpd.conf on Line 45:  # (available at <URL:http://httpd.apache.org/docs-2.0/mod/core.html#lockfile>);  This URL is wrong; the right URL is:  http://httpd.apache.org/docs-2.0/mod/mpm_common.html#lockfile  Would be nice, if this could be fixed.	I just fixed this and it will be in one of the next releases of Apache (2.0.41 presumably).  Thanks for your report, and thanks for using Apache.			Erik Abele
12678	null	CLOSED		Nathan Gardner	1032175560000	1032197017000		Bad link and short on content The FAQ is short on content.  The link provided goes to the old bug tracking DB and not the new one (although the new one is linked). It appears that the old bug database's search engine is broken making the page rather disfunctional. Pointing this straight to the new bug tracking database would seem to a lot more sense.	Thanks.  I've corrected the link.  The 2.0 faq is short on content because we still haven't decided how we are going to handle it.  The 1.3 faq is still the best faq for both versions at the moment.  Contributions welcome.			Joshua Slive
12705	null	CLOSED		Amund Elstad	1032205620000	1033494933000		mod_ssl stuck in infinite loop mod_ssl appears to be stuck forever inside apr_pool_cleanup_kill when closing the session cache (I have a 'SSLMutex sem' in the config).   Backtrace (full dump available on request):  libapr!apr_pool_cleanup_kill+0x24 [./memory/unix/apr_pools.c @ 1920] libapr!apr_file_close+0x2d [./file_io/win32/open.c @ 420] libaprutil!database_cleanup+0x31 [./dbm/sdbm/sdbm.c @ 122] libapr!apr_pool_cleanup_run+0x1b [./memory/unix/apr_pools.c @ 1959] libaprutil!apr_sdbm_close+0x18 [./dbm/sdbm/sdbm.c @ 225] libaprutil!vt_sdbm_close+0xf [./dbm/apr_dbm_sdbm.c @ 171] libaprutil!apr_dbm_close+0x10 [./dbm/apr_dbm.c @ 121] WARNING: Stack unwind information not available. Following frames may be wrong. mod_ssl+0xf837 mod_ssl+0xf154 mod_ssl+0x924d ssleay32!SSL_SESSION_new+0x609	Shouldn't the calls to dbm_close in ssl_scache_dbm_retrieve be protected by the  mutex ? Every other call to dbm_close appears to be .   The fix has been committed and will be in the next release of Apache.  Thanks for figuring this out! 			Amund Elstad	Jeff Trawick
12706	null	CLOSED		Peter H. Smith	1032208500000	1054154854000		t get created on fast build machine If your machine is fast enough, ApacheCore.mak won't build test_char.h causing the build to break when it gets to trying to build utils.c:  \tcl.exe /D 'EAPI' /DMOD_SSL=208109 /nologo /MD /W3 /O2 /I './include' /I  './os/win32' /I './os/win32 /win9xconhook' /D 'NDEBUG' /D 'WIN32' /D '_WINDOWS' /D 'WIN32_LEAN_AND_MEAN' /Fo './Release//' /Fd'./Release/ApacheCore' /FD /c ./os/win32/service.c service.c NMAKE : fatal error U1073: don't know how to make ''./main/test_char.h'' Stop. NMAKE : fatal error U1077: 'e:/sd_tools/VISUALC.60/bin/NMAKE.EXE' : return  code '0x2' Stop. NMAKE : fatal error U1077: 'e:/sd_tools/VISUALC.60/bin/nmake.exe' : return  code '0x2' Stop. make: *** [all] Error 2 NMAKE : fatal error U1077: 'C:/WINNT/system32/cmd.exe' : return code '2' Stop.  I think this is because both gen_test_char.mak and gen_uri_delims.mak use the tag file src/main/Release/postbld.dep, and it looks like when the CPU gets fast enough, the postbld.dep created by gen_uri_delims.mak has the same timestamp as the gen_test_char.exe created afterwards.  Here's a snippet from my build log:  \tcd ../.. \tcd main \tNMAKE -nologo -f gen_uri_delims.mak CFG='gen_uri_delims - Win32  Release' RECURSE=0  \tif not exist './Release/nul' mkdir './Release' \tcl.exe @e:/TEMP/nma02268. gen_uri_delims.c \tlink.exe @e:/TEMP/nmb02268. \t./gen_uri_delims > uri_delims.h \techo Helper for Post-build step > './Release/postbld.dep' \tNMAKE -nologo -f gen_test_char.mak CFG='gen_test_char - Win32 Release'  RECURSE=0  \tcl.exe @e:/TEMP/nma02176. gen_test_char.c \tlink.exe @e:/TEMP/nmb02176. \tcd .. \tdel Release/buildmark.obj The system cannot find the file specified. \tNMAKE -nologo -f ApacheCore.mak CFG='ApacheCore - Win32 Release'  RECURSE=0  \tif not exist './Release/nul' mkdir './Release' \tcl.exe /D 'EAPI' /DMOD_SSL=208109 /nologo /MD /W3 /O2 /I './include' /I  './os/win32' /I './os/win32 /win9xconhook' /D 'NDEBUG' /D 'WIN32' /D '_WINDOWS' /D 'WIN32_LEAN_AND_MEAN' /Fo './Release//' /Fd'./Release/ApacheCore' /FD /c ./main/alloc.c alloc.c  In previous builds, these lines appeared in the above log (one line of context):  gen_test_char.c \tlink.exe @e:/TEMP/nmb00884. \t./gen_test_char > test_char.h \techo Helper for Post-build step > './Release/postbld.dep' \tcd ..  The way to fix this is to choose different INTDIR values for the Visual C++ projects gen_uri_delims and gen_test_char.  Or make sure you build on a laptop with speedstep and unplug before you start the build (I think I've been building in my car since I got the new laptop :-)  I tried to find a note about this in Bugzilla, but I wasn't smart enough to get a hit.  If it's already there, my apologies; send me the search string and I'll learn from it.  This is a very minor issue but could cause stupid people like myself consternation when they upgrade their equipment.	   Invoking the .exe's should be a pre-build step of ApacheCore.dsp, methinks.   With a target file of the actual .h and the source being the .exe itself.    If you feel like authoring a patch - you could also set up a custom cl step   to compile buildmark.c as a pre-link step - I did that in httpd-2.0's   libhttpd.dsp, but have been to busy to invest much time.  Happy to review   your patch if you would like to submit.    buildmark.c is now a pre-build step.  Now ApacheCore.dsp builds both of the   test_char.h and uri_delims.h files so they should no longer conflict or   exhibit the odd behaviors that you observed.    This will show up in your Apache 1.3.28 source .zip package.  Thanks for the   report and your analysis! 			Will Rowe
12712	null	CLOSED		Sander van Zoest	1032215700000	1033736675000		[PATCH] Include conf.d/*.conf See Message-ID: <20020912124210.E7252@escher.san.yahoo.com>.  This patch adds the ability include files using a regex. This patch is a backport of the patch provided by Joe Orton for HTTPd 2.0.41  The common problem with the directory include is the fact that it includes everything. Including backup and temporary files as generated by many editors such as Emacs, etc.	Created an attachment (id=3087) apache_1_3_include_fnmatch.patch  I believe regex is not the right word.  fnmatch or 'shell-style wildcard' is what you mean. yes. that is what I meant. This feature has been added as from apache 1.3.27  Dw. --  Dirk-Willem van Gulik  			Dirk-Willem van Gulik	Joshua Slive	Sander van Zoest
12757	null	CLOSED		Shaun Kelly	1032318540000	1043146678000		mod_ldap cache tries to open an existing shared memory file File: /modules/experimental/util_ldap_cach.c  apr_status_t util_ldap_cache_init(apr_pool_t *pool, apr_size_t reqsize) { #if APR_HAS_SHARED_MEMORY     apr_status_t result;      - result = apr_shm_create(&util_ldap_shm, reqsize, '/tmp/ldap_cache', pool);     + result = apr_shm_create(&util_ldap_shm, reqsize, NULL, pool);     if (result != APR_SUCCESS) {         return result;     }  pool); #endif .... } The ldap cache used by mod_ldap and mod_auth_ldap tries to create a shared  memory file for each process forked. The problem is that only the first process  is able to create the file, all the other processes fail to create the file  because it already exists. This disables caching on all processes other than  the initial process. Caching LDAP authentication is essential as this is a slow  task, especially with Microsoft Active Directory. One solution on linux is to  use an anonymous shared memory file (fileName is NULL) but apparently anonymous  shared memory is not supported on other platforms. I assume all processes  should share a single cache. Would anonymous shared memory create a new file  for each process? If this is not desired, only the first process should create  the file and all the other processes should attach to in.	This also happens on a solaris 8 platform with the error  [debug] util_ldap.c(1066): (17)File exists: [4449] ldap cache init: File exists   i tried disabling the code in the #if APR_HAS_SHARED_MEMORY statements to at least get the per server cache to work although it has the error  [debug] util_ldap.c(1066): [8329] ldap cache init: Error 0  Actually, wouldn't it be better to just attach to the named file?  I implemented something like this:  cvs diff -c util_ldap_cache.c  Index: util_ldap_cache.c =================================================================== RCS file: /usr/src/cvs/cvsroot/contrib/Apache/modules/experimental/util_ldap_cache.c,v retrieving revision 1.1.1.1 diff -c -r1.1.1.1 util_ldap_cache.c *** util_ldap_cache.c   8 Oct 2002 20:49:28 -0000       1.1.1.1 --- util_ldap_cache.c   10 Jan 2003 22:55:51 -0000 *************** *** 296,304 ****       apr_status_t result;          result = apr_shm_create(&util_ldap_shm, reqsize, '/tmp/ldap_cache', pool); !     if (result != APR_SUCCESS) {           return result; -     }          /* This will create a rmm 'handler' to get into the shared memory area */       apr_rmm_init(&util_ldap_rmm, NULL, --- 296,310 ----       apr_status_t result;          result = apr_shm_create(&util_ldap_shm, reqsize, '/tmp/ldap_cache', pool); !     if (result == EEXIST) { !       /* !        * The cache could have already been created (i.e. we may be a child process).  See !        * if we can attach to the existing shared memory !        */ !       result = apr_shm_attach(&util_ldap_shm, '/tmp/ldap_cache', pool); !     }  !     if (result != APR_SUCCESS)           return result;          /* This will create a rmm 'handler' to get into the shared memory area */       apr_rmm_init(&util_ldap_rmm, NULL,  and it seems to work for me.  Patch applied to v2.0.45-dev and v2.1.0-dev			Graham Leggett	Michael Dean	Scooter Morris
12877	null	CLOSED		Dennis Lundberg	1032558300000	1047073074000		The AddLanguage directive for the Swedish language is wrong in httpd.conf In the default httpd.conf there is a directive to add the Swedish language like this: AddLanguage sv .se  This is wrong since 'se' is a country-code and 'sv' is a language code. The correct directive should be: AddLanguage sv .sv	This was fixed in Apache 1.3 on Tue Mar  5 08:14:25 PST 2002, following a bug report from me. That bug report had the internal identification "config/10040'. A fix for this bug also requires that the file 'htdocs/index.html.se' is renamed to 'htdocs/index.html.sv' Created an attachment (id=3157) Fixes docs/conf/httpd-std.conf.in  Created an attachment (id=3158) Fix for docs/conf/httpd-win.conf  Created an attachment (id=3159) Fix for docs/conf/httpd-nw.conf  This is not, strictly speaking, a bug.  The extension that is chosen for the filename is arbitrary.  We could just as well use .sweden-is-cool. What matters is that the correct language code is getting applied to that extension, and that is happening.  But it would probably be better if the extension and language code is consistent, unless there is some good reason to do otherwise.  On the other hand, I'm leaning very close to removing all the AddLanguage lines from httpd.conf except those necessary to do the documentation.  I don't see the benefit from us maintaining those.  All they create is bug reports ;-)  (And, as a final note, it shouldn't be necessary to rename the index.html.se file because the welcome page now uses a typemap rather than multiviews.) But why have the arbitrary chosen extension set to something that people get annoyed about? The map is for languages, se represents the country Sverige (Sweden) and sv the language Svenska (Swedish) according to ISO639: http://www.evertype.com/standards/iso639/iso639-en.html ISO639-2 uses three characters per language though..  Created an attachment (id=5094) Changes swedish language-code for config- and docroot-files  Created an attachment (id=5095) Replacement file for docs/docroot/index.html.se  I'll try this once again then. I've created attachments 5094 and 5095 which provides a complete solution for this problem.  5094 is a patch 5095 is a new file  The file docs/docroot/index.html.se should be removed, as it is replaced by attachment 5095.  Can someone please check these in? *sigh* two points:  - again: file naming has nothing to do with language codes.   (e.g. .pl for Polish is a quite bad choice) - what is your 'replacement' meant for? It's exactly the same file that exists now.  But to be consistent with 1.3 and to make you guys happy ;-), I'm going to change the config and the filename... Fixed for the next release (2.0.45).			Andr?? Malo	Dennis Lundberg	Joshua Slive	Tomas 
12880	null	CLOSED		Dennis Lundberg	1032559080000	1032635381000		Translation errors in Swedish error documents The Swedish (sv) translation in the file error/HTTP_FORBIDDEN.html.var contains some errors. Below is a corrected version.  Content-language: sv Content-type: text/html Body:----------sv-- <!--#set var='TITLE' value='&Aring;tkomst f&ouml;rbjuden!' --> <!--#include virtual='include/top.html' -->    <!--#if expr='$REDIRECT_URL = ///$/' -->      Du har inte tillr&auml;ckliga r&auml;ttigheter f&ouml;r att f&aring;     tillg&aring;ng till den &ouml;nskade katalogen. Det existerar inget     indexdokument eller s&aring; &auml;r katalogen l&auml;sskyddad.    <!--#else -->      Du har inte tillr&auml;ckliga r&auml;ttigheter f&ouml;r att f&aring;     tillg&aring;ng till det &ouml;nskade objektet. Objektet &auml;r     l&auml;sskyddat eller inte l&auml;sbart f&ouml;r servern.    <!--#endif -->  <!--#include virtual='include/bottom.html' --> ----------sv--	Created an attachment (id=3161) Patch for docs/error/HTTP_FORBIDDEN.html.var  *** Bug 12879 has been marked as a duplicate of this bug. *** *** Bug 12881 has been marked as a duplicate of this bug. *** *** Bug 12882 has been marked as a duplicate of this bug. *** See also the patches in all the 'duplicate' bugs. Thanks.  These changes have committed and will be available in a future version (but probably not the next release, because that has already  branched).			Dennis Lundberg	Joshua Slive
12901	null	CLOSED		Rusty Conover	1032686100000	1033820368000		Needed Kludge for WebDAV and Gnome-VFS To get gnome-vfs to work properly with mod_Dav you need to have the same kludge that has been added for 'Microsoft Data Access Internet Publishing Provider'.  If this line could be added to the initial config it would prevent a lot of difficulties using DAV and gnome-vfs together.  The line that needs to be added:  BrowserMatch '^gnome-vfs' redirect-carefully	This has been committed to the default conf files and will be in the next release.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
12902	null	CLOSED		Rik Arpino	1032697200000	1049496881000		DocumentRoot not being appended to URL Not the one described in the FAQ btw. Double checked that....!  I cannot get the DocumentRoot prepended to the processed URL *UNLESS* it  already contains a drive letter (in the RewriteCase). The log results are as  follows (last few lines only):  With a drive letter:  ...(2) local path result: c:/sebastian.tld/www/ ...(2) prefixed with document_root to C:/Apache/sitexc:/sebastian.tld/www/ ...(1) go-ahead with C:/Apache/sitexc:/sebastian.tld/www/ [OK]  Without drive letter:  ...(2) local path result: /sebastian.tld/www/  Without the drive letter already there, logging never reports the 'OK'  Guess this is a problem only effecting Win32 systems.....?  My conditions are in the httpd.conf and were based around the examples in the  documentation for virtual hosting (this code fails on my system):  RewriteEngine On  RewriteMap lowercase int:tolower  RewriteCond  %{REQUEST_URI}               !^/cgi-bin/ RewriteCond  ${lowercase:%{HTTP_HOST}}\t  ^([a-z0-9/_/-]+)/.(.+)$ RewriteRule  ^/(.*)$                      /%2/%1/$1  RewriteCond  %{REQUEST_URI}               ^/cgi-bin/ RewriteCond  ${lowercase:%{HTTP_HOST}}    ^([a-z0-9/_/-]+)/.(.+)$ RewriteRule  ^/(.*)$                      /%2/$1  When Fails HTTP Err 400 is generated....otherwise a 404 is generated.  This example worked fine with 1.3.4  Rik	The problem lies function hook_uri2line, beginning on line 1285:  1. the module (I think) wants to make sure that the resulting filename starts with a slash, but it uses the ap_os_is_path_absolute function. If the filename does indeed start with a slash this call will succeed on Unix, but it will fail on Windows because ap_os_is_path_absolute will expect a path starting with D:/ or //machine/share. Hence the '400 Bad Request' error.  2. next the module check if the first part ('the prefix') of the path exists. This is done using the prefix_stat function which works only on Unixes (it expects the path to start with a slash!)  I think the first part is unnecessary and that the second part should be based on core.c (as stated in the comments).    The fact is that '/foo' isn't an absolute path.on Windows.  In all fairness,   we should still try to work around this.  Note the earlier code was much   more evil, in that 'c:/foo' wasn't recognized as a rooted path.    The one case I want to avoid is accepting 'c:foo' since that path is most   definately not sufficiently rooted.  So that said, we should try to test   the APR_EINCOMPLETE result and have a static is_path_rooted function within   mod_rewrite to test the complete and some incomplete path results.    Don't have time to work up a patch at the moment, but thought I ought to   add some observations while they are fresh in my mind.  I to am having this EXACT problem. I thought maybe i just wasn't getting the  grasp of Mod_Rewrite, but it turns out to be a bug!  :-(  Any update on this bug? Been a couple of months. After a bit of playing around, I found that version 1.3.26 did NOT suffer from  the same problem - in fact I was hard pressed to find problems with mod_rewrite  in the 1.3.26 packaged version on win32. Dunno if this helps anyone? Sorry for  not updating sooner.....spoon reminded me!!! Some patches were made to the main dev branch (2.1) and are proposed for backport. I think, they will solve your problems and hopefully they will go into next 2.0 and 1.3 releases.  Thanks for your reports and thanks for using Apache! Wonder how long till the next release :-)  Is there a workaround in 2.x that  was not mentioned? Possibly some way of tricking it? Or possibly access to  apache-dev? Uh, sorry overlooked your questions ...  However, it should be fixed in 2.0.45. Please reopen this report if it's not.  Thanks.			Andr?? Malo	Rik Arpino	Silvester Erdeg	Will Rowe	spoon
12910	null	CLOSED		Bojan	1032732600000	1047229651000		htdigest.exe - The process cannot access the file because it is being used by another process. d:/WEB/Apache2/bin>htdigest.exe Usage: htdigest [-c] passwordfile realm username The -c flag creates a new file.  d:/WEB/Apache2/bin>htdigest.exe -c test testrealm user1 Adding password for user1 in realm testrealm. New password: **** Re-type new password: ****  d:/WEB/Apache2/bin>htdigest.exe test testrealm user2 New password: *** Re-type new password: *** The process cannot access the file because it is being used by another process.         0 file(s) copied.  I allways get this message no metter what !! Ok, workaroud is what I did: -create file withd password -copy/paste the only one line inthere to some file in witch you realy have  passwords! -repeate the process !   Bojan.	Please try the 2.0.42 binaries for Win32 (still an alpha release candidate  at this time, but they are not yet released).  They are available from     http://httpd.apache.org/dev/dist/  As both htpasswd and htdigest have undergone some fixes, you may find that the issue is resolved in the latest code.  Thanks  bad news:   no the problem still exists:   d:/WEB/Apache2_new/bin>htdigest.exe -c tt realm user1 Adding password for user1 in realm realm. New password: **** Re-type new password: ****  d:/WEB/Apache2_new/bin>htdigest.exe tt realm user2 Adding user user2 in realm realm New password: ** Re-type new password: ** The process cannot access the file because it is being used by another process.         0 file(s) copied.  ... [This is a mass bug update.] This bug reports a problem in an older version of Apache 2. Could you please update to the most recent version and see if you can reproduce this problem.  If the bug still exists, please update the bug with the latest version number.  If  the bug no longer exists, please close the bug report.  Sorry for this impersonal response, but we get many more bug reports than our volunteers can keep up with. Thanks for using Apache! [This is a mass bug update.] [Resolve-20021102] No response from submitter; assuming issue is resolved. If the problem still exists in the lastest version, please reopen this report and update appropriately. I just downloaded 2.0.44 and installed it several days ago and this error still  exists.   I am using the same workaround shown below, but this is an extremely  inefficient method for more than just a few users.  I have tried turning off  the service and monitor, rebooting, running from different directories,  changing file names.  It always fails when you try to update an entry or add a  new entry.  My experience is exactly that reported by 'Bojan', apparently on 22Sep02.  -David     They still didn't fix this problem ?  Hopefully I don't have many users, i think if you have many users than this is realy a big problem.  Bojan. A patch has been applied to the main dev branch (2.1) and is proposed for backport to 2.0.  Thanks for your reports and thanks for using Apache. FYI: fixed for the next release (2.0.45).			Andr?? Malo	Bojan	David Saxe	Joshua Slive	Will Rowe
12981	null	RESOLVED		Matthew H. Gerlach	1032913380000	1113585799000		t take binary post data In version 2.0.42, ApacheBench cannot handle non-ascii text in the post data.  This is due to the use of strcpy() when memcpy() should have been used.  Below is the output of diff -c on my fix to the problem:  mg-lin:~/free_source/httpd-2.0.42/support % diff -c ab.c ab.c.orig *** ab.c        Tue Sep 24 17:11:51 2002 --- ab.c.orig   Tue Sep 24 16:59:19 2002 *************** *** 1629,1635 ****       if (posting == 1) {         char *buff = (char *) malloc(postlen + reqlen + 1);         strcpy(buff, request); !       memcpy(buff + reqlen, postdata, postlen);         request = buff;       }    --- 1629,1635 ----       if (posting == 1) {         char *buff = (char *) malloc(postlen + reqlen + 1);         strcpy(buff, request); !       strcpy(buff + reqlen, postdata);         request = buff;       }    *************** *** 1939,1945 ****         return APR_EINVAL;       }       apr_file_close(postfd); -     printf('successfully read %d bytes of file, %s/n', length, pfile);       return 0;   }    --- 1939,1944 ----	Fixed on the trunk, thanks for the patch!  http://svn.apache.org/viewcvs?view=rev&rev=161483			Joe Orton
13025	null	CLOSED		Sander Holthaus	1033038240000	1033362408000		CGI and POST-requests broken when DAV enabled After updating from 2.0.40 to 2.0.42, all POST-request to the cgi-bin are  broken, and return the script source-code! GET-request to the same scripts  function normal. This is not a config issue, worked up to 2.0.40, and works for GET in 2.0.42	I had the same problem.  Do you have DAV configured for your server?  When I disabled DAV for that directory, the problem went away.  This is on my list of things to investigate. Well, now that you mention it, yes, I have. I cannot back up your theory I'm  affraid since I immediatelly downgraded to 2.0.40 (downgrade, never thought I  would do that). But it is likely that you are right. Fixed in CVS.  Mod_Dav was setting the handler for all requests for a DAV-enabled location to the DAV handler.  Unfortunately, this is not a good idea, because it means that CGI scripts that use the POST handler will always fail.  I have reverted that change.			Ryan Bloom	Sander Holthaus
13104	null	CLOSED		Han, SangBeom	1033167000000	1033172913000		suexec log file location have a problem and -with-suexec-logfile does not work If i enabled suexec option, SuExec log file was not created initally and  suexec did not work. So i created /usr/local/apache2/logs/cgi.log  or /usr/local/apache2/logs/suexec_log, but it did not work.   After that, i inspected source file of suexec. I found that source code in  support/suexec.h file says not apache2 but 'apache'.   > #ifndef AP_LOG_EXEC > #define AP_LOG_EXEC '/usr/local/apache/logs/cgi.log'   /* Need me? */                                   ~~~~~~ > #endif   In addition to this, it seems that '-with-suexec-logfile' compile flag does  not work.	I have committed a fix that makes all of the default paths for suexec /usr/local/apache2.  Thank you for the bug report and for using Apache.  I will fix the --with-suexec-log option next. The --with-suexec-log command is working in my tests now.  Please try the latest code from CVS and report back if it still fails for you.			Ryan Bloom
13119	null	CLOSED		Schneider	1033298340000	1037499799000		Translation error in German error-message Error in file HTTP_GONE.html.var  In the section under 'Content-language: de' is a colon missing (after '</a>') and  the following word 'das' has to be changed to 'dass'.  Correct: ===================================     Bitte informieren Sie den Autor der     <a href='<!--#echo encoding='url' var='HTTP_REFERER'-->'>verweisenden  Seite</a>,     dass der Link nicht mehr aktuell ist. ===================================	Thanks. This is fixed and will be included in the next release.			Erik Abele
13141	null	CLOSED		Bruno Wolff III	1033396620000	1033748119000		t document no-gzip The manual for mod_deflate doesn't document that you can set no-gzip to disable compression. Since this is hard to do otherwise and there are some lame clients out there, this is something people are going to want to know about.	I'm not exactly sure why you say that.  This page: http://httpd.apache.org/docs-2.0/mod/mod_deflate.html clearly documents the gzip-only-text/html env variable. Oops.  Sorry.  I was confused. I just updated the mod_gzip doc to mention no-gzip. 			Jeff Trawick	Joshua Slive
13204	null	CLOSED		Carsten Gaebler	1033567320000	1033750786000		RewriteRule with RewriteMap ignores default value The RewriteRule directive ignores the default value that can be specified when using a RewriteMap (at least for DBM RewriteMaps). It returns an empty string instead if the key is not found:  RewriteMap domaindb dbm=db:/var/db-data/domains.db RewriteRule ^/([^/]+)/(.*)     /${domaindb:$1|not-found.html}/$2  Should return '/not-found.html/$2' if $1 does not exist in domains.db, but it returns //  This is what the RewriteLog says:  (3) applying pattern '^/([^/]+)/(.*)' to uri '/blafasel.de/' (5) map lookup OK: map=domaindb[dbm] key=blafasel.de -> val= (2) rewrite /blafasel.de/ -> //	Please try this change to mod_rewrite at around line 2968.  Index: modules/mappers/mod_rewrite.c =================================================================== RCS file: /home/cvs/httpd-2.0/modules/mappers/mod_rewrite.c,v retrieving revision 1.134 diff -u -r1.134 mod_rewrite.c --- modules/mappers/mod_rewrite.c       30 Aug 2002 04:47:57 -0000      1.134 +++ modules/mappers/mod_rewrite.c       4 Oct 2002 16:37:02 -0000 @@ -2968,7 +2968,7 @@      if ((rv = apr_dbm_open_ex(&dbmfp, dbmtype, file, APR_DBM_READONLY,                                0 /* irrelevant when reading */, r->pool)) ==  APR_SUCCESS) {          rv = apr_dbm_fetch(dbmfp, dbmkey, &dbmval); -        if (rv == APR_SUCCESS) { +        if (rv == APR_SUCCESS && dbmval.dptr != NULL) {              memcpy(buf, dbmval.dptr,                     dbmval.dsize < sizeof(buf)-1 ?                     dbmval.dsize : sizeof(buf)-1  );  Thanks! A fix has been committed.  This will be in the next release (2.0.44).  Thanks for your report, and thanks for using Apache!			Jeff Trawick
13211	null	CLOSED		Fabien COELHO	1033572540000	1047072921000		cookies are set twice cookies are set twice :  <Directory /home/www/tp/biscuit>   CookieTracking On   CookieName DYSHIDROSE </Directory>  shell> nc localhost 80 GET /tp/biscuit/ HTTP/1.0  HTTP/1.1 200 OK Date: Wed, 02 Oct 2002 15:26:10 GMT Server: Apache/2.0.42 (Unix) Set-Cookie: DYSHIDROSE=10.2.100.100.1033572370951690; path=/; max-age=604800 Cache-Control: max-age=2592000 Expires: Fri, 01 Nov 2002 15:26:10 GMT Set-Cookie: DYSHIDROSE=10.2.100.100.1033572370951606; path=/; max-age=604800 Last-Modified: Wed, 15 Dec 1999 17:36:20 GMT	Build and install v2.0.44 as follows:  ./configure --prefix=/tmp/apache --enable-usertrack  Add 'CookieTracking on' to the end of the default httpd.conf file, start up Apache and look at the headers for '/' -- only one cookie.  Now copy /tmp/apache/htdocs/index.html.en to /tmp/apache/htdocs/index.html and look at the headers for '/'.  I get two cookies for every page that does NOT use content negotiation (which unfortunately for me is my entire site...).  I also ran the same tests with v1.3.27 built as follows:  ./configure --prefix=/tmp/apache --enable-module=usertrack  And -never- got two cookies.  I ran these tests on Red Hat Linux 7.3, but have also seen the problem on Solaris.  Comments below are from Andr?? Malo [nd@perlig.de] from the dev@httpd.apache.org  mailing list:  *hrm* I can verify that behaviour for directory requests (i.e.  mod_dir/DirectoryIndex) without negotiation of the index file.  It seems to happen the following (GET / HTTP/1.0) without negotiation:  run_fixup: ->mod_usertrack: spot_cookie ->mod_dir: search and find index.html using sub_req_lookup_uri, which runs a  fixup itself (->next spot_cookie)   ->internal_fast_redirect -> apr_table_overlay(r->headers_out,                                                  rr->headers_out)                                 ^^ two cookies here ^^  mod_negotiation instead (in case of index.html.var) does an additional normal  internal_redirect to the negotiated resource, which drops the old stuff and  cooks (not only) its own cookie.  right?  Conclusion: are overlay'ed tables in internal_fast_redirect semantically  intended? Could someone please explain in slow words ;-), why? A workaround has been applied and will appear in the next release (2.0.45). If you wanna try it before the next release, the patch is rather small and can be found here: <http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/metadata/mod_usertrack.c.diff?r1=1.39.2.1&r2=1.39.2.2>  If there are further problems, please reopen this bug report.  Thanks for using Apache!			Andr?? Malo	Frank Faubert
13311	null	CLOSED		Peter Bieringer	1033762380000	1034350875000		perchild reports permission problems because default config misses example Is there any reason why the default config for per child still misses the solution to prevent this terrible error messages like  '[emerg] (13)Permission denied: apr_proc_mutex_lock failed. Attempting to shutdown process gracefully.'  which prevents Apache2 running in perchild mode on Linux.  Here is the solution, would be great if it will applied on next version (> 2.0.43) to remove this pitfall   --- httpd-2.0.43/docs/conf/httpd-std.conf.in.orig      Fri Oct  4 22:05:16 2002 +++ httpd-2.0.43/docs/conf/httpd-std.conf.in   Fri Oct  4 22:05:38 2002 @@ -153,6 +153,8 @@  MaxSpareThreads     10  MaxThreadsPerChild  20  MaxRequestsPerChild  0 +# Mutex must be changed, otherwise perchild won't work (permission problem) +AcceptMutex fcntl  </IfModule>   # WinNT MPM	I have fixed the code to force FCNTL and write a warning to the log if the server is configured with an incorrect accept mutex. *** Bug 14674 has been marked as a duplicate of this bug. *** *** Bug 15336 has been marked as a duplicate of this bug. ***			Jeff Trawick	Ryan Bloom
13383	null	CLOSED		Steve Reppucci	1034022480000	1034099241000		Minor typo in RewriteLogLevel docs Minor typo here: The RewriteLogLevel directive shows a 'Default' setting of:     RerwiteLogLevel 0  Should read:     RewriteLogLevel 0	Fixed.  Thanks for using Apache!			Erik Abele
13511	null	CLOSED		Dave Dyer	1034278680000	1083840787000		Apache misbehaves if log file reaches 2GB If the error log can't be written, it appears that any process that tries to write to the error log is quietly terminated.   This can  cause serious errors where no serious errors existed.  Suggest 1) 'quiet termination' should be noisier, to attract attention. 2) there should be some sort of overall status information that could be routinely monitored for such 'alarm' conditions as the inability to make log file entries.  Here are some details from an event that led to this report.  The 'symptom' was that some scripted emails arrived blank.  There was no other indication of a problem, but once someone complained about the blank emails, It was  noticed that the error_log was 2GB in size and had stopped growing due to  maximum file size.  The web site was otherwise operating normally, except that errors weren't being logged.  Further investigation showed that a CGI subprocess invlolved in sending the  email was routinely emitting a warning message, which was logged, and the inability to log the warning caused the process to terminate.  Since the main  thread emitting HTML didn't fail, the user's screen didn't indicate any  problem.	Hmmm... I'm not really an expert in this, but it seems it is the CGI script that needs to guard against the out-of-space condition, not Apache. What could Apache do to prevent this?  No, the CGI is not even aware that a log file is being written; it is merely emitting some text on stderr.  For its pains, it gets terminated by apache.   Again, I'm not an expert in this, but Apache is just attaching the stderr pipe to  the error log.  If this pipe can't be written, the OS is probably just sending SIGPIPE to your CGI.  If you CGI doesn't handle that, it will die.  I don't see anything that Apache could do about this. Apache can't be doing anything as simpleminded as you suggest, because it is running many concurrent CGI threads. So the fate of this particular thread could be better.  Secondarily, as I suggested, apache must know that globally speaking, it's log file is not working.  There should be some alert procedure - it shouldn't just allow shit to happen until someone notices the mess and deduces the cause and cure.   I don't understand your first paragraph at all.  How does multiple CGI processes have anything to do with it?  They are all handled identically.  Regarding behaving better when the error log is full, that seems kind of absurd to me.  Apache writes errors to the the error log. If it can't do that, what is it supposed to do?  Write to another log file?  What if that log can't be written to?  Send a message to your pager?  Walk down the hall and tap you on the shoulder? ;-)  At some point it needs to be the administrator's responsibility to maintain available system resources.    In this case, this minimum requirement is that a 500 error (with no   additional 'helpful information') should be sent to the client of this   terminated script.  Re: multiple CGI processes - it their output was tee'd directly from stderr to a log file, the output from multiple processes would be  chaotically interspersed.  That in itself would be a problem. The  output from DTDOUT is clearly handled individually, so why not STDERR?  For the momement, lets separate the question of what happened to  this particular CGI from that happens in general.  1) For this particular CGI, a warning message caused the process to terminate, effectively turning friendly glitch audit trail into a black hole.  Clearly  not a desirable outcome.  2) From the viewpoint of apache as a whole, if log files are not being maintained and processes are being killed randomly, the system as a whole is in serious jeopordy.  Perhaps Apache should shut down (which will surely get someone's attention) but at the very least there should be an emergency channel of some sort throug which apache reports serious internal problems.  The standard log files are not a good place for this, because apache's (rare we hope) internal problems would be lost in mountains of routine log data.  Consider the current case; Apache knows exactly what is wrong, and can/should tell the sysop 'error log can't be written'.    Consider the current behavior as a debugging problem 'my email arrived blank'.  Which would you rather deal with?  This is the 2GB log file problem :(  32-bit builds of Apache (1.3 or 2.0) don't currently handle 'large' files.  Apache child processes will die trying to write logs which have reached 2GB in size.  The obvious place to report the proble is -- you guessed it -- the log file that we can't write to.  The current message to users is that they need to use log rotation to keep the size well under 2GB.  Yes this sucks, yes it will eventually get fixed, yes there are issues that make it problematic to enable on some platforms (including Linux).  Sorry :(  *** Bug 20160 has been marked as a duplicate of this bug. *** Yeah, you can improve the failure mode for this problem by setting SIGXFSZ (the signal which kills the process when it write()s past 2gb) to SIG_IGN.  It's a trivial change - I'll submit a patch. Fixed in HEAD by allowing >2Gb log files on platforms which have this limit; will be proposed for backport for the next 2.0 release. *** Bug 28968 has been marked as a duplicate of this bug. *** *** Bug 30170 has been marked as a duplicate of this bug. *** *** Bug 33937 has been marked as a duplicate of this bug. ***			Dave Dyer	Jeff Trawick	Joe Orton	Joshua Slive	Will Rowe
13594	null	CLOSED		Sam Hennebert	1034593200000	1034615076000		wrong link to mod_userdir in the http://httpd.apache.org/docs-2.0/howto/public_html.html page, in the Restricting what users are permitted to use this feature section, the link to userdirs maps to  http://httpd.apache.org/docs-2.0/mod/userdir.html#userdir instead of http://httpd.apache.org/docs-2.0/mod/mod_userdir.html#userdir	This is fixed in CVS.  Thanks for submitting the bug and for using Apache 2!			Erik Abele
13598	null	CLOSED		Dmitry Kuzkin (aka Bio)	1034600100000	1067725999000		directory listing bug with % symbol in directory or file names (Apache 2.0.43 and some above) it doesn't show directory's entry if dir. name contains % symbol in directory index.	See the thread on the Apache Users mailing list archive for more information and a reproducible test-case and verifications on Linux and Windows.  Quoting Robert Andersson: As I see it, the 'bug' in mod_autoindex would be that it doesn't URI-escape the filename before sending it to the sub_request function. A quick note. After a little further research, I see that the 'bug' is rather in server/request.c/ap_sub_req_lookup_dirent(), which calls ap_process_request_internal() with r->uri set to the plain unescaped filename, which can result in ap_process_request_internal() returning  'not found' or 'bad request', eg:  '/xxx%0.txt' -> bad request '/xxx%20.txt' -> not found  I have been able to fix this behaviour. I'll be back later. Fixed in 2.1 and proposed for backport into the 2.0 stable branch.  Thanks for your report and thanks for using Apache!			Andr?? Malo	Leif W	Robert Andersson
13609	null	CLOSED		Joseph Senulis	1034609820000	1042815060000		apachectl does not work under Tru64 Unix In Apache 2.0.40, there was a change in the bin/apachectl file which added the follwoing line:  ULIMIT_MAX_FILES='ulimit -S -n "ulimit -H -n"'  I tried to build Apache 2.0.42 and 2.0.43, and both had the same problem in that this statement did not run.  Specifically, as root, I could not issue the command:  ulimit -H -n  This is not a legitimate Bourne shell command in Tru64 5.1 or 5.1A.  The command:  ulimit -h -n  does do what I believe was desired, so I have modified my copy of apachectl to work around the problem.  The man page for sh under Tru64 says that -H is used  for setting, not getting the hard ulimit.  I don't know if this is true for all unixes or just Tru64.  This looks to be generated by configure.  Thanks.  --Joe	I'm a little confused at the symptom you saw.  I can see the ulimit command fail on Tru64 when using /bin/sh, but after the command fails at configure time I end up with this in apachectl, so apachectl doesn't try to do ulimit.  ULIMIT_MAX_FILES=''  Any ideas why we are seeing something different? Created an attachment (id=4439) configuration log which resulted in bad apachectl file  I definitely got the following in apachectl:  UMIMIT_MAX_FILES='ulimit -S -n "ulimit -H -n"'  I did not get any errors when running configure.  I have attached the configuration log from when I created this.  I will make some time to rerun configure with better logging to see if I can get better info. OK, I'm confused too.  I rebuilt Apache and I still get the problem.  When I run /bin/sh by hand on that computer, I definitely get an error when I try to run  ulimit -H -n  The configure also is running /bin/sh, but the script did not get an error when executing the line   if TMP_ULIMIT="ulimit -H -n" && ulimit -S -n $TMP_ULIMIT ; then  and as a result does not set APACHECTL_ULIMIT to null.  When I try running this code fragment by hand I get an error.  I will attach config.log and config.status.  I also piped stdout and stderr from the configure into configure.log.  I will keep checking here to see what I can find, but any suggestions would be appreciated.  Created an attachment (id=4466) config.log from rebuild  Created an attachment (id=4467) config.status from rebuild  Created an attachment (id=4468) stdout and stderr from configure, with set -v -x added at start  Regardless of why configure fails to realize that the standard ulimit command won't work on your box yet configure does realize it won't work on my box, the fix is the same: check for Tru64 and substitute the right command rather than trying the default.  The fix has been committed to Apache 2.1 development tree.  If nobody complains  about the change, I'll ask for it to be considered for merging into Apache  2.0.45.  Thanks for your report/debug assistance, and thanks for using Apache!  I have done some more poking about.  The configure script changes the shell  from Bourne to Korn, in (I believe) the line:  exec '$CONFIG_SHELL' '$0' ${1+'$@'}  which restarts the script using the Korn shell.  At that point, it eventually  gets to the line:  if TMP_ULIMIT="ulimit -H -n" && ulimit -S -n $TMP_ULIMIT ; then  and is still running the Korn shell.  The argument "ulimit -H -n" is perfectly  valid in T64 Korn shell, so the configure script would not assign null to  APACHECTL_ULIMIT.  What I don't understand is why you were seeing differently.   Presumably, when you tested this, configure did not restart itself with the  Korn Shell?  In any event, there is a discrepancy between T64 ksh and sh, in  that -H is valid in ksh, but -h should be used in sh.  *** Bug 16415 has been marked as a duplicate of this bug. ***			Jeff Trawick	Joseph Senulis
13625	null	CLOSED		Tom Heinrichs	1034643540000	1034705392000		SetHandler link on docs-2.0/handler.html link needs to be corrected. On page http://httpd.apache.org/docs-2.0/handler.html the SetHandler href should be: http://httpd.apache.org/docs-2.0/mod/core.html#sethandler It currently points incorrectly to mod_mime.html#sethandler.	Fixed in CVS. Thanks for using Apache 2.0!			Erik Abele
13914	null	CLOSED		Ville Skytt	1035436620000	1037976436000		CGI script command line broken CGI script command line is broken in 2.0.40, the query string is *always* passed to all CGI scripts as the first argument, whether it contains '=' or not.  I took a look and the patch I'm attaching to this report seems obviously correct to me (it's against CVS HEAD), but I haven't tested it.  Please take a look ASAP, this prevents running eg. the W3C checklink, <http://validator.w3.org/checklink>.  For more info, see the CGI spec at <http://cgi-spec.golux.com/draft-coar-cgi-v11-03-clean.html#5.0>.	Created an attachment (id=3590) CGI command line argument fix  This seems pretty obviously correct to me, but I'm not setup to test it at the moment.    The patch appears correct.  As simple as it is to patch and move on, it   seems like the sort of exception we should be looking for in the test   suite.  I'll see what we can do about that, since we aught to prove    the old module wrong (from the perl-testsuite), apply the patch and    confirm it solves the bug complete.   Ok, I tested this a bit further with 1.3.26 and 2.0.40 and made a perl CGI that can be used for testing (attaching it in a jiffy).  The script contains test URLs, expected results and results for the two tested servers.  1.3.26 passed all tests, while 2.0.40 failed 3 of them; 2) and 6) supposedly because of the bug described here, and 9) since it doesn't seem to check if the query string after '?' is empty, but passes an empty string. Created an attachment (id=3622) Perl CGI for testing CGI command line arguments  Fixes were just committed for mod_cgi and mod_cgid.  Thanks for the mod_cgi fix and the testcase, and thanks for using Apache! 			Jeff Trawick	Joshua Slive	Ville Skytt	Will Rowe
13946	null	RESOLVED		Fabio Wakim Trentini	1035488700000	1155068917000		reverse proxy errors when a document expires from the cache Hi! Using apache as a reverse proxy with mod_mem_cache, when using simple HTTP/1.0  requests to files, sometimes (when the object in the cache is expired) the  proxy does weird requisitions:  The request: GET /index.html HTTP/1.0 Host: 10.0.0.2  Document cached: [Fri Oct 25 18:52:07 2002] [debug] mod_cache.c(118): cache: URL /index.html is  being handled by mem [Fri Oct 25 18:52:07 2002] [debug] mod_cache.c(232): cache: fresh cache - add  cache_out filter and handle request [Fri Oct 25 18:52:07 2002] [debug] mod_cache.c(357): cache: running CACHE_OUT  filter [Fri Oct 25 18:52:07 2002] [debug] mod_cache.c(366): cache: serving cached  version of /index.html  After the document expires: [Fri Oct 25 18:59:00 2002] [debug] proxy_http.c(109): proxy: HTTP:  canonicalising URL //10.0.0.2/proxy:http://10.0.0.2/index.html [Fri Oct 25 18:59:00 2002] [debug] mod_proxy.c(461): Trying to run  scheme_handler [Fri Oct 25 18:59:00 2002] [debug] proxy_http.c(1061): proxy: HTTP: serving  URL http://10.0.0.2/proxy:http://10.0.0.2/index.html [Fri Oct 25 18:59:00 2002] [debug] proxy_http.c(221): proxy: HTTP connecting  http://10.0.0.2/proxy:http://10.0.0.2/index.html to 10.0.0.2:80  and after a few mseconds: [Fri Oct 25 18:59:00 2002] [debug] mod_cache.c(118): cache: URL /index.html is  being handled by mem [Fri Oct 25 18:59:00 2002] [debug] mod_cache.c(203): cache: no cache - add  cache_in filter and DECLINE  Here is a piece of my httpd.conf file: ProxyRequests Off ProxyVia Full ProxyTimeout 30 ProxyReceiveBufferSize 16384 ProxyMaxForwards 10 CacheEnable mem / CacheDefaultExpire 10 CacheMaxExpire 30 CacheLastModifiedFactor 0.1 CacheMaxStreamingBuffer 65536  MCacheSize 524288 MCacheMaxObjectCount 32768 MCacheMinObjectSize 1  MCacheMaxObjectSize 100000 MCacheRemovalAlgorithm GDSF RewriteEngine   on RewriteRule     ^(.*)$     $1 [P,L]	Can you specify where you think the problem is in the log you attached?  If you are concerned about the 'no cache - add cache_in filter and DECLINE' part of the message, that is perfectly normal. This simply indicates that the cache handler has noticed that new, cacheable content is arriving. It inserts the cache_in filter into the filter chain so that the caching code can store the new content as it flows through, but it returns 'declined' to indicate that the cache handler didn't process the response.  I'm going to wait a few days for a clarification on this. If there isn't something I've missed here then I'll go ahead and close this PR at that point. Having received no response to the contrary, I have to assume that this was not actually a problem after all. I'm closing it now. It can be re-opened if someone disagrees. Hi, sorry for the delay. Well, the error is right here: --- [Fri Oct 25 18:59:00 2002] [debug] proxy_http.c(221): proxy: HTTP connecting  http://10.0.0.2/proxy:http://10.0.0.2/index.html to 10.0.0.2:80 ---  it tries to get the URL http://10.0.0.2/proxy:http://10.0.0.2/index.html,  generating errors. it only happens when using mod_proxy with mod_rewrite. it  looks like mod_rewrite appends the 'http://10.0.0.2/proxy:' string, in the  example, but *only* when the document expires from the cache.  Does the server return an error to the client or does the server succeed in retrieving and returning the page from the proxy machine? In other words, is it just a logging issue or does it actually fail to retrieve the page after it expires?  I don't see a log entry indicating that the page isn't found, and the only entry in the log from the cache code indicates that it is inserting the cache_in_filter to handle the page returned from the proxy.  Thanks for any additional info you can provide. in all these requests, the server returns an error to the client. What is the error returned to the client and what error(s) get logged into the server's error_log or access_log? This seems to be a mod_cache bug hi there, the bug persists in httpd-2.0.44. Here is some piece of the error_log:  [Tue Jan 28 15:48:23 2003] [error] [client 200.164.36.73] proxy: URI cannot be  parsed: http://xxx.com.brproxy:http//xxx.com.br/imagens/pix.gif returned  by /imagens/pix.gif [Tue Jan 28 15:48:23 2003] [error] [client 200.207.161.223] proxy: URI cannot  be parsed: http://xxx.com.brproxy:http//xxx.com.br/beach/t3.jpg returned  by /beach/t3.jpg, referer: http://xxx.com.br/beach/left.html [Tue Jan 28 15:48:23 2003] [error] [client 200.191.233.186] proxy: URI cannot  be parsed: http://yyy.com.brproxy:http//yyy.com.br/imagens/b.gif returned  by /imagens/b.gif, referer: http://yyy.com.br/  another error:  access_log: 200.174.198.133 - - [28/Jan/2003:15:47:18 - 0200] 'GET /js/video.js HTTP/1.1'  400 498 'http://xxx.com.br/' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows 98)'  error_log: [Tue Jan 28 15:47:18 2003] [error] [client 200.174.198.133] proxy: URI cannot  be parsed: http://xxx.com.brproxy:http//xxx.com.br/js/video.js returned  by /js/video.js, referer: http://xxx.com.br/  It *only* happens with mod_rewrite with reverse proxy. Created an attachment (id=4670) Patch to solve the probem  A did attach a patch to solve this bug. It is caused when the mod_rewrite  reprocess the request after mod_proxy return it. Created an attachment (id=4671) Patch fix, now generated by a diff -u  Let's not mark this as resolved/fixed until a fix is actually committed...  otherwise the patch might get lost.  :)  Thanks, Cliff Is this fixed now or not? :-) I'm currently looking into porting the old patch to the current code, verifying the patch, and committing it to cvs. I am not convinced that this part of the patch needs to be present since we aren't seeing 'proxy:proxy:' which is what this if statement would prevent...  @@ -2082,6 +2098,7 @@              rewritelog(r, 2, '[per-dir %s] forcing proxy-throughput with %s',                         perdir, r->filename);          } +        if (strncasecmp('proxy:',r->filename,6))          r->filename = apr_pstrcat(r->pool, 'proxy:', r->filename, NULL);          return 1;      } Created an attachment (id=7229) Updated version of Fabio's patch from above. (current 2.1-dev branch)  I have tested the updated patch and committed it to the Apache 2.1-dev branch. I will submit it for a vote to backport to the 2.0-stable branch. Thank you for your efforts in identifying and fixing this bug. Perhaps I'm missing something... The provided config:  ProxyRequests Off ProxyVia Full ProxyTimeout 30 ProxyReceiveBufferSize 16384 ProxyMaxForwards 10 CacheEnable mem / CacheDefaultExpire 10 CacheMaxExpire 30 CacheLastModifiedFactor 0.1 CacheMaxStreamingBuffer 65536  MCacheSize 524288 MCacheMaxObjectCount 32768 MCacheMinObjectSize 1  MCacheMaxObjectSize 100000 MCacheRemovalAlgorithm GDSF RewriteEngine   on RewriteRule     ^(.*)$     $1 [P,L]  creates an infinite loop (proxying to itself), doesn't it? Why is this useful? updating PRs to add PatchAvailable keyword For updated information on submitting patches, see http://httpd.apache.org/dev/patches.html  Can you test this on 2.0.54? Lots of things in both proxy and cache have been changed since this was last reported. No activity after a very long time in NEEDINFO; assuming expired.			Andr?? Malo	Cliff Woolley	Eider Oliveira	Fabio Wakim Trentini	Graham Leggett	Jeff Trawick	Nick Kew	Paul J. Reder	Paul Querna
14037	null	CLOSED		Leif Neland	1035870420000	1037283913000		Show defaults for listen to ipv4+ipv6 in BSD example configs Suggestion: Enter both ipv4 and ipv6 listens in example httpd.conf Eg: '#For some platforms, eg BSD use ...'  http://httpd.apache.org/docs-2.0/bind.html :  On some platforms, such as NetBSD, binding to the IPv6 wildcard address ('::') does not allow Apache to accept connections on IPv4 interfaces. In this situation, multiple Listen directives are required, as shown below:  Listen 0.0.0.0:80 Listen [::]:0  Apache does not currently detect this, so the Listen statements must be edited manually by the administrator.	FYI...  Here are some notes I threw together describing what I think is the proper  solution.  Part of that is to provide multiple Listen statements.  http://www.apache.org/~trawick/v4mapped.html  Any comments are appreciated.  Just committed was a change to add --[enable|disable]-v4-mapped configure option which defaults to --disable-v4-mapped on freebsd5*|netbsd|openbsd, which will result in two listen statements in the default config file.  The default ssl config is not automatically generated, so comments were added to that describing the two necessary Listen directives. 			Jeff Trawick
14147	null	CLOSED		Dan Good	1036097460000	1036121171000		patch for filename truncation bug in ap_directory_walk Apache will, in some cases, truncate the last character of a filename causing it to either not find the file or serve the wrong file.  Below are steps to reproduce the bug, part of a gdb debugging session showing the code that causes the bug, and a small patch to fix the bug.  This is probably the cause for the symptoms seen in bug #10687.  I first encountered the problem when a customer was trying to do a virtual include of a file via mod_include SSI.  The error log consistently showed apache failing to find a file whose name was one character shorter than the desired file.  Here is an example.      $ cd ~user04      $ cat html/1/index.shtml     <html>     <body>     test<br>     <!--#include virtual='../2/in.html' -->     </body>     </html>      $ cat html/2/in.html     This is in.html      $ wget -q -O - http://sf1000.registeredsite.com/~user04/1/     <html>     <body>     test<br>     [an error occurred while processing this directive]     </body>     </html>      $ cat /usr/apache/logs/error.log.1036095600      [Thu Oct 31 15:20:12 2002] [user04] [error] [client 209.35.187.200]      (2)No such file or directory: file permissions deny server access:      /home/r/t/user04/html/2/in.htm     [Thu Oct 31 15:20:12 2002] [user04] [error] [client 209.35.187.200]      unable to include '../2/in.html' in parsed file      /home/r/t/user04/html/1/index.shtml       Here is part of a debugging session where the code causing the bug can be seen in action.  Starting with line 1066 from server/request.c in ap_directory_walk, the code reaches a goto at line 1100.  This jumps back into a loop that spans lines 731-1057.  The code proceeds to lines 920 and 921 where the last character of the filname is truncated. Lines 920 and 921 originally served to take off a temporary slash added in lines 740-744 in an earlier pass through the loop, but the boolean variable 'temp_slash' is still true when the goto jumps back into the loop.  (gdb) n 1066            if (save_path_info) { (gdb) 1080            for (; sec_idx < num_sec; ++sec_idx) { (gdb) 1083                entry_core = ap_get_module_config(sec_ent[sec_idx], &core_module); (gdb) 1085                if (!entry_core->r) { (gdb) 1089                if (ap_regexec(entry_core->r, r->filename, 0, NULL, REG_NOTEOL)) { (gdb) 1095                if (matches) { (gdb) 1096                    if (last_walk->matched == sec_ent[sec_idx]) { (gdb) 1097                        now_merged = last_walk->merged; (gdb) 1098                        ++last_walk; (gdb) 1099                        --matches; (gdb) 1100                        goto minimerge; (gdb) 813                     this_dir = ap_get_module_config(sec_ent[sec_idx], &core_module); (gdb) 815                     if (!this_dir) { (gdb) 819                     if (this_dir->opts & OPT_UNSET) { (gdb) 827                         opts = this_dir->opts; (gdb) 828                         opts_add = this_dir->opts_add; (gdb) 829                         opts_remove = this_dir->opts_remove; (gdb) 832                     if (!(this_dir->override & OR_UNSET)) { (gdb) 835                 } (gdb) 751                     ap_conf_vector_t *entry_config = sec_ent[sec_idx]; (gdb) 753                     entry_core = ap_get_module_config(entry_config, &core_module); (gdb) 758                     if (entry_core->r || entry_core->d_components > seg) { (gdb) 840                 if (seg >= startseg && override) { (gdb) 841                     ap_conf_vector_t *htaccess_conf = NULL; (gdb) 843                     res = ap_parse_htaccess(&htaccess_conf, r, override, (gdb) 846                     if (res) { (gdb) 850                     if (htaccess_conf) { (gdb) 920                 if (temp_slash) { (gdb) 921                     r->filename[--filename_len] = '/0';   The patch below ensures the boolean is set back to false when it has served its purpose, and as an added precaution, checks that the character about to be truncated is a slash.  --- request.c.bak       Tue Oct 22 10:20:09 2002 +++ request.c   Tue Oct 22 10:20:11 2002 @@ -918,6 +918,8 @@              /* That temporary trailing slash was useful, now drop it.               */              if (temp_slash) { +                temp_slash = 0; +                if (r->filename[filename_len-1] == '/')                  r->filename[--filename_len] = '/0';              }	That looks good.  I suspect that wrowe needs to bless it before committing it though.  The check below always succeeds, right?  -->       if (r->filename[filename_len-1] == '/')  I suspect that it should probably be     AP_DEBUG_ASSERT(r->filename[filename_len-1] == '/');    r->filename[--filename_len] = '/0';  The AP_DEBUG_ASSERT() is a good way to doc the assumption but  it won't generate any code unless you build with  --enable-maintainer-mode.  Thanks for digging into this!!!!!  *** Bug 10236 has been marked as a duplicate of this bug. ***    In the name of Rob, Dean, and Jon, it is blessed.    Great catch, mega kudos for tracking it down!    I like Jeff's analysis, I'm leaving only an assert.     Still makes no sense.          do {             int res;             char *seg_name;             char *delim;             int temp_slash=0;              /* We have no trailing slash, but we sure would appreciate one.              * However, we don't want to append a / our first time through.              */             if ((seg > startseg) && r->filename[filename_len-1] != '/') {                 r->filename[filename_len++] = '/';                 r->filename[filename_len] = 0;                 temp_slash=1;             } [...]             /* That temporary trailing slash was useful, now drop it.              */             if (temp_slash) {                 temp_slash = 0;                 AP_ASSERT(r->filename[filename_len-1] == '/');                 r->filename[--filename_len] = '/0';             }  There is no way around this code without resetting temp_slash to zero at the beginning of the loop...  ...UNLESS the optimizer has optimized away all but the initial assignment  to the 0 initial value, never again to reset it on the next iteration through the do {} loop.  Does this make sense as the possible scenario?  Can you check this Dan?  Bill Bill, you're forgetting the gotos :)  I'm about to post some text to dev@httpd.     Refixed this morning in CVS.  The revised server.c is attached complete,   so you don't end up with the hack-around still sitting in your sources.    directory_walk should never have the goto target above the code that   it was attempting to escape from.  In fact, a minimerge3: target should   have been used -after- the uncached-merge logic.    No matter, the new sources factor out all the goto's.  Please test this   new patch thoroughly.  request.c source to follow.   Created an attachment (id=3702) httpd-2.0/server/request.c for 2.0.43, committed to 2.0.44-dev.     The final patch doesn't reset the flag, as demonstrated in the attached   patch.  It turns out our goto loop logic was terribly flawed.  The final   patch to address this bug simply eliminates the odd looping that caused   us to chop the extra character{s}.    For each DirectoryMatch (or Directory ~ path) block, we looped back over   the wrong code, causing us to chop more than a single character off the   end of the name (when expected to simply chop off the trailing slash.)    If the fix works for you, terrific.  You might also consider the correct   patch, attaching in one moment. Created an attachment (id=3711) Patch that eliminates the looping that caused the symptoms.  *** Bug 12155 has been marked as a duplicate of this bug. *** *** Bug 10687 has been marked as a duplicate of this bug. *** *** Bug 14860 has been marked as a duplicate of this bug. *** *** Bug 15923 has been marked as a duplicate of this bug. ***			Jeff Trawick	Joshua Slive	Michael Dean	Will Rowe
14235	null	CLOSED		Sergey A. Lipnevich	1036433220000	1043147349000		util_ldap does not try to initialize LDAPv3 mod_util_ldap will only set 'protocol version 3' LDAP option if TLS is requested, but it may be necessary to set this option after every bind operation. The following patch has been tested and works in production since 2.0.41, with OpenLDAP version 2.1.x.	Created an attachment (id=3714) LDAPv3.patch  Patch applied to v2.0.45-dev and v2.1.0-dev.			Graham Leggett	Sergey A. Lipnevich
14253	null	CLOSED		Michael Henry	1036499340000	1036522986000		Broken link In the second paragraph the first sentence:  'The presented content is mainly derived, with permission by the author, from  the article Introducing SSL and Certificates using SSLeay from Frederick J.  Hirsch'  contains two broken links. The following error is returned:  The requested URL /fhirsch/Papers/wwwj/index.html was not found on this server.	The links are fixed and should be up the next days. Thanks for using Apache 2.0!			Erik Abele
14256	null	CLOSED		Gilbert van den Dobbelsteen	1036503300000	1037969411000		LoadModule order is not correct in generated httpd.conf When auth-ldap (experimental) is enabled as a module (shared), and mod_ldap is   enabled, the generated httpd.conf has the LoadModule statements in the wrong   order. First the auth-ldap module is loaded which crashes in the load process   because mod_ldap is not loaded. Exchanging the LoadModule lines resolves the  issue.    When backtracking this, I found out that the configure script processes  auth-ldap first, and then processes the mod_ldap.	A fix for this was just committed.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
14276	null	CLOSED		Frank Domina	1036532400000	1041866844000		Index option IgnoreCase not ported from 1.3 With the Win32 version, index option IgnoreCase causes an error.  If the option  is in the httpd.conf file for a directory, Apache won't even start.  If I put  the option in the directory's .htaccess file, you get an internal server error  and the error log reports 'Invalid directory indexing option'....and yes,  FancyIndexing is enabled.	Thanks for the report, but this is a configuration error. Apache 2 doesn't have the index option 'IgnoreCase'; it is only available in Apache 1.3.  For a list of available options, see http://httpd.apache.org/docs-2.0/mod/mod_autoindex.html#indexoptions But it should be available.  I'm not sure why this was never forward-ported. I'm going to reopen and mark this as an enhancement request, because I've seen other similar reports. Created an attachment (id=4341) Forward port of IgnoreCase directive.     The patch, with minor changes, is committed to the 2.0 release branch   and 2.1 development branch.    The changes to the patch should avoid future reformatting of the #defines   list and provide a deterministic ordering even for fn1.1.zzz/fn1.01.zzz which   might compare equally using the strnatcmp family of functions.  			David Shane Holden	Erik Abele	Joshua Slive	Will Rowe
14303	null	CLOSED		Paul M	1036602900000	1036672384000		closing tag is /LocationMatch and not /Location Opening tag is LocationMatch, closing tag should be /LocationMatch  just a minor  niggle  no worries	Thanks for your report, and thanks for using Apache!  This problem has now been fixed. 			Jeff Trawick
14321	null	CLOSED		Ken Franken	1036626840000	1037301781000		memory leak in mod_deflate with dynamic content mod_deflate shows substantial memory leakage when used with dynamic content, at least on WindowsXP. Below is a test module to generate some dynamic content and a section of the httpd.conf file I used.  The URL http://localhost/compressed-dynamic leaks about 8k per request over the course of 20,000 requests using ab.exe; http://localhost/compressed-static and http://localhost/uncompressed-* did not show any leaks. The leak_test.html file used for the -static tests is just a saved version of one of the dynamic files.   httpd.conf ### Leak testing Alias /leak_test 'E:/Apache2/leak_test' Alias /uncompressed-static 'E:/Apache2/leak_test/leak_test.html' Alias /compressed-static 'E:/Apache2/leak_test/leak_test.html'  <Directory 'E:/Apache2/leak_test'> \tOrder deny,allow \tAllow from all </Directory>  <LocationMatch '^/compressed-'> \tSetOutputFilter DEFLATE \tOrder deny,allow \tAllow from all </LocationMatch> <LocationMatch '^/[a-z]+-dynamic'> \tSetHandler leak-test \tOrder deny,allow \tAllow from all </LocationMatch>  mod_leak_test.c /* mod_leak_test */ /* An example Apache 2.0 module that generates dynamic content that can be used to */ /* test/demonstrate mod_deflate memory leakage */ /* 11/6/02 Ken Franken */  #include 'ap_config.h' #include 'http_protocol.h' #include 'http_config.h'  #include <math.h>  module AP_MODULE_DECLARE_DATA leak_test_module;  static int leak_test_handler(request_rec *r) { \tlong i;  \t/* if we aren't registered as a handler for the document, punt */     if(strcmp(r->handler, 'leak-test') != 0)         return DECLINED;      ap_set_content_type(r, 'text/html'); \tr->status = HTTP_OK;      if (r->header_only) { \t\treturn OK; \t} \t/* write some random data to the client */ \tap_rputs(DOCTYPE_HTML_4_0S, r);  \tap_rputs('<html><body>', r);  \tfor(i=0; i<1000; i++)  \t\tap_rprintf(r, '%d%d%d<br>/n', rand(), rand(), rand()); \tap_rputs('</body></html>', r);  \treturn OK; }  static void register_hooks(apr_pool_t *p) {     ap_hook_handler(leak_test_handler, NULL, NULL, APR_HOOK_MIDDLE); }  module AP_MODULE_DECLARE_DATA leak_test_module = {     STANDARD20_MODULE_STUFF,     NULL,                        /* dir config creater */     NULL,                        /* dir merger --- default is to override */     NULL,                        /* server config */     NULL,                        /* merge server config */     NULL,                        /* command apr_table_t */     register_hooks               /* register hooks */ };	some comments in case somebody else has started looking at this:  I was able to duplicate this on Linux easily :(  The problem does not seem to be thread-related because I duplicated it using the prefork MPM.  The problem does not seem to be a misuse of zlib.  To test that theory I used the following patch to replace the memory allocation/deallocation routines used by zlib with something that allocates from the request pool. I still observed the storage leak with that patch in place.  (I assume that zlib always calls that hook to allocate storage.)  Index: modules/filters/mod_deflate.c =================================================================== RCS file: /home/cvs/httpd-2.0/modules/filters/mod_deflate.c,v retrieving revision 1.24 diff -u -r1.24 mod_deflate.c --- modules/filters/mod_deflate.c\t30 Aug 2002 16:31:17 -0000\t1.24 +++ modules/filters/mod_deflate.c\t7 Nov 2002 12:04:11 -0000 @@ -228,6 +228,27 @@      return NULL;  }   +static voidpf mdalloc(voidpf opaque, uInt items, uInt size) +{ +    request_rec *r = opaque; +    voidpf buffer = apr_pcalloc(r->pool, items * size); + +    ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r, +                  'alloced buffer %pp', buffer); + +    return buffer; +} + +static void mdfree(voidpf opaque, voidpf buffer) +{ +    request_rec *r = opaque; + +    ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r, +                  'freed buffer %pp', buffer); + +    /* no work to do */ +} +  /* magic header */  static char deflate_magic[2] = { '/037', '/213' };   @@ -330,7 +351,9 @@          ctx = f->ctx = apr_pcalloc(r->pool, sizeof(*ctx));          ctx->bb = apr_brigade_create(r->pool, f->c->bucket_alloc);          ctx->buffer = apr_palloc(r->pool, c->bufferSize); - +        ctx->stream.zalloc = mdalloc; +        ctx->stream.zfree  = mdfree; +        ctx->stream.opaque = r;          zRC = deflateInit2(&ctx->stream, Z_BEST_SPEED, Z_DEFLATED,                             c->windowSize, c->memlevel,                             Z_DEFAULT_STRATEGY); @@ -341,8 +364,11 @@                            'unable to init Zlib: '                            'deflateInit2 returned %d: URL %s',                            zRC, r->uri); +            ap_remove_output_filter(f);              return ap_pass_brigade(f->next, bb);          } +        ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r, +                      'alloced stream %pp', &ctx->stream);            /* RFC 1952 Section 2.3 dictates the gzip header:           * @@ -443,7 +469,8 @@              }                deflateEnd(&ctx->stream); - +            ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r, +                          'freeing stream %pp', &ctx->stream);              /* Remove EOS from the old list, and insert into the new. */              APR_BUCKET_REMOVE(e);              APR_BRIGADE_INSERT_TAIL(ctx->bb, e); problem isn't specific to windows... change some fields as appropriate... The problem seems to be the apr_brigade_destroy(bb) call on the next to last line of deflate_out_filter(). If I remove this call, the leak stops.   Someone with more familiarity with the code might be able to confirm this, but I think the apr_brigade_destroy() call unregisters the brigade from the pool cleanup. This would be OK (since we are cleaning it up manually), but the last time the filter is called (with an EOS bucket), the function exits w/o a last apr_brigade_destroy() call, so the last bucket brigade leaks.  I got a brigade guru to look at your PR and your debugging.  He suggested this patch:  Index: modules/filters/mod_deflate.c =================================================================== RCS file: /home/cvs/httpd-2.0/modules/filters/mod_deflate.c,v retrieving revision 1.25 diff -u -r1.25 mod_deflate.c --- modules/filters/mod_deflate.c       10 Nov 2002 06:09:20 -0000      1.25 +++ modules/filters/mod_deflate.c       14 Nov 2002 13:52:36 -0000 @@ -510,7 +510,7 @@          }      }  -    apr_brigade_destroy(bb); +    apr_brigade_cleanup(bb);      return APR_SUCCESS;  }   I have tested this with your sample module and I don't see a storage leak or any other bad behavior.  Upon further review, I do believe that to be the correct patch.  We can't destroy the brigade because it is only created when the ctx is first initialized at the beginning of the request.  All we really want is to make sure it has no buckets in it.  That's what apr_brigade_cleanup() is for.  Ken, I'll wait for confirmation from you that the patch works as expected before committing, but it seems quite logical to me.  Note: I found a few other bucket-related buglets in that function -- I'll bring them up on dev@httpd.  I tested the patch and it works fine for me. Thanks. Committed.  Thanks!			Cliff Woolley	Jeff Trawick	Ken Franken
14376	null	CLOSED		L.C.	1036712100000	1050428689000		Date header overwritten in proxied requests It appears that mod_proxy overwrites the Date header with the local date. Mine is configured as a Reverse Proxy (have not tried the other way). The date header is in the proper format (comes from an Apache 1.3 server).  This should not happen because this way the client loses the reference for the Expires header (which passes through unmodified).  Below are two sets of response headers I tested with. The first one is the backend server accessed directly, the second is via the proxy, at about 20 seconds time difference. The time on the proxy is 2-3 minutes behind the backend's. The frontend always sets the expiration date to  same value as date.  HTTP/1.1 200 OK Date: Thu, 07 Nov 2002 21:41:15 GMT Server: Apache/1.3.27 (Unix) Cache-control: no-cache Content-Length: 1924 Connection: close Content-Type: text/html; charset=UTF-8 Expires: Thu, 07 Nov 2002 21:41:15 GMT  HTTP/1.0 200 OK Date: Thu, 07 Nov 2002 21:38:31 GMT Server: Apache/1.3.27 (Unix) Cache-control: no-cache Content-Type: text/html; charset=UTF-8 Expires: Thu, 07 Nov 2002 21:41:37 GMT Via: 1.1 <proxyhostname> Connection: close	The last statement should read: 'The backend always sets the expiration date to same value as date.'     I need to refer to the docs, but your error is setting the Expires: tag   in the first place after using Cache-Control: no-cache    You can't have it both ways and you will probably confuse some caches. Ok, from RFC 2616;     The Date general-header field represents the date and time at which    the message was originated, having the same semantics as orig-date in    RFC 822. The field value is an HTTP-date, as described in section    3.3.1; it MUST be sent in RFC 1123 [8]-date format.  and     A received message that does not have a Date header field MUST be    assigned one by the recipient if the message will be cached by that    recipient or gatewayed via a protocol which requires a Date.  So, if we have a Date:, the proxy should assign that, if we have no date, we invent one.  Finally, about your Expires: tag... I strongly suggest you follow the following semantic;     An origin server [...] MAY assign an Expires value that is known,     at or before server configuration time, to be in the past (this allows     'pre-expiration' of responses without storing separate Expires values     for each resource).  which is precisely the behavior you desired.  The conclusion that the proxy must set the Date header when it has already been provided by the origin server cannot be inferred from the two paragraphs quoted (since the message is not originated on the proxy).  Using the rfc822 analogy mentioned in the text would imply a mail relay changing the Date: header as the email passes through it, even if there is one already  there that respects the format. That does not happen.  The proxy's changing of the date makes the Expires header as unreliable as the time on the proxy machine, because other than the Date header, the client has  no way to know the time reference of the origin server. That essentially makes Expires unusable for anything other than very distant times in the future (depending on how much the proxy time is off).  Having both Cache-Control: no-cache and Expires is perfectly valid/legal. 'no-cache' does not mean 'do not cache/store'; it means 'revalidate on every request'. Expires refers to content freshness which is often a separate issue.  Some applications may be able to predict expiration times and may still want to see all [validation] requests. Some caches (think CDNs like Akamai or bookmark revalidation services) may use the combination to optimize their [caching] decisions.  Cache-control overrides Expires:     The presence of an Expires header field with a date value of some    time in the future on a response that otherwise would by default be    non-cacheable indicates that the response is cacheable, unless    indicated otherwise by a Cache-Control header field (section 14.9).  Since this is not really realted to Date header changes, I will  probably submit a separate bug report.  According to proxy_http.c this is the only code that touches the date field:    \t      if ((buf = apr_table_get(r->headers_out, 'Date')) != NULL) {   \t\tapr_table_set(r->headers_out, 'Date',                                    ap_proxy_date_canon(p, buf));   \t      }                                               What it does is try and parse the date provided using ap_proxy_date_canon(). This tries to parse the date, but if it fails to parse the date, the date is transferred through unaltered.  If the date is being overwritten, it is likely to be happening inside the Apache core, and not mod_proxy. I have updated the component to reflect this.  Found the problem: inside modules/http/http_protocol.c the date is being set to the current time, and the contents of the output headers array is ignored in the case of the date header. The attached patch fixes this.  Created an attachment (id=5840) Patch to fix for v2.0.46-dev  Created an attachment (id=5841) Patch this time without compiler warnings!  Patch applied to v2.1 and v2.0 			Co-Advisor	Graham Leggett	L.C.	Will Rowe
14399	null	CLOSED		Detlev Vendt	1036793640000	1036869728000		ISAPI Call w/o params will crash Within mod_isapi.c, line 1415 it stated:  /* Based on some examples I've noticed, NULL is expected here.   */     if (!*cid->ecb->lpszQueryString) {         cid->ecb->lpszQueryString = NULL;     }  Please refer to to Visual Studio 6.0 VC98/mfc/src/isapi.cpp, line 447. There's  always a zero terminated string expected. Giving NULL results in exception with  ISAPI-Call w/o params.  Suggestion for solution: delete the three lines.	   Your suggested patch is in and will be in the next release 2.0.44.  Thanks!!! 			Will Rowe
14451	null	CLOSED		Bruno Wolff III	1037030760000	1045528746000		Using mod_deflate on an internally redirected request results in an extra 20 byte gzip header appended to the response. When I filter CGI output with the DEFLATE filter (with or without also using INCLUDES) I get a content-length header with a byte count off by 20 bytes. The ones I have observed have been low in GET requests and high in HEAD requests (for the latter a count of 20 was returned even though there was no body data returned). You can see a sample of this using http://www.schroepl.net/cgi-bin/http_trace.pl to fetch the page http://wolff.to/area/G_776.html . I currently am not compressing output for browsers that supply the string MSIE in the user-agent header. I am using a CVS version of 2.0.44 from last week.	I saw that some other fixes to mod_deflate were applied recently and retested on current CVS and the problem still exists. Is there some additional information that I can provide that would help you guys confirm this bug? I have tried looking through the bucket passing code in the past when reporting mod_deflate bugs and wasn't able to understand enough to be able to spot where the errors are. I see that you are possible going to change the status of mod_deflate to be a normal module instead of experimental. I have found that people running IE 5.0 and IE 6.0 have been having a lot of problems viewing pages generate by cgi scripts and filtered by mod_deflate. I suspect that the problem is related to the content-length header issue, but I am not absolutely sure of this. If confirming this would help increase the priority on figuring this problem out, I could try using mod_headers to strip the content-length headers and see if that solves the problem for the IE users. However, I have to ask others to do the testing and it might take a few days before I get help after I have some modified pages for them to look at. Supplying the simplest testcase you can come up with that shows the problem would be very helpful.  I've tried to duplicate the problem with GET requests on current code but I haven't been successful.  I haven't looked at the HEAD issue yet.  I think I have figured out enough so that you should be able to reproduce the problem. The missing part is that I do an internal redirect and that is needed to make the problem show up. http://wolff.to/area/htaccess (no period) with show the .htaccess file. The first line (the filter list) and the last line (the relevant redirect) should be all that matters. http://wolff.to/area/test.pl , http://wolff.to/area/test.cgi and http://wolff.to/area/test.html all point to the same file. The first will give you the source, the second will work correctly and the third has a content-length header off by 20. However, note that in the second case the file is 20 bytes longer. I looked at the difference between the compressed output returned by test.cgi and test.html and it appears that test.html has an extra 20 bytes of what appears to be a gzip header tacked on to the end. I also updated to use the latest cvs yesterday so I am now running a 2.1.0 version of httpd. The HEAD and GET problems appear to be separate. The extra 20 bytes get added when there is an internal redirect (using mod_rewrite) and both the new and old extension are subject to mod_deflate filtering. I added another rewrite rule to the htaccess file and a test.txt file accessible through a redirect as test1.txt to illustrate this case. I will see if I can do a better job of isolating the bad content-length header returns on HEAD requests. I figured out what was happenning with the odd content-length header values on HEAD requests. The short story is that it isn't a bug. The script I was using only returns a content-type header on HEAD requests (this is probably broken behavior) to save doing database lookups that won't be used. Even though the body is 0 bytes, it still gets gzip encoded and this encoding takes up 20 bytes. That is why there is a content-length of 20. So the only issue is the extra 20 bytes being tacked on to the body of requests that have a filtered (by mod_deflate) on both the initial and final filename extensions. This is sort of a related note. Normally a content-lenght header isn't sent when an includes filter is used or when the output comes from a cgi script. However if mod_deflate is used, then a content-length header is included for either or both of these cases. I tried using addoutputfilterbytype to see if that would work around the problem, but it didn't help. Is there anything else I can do to help get this bug verified? I think I have included enough information for someone to check on it, but haven't heard back either way since figuring out that combining internal redirects and mod_deflate exhibits the problem. I was able to find a configuration that avoided the problem in my setup. I have changed things to reflect this and have removed some of the test pages I had up. The successful way to handle *.html URLs that were redirected to *.cgi URLs (with internal redirects) so that the output was passed both though INCLUDES and DEFLATE without getting the extra 20 bytes of gzip header or messing *.html files that aren't redirected is: AddOutputFilter INCLUDES;DEFLATE .html AddOutputFilter DEFLATE .txt .pl .sql .cgi AddOutputFilterByType INCLUDES text/html This is now all being done at the top level of my document root. Previously there was an addoutputfilter for .cgi files that only specified DEFLATE at the top level and this was overridden in a subdirectory (area) where cgi output was to get passed through both INCLUDES and DEFLATE. This may be related to the problem I was having as reduplicating the issue with the output filter directives only at the top level doesn't seem to work. By using the addoutputfilterbytype directive I can just do INCLUDES processing for cgi output that returns text/html (as opposed to text/plain) and don't need to have diferent rules in different directories. So, I am not completely sure what is needed to make the problem show up. I was able to get the problem to occur with just plain html files (no cgi script) subject to a redirect in the subdirectory. I am asking one of my users to see if this fixes the problem with accessing the pages with IE. It turns out my new configuration didn't fix things. http://www.schroepl.net/cgi-bin/http_trace.pl started reporting a data returned size that matched the content length header, but according to my access_log another 20 bytes were actually sent. I noticed this when I got a report back from an IE user that they still couldn't get compressed responses to work. So what I think changed was the testing service, not the content being served. I think I have something that will point out where I am seeing the problem. In mod_deflate.c there is code to not due compression for subrequests. I think this check should be extended to not do it for internal redirects. (I am not sure why the check that the request doesn't already have a gzip encoding doesn't catch this.) I checked r->next to see if there will be more processing after this request is completed. I am not sure this is correct, because the .h that defines record_rec has a comment that this link refers to external requests. I suspect that that is a typo. Anyway the patch seems to work for my problem. I will let you know if this fixes the IE problem when I hear back from the person who has been having problems with compressed responses. The diff versus mod_deflate.c follows: *** mod_deflate.c.orig  Sun Dec 22 13:53:19 2002 --- mod_deflate.c       Sun Dec 22 13:36:55 2002 *************** *** 260,266 ****           const char *encoding, *accepts;            /* only work on main request/no subrequests */ !         if (r->main) {               ap_remove_output_filter(f);               return ap_pass_brigade(f->next, bb);           } --- 260,266 ----           const char *encoding, *accepts;            /* only work on main request/no subrequests */ !         if (r->main || r->next) {               ap_remove_output_filter(f);               return ap_pass_brigade(f->next, bb);           } I heard back from the IE user who was having problems and now that there aren't an extra 20 bytes being tacked on to compressed responses, things are working OK. I'll try to have a closer look at the problem and the patch these days, but one word anyway:  sending different headers for GET and HEAD is wrong. You should _not_ handle both methods not differently. Just send the content regardless of the method. Apache will do the right thing and discard the body if neccessary. But he's able to maintain the Content-length header (or TRansfer-Encoding). Thanks for looking at this! While working on this issue I did figure out that suppressing the content for the head method was wrong. I haven't gotten around to changing the code yet, but I plan to. The original idea was to save resources by not doing database calls if the content was going to be thrown away anyway, but it turned out that keeps the head method from being as useful as it should. I also got confused by this as I was expecting the content-length to be zero since there was no body, not realizing that a gzip'd version of an empty content takes up 20 bytes. Get requests do seem to be broken though. And since mod_deflate checks to make sure it isn't run twice, I am pretty sure there is something wrong where I have patched the code. (Especially since it fixes things for me.) I am just not sure that the fix is really correct for all cases. strange ...  Seems to happen only when redirecting to the cgi-handler. Can someone confirm or disprove this?  Thanks anyway for your patience with us :) errr, forget my last comment. I did the wrong tests ;-)  However, your patch worked around the actual problem, it did not solve it. The problem was that after finalizing the (redirected) request, the original request sent an(other) EOS bucket down the filter chain, which caused mod_deflate to init zlib and exit zlib with the result of 20 extra bytes.  The following patch should solve the problem entirely: <http://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/util_filter.c.diff?r1=1.94&r2=1.95>  It's proposed for backport and may be in the next 2.0 release.  Thanks again for your patience and your detailed reports! I removed my patched mod_deflate and resynced with current CVS and retested for the problem. It seems to be fixed now. Thanks! FYI: The fix will be in 2.0.45. *** Bug 17629 has been marked as a duplicate of this bug. *** *** Bug 14678 has been marked as a duplicate of this bug. *** *** Bug 14678 has been marked as a duplicate of this bug. ***			Andr?? Malo	Bruno Wolff III	Jeff Trawick	Joe Orton	Ruediger Pluem	Steven Grimm
14453	null	CLOSED		Dr Philip J. Naylor	1037037180000	1073935935000		mod_rewrite external programs disrupted by URLs with newlines in We are using mod_rewrite with an external rewrite program to produce an inbound  proxy that splits requests between staff and student back-end servers.  Occassionally the rewrite program starts returning results that relate to  previous requests, rather than the current one and the server has to be restarted.  Having added some extra debugging to mod_rewrite.c I have determined that (at least on the last occassion) the problem is with someone trying to access a URL that has a newline character encoded in it :  http://www.cems.uwe.ac.uk/~opkgyaas%0a/images/livingeaston.JPG  The customised debug output when this happens is :  lookup_map_program: called for /~jsmith/ec/perm+csp/sld026.htm rewritelock_alloc: called for /~jsmith/ec/perm+csp/sld026.htm fd_lock: called for /~jsmith/ec/perm+csp/sld026.htm fd_lock: ended fcntl() loop [rc=0, errno=11, EINTR=4] for /~jsmith/ec/perm+csp/s ld026.htm fd_lock: got lock for /~jsmith/ec/perm+csp/sld026.htm lookup_map_program: rewrote -         203.197.98.2,/~jsmith/ec/perm+csp/sld026.htm to http://web03.cems.uwe.ac .uk/~jsmith/ec/perm+csp/sld026.htm                  for /~jsmith/ec/perm+csp/sld026.htm rewritelock_free: called for /~jsmith/ec/perm+csp/sld026.htm fd_unlock: called for /~jsmith/ec/perm+csp/sld026.htm fd_unlock: unlocked for /~jsmith/ec/perm+csp/sld026.htm lookup_map_program: called for /~jsmith/ec/perm+csp/img026.gif rewritelock_alloc: called for /~jsmith/ec/perm+csp/img026.gif fd_lock: called for /~jsmith/ec/perm+csp/img026.gif fd_lock: ended fcntl() loop [rc=0, errno=11, EINTR=4] for /~jsmith/ec/perm+csp/i mg026.gif fd_lock: got lock for /~jsmith/ec/perm+csp/img026.gif lookup_map_program: rewrote -         203.197.98.2,/~jsmith/ec/perm+csp/img026.gif to http://web03.cems.uwe.ac .uk/~jsmith/ec/perm+csp/img026.gif                  for /~jsmith/ec/perm+csp/img026.gif rewritelock_free: called for /~jsmith/ec/perm+csp/img026.gif fd_unlock: called for /~jsmith/ec/perm+csp/img026.gif fd_unlock: unlocked for /~jsmith/ec/perm+csp/img026.gif lookup_map_program: called for /~opkgyaas /images/livingeaston.JPG rewritelock_alloc: called for /~opkgyaas /images/livingeaston.JPG fd_lock: called for /~opkgyaas /images/livingeaston.JPG fd_lock: ended fcntl() loop [rc=0, errno=2, EINTR=4] for /~opkgyaas /images/livingeaston.JPG fd_lock: got lock for /~opkgyaas /images/livingeaston.JPG lookup_map_program: rewrote -         209.237.238.163,/~opkgyaas /images/livingeaston.JPG to http://www.cems.uwe.ac.uk/blocked.html                  for /~opkgyaas /images/livingeaston.JPG rewritelock_free: called for /~opkgyaas /images/livingeaston.JPG fd_unlock: called for /~opkgyaas /images/livingeaston.JPG fd_unlock: unlocked for /~opkgyaas /images/livingeaston.JPG lookup_map_program: called for /~jsmith/ec/perm+csp/sld027.htm rewritelock_alloc: called for /~jsmith/ec/perm+csp/sld027.htm fd_lock: called for /~jsmith/ec/perm+csp/sld027.htm fd_lock: ended fcntl() loop [rc=0, errno=11, EINTR=4] for /~jsmith/ec/perm+csp/s ld027.htm fd_lock: got lock for /~jsmith/ec/perm+csp/sld027.htm lookup_map_program: rewrote -         203.197.98.2,/~jsmith/ec/perm+csp/sld027.htm to NULL                  for /~jsmith/ec/perm+csp/sld027.htm rewritelock_free: called for /~jsmith/ec/perm+csp/sld027.htm fd_unlock: called for /~jsmith/ec/perm+csp/sld027.htm fd_unlock: unlocked for /~jsmith/ec/perm+csp/sld027.htm lookup_map_program: called for /~ngunton/worksheets/shell.pdf rewritelock_alloc: called for /~ngunton/worksheets/shell.pdf fd_lock: called for /~ngunton/worksheets/shell.pdf fd_lock: ended fcntl() loop [rc=0, errno=11, EINTR=4] for /~ngunton/worksheets/s hell.pdf fd_lock: got lock for /~ngunton/worksheets/shell.pdf lookup_map_program: rewrote -         66.130.224.176,/~ngunton/worksheets/shell.pdf to http://web03.cems.uwe.a c.uk/~jsmith/ec/perm+csp/sld027.htm                  for /~ngunton/worksheets/shell.pdf rewritelock_free: called for /~ngunton/worksheets/shell.pdf fd_unlock: called for /~ngunton/worksheets/shell.pdf fd_unlock: unlocked for /~ngunton/worksheets/shell.pdf lookup_map_program: called for /~ngunton/worksheets/first.gif rewritelock_alloc: called for /~ngunton/worksheets/first.gif fd_lock: called for /~ngunton/worksheets/first.gif fd_lock: ended fcntl() loop [rc=0, errno=9, EINTR=4] for /~ngunton/worksheets/fi rst.gif fd_lock: got lock for /~ngunton/worksheets/first.gif lookup_map_program: rewrote -         66.130.224.176,/~ngunton/worksheets/first.gif to http://web03.cems.uwe.a c.uk/~ngunton/worksheets/shell.pdf                  for /~ngunton/worksheets/first.gif rewritelock_free: called for /~ngunton/worksheets/first.gif fd_unlock: called for /~ngunton/worksheets/first.gif fd_unlock: unlocked for /~ngunton/worksheets/first.gif   Since the external rewrite programs rely on receiving newline delimited data on stdin, any newlines should really be stripped out, or URL encoded, before they receive them.	Created an attachment (id=7543) Patch we use successfully since monthes about this problem  This was fixed in 2.1 some time ago and waits for backport approval (another vote from a core developer).  Thanks for your report! *** Bug 21975 has been marked as a duplicate of this bug. *** It will be fixed in 1.3.30 and 2.0.49 versions.			Andr?? Malo	Cedric Gavage
14550	null	CLOSED		Piotr Czejkowski	1037274060000	1037328699000		bug in server-client comunication while sending enviroment variables While sending paramters of called cgi script from working thrad to cgid serwer by socket '/n' char is used to separate each part. If in sending enviroment '/n' char will be used, all parameters will be send bad, some enviroment elements and - what worst - every PUT variable will be lost. This bug making cgi scripts which are working in SSL enviromend and which need SSL information unusable.  Maybe this patch to mod-cgid.c will help:  284,287d283 <     rc = read(fd, &j, sizeof(int)); <     if (rc != sizeof(int)) { <         return 1; <     } 303a300,303 >     rc = read(fd, &j, sizeof(int)); >     if (rc != sizeof(int)) { >         return 1; >     } 305,307c305,313 <     i = 0;  <     for (i = 0; i < j; i++) {  <         environ[i] = ap_getword(r->pool, (const char **)&data, '/n');  --- >     for(i=0;i<j;i++){ >     \trc = read(fd, &len, sizeof(int)); >     \tif (rc != sizeof(int)) { > \t    return 1; > \t} > \tenviron[i] = apr_pcalloc(r->pool,len+1); > \trc = read(fd,environ[i],len); > \tif (rc != len){ > \t    return 1; 308a315,316 >     } >  310c318,331 <     r->args = ap_getword(r->pool, (const char **)&data, '/n');  --- >  >     rc = read(fd, &len, sizeof(int)); >     if (rc != sizeof(int)) { > \treturn 1; >     } >     if(rc!=0){ >     \tr->args = apr_pcalloc(r->pool,len+1); >     \trc = read(fd,r->args,len); >     \tif (rc != len){ > \t     \treturn 1; >     \t} >     } else { >     \tr->args=NULL; >     }\t 399a421,425 >     /* Write the request type (SSI 'exec cmd' or cgi). */ >     if (write(fd, &r_type, sizeof(int)) < 0) { > \tap_log_rerror(APLOG_MARK, APLOG_ERR, errno, r, > \t\t     'write to cgi daemon process'); >     } 403,404c429,432 <     for (i =0; env[i]; i++) {  <         continue;  --- >     len=strlen(data); >     if (write(fd, &len, sizeof(int))<0){ >         ap_log_rerror(APLOG_MARK, APLOG_ERR, errno, r, > \t\t     'write to cgi daemon process'); 407,408c435 <     /* Write the request type (SSI 'exec cmd' or cgi). */ <     if (write(fd, &r_type, sizeof(int)) < 0) { --- >     if(write(fd,data,len)<0){ 412a440,444 >    for (i =0; env[i]; i++) {  > \tcontinue;  >     }  >  >  420c452,465 <         data = apr_pstrcat(r->pool, data, env[i], '/n', NULL);  --- >         len=strlen(env[i]);  > \tif(write(fd,&len,sizeof(int)) < 0) { > \t\tap_log_rerror(APLOG_MARK, APLOG_ERR, errno, r, > \t\t\t      'write to cgi daemon process'); > \t} > \tif(write(fd,env[i],len) < 0){ > \t\tap_log_rerror(APLOG_MARK, APLOG_ERR, errno, r, > \t\t             'write to cgi daemon process'); > \t}\t\t >     } >     if(r->args!=NULL){  >     \tlen=strlen(r->args); >     } else { > \tlen=0; 422,424c467 <     data = apr_pstrcat(r->pool, data, r->args, NULL);  <     len = strlen(data);  <     /* Write the length of the concatenated env string. */ --- >  429,430c472,473 <     /* Write the concatted env string. */      <     if (write(fd, data, len) < 0) { --- >     if( len!=0){ >    \tif (write(fd,r->args,len)<0){ 433a477,478 >     } >	A fix has just been committed.  Communication between handler and daemon was extensively reworked. Environment variables were handled as in the patch submitted with this PR.  Thanks for your debug work, and thanks for using Apache 2.0!  *** Bug 9953 has been marked as a duplicate of this bug. ***			Jeff Trawick	Joe Orton
14639	null	CLOSED		Tilman Giese	1037634540000	1055541534000		Apache 404 error when %2f occurs in path_info I used AcceptPathInfo On to allow parsing of query strings, e.g.  /www/test.php/category/234  where test.php is the real file. But if there is a slash as %2f in the query  string, e.g.  /www/test.php/category%2f234  apache creates a 404 error.	I have the same problem, only when apache is configured as a transparent proxy.    You aren't reporting a bug in query strings (those strings following the   '?' question mark delimiter.)  You are speaking of path info, which only   makes sense when interpreted with the filesystem.  Because of security   implications, that ambiguity was disabled eaons ago.  This has been addressed in Apache 2.0.46 through the new AllowEncodedSlashes directive.			Rodent of Unusual Size	Warren Volz	Will Rowe
14648	null	CLOSED		Alex Krohn	1037648880000	1074040899000		mod_rewrite does not proxy included requests This is a duplicate of PR2074, PR5338, PR6804 and possibly others I couldn't  find in bugzilla.  Basically the problem is, if you have:  ProxyPass /foo http://newserver/foo ProxyPassReverse /foo http://newserver/foo  Then an SSI of:  <!--#include virtual='/foo/bar'-->  _will_ be proxied. If instead of ProxyPass you use:  RewriteRule /foo(.*) http://newserver/foo$1 [P]  then the above SSI is _not proxied_. This is because of:          /*          *  Ignore this rule on subrequests if we are explicitly          *  asked to do so or this is a proxy-throughput or a          *  forced redirect rule.          */         if (r->main != NULL &&             (p->flags & RULEFLAG_IGNOREONSUBREQ ||              p->flags & RULEFLAG_PROXY          ||               p->flags & RULEFLAG_FORCEREDIRECT    )) {             continue;         }  in mod_rewrite. If you comment out the RULEFLAG_PROXY, it works as expected.  I'm not sure of the consequences this has. Can anyone comment on the reasoning  behind this?   I believe this also applies to httpd-2.0, but I haven't actually compiled it  yet.	This doesn't work perfectly, I've discovered. Take the follwoing setup:  ## relevant conf directives DirectoryIndex index.html index.php RewriteRule ^/(.*/.php)$ http://localhost:8888/$1 [P] ##  $DocRoot/blah/ contains: index.php and test.html  Now...*without* patching mod_rewrite, a request for http://www.domain.org/blah/ will return index.php just fine, and it will be properly proxied over to localhost:8888. And, as this bug points out, if test.html just contains <!--#include virtual='index.php'-->, requests for it return the unparsed source of index.php, which is incorrect.  But if you remove the one line from mod_rewrite, allowing proxy requests in subrequests, the situation reverses. The SSI part works properly, but requests for /blah/ give you a directory index instead of the output of index.php.  So this patch doesn't do exactly the right thing.   I've done some more digging and think I've come a little closer to the real source of the problem:  mod_dir makes subrequests for each of its potential index file names until it finds one to return. Line 165 of mod_dir.c is this:  if (rr->status == HTTP_OK && S_ISREG(rr->finfo.st_mode)) {  So, for mod_dir to return an index file the subrequest has to be HTTP_OK and it must be a regular file. This works fine with the unpatched mod_rewrite, because it will return HTTP_OK and the file will be there -- even if the server is going to end up proxying it in the end.  But, if you patch mod_rewrite then you'll still get the HTTP_OK, but rr->filename will have been changed to start with 'proxy:', so S_ISREG() will fail.   Which leads to this solution:  change the call to ap_sub_req_lookup_uri on line 163 of mod_dir.c to ap_sub_req_lookup_file. ap_sub_req_lookup_file doesn't do the URI translation, so it skips mod_rewrite in the subrequest. But then mod_dir still does an internal redirect, which in turn *does* do the URI translation, so everything works out in the end.  With these changes both mod_include and mod_dir do the right thing when they are dealing with a file proxied via mod_rewrite+mod_proxy. I'll attach a patch which changes both parts. Created an attachment (id=3973) One line fix to each: mod_dir & mod_rewrite  I'm going through the bug db to make sure patches are findable.  Please see  http://httpd.apache.org/dev/patches.html  Another solution to this problem is to utilize the proxy: moniker instead of  [P} to invoke the proxy client.  [P] as you have pointed out invokes the proxy client but does not continue with  additional includes on the invoked page.  Wheras the proxy: moniker is invoked in the file mapping handler which contiues  with additional ssi requests.  Example: RewriteRule ^(.*) proxy:http://host/$1  This assumes that mod_proxy is installed and configured correctly!  The other benefit is that additional SSI requests will continue to be processed  on the calling page.  Fixed in 2.1.  Thanks for the report and thanks for using Apache.			Andr?? Malo	Jeff Trawick	Jeremy Brown	Mike Cramer
14892	null	CLOSED		Sander Holthaus	1038404640000	1038624260000		security tips should suggest subscribing to announcements list The documentation should emphasize (where appropriate) the importance of  upgrading, decent configuration and the responsibilities that come with  operating a webserver on the internet.  For instance, in the section security tips, there is no mentioning of that  Apache users should regularly check the Apache-website for security issues and  releases.	Specific suggestions are always appreciated, and the suggestion for the security tips doc is good.  General statements about being more secuity conscious aren't very helpful, however.  If you have more ideas, feel free to file specific bug reports, or even better, join the documentation project: http://httpd.apache.org/docs-project/  Thanks. This security tip will be added to the next version.  Thanks.			Joshua Slive
14921	null	CLOSED		Julian Reschke	1038475260000	1043861374000		reported entity tags differ between HEAD/GET and PROPFIND For the filesystem backend, HEAD/GET return weak entitiy tags, while PROPFIND (DAV:getetag) returns the same tokens with the leading 'W/' removed.	(likely cause: moddav duplicates code from ap_make_etag in http_protocol.c  instead of reusing it directly -- etag computation probably should be done in  one single place) This is not really a bug per se.  What happens is that we generate a weak ETag when the request is too close to the modification time of the file (as dictated by RFC 2616, ETags should have 60-second resolutions).  After that second has elasped and the file hasn't changed, that weak entity tag would be made strong.  Creating a weak tag in mod_dav_fs isn't always desirable since it isn't keyed to a request - therefore all of its entity tags should be strong rather than weak.  However, RFC 2616 explicitly calls out strong entity comparison and weak entity comparison functions.  Currently, mod_dav only uses strong entity comparison.  So, I modified mod_dav to do weak entity comparison instead.  See modules/dav/main/util.c r1.45.  This has been proposed for the next stable release of httpd-2.0.  Thanks for using Apache! *** Bug 16451 has been marked as a duplicate of this bug. *** I'm not sure that I agree with the analysis. First of all, RFC2616 doesn't  define a specific resolution for etags.  (all this probably only applies to the fs backend)  The issue here seems to be that the resource's etag starts it's life as a weak  one, and then turns into a strong etag after some delay. This works fine if you  discover an already existing resource using GET/HEAD/PROPFIND, but leads to  ugly results if a client takes the entity tag returned by a PUT as validator  for subsequent PUT operations (because upon PUT, the entity tag returned is  always a weak one, because it's 'fresh').  As far as the If-* headers defined in RFC2616 are concerned (not the If:  defined in RFC2518), strong comparison should be applied to etags (end of para  13.3.3). This is why I believe the only workable solution here is to do weak entity comparison for the If: header.  mod_dav must be able to handle weak entity tags for its conditional headers because the entity tag might be promoted from a weak to a strong one at any time (given rules of 13.3.3).  Note that using ap_make_etag is not an option since we don't have access to the original request, nor is that resource in the etag hook even related to the original resource that was requested.  (ap_make_etag has certain configurable properties that may not be correct if we are not dealing with the original resource.)  And, doing so, wouldn't solve the real problem of ETag promotion.  If 2518bis clarifies this and says that If should only have strong entity comparison, then we might want to rethink this.  Regardless, perhaps it should clarify this corner case.			Julian Reschke	Justin Erenkrantz
15001	null	CLOSED		Todd Walton	1038856860000	1038858541000		Improper Case In httpd.conf In the explanatory notes for the Options directive in httpd.conf there is a list of possible values for the Options directive.  One of the possible values is 'Mulitviews'.  Immediately following is a note about 'MultiViews'.  Note the change in case of the letter 'v'.  This makes it unclear whether the proper possible value is 'MultiViews' or 'Multiviews'.  This may not matter, I actually don't know if the directive values are case sensitive, but at the very least it's untidy.  Thank you.	It's actually case insensitive, but you're right, it may be confusing.  Thanks for using Apache!			Andr?? Malo
15057	null	CLOSED		Otmar Lendl	1039003980000	1073904797000		ssl_var_lookup_ssl does not handle SSL_get_session returning NULL While working on an Apache 2.0 connection handler to implement EPP within Apache (see https://sourceforge.net/projects/aepps/) I noticed the following:  If I turn on StdEnvVars httpd will dump core in ssl_var_lookup_ssl as SSL_get_session returns a NULL pointer. After spending an afternoon with gdb, etherreal and ssl-telnet I have no clue why connecting with ssl-telnet to  an SSL/HTTP port gives me a non-NULL session variable whereas using the same client to connect to my connection-handler returns a NULL value.  I'm using openssl 0.9.6g.  To work around the issue until I eventually find the real cause, I applied the folllowing patch to my 2.0.43 source-tree:  --- ssl_engine_vars.c   2002/12/04 11:27:14     1.1 +++ ssl_engine_vars.c   2002/12/04 11:27:34 @@ -280,7 +280,8 @@      else if (ssl != NULL && strcEQ(var, 'SESSION_ID')) {          char buf[SSL_SESSION_ID_STRING_LEN];          SSL_SESSION *pSession = SSL_get_session(ssl); -        result = apr_pstrdup(p, SSL_SESSION_id2sz( +       if (pSession) +               result = apr_pstrdup(p, SSL_SESSION_id2sz(                                  SSL_SESSION_get_session_id(pSession),                                  SSL_SESSION_get_session_id_length(pSession),                                  buf, sizeof(buf)));   I'm not sure whether this is an issue with mod_ssl, my connection-handler or openssl. As the patch is simple enough, I would recommend to apply it to the offcial tree in any case.  cheers,  /ol	Ah, I just found a repro case for SSL_get_session returning NULL: when serving the 'you sent a plain HTTP request over an SSL connection' error message.  Thanks for the patch! It's committed to 2.1 and will be proposed for backport for 2.0.			Joe Orton
15113	null	CLOSED		Thomas CASTELLE	1039105800000	1040139726000		Child Segmentation Fault when Mod_Cache receive a 302 ok response Hello there !  We have this friendly message :  '[notice] child pid 19283 exit signal Segmentation fault (11)'  when we try to retrieve some web pages through an Apache 2.0.43 proxy running mod_cache, from a serveur returning 302 ok responses.  I looked a little bit in the code, and, I'm not a specialist, but the problem seems to be in mod_cache.c, in the cache_in_filter function, when there is a call to apr_pstrcat :  if (r->status != HTTP_OK && r->status != HTTP_NON_AUTHORITATIVE          && r->status != HTTP_MULTIPLE_CHOICES          && r->status != HTTP_MOVED_PERMANENTLY          && r->status != HTTP_NOT_MODIFIED) {          /* RFC2616 13.4 we are allowed to cache 200, 203, 206, 300, 301 or 410           * We don't cache 206, because we don't (yet) cache partial responses.           * We include 304 Not Modified here too as this is the origin server           * telling us to serve the cached copy.          */          reason = apr_pstrcat(p, 'Response status %d', r->status); }  Commenting this line prevent us from having this problem (on this particular web-serveur) but I don't think it's really clean... ;-)  Can you look at this ?  Thanks in advance,  Thomas.	Hello !  Have you checked this problem ? Can anyone look at it, because this is quite annoying for us (we are in production environment !)  Thanks a lot in advance,  Thomas.  Thomas, I am currently looking at this PR. While I am working to debug this, could you attach a section of your error_log around the time this happens (with loglevel set to debug)? Thanks. OK, thanks for looking !  I reproduced the bug.  Last CVS snapshot used, compiled with :  ./configure --prefix=/opt/ApacheProxy2.0 --localstatedir=/logs/ApacheProxy2.0 --enable-cache --enable-disk-cache --enable-proxy --enable-rewrite --enable-deflate  It is configured as a proxy-cache. When the serveur behind answers a 403 or 302 response, the child dies. With a telnet on a 403 page :  # telnet 172.30.16.21 80 Trying 172.30.16.21... Connected to 172.30.16.21. Escape character is '^]'. GET /blablabla HTTP/1.1 Host: front.www.leda.rev.proto.generali.fr  Connection closed by foreign host. #  In the error.log :  [Wed Dec 11 18:26:57 2002] [notice] Apache configured -- resuming normal operations [Wed Dec 11 18:26:57 2002] [info] Server built: Dec 11 2002 18:20:58 [Wed Dec 11 18:26:57 2002] [debug] prefork.c(1039): AcceptMutex: sysvsem (default: sysvsem) [Wed Dec 11 18:27:33 2002] [notice] child pid 1574 exit signal Segmentation fault (11)  In the virtual host error log :  [Wed Dec 11 18:27:32 2002] [debug] mod_cache.c(118): cache: URL /blablabla is being handled by disk [Wed Dec 11 18:27:32 2002] [debug] mod_cache.c(202): cache: no cache - add cache_in filter and DECLINE [Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(109): proxy: HTTP: canonicalising URL //www.leda.rev.proto.generali.fr/blablab la [Wed Dec 11 18:27:32 2002] [debug] mod_proxy.c(440): Trying to run scheme_handler against proxy [Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(1170): proxy: HTTP: serving URL http://www.leda.rev.proto.generali.fr/blablabl a [Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(221): proxy: HTTP connecting http://www.leda.rev.proto.generali.fr/blablabla t o www.leda.rev.proto.generali.fr:80 [Wed Dec 11 18:27:32 2002] [debug] proxy_util.c(1201): proxy: HTTP: fam 2 socket created to connect to proxybo1.generali.fr [Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(370): proxy: socket is connected [Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(404): proxy: connection complete to 172.30.4.4:9080 (proxybo1.generali.fr) [Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(1012): proxy: start body send [Wed Dec 11 18:27:32 2002] [debug] mod_cache.c(436): cache: running CACHE_IN filter  As I said before, it seems to crash on the particular call to apr_pstrcat. If I comment it, it works.  in error.log : [Wed Dec 11 18:38:31 2002] [notice] Apache configured -- resuming normal operations [Wed Dec 11 18:38:31 2002] [info] Server built: Dec 11 2002 18:20:58 [Wed Dec 11 18:38:31 2002] [debug] prefork.c(1039): AcceptMutex: sysvsem (default: sysvsem)  in virtual host error log : [Wed Dec 11 18:39:03 2002] [debug] mod_cache.c(118): cache: URL /blablabla is being handled by disk [Wed Dec 11 18:39:03 2002] [debug] mod_cache.c(202): cache: no cache - add cache_in filter and DECLINE [Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(109): proxy: HTTP: canonicalising URL //www.leda.rev.proto.generali.fr/blablab la [Wed Dec 11 18:39:03 2002] [debug] mod_proxy.c(440): Trying to run scheme_handler against proxy [Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(1170): proxy: HTTP: serving URL http://www.leda.rev.proto.generali.fr/blablabl a [Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(221): proxy: HTTP connecting http://www.leda.rev.proto.generali.fr/blablabla t o www.leda.rev.proto.generali.fr:80 [Wed Dec 11 18:39:03 2002] [debug] proxy_util.c(1201): proxy: HTTP: fam 2 socket created to connect to proxybo1.generali.fr [Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(370): proxy: socket is connected [Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(404): proxy: connection complete to 172.30.4.4:9080 (proxybo1.generali.fr) [Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(1012): proxy: start body send [Wed Dec 11 18:39:03 2002] [debug] mod_cache.c(436): cache: running CACHE_IN filter [Wed Dec 11 18:39:03 2002] [info] disk_cache: Caching URL front.www.leda.rev.proto.generali.fr/blablabla? [Wed Dec 11 18:39:03 2002] [debug] mod_cache.c(806): cache: Caching url: /blablabla [Wed Dec 11 18:39:03 2002] [info] disk_cache: Caching headers for URL front.www.leda.rev.proto.generali.fr/blablabla? [Wed Dec 11 18:39:03 2002] [info] disk_cache: Cached body for URL front.www.leda.rev.proto.generali.fr/blablabla? [Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(1071): proxy: end body send  Thanks for your help ! And as a bonus-question... is mod_cache actively developped in the moment ? Because the only problems we have with Apache 2 come from this module, and it doesn't seem to be really often updated (well, as far as i can see on the cvs snapshots...). Can someone tell me if it will we stable in the next release ?  Thanks a lot for your effort !  Thomas.  Hi there !  Is there some news about this bug ? Have you reproduced the problem ? Please keep me informed ! Thanks in advance,   Thomas. I just applied a fix to mod_cache.c that cures the core dump. This fix will be included in a future release of Apache. Thank you for reporting this problem.			Paul J. Reder	Thomas CASTELLE
15114	null	CLOSED		Mike Cramer	1039106760000	1074040672000		t pass Proxy Throughput on internal subrequests This is basically the same bug as #14648 for Apache 1.3. It is also in the old bug DB as PR#2074.   Three things have to change:  1) mod_rewrite has to run proxy rules in subrequests. This allows mod_include to work with the proxy rules. 2) mod_dir has to use ap_sub_req_lookup_file instead of ap_sub_req_lookup_uri. The mod_rewrite change, will break mod_dir with out this change. Basically, using _file instead of _uri avoids the rewrite rule entirely, allowing mod_dir to find the index file. 3) But mod_dir still doesn't do the entirely right thing, because of bug #15112. So apply that patch and it everything will work properly.	Created an attachment (id=4060) Fix mod_rewrite proxy bug for mod_include  Oh yea...and the code that adds the args to the subrequest when checking each file has to go again if it's changed to use ap_sub_req_lookup_file. Otherwise a request like http://domain.org/foo/?bar=1 will fail. Granted, the original logic -- that the args could be relevant to decision of which index file to use -- is good, but this seems like the lesser of two evils. I'm going through the bug db to make sure patches are findable.  Please see  http://httpd.apache.org/dev/patches.html  Another solution to this problem is to utilize the proxy: moniker instead of  [P} to invoke the proxy client.  [P] as you have pointed out invokes the proxy client but does not continue with  additional includes on the invoked page.  Wheras the proxy: moniker is invoked in the file mapping handler which contiues  with additional ssi requests.  Example: RewriteRule ^(.*) proxy:http://host/$1  This assumes that mod_proxy is installed and configured correctly!  The other benefit is that additional SSI requests will continue to be processed  on the calling page.   Fixed in 2.1.  Thanks for the report and thanks for using Apache.			Andr?? Malo	Jeff Trawick	Jeremy Brown	Mike Cramer
15207	null	RESOLVED		Phil Gregory	1039485480000	1123257749000		mod_proxy alters URIs when acting as a reverse proxy When a URI passes through mod_proxy, either via ProxyPass or a proxying RewriteRule, mod_proxy appears to be decoding percent escaped characters before passing the URI on to the destination server.  (So, for example, if the original URI contains a '%2B', the destination server will see a '+'.)  This is contrary to RFC 2616 (HTTP/1.1), which says 'A transparent proxy MUST NOT rewrite the 'abs_path' part of the received Request-URI when forwarding it to the next inbound server, except as noted above to replace a null abs_path with '/'.' (section 5.1.2).  In addition, it breaks a CGI I'm using.  :)  As further information, the decoding seems to be recursive to a degree.  '%252B' is also converted into '+', but '%25252B' merely becomes '%252B'.	A reverse proxy doesn't need to be transparent. It may be as well a caching proxy, that approached the backend server only if it doens't have a fresh copy of the requested object. There fore, it MAY alter the URL. However, there is a bug in this alteration: In the reverse proxy case, unescaping is done twice. In the first   unesacping, the core does this for any non-proxy request. However, this is done before reverse proxy requests are identified by matching the URL with ProxyPass directives. Therefore, the second unescaping, in the function ap_proxy_canonenc in proxy_util.c, should be done only for a standard proxy, and not for a reverse proxy, and the line  if (isenc && ch == '%') {  (proxy_util.c:206 in httpd_2.0.45) should be replaced by  if (isenc == PROXYREQ_PROXY && ch == '%') { *** Bug 24873 has been marked as a duplicate of this bug. *** *** Bug 18564 has been marked as a duplicate of this bug. *** Fix now committed to HEAD (subject to review) This bug still exists as of 2.0.53. The suggested patch in proxy_util.c from Zvi Har'El, listed below, corrects the problem for me:  if (isenc == PROXYREQ_PROXY && ch == '%') {  To reproduce the bug, I setup a Reverse Proxy and use the following urls for testing:  http://1.2.3.4/%\t\t-Returns bad request http://1.2.3.4/%25\t\t-Works http://1.2.3.4/proxy/%\t\t-Returns bad request http://1.2.3.4/proxy/%25\t-Returns bad request  After the patch, the last example works properly. I have also the same problem with apache 2.0.54,  is there any plan to fix it in the next release? thanks Fixed for 2.0.55: http://svn.apache.org/viewcvs.cgi?rev=227435&view=rev			Cahya	Joe Orton	Joshua Hirsh	Nick Kew	Zvi Har'El
15242	null	RESOLVED		Taisuke Yamada	1039538760000	1129680320000		mod_cgi prevents handling of OPTIONS request This is a re-submission of old bug (mod_cgi/PR#4490, 1999) that was once  confirmed but was lost for some unknown reason (probably during transition to  new bug database?).  The problem resides in following code in mod_cgi.c:      if (r->method_number == M_OPTIONS) {         /* 99 out of 100 CGI scripts, this is all they support */         r->allowed |= (1 << M_GET);         r->allowed |= (1 << M_POST);         return DECLINED;     }  This code obviously prevents userland CGI to handle OPTIONS request. Because of this code, I've been unable to release/distribute CGI-based WebDAV provider script as WebDAV protocol requires service endpoint to handle OPTIONS request properly.  This same report was once submitted to apache-bugdb list in 1999 and seems to have been confirmed and almost got accepted. You can read how last conversation went in the following URL:    http://www.geocrawler.com/mail/thread.php3?subject=mod_cgi%2F4490% 3A+mod_cgi+prevents+handling+of+OPTIONS+requests&list=192  It seems the last piece needed to get the fix done is a submission of a patch, and here I'm submitting it. You can download the patch from    http://www.imasy.or.jp/~tai/temp/mod_cgi.c.patch  This patch will add 'ScriptTrapOptions (on|off)' directive, which allows user to control whether CGI script will handle OPTIONS request or not.  Just FYI, during googling, I also found Zope people is also hit by this bug. In fact, author of the patch below is the one who have submitted last bug report on this issue.    http://www.zope.org/Members/Brian/Misc/mod_cgi_webdav_patch.html  His patch simply removes above code block, whereas mine adds new diretive to control the behavior.  If this patch gets accepted, I will also submit a report for apache-2.0, as mod_cgi.c in 2.0 also has this code.	Created an attachment (id=4116) Patch to configure whether userland CGI could handle OPTIONS request.  Created an attachment (id=4117) Patch to configure whether userland CGI could handle OPTIONS request.  I'm going through the bug db to make sure patches are findable.  Please see  http://httpd.apache.org/dev/patches.html  Created an attachment (id=11102) Fixed for the Windows Update problem  Just a thought -- requiring extra configuration will be onerous for some users (e.g., those at certain  hosting providers). Rather than adding a configuration directive, why not require the script that wants  to handle OPTIONS to just emit an Apache-Specified HTTP header that gets consumed?  E.g.,  print 'Status: 200 OK' print 'Handling-OPTIONS: 1' print 'Allow: GET, POST' ... Did you ever submit a report for 2.0? Can't seem to find anything, and 2.0.53 seems to have the same  problem. Hmm, never mind the previous suggestion; if the script had side effects, they'd still take place, which  won't be good. Wow, it's been long time since I submitted this one...  No, I haven't submitted patch for 2.0. At that time, 2.0 was not really for production, so I simply waited for 1.3 patch to get in.  It 2005 now, so maybe I should push this patch for 2.0 - I guess developers are more active on 2.0 than on 1.3.  I'd just like to add that it's been awhile and it would be nice if the patch was accepted. Also known as     http://archive.apache.org/gnats/4490  This misfeature was supposed to be deleted almost immediately following its addition to the server, as described in  <http://mail-archives.apache.org/mod_mbox/httpd-dev/199608.mbox/%3c9608132318.aa12603@paris.ics.uci.edu%3e>  Yep, that's Aug 1996.  In fact, I thought that I had deleted it, and if this issue had been under 'core' I would have noticed it a long long time ago. Oh well...  The block has now been deleted from all active branches of httpd (1.3.35, 2.0.56, 2.1+).  Thanks for sending in the more complicated patches, but I feel that CGI scripts should be able to handle all methods by now (or be fixed to do so properly).  ....Roy 			Bayle Shanks	Jeff Trawick	Mark Nottingham	Roy T. Fielding	Taisuke Yamada	Thomas Jarosch
15423	null	CLOSED		Steven Grimm	1040086680000	1046048422000		mod_include ends chunked encoding if included script issues a redirect If I have the following .shtml file:  <!--#include virtual='/cgi-bin/redir' --> Got to end!  And /cgi-bin/redir is a script like:  #!/bin/sh echo 'Location: /foo.html' echo ''  Then I'll see the contents of foo.html, but not the 'Got to end' message.  This works fine in Apache 1.x.	Works for me with HEAD of httpd.  Please try Apache 2.0.44.  Thanks for using Apache HTTP Server! Still broken under 2.0.44.  I've poked around a bit more and figured out some additional details; it looks like this is a problem with interaction between chunked encoding and mod_include:  --- dozer% cat test-apache2-redir.shtml <!--#include virtual='/cgi-bin/redirtest' --> Got to end! dozer% cat foo.html hiya dozer% cat ~/apache/cgi-bin/redirtest #!/bin/sh echo Location: /foo.html echo '' dozer% nc dozer 8763 GET /test-apache2-redir.shtml HTTP/1.1 Host: dozer.ironplanet.com:8763  HTTP/1.1 200 OK Date: Mon, 17 Feb 2003 19:09:24 GMT Server: Apache/2.0.44 (Unix) mod_fastcgi/mod_fastcgi-SNAP-0210222112 Accept-Ranges: bytes Connection: close Transfer-Encoding: chunked Content-Type: text/html; charset=ISO-8859-1  5 hiya  0  0  d  Got to end!  0  ---  Notice that although the 'got to end' message *does* make it through, it comes through *after* not one but two 0-length chunks, each of which is supposed to indicate the end of the document (see RFC2616 section 3.6.1).  If you hit this URL with Mozilla or MSIE or links, you just see the 'hiya' message.  Now, if I replace the include of the CGI script with a direct include of /foo.html, the result is much more reasonable:  --- dozer% cat test-apache2-redir2.shtml <!--#include virtual='/foo.html' --> Got to end! dozer% nc dozer 8763 GET /test-apache2-redir2.shtml HTTP/1.1 Host: dozer.ironplanet.com:8763  HTTP/1.1 200 OK Date: Mon, 17 Feb 2003 19:22:29 GMT Server: Apache/2.0.44 (Unix) mod_fastcgi/mod_fastcgi-SNAP-0210222112 Accept-Ranges: bytes Connection: close Transfer-Encoding: chunked Content-Type: text/html; charset=ISO-8859-1  5 hiya  d  Got to end!  0  --- I'd expect to see exactly the same output whether or not there's an internal redirect in the middle of the server-side processing of the .shtml file. I can easily reproduce this on current code.  The problem is that we're getting down to the chunk filter on an internal redirect.  I'll attach a patch that fixes it for me in just a second.  I'm not sure if the patch is complete, so I'm not ready to commit it.  Created an attachment (id=4981) patch file for adding the subrequest filter in internal_internal_redirect()  This patch appears to fix the problem for me. Thanks for the quick feedback.  After reviewing my patch some more I understand it well enough, so I've committed it to 2.1-dev.  I'll propose that it be merged into the stable tree (2.0.45-dev).  Thanks for using Apache, and thanks for your report!  *** Bug 16673 has been marked as a duplicate of this bug. *** FYI, the fix for this problem has been merged into the stable tree for 2.0.45.			Jeff Trawick	Justin Erenkrantz	Steven Grimm
15491	null	CLOSED		Dmitri Tikhonov	1040232540000	1042486707000		A period in command produces an error in some config circumstances. I was plating with mod_ext_filter in 2.0.43, when I noticed that a shell command with a period in its name produces an error.  After playing with it some more, I came up with a test case that I can reproduce without fail.  Script: ------- #!/bin/sh  cat | tr a-z A-Z -------  Working Config: ------------------- # caser, caser.x, and caser.sh are all copies of the same file. ExtFilterDefine caser intype=text/html mode=output cmd=/usr/local/bin/caser ExtFilterDefine caserx intype=text/html mode=output cmd=/usr/local/bin/caser.x ExtFilterDefine caserq intype=text/html mode=output cmd='/usr/local/bin/caser.sh ' ExtFilterDefine casersh intype=text/html mode=output cmd=/usr/local/bin/caser.sh <Directory />     Options FollowSymLinks     AllowOverride None     SetOutputFilter casersh     ExtFilterOptions DebugLevel=1 </Directory> -------------------  Error-producing config: ----------------------- # caser, caser.x, and caser.sh are all copies of the same file. ExtFilterDefine caser intype=text/html mode=output cmd=/usr/local/bin/caser ExtFilterDefine caserx intype=text/html mode=output cmd=/usr/local/bin/caser.x #ExtFilterDefine caserq intype=text/html mode=output cmd='/usr/local/bin/caser.s h' ExtFilterDefine casersh intype=text/html mode=output cmd=/usr/local/bin/caser.sh <Directory />     Options FollowSymLinks     AllowOverride None     SetOutputFilter casersh     ExtFilterOptions DebugLevel=1 </Directory> --------------------------   Note that the only change is that caserq definition is commented out.  Here's the error:  [Wed Dec 18 12:27:45 2002] [debug] mod_ext_filter.c(611): [client 192.168.1.105] filtering "/manual/mod/mod_ext_filter.html.en' of type "text/html' through "/usr/local/bin/caser.sh', cfg ExtFilterOptions DebugLevel=1 NoLogStderr !PreserveContentLength ExtFilterInType text/html ExtFilterOuttype (unchanged), referer: http://socrates.netilla.com/manual/filter.html [Wed Dec 18 12:27:45 2002] [error] [client 192.168.1.105] (32)Broken pipe: apr_file_write(child input), len 0, referer: http://socrates.netilla.com/manual/filter.html	looks like exec*() is returning EFAULT in the failure case...  mod_ext_filter wasn't properly building the argument array in the simple case where there are no quotation marks...  sometimes it worked, sometimes exec*() hit bad storage...  Here is the fix:  Index: modules/filters/mod_ext_filter.c =================================================================== RCS file: /home/cvs/httpd-2.0/modules/filters/mod_ext_filter.c,v retrieving revision 1.1 diff -u -r1.1 mod_ext_filter.c --- modules/filters/mod_ext_filter.c    14 Nov 2002 20:22:50 -0000      1.1 +++ modules/filters/mod_ext_filter.c    13 Jan 2003 19:31:11 -0000 @@ -222,9 +222,10 @@      else      {          /* simple path */ -        /* Allocate space for one argv pointer and parse the args. */ -        filter->args = (char **)apr_palloc(p, sizeof(char *)); +        /* Allocate space for two argv pointers and parse the args. */ +        filter->args = (char **)apr_palloc(p, 2 * sizeof(char *));          filter->args[0] = ap_getword_white(p, args); +        filter->args[1] = NULL; /* end of args */      }      if (!filter->args[0]) {          return 'Invalid cmd= parameter';  It is now in CVS for Apache 2.1.  I can't make any promises on whether or  not it will be in 2.0.44, but it should be in one of the next couple of 2.0 releases.  Thanks for your report, and thanks for using Apache!			Jeff Trawick
15571	null	CLOSED		Christopher M. Tan	1040397000000	1070973885000		No WWW-Authenticate header returned in 401 message Overview Description:  No WWW-Authenticate header is returned when access to a URI indicated in  the 'Destination:' header of a request fails authentication.  Steps to Reproduce:  1. Try copying a file from a normal area to a password-protected area without  supplying any authentication information (I used http://test.webdav.org/dav as  my normal area, and http://test.webdav.org/auth-basic as my password-protected  area).  Note: 'normal area' refers to an area not requiring authorization.  Actual Results:  The copy failed and a '401 Unauthorized' message was returned from the server.   However, the '401 Unauthorized' message did not contain a 'WWW-Authenticate'  header as the HTTP/1.1 specs mention it should.  Expected Results:  The copy should fail and a '401 Unauthorized' message should be returned from  the server containing a 'WWW-Authenticate' header.  The HTTP/1.1 specs mention  that this header *must* be included in a 401 response.  Build Date & Platform:  Apache/2.0.41-dev (Unix) DAV/2 SVN/0.14.2 (dev build) The server is running the mod_dav and mod_dav_fs modules.  Additional Builds and Platforms:  It has been mentioned that this problem occurs with Apache 1.3/mod_dav 1.0.  Additional Information:  This also occurs on a MOVE (or any request with a 'Destination' URI requiring  Authorization).  From the dav-dev mailing list: '...the 401 is being generated in an Apache 'subrequest', but the WWW-Auth header is not being promoted to the 'real' request, so it gets lost...'	It would certainly be helpful if you could try this with a more recent version of apache.  2.0.41-dev is quite old. No response from submitter.  Assuming issue is resolved. This is a real bug, there's a fix in the mod_dav 1.0 tree which can be ported over. I suspect that the fix below is what is needed.  I haven't found the mod_dav 1.0 change yet, but I found this change entry:  'if a lock fails due to authentication problems, return a 403 (Forbidden) rather than 401 (Unauthorized). this fixes an HTTP conformance issue where we returned 401 but no WWW-Authenticate response header. (Joe Orton)'  I'm guessing this is Joe's fix...  patch to 2.0's mod_dav:  Index: util.c =================================================================== RCS file: /home/cvs/httpd-2.0/modules/dav/main/util.c,v retrieving revision 1.48 diff -u -r1.48 util.c --- util.c      22 Apr 2003 21:52:46 -0000      1.48 +++ util.c      11 Nov 2003 21:30:58 -0000 @@ -1212,7 +1212,7 @@                                              '/' submitted a locktoken created '                                              'by user /'',                                              lock->auth_user, '/'.', NULL); -                        return dav_new_error(p, HTTP_UNAUTHORIZED, 0, errmsg); +                        return dav_new_error(p, HTTP_FORBIDDEN, 0, errmsg);                      }                       /*  The fix I used was to copy over the www-auth header from the subrequest to the main request, I can dig it out... Committed to HEAD, proposed to backport to 2.0:  http://cvs.apache.org/viewcvs/httpd-2.0/modules/dav/main/mod_dav.c.diff?r1=1.100&r2=1.101  Thanks for the report.			Jeff Trawick	Joe Orton	Joshua Slive
15603	null	CLOSED		Ralf Hauser	1040543640000	1042131241000		' The http://www.thawte.com/certs/server/keygen/mod_ssl.html is no longer existing.	Thanks!  Fixed. Just checked the above URL again (since I am interested in what Thawte says) and I still get their 'You have followed a link to a page that the server can no longer find.' page. Docs changes don't instantantly appear on the website.  You need to have a little patience.  But I did just do an update for you, so you can find it now.  Of course, there are still some other dead links on that page.  Someone needs to do a really throrough rewrite of the ssl docs.			Joshua Slive	Ralf Hauser
15610	null	CLOSED		Bruno Wolff III	1040568900000	1040571482000		Typo in documenation In the mod_deflate documentation 'dependant' is used instead of 'dependent'. Unless this is a British spelling, this is a typo. For context: 'If you use some special exclusions dependant on, for example, the User-Agent header, you must manually configure an addition to the Vary header to alert proxies of the additional restrictions. For example,'	that happens, when a German trys to type English documentation... ;-)  Thanks for using Apache!			Andr?? Malo
15616	null	CLOSED		Jonatan	1040606340000	1040662124000		Hyperlink to cURL links to wrong address The Apache SSL FAQ mentions cURL and links to <http://curl.haxx.nu/>. That address will redirect your browser to <http://www.tetrapod.com/>, a web site completely unrelated to cURL. The correct URL for cURL is <http://curl.haxx.se/>.	Fixed in the next release.  Thanks reporting this and the other issues and thanks for using Apache 2.0!			Erik Abele
15627	null	CLOSED		Ralf Hauser	1040631060000	1042049803000		dead links to http://jya.com/wass-ch.htm (same for Germany) jya.com and www.jya.com no longer existing. The BAWI is now reorganized and became a department of the 'Staatssekretariat fuer Wirtschaft' (SECO) and you can find it directly under http://www.seco-admin.ch/e_index.html. I don't know which press release that site originally was referring to, but linking to original source hopefully will provide greater longevity of the URI-to-content-binding.	Thanks for your note.  That whole paragraph is no longer relevant since mod_ssl was incorporated into the Apache Software Foundation, so I deleted it.			Joshua Slive
15679	null	CLOSED		Seth W. Klein	1040974500000	1045449540000		configure broken if layout begins on first line of config.layout The configure script is broken if the selected layout begins on the first line of config.layout.  To reproduce:  cd httpd-2.0.43 mv config.layout config.layout.orig sed -n '13,34p' config.layout.orig | tee config.layout ./configure # the result is an exceedingly unobvious error from the APR sub configure # script which complains about '--bindir: NONE/bin' sed -n '12,34p' config.layout.orig | tee config.layout ./configure # works  This is with GNU Sed 4.0.4 which is relevent because the problem is with the sed program that configure uses to parse config.layout.  The following patch (which i will also attach, if the system lets me) fixes the problem for me.  --- acinclude.m4.orig\t2002-12-27 01:26:56.000000000 -0500 +++ acinclude.m4\t2002-12-27 01:27:28.000000000 -0500 @@ -275,7 +275,7 @@    fi    pldconf=./config.pld    changequote({,}) -  sed -e '1,/[ \t]*<[lL]ayout[ \t]*$2[ \t]*>[ \t]*/d' / +  sed -e '0,/[ \t]*<[lL]ayout[ \t]*$2[ \t]*>[ \t]*/d' /        -e '/[ \t]*<//Layout>[ \t]*/,$d' /        -e 's/^[ \t]*//g' /        -e 's/:[ \t]*/=/'/g' /  I am tempted to indulge in a rant about the wisdom of using configure args instead of weird config files in this situation but this bug report is hardly the place.  I will however indulge in a suggestion. Something like: if [ ! -s '$pldconf' ];then     echo '*** Error: unable to find layout /'$LAYOUT/''     exit 1 fi at the logical place would give a much clearer error message.	Created an attachment (id=4274) patch to acinclude.m4 to fix sed program used to parse config.layout  *** Bug 15678 has been marked as a duplicate of this bug. *** Adding the 0, causes the leading parts of the files to still be included.  I finally figured out what the  right sed invocation was and committed a fix.  httpd-2.0: acinclude.m4 r1.136, configure.in r1.244 apr: build/apr_common.m4: 1.52  Note that it is really unlikely that this will be backported to 2.0 though.  Thanks for using Apache HTTP Server!			Jeff Trawick	Justin Erenkrantz	Seth W. Klein
15713	null	CLOSED		Jeffrey Dwoskin	1041231540000	1043958871000		suexec-logfile has hardcoded default instead of being placed in --logfiledir If --with-suexec-logfile=FILE isn't specified in configure, the default is set by:    suexec.h:#define AP_LOG_EXEC '/usr/local/apache2/logs/cgi.log'  /* Need me? */ instead of suexec_log 'in your standard logfile directory (--logfiledir).' as specified in the documentation (http://httpd.apache.org/docs-2.0/suexec.html).  Therefor on my system where I chose a different prefix and logfile dir and /usr/local/apache2 does not exist, suexec does not function correctly (virtualhost cgi's give internal server errors) and (i think) userdir cgi's run as the apache user. Plus in the main server's error logs, we get:    failed to open log file    fopen: No such file or directory from suexec.c.  Again, this is only the default and the obvious workaround is to specify --with-suexec-logfile=FILE in configure.	This is fixed in cvs and will be in 2.0.45.  It will use your compiled-in apache log directory.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
15761	null	CLOSED		Thomas Linden	1041511140000	1044894804000		apache stops working after 260 requests I searched the bug database but could not find a similar entry.  My problem is as follows:  I am using FreeBSD 4.7. I compiled apache 2.0.43 out of the box (without any patches) with MPM set to 'prefork'. Compilation works and its also no problem to start the daemon.  After that I run siege (I used 'ab' as well as a self-written tool with identical results) on the apache. After 260 requests siege stopped working (it sleeped). I interrupted siege and tried it manually (telnet *.*.*.* 80 GET /). apache still responded to my connection and it did also deliver the / request. But it did not *close* the connection. I had to kill my telnet session.  My next try was to compile apache as MPM worker. For this to work correctly I applied the patches of the apache 2.0.43 freebsd-port. But the result is the very same. 260 requests are working then it stops closing connections.	For your prefork test, add --disable-threads to your configure invocation and try again, then report back whether or not it is still a problem.  make distclean && ./configure --disable-threads --whatever-else && make && make install  Anything thread-enabled with Apache or APR does not work reliably on FreeBSD.  Note that www.apache.org runs on FreeBSD 4.7 24x7 with no reliability problems. But it uses prefork MPM and --disable-threads.  In the meanwhile I found what has been the problem, and I can reproduce it:  In my config I had the following log-config entry:  CustomLog |/usr/bin/ipwebcollect accounting  The script '/usr/bin/ipwebcollect' did not exist during my tries. In the error log I found several (260 to be exact) entries that httpd could not find the program.  If I install the program or if I comment out the CustomLog line then the apache works as expected.  This behavior could be re-produced with proforker and worker (it seems to be the general behavior of apache, I think).   THe suggested fix would be to exit the httpd process if it cannot find a log pipe program, or ot could just de-activate the log-pipe if it does not exist or is not executable.   regards, Tom quick update: Apache hangs once the pipe to the logger fills in each child process. Apache 1.3 had the same problem, though something more helpful would be logged.  Some small improvement has been committed, but some infrastructure (APR) changes are in the works to improve it beyond the way it worked in Apache 1.3.  one question for you: You mentioned seeing the 260 error messages in the log.  I never saw messages in my testing prior to some changes I committed a couple of days ago.  Can you update the PR with the text of those messages please?  Thanks! Changes have been committed to Apache 2.1 (active development) to utilize new APR features for finding process creation errors on Unix.  These changes keep Apache from starting up if a piped log program doesn't exist or isn't executable. (There are some possible errors that are found out too late, but now they should result in an error message.)  I'll propose these changes for merging into Apache 2.0.x (stable tree).  Thanks for your report, and thanks for using Apache!  FYI...  the fix has been merged into the stable tree for inclusion in 2.0.45 *** Bug 17764 has been marked as a duplicate of this bug. ***			Jeff Trawick	Lone Wolf	Thomas Linden
15859	null	RESOLVED		Co-Advisor	1041973260000	1188648756000		wrong Content-Length header is forwarded when de-chunking Looks like a possible RFC 2616 MUST violation.  Apache decodes chunked encoding correctly but forwards wrong Content-Length header which now MUST be honored since Apache removed chunked encoding. Thus, the overall result is that a compliant client would see truncated content (e.g., $100 instead of $1000) because of how Apache changed the message it was forwarding.  See attached trace for details and ways to reproduce.  Test case IDs in the trace link to human-oriented test case description and RFC quotes, if available.	Created an attachment (id=4352) test case trace  Is the following sentence correct?  'A proxy MUST remove a Content-Length header from chunked responses, in case this content length header is wrong'.  Not exactly, but very close, IMO.  The proxy MUST ignore wrong Content-Length header in chunked responses (which is what Apache is probably doing). It would be OK to forward that header, provided that the proxy does not decode chunks on-the-fly. A compliant recipient would not have a problem handling such a response (chunked encoding with wrong Content-Length header).  However, Apache decodes chunks into 'normal' (identity) encoding and forwards the response with the original (wrong) Content-Length value. While there is no specific MUST about this case, the only logical interpretation or RFC 2616 suggests that the wrong Content-Length header must be removed. Otherwise, a compliant recipient will mis-interpret the response!  If you want a one sentence summary, I would say: 'A proxy has to remove the wrong Content-Length header when forwarding a chunked response using identity encoding (i.e., when de-chunking on-the-fly).'  The problem though is that we cannot know the Content-Length is wrong until we have processed the entire request. At this point we would have already sent the Content-Length header onwards, so it's too late to fix it if it is wrong - it would require the proxy to buffer the entire request before sending it on, which is not practical.  One possible thing to do though is to remove the Content-Length header should Apache decide to send chunked encoding. This needs to be done inside the filter responsible for chunking, rather than mod_proxy.  Thoughts?  The Content-Length header is _always_ wrong when it is used together with chunking because Content-Length header is defined to represent both entity-length and the transfer-length. It is not possible to represent both with a single value when chunking is used.  Thus, only two actions would be correct, IMO:    - leave wrong Content-Length header and do NOT de-chunk    - remove wrong Content-Length header  Note that there is no need to remove Content-Length header if Apache decides to send chunked encoding. It is de-chunking that causes the problem. Is this related to: <http://nagoya.apache.org/bugzilla/show_bug.cgi?id=21348>  If so, this bug breaks WindowsUpdate when used behind mod_proxy. Patch is linked in above bug that might be applicable. The WindowsUpdate patch you mentioned has no visible effect on this bug. Note that the patch seems to be designed to affect HEAD responses while this bug deals with GET responses.  *** Bug 31454 has been marked as a duplicate of this bug. *** *** Bug 11993 has been marked as a duplicate of this bug. *** I believe that this problem relates to proxying of _all_ requests with chunked request data, not just those with a bogus Content-Length.  mod_proxy is de-chunking and removing Transfer-Encoding: chunked, forwarding a request with neither Content-Length: or Transfer-Encoding: header. This causes the downstream server to reply with error 411 'Length Required'.  Bug 11618 has a network trace showing this clearly.  Since it is not possible to send a correct Content-Length header without buffering all request data, it seems to me that the proper fix is to not de-chunk if the original request is chunked?  I looked briefly in the function ap_proxy_http_request in proxy_http.c. How about if the original request uses chunked transfer-encoding, then the proxied request is also send as chunked? I could try to create a patch to add that to the code, it seems not too hard:      /* send the request data, if any. */     seen_eos = 0;     do {         status = ap_get_brigade(r->input_filters, bb, AP_MODE_READBYTES,                                 APR_BLOCK_READ, HUGE_STRING_LEN);          if (status != APR_SUCCESS) {             return status;         }          /* If this brigade contain EOS, either stop or remove it. */         if (APR_BUCKET_IS_EOS(APR_BRIGADE_LAST(bb))) {             /* As a shortcut, if this brigade is simply an EOS bucket,              * don't send anything down the filter chain.              */             if (APR_BUCKET_IS_EOS(APR_BRIGADE_FIRST(bb))) {                 break;             }              /* We can't pass this EOS to the output_filters. */             e = APR_BRIGADE_LAST(bb);             apr_bucket_delete(e);             seen_eos = 1;         }          e = apr_bucket_flush_create(c->bucket_alloc);         APR_BRIGADE_INSERT_TAIL(bb, e);          status = ap_pass_brigade(origin->output_filters, bb);         if (status != APR_SUCCESS) {             ap_log_error(APLOG_MARK, APLOG_ERR, status, r->server,                          'proxy: pass request data failed to %pI (%s)',                          p_conn->addr, p_conn->name);             return status;         }         apr_brigade_cleanup(bb);     } while (!seen_eos);  You do not need to code it as httpd-2.1 has it already fixed. I also backported it in the patch of Bug 31454 which was apparently a DUPE, you can repost the patch here if you wish. I am using my patch on my server for: Fedora Core 3 httpd-2.0.52-3.1  I've been working on some improvements to the current solution in Apache 2.1.  A backport of my current 2.0 code is in a patch at http://www.apache.org/~trawick/20proxyreqbody.txt The version of this for Apache 2.1-dev is in the proxy-reqbody branch in subversion. . Any comments or additional testing would be appreciated.  The current version of http://www.apache.org/~trawick/20proxyreqbody.txt successfully tested on SonyEricsson P900 (sorry for the response time as I do not have the device available). <bite>Patch version-name change on its content change would be preferred.</bite>  >Patch version-name change on its content change would be preferred.  good idea for the future...  and thanks for the test report!  I assume that some type of upload from the phone would not work through mod_proxy without this patch???? SonyEricsson P900 uses buzzword WAP-2.0 which no longer transfers WAP/WML over WSP/WTP protocols but it started using HTTP/TCP. P900 will interpret WAP-1.x WAP gateway settings sent over SMS as HTTP proxy for its WAP-2.0 (IMO incorrectly). During MMS send operation P900 will send chunked POST, current mod_proxy will dechunk it but it will not fill in the Content-Length making the final head+body POST request combo invalid. See (I could no longer find the TCP snaps): http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=109186315924289  fix committed to 2.0.next Created an attachment (id=15295) fresh test trace  Sorry, but the current http://www.apache.org/~trawick/20proxyreqbody.txt fix does not solve the problem. Patched Apache httpd-2.0.54 is still sending     Content-Length: 15 when the [dechunked] content is actually 20 bytes.  Please see the attached fresh trace. Are we testing with the wrong fix?  I am taking the liberty of reopening this bug because the test case still fails (see above).  btw, the proxy-reqbody patch did not affect the response processing...  any idea what is required to have the origin server send both Content-Length *and*  Transfer-Encoding?  Sending both would violate 2616, if the proxy receives a message with both C-L and T-E it MUST ignore the C-L header per comment 3. Created an attachment (id=16218) security fix for C-L vs T-E handling (Joe Orton, CVE CAN-2005-2088)  Just FYI Joe Orton fixed: Fedora Core Bug: https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=162245 , the same as Red Hat Enterprise Bug: https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=162244 but unfortunately these patches will disable the funtionality of: http://www.apache.org/~trawick/20proxyreqbody.txt as presented here in Comment #17 . Reverting its first part restores 20proxyreqbody.txt back as WORKSFORME, Not sure if its second part resolves the issue of Comment #17 .  Is this still open?  It appears to be fixed in trunk at least. OK, tested in 2.2.5; the proxy removes the Content-Length.			Co-Advisor	Cymen Vig	Graham Leggett	Jan Kratochvil	Jeff Trawick	Joe Orton	Kristian Nielsen	Nick Kew
15993	null	RESOLVED		Detlev Vendt	1042284180000	1150964987000		HSE_REQ_MAP_URL_TO_PATH returns slashes instead of backslashes Using ISAPI ServerSupportFunction with the above constant works incorrectly if used in a virtual directory that is not located in the Apache document root  directory.  Example: Assume to have a virtual directory mapped to d:/westwind/wconnect.  If I have a script that references /wconnect ServerSupportFunction returns:  d:/program files/apache group/apache/htdocs/wconnect/  It should return:  d:/westwind/wconnect  The reason for that behavior seems to be, that the core handler resolves the  directory as a part of the document root. All other handlers (in fact mod_alias  should do this) will not have a chance to do a correct mapping.	   This may be trivial.  If you  Alias /foo c:/somepath/foo  the request /foo   will map to c:/somepath/foo, but if you  Alias /foo/ c:/somepath/foo/     (or you have unbalanced trailing slashes - that is, if the virtual path has   a trailing slash the target path must have one as well...) then the request   /foo  (or a request to map the url to that path) will fail because that   alias '/foo/' can't evaluate the shorter path '/foo'.   Thanks to Will Rowe for that hint - it works so far. A little ugly behaviour is  still there: mod_isapi puts a trailing backslash to the end of the path. With      ScriptAlias /foo/ 'c:/myfiles/foo/'  mod_isapi returns the translation      c:/myfiles/foo//  To substitute all slashes by backslashes will be a completely correct behaviour  with Win32 - including to avoid a double backslash at the end.     Note that the trailing backslash is due to the fact that there wasn't a trailing   backslash already.  Correcting the path to backslashes first will assure that   doubled-trailing slashes don't occur.     Think that we've squished this in commit 416291, but it will still not   backslash format the filename string.    Commit 416294 changes the order a bit, appends the slash first only if   it's needed, and then normalizes Win32 paths to backslash.  However,   it's platform neutral and will not normalize the path on Unix etc.    We also pay more attention to the fact that PATH_INFO is the rest of   the file path that didn't corespond to a disk file, and append it.  Whoops, closing.  See  http://svn.apache.org/viewvc/httpd/httpd/trunk/modules/arch/win32/mod_isapi.c  to obtain the source Will Rowe has posted a zipfile containing compiled mod_isapi modules which include the patch correcting this bug (for use with 2.0.58 and 2.2.2), for testing purposes. It is available at:  http://people.apache.org/~wrowe/mod_isapi-416293.zip  You may read his full email to the dev@httpd.apache.org list here:  http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=115206683718140&w=2  If you test this version of mod_isapi, please post your feedback to the dev@httpd.apache.org list. Your feedback will help ensure that there are no regressions or other issues in this version of mod_isapi.			Detlev Vendt	Matt Lewandowsky	Will Rowe
16046	null	CLOSED		Dmitri Dmitrienko	1042507200000	1045457344000		Memory leak Memory leak ~ 8k occurs every time I run PROPFIND webdav method when  mod_deflate is activated, e.g. if client issued Accept-Encode: gzip header. PROPFIND was used against a quite big directory (~400files) and the responce  stream was ~ 400kB (after de-compression). Problem does not appear if either mod_deflate is not loaded or if 'Accept- Encode: gzip' is not used.  Following configuration directives are in my httpd.conf:  #stripped off common top LoadModule deflate_module modules/mod_deflate.so NameVirtualHost localhost:80 NameVirtualHost localhost:801 <VirtualHost localhost:80> </VirtualHost> <VirtualHost localhost:801>  DAVLockDB logs/DavLock <Directory 'D:/apa2_0_43/htdocs'>     SetInputFilter DEFLATE     SetOutputFilter DEFLATE     DAV On     <Limit PUT POST DELETE PROPFIND PROPPATCH MKCOL COPY MOVE LOCK UNLOCK>         AuthName             'Fx'         AuthType             Basic         AuthUserFile         logs/passw         Require user dmitri     </Limit> </Directory> </VirtualHost>	A memory leak was fixed after 2.0.43.  Please download the latest mod_deflate (from http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/filters/mod_deflate.c) or wait for 2.0.44, then report back.  Thanks!  I've checked. Yes indeed the bug went away.  But please don't close it immediately. By learning sources I see that there  are some conditions when some additional leaks may occur again. mod_deflate does not always make a paired call to inflateEnd() after  inflateInit2() was called. It make a big concern that the leak can be  reproduced with for example a trimmed compressed part. Remember that after inflateInit2() was called zlib may allocate up to  256kb of memory and releases all in inflateEnd() only.  I checked with a 'trimmed' (e.g. wrong) compressed request. As expected Apache gets HTTP/1.1 400. But as predicted a memory leak occurs  too. Approx. 48kB for a request.  Conditions: mod_deflate mod_dav mod_dav_fs installed. PROPFIND request made with Content-encoding: gzip and content is too short  (trimmed) for example just 11 bytes. Gzipped content can never be less than 18  bytes:  #####Headers:  PROPFIND / HTTP/1.1 Content-Encoding: gzip Content-Type: text/xml; charset='utf-8' Content-Length: 11 Host: localhost:801 Accept: text/html, */* Accept-Encoding: gzip User-Agent: Mozilla/3.0 (compatible; DD Library) Depth: 1  #####Content - gzipped but trimmed, hex dump 0x1F 0x8B 0x08 0x00 0x00 0x00 0x00 0x00 0x00 0x0B 0xB3    My investigation showed that a call to inflateEnd() is missed. Occurs when  conditions above are met.  Should be fixed in modules/filters/mod_deflate.c r1.30  Thanks for using Apache HTTP Server!			Dmitri Dmitrienko	Jeff Trawick	Justin Erenkrantz
16134	null	CLOSED		Dmitri Dmitrienko	1042661940000	1045462590000		mod_deflate may lead to HTTP/1.1 400 responce when a request is absolutely correct When following conditions are met, mod_deflate (as a filter) does not  propagate EOS to the upper level and leads to WRONG REQUEST (HTTP 400)  responce. 1. enable mod_dav, mod_dav_fs, mod_deflate 2. compression is enabled for both - input and output 3. client sends PROPFIND HTTP/1.1 request with Content-Encoding: gzip header  and a properly gzip'ed xml content.  Example of httpd.conf: ###httpd.conf BEGIN ... skipped all common options ...  LoadModule deflate_module modules/mod_deflate.so NameVirtualHost localhost:80 NameVirtualHost localhost:801 <VirtualHost localhost:80> </VirtualHost> <VirtualHost localhost:801>     DAVLockDB logs/DavLock     <Directory 'D:/apa2_0_43_15JAN03/Debug/htdocs'>       SetInputFilter DEFLATE       SetOutputFilter DEFLATE       DAV On       <Limit PUT POST DELETE PROPFIND PROPPATCH MKCOL COPY MOVE LOCK UNLOCK>         AuthName             'Foo'         AuthType             Basic         AuthUserFile         logs/passw         Require user dmitri       </Limit>     </Directory> </VirtualHost>  ###httpd.conf END  My investigation showed that the trouble is in xml_util.c and mod_delate.c  files. First requires data until a len=0 (normal condition) or len<0 (error)  returned while the second never returns EOS and as a result len is never 0.  See mod_deflate.c:662:             /* If we actually see the EOS, that means we screwed up! */             if (APR_BUCKET_IS_EOS(bkt)) {                 return APR_EGENERAL;             }  I propose a patch that works:  --- mod_deflate.c~\t2003-01-03 02:12:36.000000000 +0300 +++ mod_deflate.c\t2003-01-15 23:15:38.000000000 +0300 @@ -648,6 +648,15 @@          apr_brigade_cleanup(ctx->bb);      }   +    if (APR_BUCKET_IS_EOS(APR_BRIGADE_FIRST(ctx->bb))) { +        apr_bucket *eos; + +        apr_brigade_cleanup(ctx->bb); +        eos = apr_bucket_eos_create(f->c->bucket_alloc); +        APR_BRIGADE_INSERT_TAIL(bb, eos);  +        return APR_SUCCESS; +\t} +      if (APR_BRIGADE_EMPTY(ctx->proc_bb)) {          rv = ap_get_brigade(f->next, ctx->bb, mode, block, readbytes);    I'm not sure that it's absolutely correct and it needs to be reviewed by  somebody who knows Apache2 architecture better.	Once again the proposed patch agains the most recent version of mod_deflate.c:  --- mod_deflate.c~\t2003-01-03 02:12:36.000000000 +0300 +++ mod_deflate.c\t2003-01-15 23:31:04.000000000 +0300 @@ -557,7 +557,7 @@      int zRC;      apr_status_t rv;      deflate_filter_config *c; - +      /* just get out of the way of things we don't want. */      if (mode != AP_MODE_READBYTES) {          return ap_get_brigade(f->next, bb, mode, block, readbytes); @@ -655,6 +655,15 @@              return rv;          }   +\t\tif (APR_BUCKET_IS_EOS(APR_BRIGADE_FIRST(ctx->bb))) { +\t\t\tapr_bucket *eos; + +\t\t\tapr_brigade_cleanup(ctx->bb); +\t\t\teos = apr_bucket_eos_create(f->c->bucket_alloc); +\t\t\tAPR_BRIGADE_INSERT_TAIL(bb, eos);  +\t\t\treturn APR_SUCCESS; +\t\t} +          APR_BRIGADE_FOREACH(bkt, ctx->bb) {              const char *data;              apr_size_t len;  Changed how ap_xml_parse_input works in server/util_xml.c r1.22 so that it realizes when EOS is sent.  I've proposed this to be backported to the next stable release.  Thanks for using Apache HTTP Server!			Dmitri Dmitrienko	Justin Erenkrantz
16261	null	CLOSED		Laurent Faillie	1043077560000	1043219573000		mod_auth_ldap documentation is wrong when using space in name. Hi all,  My web server is runing under an HP-UX 10.20 workstation (but I think it's the  same w/ other OS).  The documentation says we must following syntaxe if username have space in it :  require user Barbara Jenson  It doesn't work because Apache try to grand access to user w/ name 'Barbara' or  'Jenson'. To make it work, I have to enclose the name in double cote like :  require user 'laurent faillie'  Same problem w/ use of a redundant LDAP server :       AuthLDAPURL ldap://ldap1.airius.com ldap2.airius.com/ou=People, o=Airius      require valid-user  I have to use double cote around LDAP URL :  AuthLDAPURL 'ldap://ldap2.sgp.st.com ldap1.sgp.st.com/ou=People'  or I got a misconfiguration error.	Docs updated to v2.0.45-dev and v2.1.0-dev.			Graham Leggett
16313	null	CLOSED		John Kearns	1043205180000	1043279511000		Multiple MMapFile causes Segmentation fault Specifying more than one file with the MMapFile configuration command causes  httpd to core dump with a Segmentation fault.  Problem did not happen in 2.0.43.  Some debug of the code with gdb shows that mmap_cleanup (mmap.c) is called with  a *themap with it's next and prev pointers set to NULL, causing APR_RING_REMOVE  to fail.  Tested with MMapFile commands: MMapFile /usr/local/apache/htdocs/apache_pb2.gif MMapFile /usr/local/apache/htdocs/apache_pb2.png (also segfaults if both files specified with one MMapFile command)  Here is the gdb dump:  (gdb) r -DONE_PROCESS Starting program: /usr/local/apache/bin/httpd -DONE_PROCESS [New Thread 1024 (LWP 19351)]  Program received signal SIGSEGV, Segmentation fault. [Switching to Thread 1024 (LWP 19351)] 0x400fca8d in mmap_cleanup (themmap=0x80e6340) at mmap.c:90 90          APR_RING_REMOVE(mm,link); (gdb) where #0  0x400fca8d in mmap_cleanup (themmap=0x80e6340) at mmap.c:90 #1  0x400fe986 in apr_pool_cleanup_run (p=0x80a8ef0, data=0x80e6340,  cleanup_fn=0x400fca58 <mmap_cleanup>) at apr_pools.c:1967 #2  0x400fccee in apr_mmap_delete (mm=0x80e6340) at mmap.c:195 #3  0x402ce2a2 in cleanup_file_cache (sconfv=0x80d7870) at mod_file_cache.c:177 #4  0x400fe9c7 in run_cleanups (cref=0x80a8f00) at apr_pools.c:1976 #5  0x400fde3f in apr_pool_clear (pool=0x80a8ef0) at apr_pools.c:718 #6  0x08071d08 in main (argc=2, argv=0xbffffb04) at main.c:608 #7  0x401a0657 in __libc_start_main (main=0x80715fc <main>, argc=2,  ubp_av=0xbffffb04, init=0x80609c4 <_init>,      fini=0x80917a0 <_fini>, rtld_fini=0x4000dcd4 <_dl_fini>,  stack_end=0xbffffafc) at ../sysdeps/generic/libc-start.c:129	 aawwwww mannnnnnnnnn.  :(  That would be my fault.  Sheesh.  I'll look into  it.  Thanks for the report and the backtrace!  Try the patch given in   http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=104321419500550&w=2 and see  if that fixes it for you.  Assuming it stops crashing, try some server restarts  and make sure you don't get any memory or file descriptor leaks.    Thanks,  Cliff  Tried the patch...it works just fine. Out of interest though, instead of (or also with) deleting the section of code  that calls the APR_RING_REMOVE define, why not just add error-checking into the  APR_RING_UNSPLICE define with a couple of 'if' statements in apr_ring.h? Example:  #define APR_RING_UNSPLICE(ep1, epN, link) do {                          /         if (APR_RING_PREV((ep1), link))                                 /                 APR_RING_NEXT(APR_RING_PREV((ep1), link), link) =       /                         APR_RING_NEXT((epN), link);                     /         if (APR_RING_NEXT((epN), link))                                 /                 APR_RING_PREV(APR_RING_NEXT((epN), link), link) =       /                         APR_RING_PREV((ep1), link);                     /    } while (0)  I tested this modification with the original mod_file_cache.c and it seems to  work as well.  Although, truth be told, I'm not entirely sure how to find out  if it has memory or fd leaks (I program mainly on win32...unix still mystifies  me at times!)  The only reason I'd suggest this is to keep this same problem  happening in potential future modules that register a cleanup call for a  simular list.  Thanks- Drew  It's a design decision we made through all of APR: we don't test for NULL.  If it's NULL, that's a bug, and it will cause a segfault.  If it segfaults, that's good, because it lets us find the bug very easily.  Another concern is that code with no bugs will never have those pointers be NULL, so non-buggy code would be paying a performance penalty just to accommodate buggy code.  Thanks for testing the patch.  I'll look for leaks myself.  --Cliff  Heh..makes sense!  Thanks for quick fix on this. Looking forward to the next release! -Drew			Cliff Woolley	John Kearns
16368	null	CLOSED		andre breiler	1043337900000	1045602082000		LoadModule order for mod_proxy and mod_rewrite It seems that some strange side effects happen if mod_rewrite is loaded before mod_proxy.  I have the following in the httpd.conf: --- snip --- LoadModule rewrite_module modules/mod_rewrite.so LoadModule proxy_module modules/mod_proxy.so --- snap ---  and the following in an .htaccess (cgi-perl/.htaccess): --- snip --- RewriteEngine   On RewriteRule     (.*)    http://192.168.111.111:8080/no/$1 [P] --- snap ---  which produces an unexptected result for the request:  http://127.0.0.1/cgi-perl/blah?world=reboot . It sends an request   http://192.168.111.111:8080/no/blah%3Fworld=reboot?world=reboot .  The the two LoadModule lines are exchanged so that mod_proxy is before mod_rewrite it works as expcted (request  http://192.168.111.111:8080/no/blah?world=reboot is sent).  I don't know if this is really an bug or intended (I see it a bit as bug).	   This is a bug, in that the Apache 2.0 hook mechanisms were designed to be   independent of LoadModule order.  That said, we are sure to find a few edge   cases like the one you've identified.    Thanks for the report!  hmm, it looks like the fixup hooks of mod_rewrite and mod_proxy create the problem (both HOOK_FIRST).  first case: mod_rewrite runs first: create r->filename=proxy:http://foo/bar?baz mod_proxy runs afterwards: enode that url and append query (again): http://foo/bar%3Fbaz?baz -> proxy handler runs with the result  second case: mod_proxy fixup runs empty (no proxy request) mod_rewrite creates r->filename=proxy:http://foo/bar?baz -> proxy handler runs with the result.  We can solve this for now by hooking mod_proxy fixup explicitely before mod_rewrite. But AFAICS we need some further research to handle all the proxy stuff more clean.  Opinions? Been there, done that. It's fixed in HEAD (2.1) and proposed for backport.  Thanks for using Apache! The fix will appear in the next release (2.0.45).			Andr?? Malo	Will Rowe
16452	null	CLOSED		Julian Reschke	1043677920000	1043817360000		If header only accepts state tokens that match mod_davs lock token format Supplying a lock token which uses a format which is not known to moddav (and therefore can't possibly represent an existing lock) causes the If header validation to fail with 400 Bad Request.   Error.log shows:  The lock token uses an unknown State-token format and could not be parsed.  [400, #403]  Instead this part of the expression should just evaluate to false, and If header processing should continue. For instance, for a resource with lock token 'opaquelocktoken:8aeb4384-04ee-8042-bd51-d18cc4a34143', a PUT request with the following If header should suceed:  (<opaquelocktoken:8aeb4384-04ee-8042-bd51-d18cc4a34143>) (Not <DAV:no-lock>)  (note that 'DAV:no-lock' is a well-formed URI that provably does not represent any existing lock, so 'Not<DAV:no-lock>' should evaluate TRUE.	Fixed in modules/dav/main/util.c r1.43 of httpd-2.0.  We will now skip all lock tokens that are denoted as invalid format.  This patch has been suggested for inclusion in the next httpd 2.0 release.  Thanks for using Apache HTTP Server!			Justin Erenkrantz
16533	null	CLOSED		Gerard Eviston	1043833740000	1043863748000		child segfaults when servicing a request, in apr_pool_cleanup_kill Apologies if this has already been reported / fixed.  [Wed Jan 29 15:11:09 2003] [notice] child pid 44946 exit signal Segmentation fault (11) [Wed Jan 29 15:11:12 2003] [notice] child pid 52174 exit signal Segmentation fault (11)  (dbx) where apr_pool_cleanup_kill(p = 0x3c68746d6c3e0a3c, data = 0x00000001102e5880, cleanup_fn = 0x09001000a02074c8), line 1926 in 'apr_pools.c' mmap_bucket_destroy(data = 0x00000001102e5880), line 99 in 'apr_buckets_mmap.c' mmap_bucket_setaside(b = 0x00000001102dea18, p = 0x00000001102ea8b8), line 167 in 'apr_buckets_mmap.c' ap_save_brigade(f = 0x00000001102dcfe8, saveto = 0x00000001102dd058, b = 0x0ffffffffffff1d8, p = 0x00000001102ea8b8), line 560 in 'util_filter.c' unnamed block $b319, line 3932 in 'core.c' core_output_filter(f = 0x00000001102dcfe8, b = 0x00000001102ea920), line 3932 in 'core.c' unnamed block $b263, line 540 in 'util_filter.c' ap_pass_brigade(next = 0x00000001102dcfe8, bb = 0x00000001102e54b8), line 540 in 'util_filter.c' ap_http_header_filter(f = 0x00000001102e1bc8, b = 0x00000001102e54b8), line 1716 in 'http_protocol.c' unnamed block $b263, line 540 in 'util_filter.c' ap_pass_brigade(next = 0x00000001102e1bc8, bb = 0x00000001102e54b8), line 540 in 'util_filter.c' ap_content_length_filter(0x1, 0x78280), line 1299 in 'protocol.c' unnamed block $b263, line 540 in 'util_filter.c' ap_pass_brigade(next = 0x00000001102e1ba0, bb = 0x00000001102e54b8), line 540 in 'util_filter.c' unnamed block $b125, line 2881 in 'http_protocol.c' ap_byterange_filter(f = 0x00000001102e1b78, bb = 0x00000001102e54b8), line 2881 in 'http_protocol.c' unnamed block $b263, line 540 in 'util_filter.c' ap_pass_brigade(next = 0x00000001102e1b78, bb = 0x00000001102e54b8), line 540 in 'util_filter.c' default_handler(r = 0x00000001102e0880), line 3384 in 'core.c' ap_run_handler(0x0), line 194 in 'config.c' ap_invoke_handler(0x0), line 401 in 'config.c' ap_process_request(0x0), line 288 in 'http_request.c' ap_process_http_connection(0x1), line 293 in 'http_core.c' ap_run_process_connection(0x1), line 85 in 'connection.c' ap_process_connection(0x0, 0x0), line 207 in 'connection.c' child_main(child_num_arg = 2), line 696 in 'prefork.c' make_child(s = 0x000000011022a168, slot = 2), line 790 in 'prefork.c' perform_idle_server_maintenance(p = 0x00000001102263b8), line 925 in 'prefork.c' ap_mpm_run(_pconf = 0x00000001102263b8, plog = 0x0000000110252678, s = 0x000000011022a168), line 1120 in 'prefork.c' main(argc = 3, argv = 0x00000000200fe8d0), line 651 in 'main.c' (dbx)  Interesting argument p = 0x3c68746d6c3e0a3c = '<html>/n<' :-)  I managed to fix the coredumps by patching like so, but it does seem a little too simple to be correct.  *** apr_buckets_mmap.c  Wed Jan 29 17:59:09 2003 --- apr_buckets_mmap.c.orig     Wed Jan 29 17:58:50 2003 *************** *** 164,170 ****       }        /* decrement refcount on old apr_bucket_mmap */ !     mmap_bucket_destroy(m);        /* create new apr_bucket_mmap pointing to new apr_mmap_t */       apr_bucket_mmap_make(b, new_mm, b->start, b->length); --- 164,170 ----       }        /* decrement refcount on old apr_bucket_mmap */ !     mmap_bucket_destroy(mm);        /* create new apr_bucket_mmap pointing to new apr_mmap_t */       apr_bucket_mmap_make(b, new_mm, b->start, b->length);	Ouch!!!!  Yes that's a very big bug.  void* killed me on that one.  :-/  Thanks for the great catch  and for the patch!  It's now committed to 2.1.0-dev and will be suggested for inclusion in  2.0.45.    --Cliff 			Cliff Woolley
16637	null	RESOLVED		Laimutis Ignatavicius	1044018840000	1150958817000		ISAPI: HTTP 200 OK error response is still returned Thank you for fixing the Bug#: 10216 in version 2.0.44. It stopped displaying  HTTP 200 OK error response in very most cases.  But there is one more case when this 'error' response is displayed: when ISAPI  extension does not include any HTTP header in it response.   We traced mod_isapi.c and found such a situation:  1. ISAPI extension calls ServerSupportFunction with '200 OK' in buf_data  parameter, 0 in buf_size parameter, and pointer to a 'null-terminated string  pointing to optional headers or data to be appended and sent with the header'  (excerpt from Microsoft MFC Library Reference) in data_type parameter.  2. ServerSupportFunction calls send_response_header function, and it returns  at line 795:      /* If only Status was passed, we consumed nothing       */     if (!head_present)         return 0;             /* <- line 795 */      cid->headers_set = 1;     /* <- line 797 */  3. Line 797, added in version 2.0.44, is not entered, and bug fix code, added  for correcting the buggy '200 OK' response, is not entered (line 1597). Line  1595 returns the value 200, causing the result to run through the core die  handler:      /* Flush the response now, including headers-only responses */     if (cid->headers_set) { <...>         cid->response_sent = 1;          return OK;  /* NOT r->status or cid->r->status, even if it has  changed. */     }          /* As the client returned no error, and if we did not error out      * ourselves, trust dwHttpStatusCode to say something relevant.      */     if (!ap_is_HTTP_SERVER_ERROR(r->status) && cid->ecb->dwHttpStatusCode) {         r->status = cid->ecb->dwHttpStatusCode;     }      /* For all missing-response situations simply return the status.      * and let the core deal respond to the client.      */     return r->status; /* <- line 1595 */   Recommendations for solving the problem: move code line 797 four lines above.   Another minor problem, considering the same bug-fix code added, is that HTTP  status code 200 is not logged in 'access.log' for all successful calls of an  ISAPI extension, with exception to the problem described above. These  responses are logged normally. :-)  Recommendations for solving problem: insert one line of code in mod_isapi.c,  line 1582:          r->status = cid->ecb->dwHttpStatusCode; /* <- line 1582 */          return OK;  /* NOT r->status or cid->r->status, even if it has  changed. */	   Actually, there was a small logic error related to the way that some   calls were processed in send_response_header.  We believe the new code   is cleaner, but it may or may not resolve your issue altogether.    If you are building Apache yourself, please replace your mod_isapi.c module   with the current CVS available from;  http://cvs.apache.org/viewcvs.cgi/*checkout*/httpd-2.0/modules/arch/win32/mod_isapi.c?rev=1.88.2.2    And let us know if the error remains.  I suspect it does.    One thing you mention is that we call from ServerSupportFunction() ... in   fact we have several potential calls from that code - please identify which   call to ServerSupportFunction is't working.    I guess that sending any body, whatsoever should toggle cid->headers_set to   1 so that everything else works.    Let me make certain; are you trying to send a response 200 OK with *no*   headers, *AND* no body?     Closed 30033, presuming fixed in trunk.  Will Rowe has posted a zipfile containing compiled mod_isapi modules which include the patch correcting this bug (for use with 2.0.58 and 2.2.2), for testing purposes. It is available at:  http://people.apache.org/~wrowe/mod_isapi-416293.zip  You may read his full email to the dev@httpd.apache.org list here:  http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=115206683718140&w=2  If you test this version of mod_isapi, please post your feedback to the dev@httpd.apache.org list. Your feedback will help ensure that there are no regressions or other issues in this version of mod_isapi. *** Bug 40067 has been marked as a duplicate of this bug. ***			Matt Lewandowsky	Will Rowe
16656	null	CLOSED		Olivier Cahagne	1044051660000	1044200294000		 table for english vhosts doc On URL: http://httpd.apache.org/docs-2.0/vhosts/ (or http://httpd.apache.org/docs-2.0/vhosts/index.html.en if another language is set on your browser)  There's a table on the right 'See Also' which last link is called 'Detalis of host matching'. Should be 'Details of host matching'.  Also in current CVS: http://cvs.apache.org/viewcvs.cgi/httpd-docs-2.0/manual/vhosts/index.html.en	Fixed, thanks for reporting the issue and using Apache 2.0!			Erik Abele
16661	null	CLOSED		Manni Wood	1044058740000	1064356740000		use of strstr() in spot_cookie() mis-identifies cookies in other cookie names or cookie values Example: If you have CookieName set to 'ID', then use of strstr() in spot_cookie() mod_usertrack.c will get false positives on the following sorts of cookies: 'MyID=binky', 'MyCookie=IDExpired'. This follows up bugs 11998, 8906, 8048, 5811, and probably others. This bug keeps getting submitted. Here is a patch that has been thoroughly tested (more details at http://www.manniwood.net/mod_usertrack_patch.html):  --- mod_usertrack.c\t2002-03-13 16:05:34.000000000 -0500 +++ mod_usertrack_1.3_fixed.c\t2003-01-31 12:10:46.000000000 -0500 @@ -119,6 +119,8 @@      cookie_type_e style;      char *cookie_name;      char *cookie_domain; +    char *regexp_string;  /* used to compile regexp; save for debugging */ +    regex_t *regexp;  /* used to find usertrack cookie in cookie header */  } cookie_dir_rec;    /* Define this to allow post-2000 cookies. Cookies use two-digit dates, @@ -250,31 +252,44 @@  {      cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config,  \t\t\t\t\t\t&usertrack_module); -    const char *cookie; -    char *value; +    const char *cookie_header; + +    /* There are only three possibilities from the regexp +     * ^cookie_name=([^;]+)|;[ /t]+cookie_name=([^;]+) +     * because $0 is always filled with the whole match, and $1 and $2 will +     * be filled with either of the parenthesis matches. So, I  +     * allocate regm[3] to cover all these cases. */ +    regmatch_t regm[3]; +    int i;        if (!dcfg->enabled) {          return DECLINED;      }   -    if ((cookie = ap_table_get(r->headers_in, -                               (dcfg->style == CT_COOKIE2 -                                ? 'Cookie2' -                                : 'Cookie')))) -        if ((value = strstr(cookie, dcfg->cookie_name))) { -            char *cookiebuf, *cookieend; - -            value += strlen(dcfg->cookie_name) + 1;  /* Skip over the '=' */ -            cookiebuf = ap_pstrdup(r->pool, value); -            cookieend = strchr(cookiebuf, ';'); -            if (cookieend) -                *cookieend = '/0';      /* Ignore anything after a ; */ - -            /* Set the cookie in a note, for logging */ -            ap_table_setn(r->notes, 'cookie', cookiebuf); +    if ((cookie_header = ap_table_get(r->headers_in, +                                      (dcfg->style == CT_COOKIE2 +                                       ? 'Cookie2' +                                       : 'Cookie')))) { +\tif (!ap_regexec(dcfg->regexp, cookie_header, dcfg->regexp->re_nsub + 1, regm, 0)) { +\t    char *cookieval = NULL; +\t    /* Our regexp, +\t     * ^cookie_name=([^;]+)|;[ /t]+cookie_name=([^;]+) +\t     * only allows for $1 or $2 to be available. ($0 is always +\t     * filled with the entire matched expression, not just +\t     * the part in parentheses.) So just check for either one +\t     * and assign to cookieval if present. */ +\t    if (regm[1].rm_so != -1) { +\t\tcookieval = ap_pregsub(r->pool, '$1', cookie_header, dcfg->regexp->re_nsub + 1, regm); +\t    } +\t    if (regm[2].rm_so != -1) { +\t\tcookieval = ap_pregsub(r->pool, '$2', cookie_header, dcfg->regexp->re_nsub + 1, regm); +\t    } +\t    /* Set the cookie in a note, for logging */ +\t    ap_table_setn(r->notes, 'cookie', cookieval);   -            return DECLINED;    /* There's already a cookie, no new one */ -        } +\t    return DECLINED;    /* There's already a cookie, no new one */ +\t} +    }      make_cookie(r);      return OK;                  /* We set our cookie */  } @@ -382,7 +397,20 @@  {      cookie_dir_rec *dcfg = (cookie_dir_rec *) mconfig;   +    /* The goal is to end up with this regexp,  +     * ^cookie_name=([^;]+)|;[ /t]+cookie_name=([^;]+) +     * with cookie_name +     * obviously substituted with the real cookie name set by the +     * user in httpd.conf. */ +    dcfg->regexp_string = ap_pstrcat(cmd->pool, '^', name, '=([^;]+)|;[ /t]+', name, '=([^;]+)', NULL); +      dcfg->cookie_name = ap_pstrdup(cmd->pool, name); + +    dcfg->regexp = ap_pregcomp(cmd->pool, dcfg->regexp_string, REG_EXTENDED); +    if (dcfg->regexp == NULL) { +\treturn 'Regular expression could not be compiled.'; +    } +      return NULL;  }	Created an attachment (id=4674) patch for spot_cookie() bug in mod_usertrack  *** Bug 11998 has been marked as a duplicate of this bug. *** *** Bug 16662 has been marked as a duplicate of this bug. *** Fixed in 2.1.0-dev, thanks Manni.  Backports to 2.0-dev and 1.3-dev will be  proposed. 			Cliff Woolley	Manni Wood
16739	null	CLOSED		Laurent Faillie	1044315960000	1045231927000		Problem w/ IPv4 when system can also use IPv6 Hi all,  I'm using Apache 2.0.44 on a old Sun Sparc Station 5 under NetBSD 1.6. I think, there is no problem on this server as another Apache 1.3.26 is running on an other port w/o troubles.   This station has 2 ethernets card :  - 1 connected to my internal network w/ a fixed address (192.168.0.3), - 1 connected to a cable modem binding to a dynamicaly address allocated by my ISP DHCP server.  My problem is I can't access to this web server if I haven't specified the address in the Listen directive.  For example : If I use 'Listen 8085', only telnet localhost 8085 succeed. Connection from other machine fails w/ 'Connection refused' error.  If I use 'Listen 192.168.0.3:8085', I can connect from a machine on my own network but a telnet fails : telnet localhost 8085 Trying ::1... telnet: connect to address ::1: Connection refused Trying 127.0.0.1... telnet: Unable to connect to remote host: Connection refused  A simple workaround should be to use some Listen directive, but I will be difficult w/ DHCP address. Any help welcome ;-D  Rgds,  Laurent	According to 'netstat', it seems Apache2 only listening IPv6 networks on my system. I will try to add option '--enable-v4-mapped'.  Anyway, as the documentation said 'Listen w/o network make apache waiting for all network', it should implie both v4 and v6 by default. Using '--enable-v4-mapped', I can now connect to the machine ... but no data is sent :-(  telnet ra 8085 Trying 192.168.0.3... Connected to ra.chez.moi. Escape character is '^]'. GET / Connection closed by foreign host.  Any help welcome ;-D  Bye  Laurent  Well, I found a workaround in the database : as for bug #7492 of the 'old database', I have added a 'Listen 0.0.0.0:8085'. Now it's working :-)  I keep this bug open, because I think a problem remains : ok, using --enable-v4-mapped, IPv4 networks is checked, but w/o this second Listen directive, the server won't return correct page but only close the connection.  Bye  Laurent  Here is what is supposed to happen with recent Apache:  For any version of netbsd with IPv6, apache  1) assumes v4-mapped addresses can't/shouldn't be used (i.e., assumes    --disable-v4-mapped) 2) puts two listen statements in default config file:    Listen 0.0.0.0:port    Listen [::]:port     (note that if you have old config file the one with the 'right' listen    statements will be httpd-std.conf)  Also, when Apache doesn't plan to use v4-mapped addresses, it will enable the IPV6_V6ONLY socket option if it exists.  The documentation needs to talk about --enable-v4-mapped vs. --disable-v4-mapped and what Listen statement(s) is(are) needed in either case.  As far as the weird error scenario (--enable-v4-mapped, 'Listen 8085', whatever is listening on port 8085 drops the connect): Is there truss or strace that you can use on Apache for this case to give an idea of what is happening?   Hum, netstat -a doesn't help (apache listening on both ipv4 and v6 worlds, so  nothing abnormal).  I duno which other tests I can made to have more informations but add some  tracing 'printf()' inside Apache code. But ... where can I start ? I'm not fully  aware of 'deep inside' stuffs in Apache code. Anyway, I will try.  If someone want to make some checks or tests, I can give a temporary access to  this machine. A slow machine but w/ a permanent connection to the web thru  cable.  Bye  Laurent  PS: hum, what do you think about adding NetBSD as target OS in your side ? ;-D I'm changing this to a doc problem.  I was able to verify that on NetBSD 1.6, the --enable-v4-mapped and --disable-v4-mapped configure options work properly and generate the proper Listen directives in the default configuration file. But the documentation was woefully inadequate for this issue, so it could not be expected that users who ignore the default configuration file would automatically arrive at the right set of Listen directives.  Better doc for this has now been added to the manual in this  section:  http://httpd.apache.org/docs-2.0/bind.html#ipv6			Jeff Trawick	Laurent Faillie
16812	null	CLOSED		Jeff Melnick	1044470400000	1088491797000		ReverseProxy not rewriting Location Header due do case sensitivity ap_proxy_location_reverse_map() is doing a case sensitive comparision. However, according to RFC2396 section 6: ...the host names used in URL are actually case insensitive... So, ap_proxy_location_reverse_map() should be doing a case insensitive  comparison.  At least on the hostname part.	Created an attachment (id=7101) Replace strncmp with strncasecmp  The patch i sent should fix the problem, i just replaced the compare function with a case insensitive one.  Matthieu enabling the PatchAvailable keyword updated doc on submitting patches is at http://httpd.apache.org/dev/patches.html  Fix committed in HEAD (cf bug 10722)			Jeff Trawick	Matthieu Estrade	Nick Kew
16813	null	CLOSED		fish bulb	1044472740000	1045465711000		t stop if httpd.conf has an error. 'apachectl stop' won't stop if you have an error in your httpd.conf... just shows the error and keeps on running. Have to make httpd.conf error free to stop the server.	Yup, this is a major annoyance.  I've committed a fix to the tree for this problem, but it can't be backported to 2.0 because it changes a function signature.  httpd-2.0: include/http_config.h: r1.99, server/config.c: r.1.164, server/main.c: r1.143  Thanks for using Apache HTTP Server!			Justin Erenkrantz
16908	null	CLOSED		Andrew Gapon	1044736020000	1045634454000		mod_mime_magic incorrectly handles unrecognized files there is a bug in mod_mime_magic, due to which mod_mime_magic sets content type for a file, that it can not actually recognize, to text/plain and returns successful status. This happens because ascmagic() sets type to 'text/plain' and reurns success even if all magic check have failed. In addition to that, even if ascmagic() would behave correctly, module would anyway set content type to application/octet-stream and returned success. Such a behaviour (1) overrides DefaultType parameter and makes it useless in the presense of mod_mime_magic and (2) puts too much intelegence in  mod_mime_magic by making a decision about 'last resort' content type, instead of honestly returning an error.	Created an attachment (id=4791) proposed patch  How-To-Repeat  1. enable mod_mime_magic in apache 2. set DefaultType to anything but text/plain 3. create a file that is not of any known type and does not have any known  extension, (in my case it was export of Windows2000 security console settings - *.msc file) 4. make the file accessible via apache via http 5. get the file from http client 6. observe that apache returns content type as text/plain    This has been fixed in httpd-2.0: modules/metadata/mod_mime_magic.c r1.61.  I'm not entirely sure this will be backported to 1.3 or 2.0.  It could be, but this is esoteric enough that I think it can wait until 2.2.			Andrew Gapon	Justin Erenkrantz
16984	null	CLOSED		Richard Fall	1045039500000	1045056060000		suexec.c error This line is the suexec.c file is in error:          fprintf(stderr, ' -D SUEXEC_UMASK=%03o/n', SUEXEC_UMASK);  Here's why:  most users who want to define their own SUEXEC_UMASK value probably assume that, like the system umask command, the value provided is in octal.  So, in setting up the make configuration using the 'configure' script, the user would probably enter:        'suexec-umask=22'  believing that this would cause the group and world write bits to be turned off in any file created by a program running under suexec.  However, because of the format used in the suexec.c line above, the value of  'SUEXEC_UMASK' is treated as a decimal value and converted to octal for internal use by suexec.  The above value of 22 (assumed by the user to already be in octal) would become 26 inside suexec, which is definitely not what the user expected!  The proper line would be, I think:          fprintf(stderr, ' -D SUEXEC_UMASK=%03d/n', SUEXEC_UMASK);  Either that, or the suexec documentation should be modified to make it clear that suexec-umask requires a decimal  value.  I would prefer the first solution.	It's silently assumed, that people use 'suexec-umask=022'. However, changed configure to always prepend a '0' as 2.x configure does, too.  Thanks for the report and thanks for using Apache!			Andr?? Malo
17006	null	CLOSED		Alex Hughes	1045066080000	1045169872000		original and rewritten URLs transposed Applies to Rewrite Guide documentation on Apache site (and presumably all other  copies of this documentation). In 'Content Handling' section, subsections 'From Old to New (intern)' and 'From  Old to New (extern)', the description states 'Assume we have recently renamed  the page bar.html to foo.html'. This should be reversed: '...renamed the page  foo.html to bar.html', to match the code given in the solution under each  description.	Right, this is fixed now in all versions. Thanks for the report and thanks for using Apache!  Erik			Erik Abele
17073	null	CLOSED		Piero Calucci	1045214520000	1045231695000		bad href in mod_proxy documentation in mod_proxy.html 'Other dedicated forward proxy packages include Squid.' is linked to www.squid.org instead of www.squid-cache.org. This is still present in online docs for 2.0.44	Fixed.  Thanks for your care and thanks for using Apache!			Andr?? Malo
17093	null	CLOSED		Chris Pepper	1045276500000	1045314195000		 in included file causes segfault I have an included vhost.conf file, and when I left off a </VirtualHost> entry near the end, both apachectl and httpd segfaulted, even on 'apachectl configtest'. This is httpd 2.0.44 (with mod_php) on FreeBSD 4.7-STABLE. Adding the missing </VirtualHost> line cleared the problem. httpd should provide an error message in this situation.  www# apachectl configtest fatal process exception: page fault, fault VA = 0x18 Segmentation fault (core dumped)  dmesg shows: 'pid 227 (httpd), uid 0: exited on signal 11 (core dumped)'.  Here's the relevant bit of vhost.conf (Included from httpd.conf).  NameVirtualHost 66.92.104.200:80  <VirtualHost 66.92.104.200:80>     ServerAdmin webmaster@reppep.com #   DocumentRoot /home/httpd/html/     DocumentRoot /home/amy/www/     ServerName www.reppep.com:80     ServerAlias reppep.com www     CustomLog '|/usr/local/sbin/cronolog /var/log/httpd/reppep-%Y-%m-access_log' combined     UserDir disabled root     Redirect permanent /mail https://www.reppep.com/mail/ </VirtualHost>  [snip]  <VirtualHost 66.92.104.200:80>     ServerAdmin rachel@reppep.com     DocumentRoot /home/rachel/public_html/     ServerName www.xanny.net:80     ServerAlias xanny.net     CustomLog '|/usr/local/sbin/cronolog /var/log/httpd/xanny-%Y-%m-access_log' combined  <VirtualHost 66.92.104.200:80>     ServerAdmin bjorn@reppep.com     DocumentRoot /home/bjorn/public_html/     ServerName www.xoaudio.com:80     ServerAlias xoaudio.com www.xoxoaudio.com xoxoaudio.com     CustomLog '|/usr/local/sbin/cronolog /var/log/httpd/xoaudio-%Y-%m-access_log' combined </VirtualHost>	ouch. reproduced. It happens only if it appears in an external file.  will look at it ... Well, this was a typical NULL pointer kaboom :) Fixed in 2.1 and proposed for backport, so it will hopefully go into 2.0.45.  Thanks for you report and thanks for using Apache! FYI: The fix will be in the next release (2.0.45). *** Bug 23247 has been marked as a duplicate of this bug. ***			Andr?? Malo
17108	null	CLOSED		Eric S. Raymond	1045412220000	1045618865000		Bugs in ab.1 man page.  Fix patch enclosed --- ab.1-orig\t2003-02-14 18:03:30.000000000 -0500 +++ ab.1\t2003-02-14 18:09:20.000000000 -0500 @@ -88,22 +88,16 @@  .BI /-X ' proxy [ :port ]'  ] [  .BI /-v ' verbosity' -]  ] [  .BI /-w ' output HTML' -]  ] [  .BI /-g ' output GNUPLOT' -]  ] [  .BI /-e ' output CSV' -]  ] [  .BI /-x ' <table> attributes' -]  ] [  .BI /-y ' <tr> attributes' -]  ] [  .BI /-z ' <td> attributes'  ] @@ -278,11 +272,11 @@  .P  Up to version 1.3d  .B ab -has propably reported values way to low for most measurements; +has propably reported values way too low for most measurements;  as a single timeout (which is usually in the order of seconds) -will shift several thousands of milli-second responses by a +will shift several thousands of millisecond responses by a  considerable factor. This was further componded by a serious -interger overrun which would for realistic run's (i.e. those +integer overrun, which would for realistic runs (i.e. those  longer than a few minutes) produce believable but totally   bogus results. Thanks to Sander Temme <sander@covalent.net>  for solving this riddle.	patch applied to 2.1-dev and 2.0.45-dev  thanks! 			Jeff Trawick
17135	null	CLOSED		Laurent Faillie	1045504260000	1052867492000		t like tabulation. Hi all,  I duno if it's realy related to mod_auth_ldap itself or not ...  Well, I use LDAP authentification to protect some pages, and I try to use  groups.So I use following line :  require group cn=my_group ...  The problem is : - if I use 1 (or more) space b/w 'group' and 'cn=', it's working. - if I use a tab b/w 'group' and 'cn=', the authentification always fails.  I have made some checks w/ 'require user' with both separator, so it seems it's  only related to groups.  Bye  Laurent	yeah, it's looking for a space. will fix.  Thanks for your report and thanks for using Apache. FYI: The fix has been merged into the stable tree and will be in the next release (2.0.46).			Andr?? Malo
17206	null	CLOSED		Christian Kratzer	1045669560000	1048198120000		Filehandles of logs not closed before exec of cgi scripts We updated one of our servers from apache-2.0.39 to  apache-2.0.44 and noticed that 2.0.44 fails to close  the file handles of the logfiles before executing cgi  scripts.  We test by running a php script via the cgi interface and  using lsof to list the open file handles. (See below)  This enables cgi's to access the logs of other virtual hosts.  We can reproduce this under FreeBSD 4-STBALE and 5.0 RELEASE using the preforked mpm and apache-2.0.40, 2.0.43 and 2.0.44. The problem does not occur on apache-2.0.39.    We think this bug might be related to Bug 12774 which was closed due to lack of response from the original poster.  This was also  oing from 2.0.39 to 2.0.40.  This could also be related to the changes in apr/file_io/src/unix/file_dup.c from 1.48 to 1.49 and the introduction of apr_file_setaside().    These changes were after 2.0.39 and before 2.0.40.  Greetings Christian Kratzer CK Software GmbH  --snipp-- COMMAND  PID    USER   FD   TYPE     DEVICE SIZE/OFF    NODE NAME php     3308 webmail  cwd   VDIR 151,131079      512 1474242 /u1/jails/jail-webmail/www/servers/webmail/htdocs php     3308 webmail  rtd   VDIR 151,131079      512 1291924 /u1/jails/jail-webmail php     3308 webmail  txt   VREG 151,131079  1343042 1473554 /u1/jails/jail-webmail/www/cgi-php/php php     3308 webmail  txt   VREG 151,131079    80080 1293805 /u1/jails/jail-webmail/usr/libexec/ld-elf.so.1 php     3308 webmail  txt   VREG 151,131079   749398 1473486 /u1/jails/jail-webmail/usr/local/lib/libc-client4.so.8 php     3308 webmail  txt   VREG 151,131079   126427 1452224 /u1/jails/jail-webmail/usr/local/lib/libexpat.so.4 php     3308 webmail  txt   VREG 151,131079    19544 1292898 /u1/jails/jail-webmail/usr/lib/libhistory.so.4 php     3308 webmail  txt   VREG 151,131079   147000 1292903 /u1/jails/jail-webmail/usr/lib/libreadline.so.4 php     3308 webmail  txt   VREG 151,131079   258872 1292446 /u1/jails/jail-webmail/usr/lib/libncurses.so.5 php     3308 webmail  txt   VREG 151,131079    85712 1473115 /u1/jails/jail-webmail/usr/local/lib/libpq.so.3 php     3308 webmail  txt   VREG 151,131079   132379 1473270 /u1/jails/jail-webmail/usr/local/lib/mysql/libmysqlclient.so.10 php     3308 webmail  txt   VREG 151,131079    51156 1292749 /u1/jails/jail-webmail/usr/lib/libz.so.2 php     3308 webmail  txt   VREG 151,131079    28480 1292428 /u1/jails/jail-webmail/usr/lib/libcrypt.so.2 php     3308 webmail  txt   VREG 151,131079   192724 1452773 /u1/jails/jail-webmail/usr/local/lib/libldap.so.2 php     3308 webmail  txt   VREG 151,131079    47937 1452770 /u1/jails/jail-webmail/usr/local/lib/liblber.so.2 php     3308 webmail  txt   VREG 151,131079    38500 1292702 /u1/jails/jail-webmail/usr/lib/libpam.so.1 php     3308 webmail  txt   VREG 151,131079   908698 1473181 /u1/jails/jail-webmail/usr/local/lib/libiconv.so.3 php     3308 webmail  txt   VREG 151,131079   211156 1473420 /u1/jails/jail-webmail/usr/local/lib/libgd.so.4 php     3308 webmail  txt   VREG 151,131079   340310 1473287 /u1/jails/jail-webmail/usr/local/lib/libfreetype.so.9 php     3308 webmail  txt   VREG 151,131079   139364 1472995 /u1/jails/jail-webmail/usr/local/lib/libpng.so.5 php     3308 webmail  txt   VREG 151,131079   135696 1473155 /u1/jails/jail-webmail/usr/local/lib/libjpeg.so.9 php     3308 webmail  txt   VREG 151,131079   117736 1292433 /u1/jails/jail-webmail/usr/lib/libm.so.2 php     3308 webmail  txt   VREG 151,131079   762896 1293883 /u1/jails/jail-webmail/usr/lib/libcrypto.so.2 php     3308 webmail  txt   VREG 151,131079   181720 1293903 /u1/jails/jail-webmail/usr/lib/libssl.so.2 php     3308 webmail  txt   VREG 151,131079   575584 1292596 /u1/jails/jail-webmail/usr/lib/libc.so.4 php     3308 webmail    0u  PIPE 0xf08bb4e0    16384 php     3308 webmail    1u  PIPE 0xeba05bc0    16384         ->0xf08bb760 php     3308 webmail    2u  PIPE 0xebcb63a0    16384         ->0xeba03960 php     3308 webmail    4u  PIPE 0xeba03a00    16384         ->0xeb666a00 php     3308 webmail    5u  PIPE 0xeb666a00    16384         ->0xeba03a00 php     3308 webmail    6u  VREG 151,131079     4519 1474234 /u1/jails/jail-webmail/www/logs/httpd-error.log php     3308 webmail    7u  VREG 151,131079        0 1474628 /u1/jails/jail-webmail/www/servers/webmail109/logs/httpd-error.log php     3308 webmail    8u  VREG 151,131079        0 1474629 /u1/jails/jail-webmail/www/servers/webmail108/logs/httpd-error.log php     3308 webmail    9u  VREG 151,131079        0 1474630 /u1/jails/jail-webmail/www/servers/webmail107/logs/httpd-error.log php     3308 webmail   10u  VREG 151,131079        0 1474631 /u1/jails/jail-webmail/www/servers/webmail106/logs/httpd-error.log php     3308 webmail   11u  VREG 151,131079        0 1474632 /u1/jails/jail-webmail/www/servers/webmail105/logs/httpd-error.log php     3308 webmail   12u  VREG 151,131079        0 1474633 /u1/jails/jail-webmail/www/servers/webmail104/logs/httpd-error.log php     3308 webmail   13u  VREG 151,131079        0 1474634 /u1/jails/jail-webmail/www/servers/webmail103/logs/httpd-error.log php     3308 webmail   14u  VREG 151,131079        0 1474635 /u1/jails/jail-webmail/www/servers/webmail102/logs/httpd-error.log php     3308 webmail   15u  VREG 151,131079        0 1474636 /u1/jails/jail-webmail/www/servers/webmail101/logs/httpd-error.log php     3308 webmail   16u  VREG 151,131079        0 1474637 /u1/jails/jail-webmail/www/servers/webmail100/logs/httpd-error.log php     3308 webmail   17u  VREG 151,131079     2109 1474254 /u1/jails/jail-webmail/www/servers/webmail/logs/httpd-error.log php     3308 webmail   18w  VREG 151,131079      675 1474236 /u1/jails/jail-webmail/www/logs/httpd-access.log php     3308 webmail   19w  VREG 151,131079        0 1474638 /u1/jails/jail-webmail/www/servers/webmail109/logs/httpd-access.log php     3308 webmail   20w  VREG 151,131079        0 1474639 /u1/jails/jail-webmail/www/servers/webmail108/logs/httpd-access.log php     3308 webmail   21w  VREG 151,131079        0 1474640 /u1/jails/jail-webmail/www/servers/webmail107/logs/httpd-access.log php     3308 webmail   22w  VREG 151,131079        0 1474641 /u1/jails/jail-webmail/www/servers/webmail106/logs/httpd-access.log php     3308 webmail   23w  VREG 151,131079        0 1474642 /u1/jails/jail-webmail/www/servers/webmail105/logs/httpd-access.log php     3308 webmail   24w  VREG 151,131079        0 1474643 /u1/jails/jail-webmail/www/servers/webmail104/logs/httpd-access.log php     3308 webmail   25w  VREG 151,131079        0 1474644 /u1/jails/jail-webmail/www/servers/webmail103/logs/httpd-access.log php     3308 webmail   26w  VREG 151,131079        0 1474645 /u1/jails/jail-webmail/www/servers/webmail102/logs/httpd-access.log php     3308 webmail   27w  VREG 151,131079        0 1474646 /u1/jails/jail-webmail/www/servers/webmail101/logs/httpd-access.log php     3308 webmail   28w  VREG 151,131079        0 1474647 /u1/jails/jail-webmail/www/servers/webmail100/logs/httpd-access.log php     3308 webmail   29w  VREG 151,131079     7821 1474255 /u1/jails/jail-webmail/www/servers/webmail/logs/httpd-access.log --snipp--	Created an attachment (id=4966) disables inheriting of access and error logs  Apache httpd fails to close access and error logs when it forks and  execs cgi scripts.  From our preliminary understanding of the code the fix is to call apr_file_inherit_unset() in place of  apr_file_inherit_set() in both server/log.c and loggers/mod_log_config.c.  The bug first appeared going from 2.0.39 to 2.0.40 because a typo in the definition of the APR_INHERIT flag had reversed the effect of apr_file_inherit_set().  For this please see cvs diff of /apr/include/arch/unix/Attic/inherit.h between 1.10 and 1.11.  The attached patch forces cleanup of logfiles on fork/exec of cgi's.  All calls of *_inherit_set() and *_inherit_unset() should be validated  for correct behavior in their respective contexts.  Credit for digging through the sources and finding the fix goes Bjoern Zeeb <bzeeb@zabbadoz.net>.  In case of questions we have more detailed information available. Please email.     the fix does not help with all mpms. People who need to know more got 2nd mail. further public discussions on patches are here (apr) http://marc.theaimsgroup.com/?t=104688218100008&r=1&w=2 and here (httpd) http://marc.theaimsgroup.com/?t=104696493400002&r=1&w=2  Also pointed wrowe to his commit http://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/log.c.diff?r1=1.94&r2=1.95&di ff_format=h     Thanks to you, Christian, Bjoern and Joe I believe we have this licked.   Fixes are applied to the forthcoming 2.0.45 release and the 2.1.0-dev tree.  Many thanks back to you, William Rowe, for your great work solving even more problems in apr/httpd related to this. Thanks.			Bjoern A. Zeeb	Christian Kratzer	Will Rowe
17217	null	CLOSED		Aaron Axelsen	1045684080000	1078942071000		mod_ssl cannot be used as a DSO with static OpenSSL libraries Since upgrading to apache 2.0.44 I cannot get ssl to work.  I get the following  errors when I try to start apache loading the mod_ssl module:  Syntax error on line 263 of /usr/local/apache/conf/httpd.conf: Cannot load /usr/local/apache/modules/mod_ssl.so into server: /usr/local/apache/ modules/mod_ssl.so: undefined symbol: SSL_CTX_set_tmp_rsa_callback  This is loading the exact same ssl.conf file that i used for apache 2.0.43.  Is  there some kind of a bug with 2.0.44 and ssl?	The only code that references SSL_CTX_set_tmp_rsa_callback was added before 2.0.43.  Perhaps you have a version of openssl in your library path now that doesn't implement that function?  Maybe openssl isn't found at all and that is simply the first function that couldn't be resolved?  Just maybe you didn't specify --enable-ssl on your configure invocation for 2.0.44 and so httpd executable didn't reference the openssl library?  In this case, the mod_ssl.so you're trying to use could be from a previous build of 2.0.43.  ?????  the only way i could get it to work was to recomiple it with --enable- ssl=static.  It fails to load as a loadable module. That would be consistent with your openssl library being built as a static library instead of as a dynamic library.  Even if it was static and noy dynamic, how come it worked with only --enable- ssl in 2.0.43 and i had to do --enable-ssl=static in 2.0.44? You need to post exactly how you build apache and openssl, this could mean any  number of things. And how you start Apache. To state the issue concisely:  If building mod_ssl as a DSO against static OpenSSL libraries, mod_ssl will not load.  This is because the only place that symbols from the SSL libraries are referenced is mod_ssl, but only httpd itself is linked against -lssl -lcrypto.  The workaround is to use shared OpenSSL libraries or a statically-linked mod_ssl. *** Bug 22057 has been marked as a duplicate of this bug. *** Fixed on HEAD, probably worthy of backport.			Aaron Axelsen	Jeff Trawick	Joe Orton	askme
17236	null	CLOSED		Ralf Hauser	1045730100000	1080056705000		say whether it is possible to comment in a htaccess file and what the comment syntax is!  same for http://httpd.apache.org/docs-2.0/mod/mod_auth.html#authgroupfile  and http://httpd.apache.org/docs-2.0/mod/mod_auth.html#authuserfile	.htaccess files are well documented here: <http://httpd.apache.org/docs- 2.0/configuring.html>.  The use of comments within AuthUserfile/AuthGroupfile isn't really recommended,  so I tend to say 'wontfix' here.  Thanks for the hint.  How about putting a link to http://httpd.apache.org/docs-2.0/configuring.html#syntax in the htaccess file ? (after all we are no longer in the paper world of sequential reading, but hypertext and search engines are typically used today, so a user may just see the htaccess file, but not all the rest of the documentation.)  As for the other two, what do you mean with 'not really recommended'?  I would guess it is good practice to put such files under version control and thus  a comment with at least the version control tag would be recommended too? Does it work or will it break something? I.e. s the Group file a configuration file as per  http://httpd.apache.org/docs-2.0/configuring.html where  http://httpd.apache.org/docs-2.0/configuring.html#syntax applies or not? An appropriate link has been added.  Thanks for the suggestion.			Andr?? Malo	Joshua Slive	Ralf Hauser
17274	null	RESOLVED		Laurent Blume	1045822440000	1118665133000		 after an erroneous login attempt (this is the copy of an email I posted on the mod_ldap list and the Apache users list - two emails actually, I replied to myself - I hope nobody will mind, I already spent time diagnosing the bug, I just had no time to follow a bug report till now :-)  I can confirm that this problem is a bug related to how mod_ldap handles the behaviour of the AD server. When a bind has succeeded, the module keeps the session open for any following request. However, when the first bind (with AuthLDAPBindDN) was successful, and then the second (with login/wrong password) failed, the module considers the session is still bound, while the AD server thinks it has no permission anymore. So, on the next search, the AD server replies with a 'Success' with no entry, that the module interprets as a 'User not unique'.  Since I don't mind the module establishing a new session everytime, I made sure that it's killed after every search.  If I have the time, I'll try to make a more consistent patch  IS this the right mailing list to post it or should it go to an Apache one now that this module has been included ?  My quick fix: $ diff mod_auth_ldap.c~  mod_auth_ldap.c 279c279 <     util_ldap_connection_close(ldc); --- >     util_ldap_connection_destroy(ldc);   Laurent Blume wrote:  > I snooped the packets, and I did notice something weird: > > When there is a successful authentication (login and password are ok on the first try), the conversation between the Apache server and the LDAP server goes like this: >  - new TCP session established; >  - bind request with the AuthLDAPBindDN and AuthLDAPBindPassword; >  - bind result: success; >  - search request with the Base DN, attribute name, and the login entered as the attribute value; >  - search result: success, containing only one value; >  - bind request with the DN in the value just received; >  - bind result: success; >  - TCP session ends; > > All those steps are repeated every time. > > When the login password is wrong for the first try, it goes like this: >  - new TCP session established; >  - bind request with the AuthLDAPBindDN and AuthLDAPBindPassword; >  - bind result: success; >  - search request with the Base DN, attribute name, and the login entered as the attribute value; >  - search result: success, containing only one value; >  - bind request with the DN in the value just received; >  - bind result: Invalid credentials; > > The main difference being, _the TCP session is not closed_. > When there is another try with the same login, whatever the password is, there is no new TCP session, it continues in the same, right after the bind result, like this: >  - search request with the Base DN, attribute name, and the login entered as the attribute value; >  - search result: success, containing no value; > > Nothing else, the TCP session is still *not* closed, it continues with the same values for every try. > >  From what I understand, since the last Bind request failed, the AD server considers the client has no authorization. Its behaviour in that case is to reply with a Success, but with no value returned. 0 being different from 1, the module interprets this as 'User is not unique'. > I haven't used any other LDAP server so far, but I've seen that AD is different in that it requires authentication before allowing a search. > Actually, a server allowing an anonymous search would probably work in my case, so I guess it's AD particular behaviour that is not correctly handled. > > I've started to look at the sources to get a better understanding on what goes on, but my C days are a bit far in my past, I'm not sure I'll be able to fix that.	i have exactly the same problem with openldap 2.0.25, apache 2.0.44 and freebsd 4.7. the quick fix solved the problem for me. i agree that the problem seems to be that the module assumes that the session can be used for authentication attempts again, which is not be permitted by the ldap servers access control. I have the same problem, I'm using: httpd-2.0.44 against ms active directory (ms w2k)  I'm going through the bug db to make sure patches are findable.  Please see  http://httpd.apache.org/dev/patches.html  I have this problem in my production mandrake 9.2 server, and would love to just get a fixed binary - is this being fixed in the actual binaries, or will this just continue to be a sourcecode patch? Seeing this on Windows 200 SP4 Active Directory, using Apache HTTP Server 2.0.49 on Windows.    When incorrect password is input, error log logs:  [*date*] [warn] [client *ipaddress*] [832] auth_ldap authenticate: user *username* authentication failed; URI *uri* [ldap_simple_bind_s() to check user credentials failed][Invalid Credentials]  Subsequent attempt to login with correct password cause this error in the logs:  [*date] [warn] [client *ipaddress*] [832] auth_ldap authenticate: user *username* authentication failed; URI *uri* [User not found][No Such Object] Please try the patch at http://nagoya.apache.org/bugzilla/show_bug.cgi?id=27748 and tell me if it fixes this problem. This patch has been applied to v2.1.0-dev, and awaits backporting to v2.0.50-dev.  I applied the patch to 2.0.49, built it with similar options. It now authenticates correctly against the AD server, even when entering invalid login/password combinations first.  So it seems to fix the problem for me. Sweet, thanks :) Does 2.0.53 fix this problem??  I was using 2.0.47 and it has the same problem...  I couldnt change the source,  from: <     util_ldap_connection_close(ldc);  to >     util_ldap_connection_destroy(ldc);    It would give compile errors     thanks  Joshua This was fixed in v2.0.51 - can you confirm whether this is still broken, and reopen if so?			Graham Leggett	Jeff Trawick	John Coonrod	Laurent Blume	Marte Castro	Stephen Duncan Jr	joshua@idx.com.au	till toenges
17433	null	CLOSED		Robert La Ferla	1046269500000	1046370690000		Please update URL in httpd.conf comment There is an outdated URL in **TWO** places in the httpd.conf file.  Please  update:   # See ftp://ftp.isi.edu/in-notes/iana/assignments/character-sets  should be:  # See http://www.iana.org/assignments/character-sets	This is fixed now and will show up in the next release (2.0.45). Thanks for reporting the issue.			Erik Abele
17462	null	CLOSED		Dario Gomes	1046321400000	1048089136000		Prevent mod_rewrite from deadlooping The following code on an .htaccess file  RewriteEngine On RewriteBase / RewriteRule ^(.*) /index.html  can get the httpd process REALLY busy. Just place it in the main directory, but  it'll work in a subdirectory, in which case change the last line to  RewriteRule ^(.*) /subdir/index.html  The file index.html SHOULD NOT exist. Then call  http://yoursite.com/  or  http://yoursite.com/subdir/  and the browser window won't stop loading. On the server side, you'll get a  pretty nasty httpd process using up a whole lot of CPU and memory. And if the  URL is called a bunch of times, the server can lock up!  I did not experience the bug on Apache 2.0.40 (Red Hat 8.0 RPM install), only  on 1.3.27, both compiled by hand and RH 7.3 RPM install.  -Dario Gomes	he, you'll need a better system that finishs this endless loop under one minute ;-)  It's a known issue. You're simply creating an endless loop of internal redirects. Thatswhy you already should test your rules before putting them on a production server.  However, I'm changing this to an Enhancement request. We should be able to set a configurable limit of maximum redirects issued by mod_rewrite.  Thanks for using Apache! The problem is I run a shared hosting server, and I have no control of the  rules my users put on their sites... I got the server locked up two times  before I found the source of the problem!  Why doesn't this bug affect Apache 2.0.4x? Maybe they've worked out this issue  already?  -Dario In 2.0 the trick doesn't work with your ruleset, because of a different behaviour of mod_dir. You can crash the server, for example, with the following in a htaccess file (in docroot):  RewriteEngine On RewriteBase / RewriteRule (.*) / [L]  However, a configurable limit was introduced in 2.1 and is proposed for backport. FYI: The enhancement will appear in the next releases (1.3.28 and 2.0.45).			Andr?? Malo	Dario Gomes
17564	null	CLOSED		Maxim Zakharov	1046547780000	1053799595000		Somtimes mod_negotiation fails  select right variant Sometimes mod_negotiation fails to select right veriant. At once after restart it works, but after several page reloads it get 406 Not Acceptaple. This hapens if, for exaple, browse send following headers  Accept:text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,video/x-mng,image/png,image/jpeg,image/gif;q=0.2,text/css,*/*;q=0.1 Accept-Charset: KOI8-R, utf-8;q=0.66, *;q=0.66 Accept-Language: ru, en;q=0.66, fr;q=0.33  After server restart atof at line 392 of mod_negotiation.c:  result->quality = (float)atof(cp); works right  text/html Quality: 0.9 -> 0.900000 text/plain Quality: 0.8 -> 0.800000 image/gif Quality: 0.2 -> 0.200000 */* Quality: 0.1 -> 0.100000 compress Quality: 0.9 -> 0.900000 en Quality: 0.66 -> 0.660000 fr Quality: 0.33 -> 0.330000 utf-8 Quality: 0.66 -> 0.660000 * Quality: 0.66 -> 0.660000  (value before '->' is string passed as argument for atof function, value after - is a value returned by atof)  Buf after i get 406 (Not Acceptable) it look like text/html Quality: 0.9 -> 0,000000 text/plain Quality: 0.8 -> 0,000000 image/gif Quality: 0.2 -> 0,000000 */* Quality: 0.1 -> 0,000000 compress Quality: 0.9 -> 0,000000 en Quality: 0.66 -> 0,000000 fr Quality: 0.33 -> 0,000000 utf-8 Quality: 0.66 -> 0,000000 * Quality: 0.66 -> 0,000000  If i change atof call at line 392 for this function:  static float ap_atoq(const char *str) {   float result1 = atof(str);   float result2 = 0.0;   char *p = strchr(str, '.'), *d;      if (p != NULL) {     *p = ',';     result2 = atof(str);   } else {     d = strchr(str, ',');     if (d != NULL) {       *d = '.';       result2 = atof(str);     }   }   if (result2 > result1) return result2;   return result1; }  it seems all work fine.  Probably, httpd-2.0 is also affected.	I'm not sure whether I fully understand your report. Why should we parse wrong numbers with commas in it?  ...err, I think, I start to understand. The atof function is dependent on some locale settings? In some locales (include russian), comma is used as decimal point separator. Thus atof function under such locales is false to parse right variant weight with dot as desimal point separator. Well, I've fixed the problem by dropping atof() entirely (and writing our own more RFC compliant version). The fix currently applies to version 2.1 (main dev branch) and is proposed for backport.  Thanks for your report and thanks for using Apache! *** Bug 9427 has been marked as a duplicate of this bug. *** Sounds fixed to me.			Andr?? Malo	Joshua Slive	Maxim Zakharov
17719	null	CLOSED		Ralph Giles	1046957580000	1057699932000		please add application/ogg for .ogg to mime.types IANA has officially approved application/ogg for multimedia files in the Ogg bitream encapsulation format. We hereby request that the new mime-type be added to the mapping apache ships (doc/conf/mime.types) for the '.ogg' extension. Ogg files can also be identified by the 'OggS' magic in the first four bytes.  The format was developed by the xiph.org open multimedia effort, and has recently been ratified by the IETF and is only awaiting RFC number assignment. See http://www.iana.org/assignments/media-types/application/ for confirmation.  When we requested application/x-ogg be added, we were told to come back when we had better credentials. Hopefully this will suffice. :-)	As an update, our rfc's have been released. Please see http://ietf.org/rfc/rfc3534.txt or a description of the application/ogg mimetype.   http://ietf.org/rfc/rfc3533.txt documents the ogg file format itself. It's been three months with absolutely no response on this issue. What's the hold up? Please let me know if there's anything more that we need to do to support the inclusion.  Based on the discussion around bug 20440, I don't see that there can be. After all, we *did* jump through the hoops and obtained an official IANA mime-type. This is now fixed in CVS and will be in the 2.0.48 release. Sorry for the delay and thanks for using  Apache.			Erik Abele	Ralph Giles
17720	null	CLOSED		Ralph Giles	1046957940000	1057699902000		please add application/ogg mimetype IANA has officially approved application/ogg for multimedia files in the Ogg bitream encapsulation format. (Mostly vorbis audio at this point.) We hereby request that the new mime-type be added to the mapping apache ships (conf/mime.types) for the '.ogg' extension. Ogg files can also be identified by the 'OggS' magic in the first four bytes.  The format was developed by the xiph.org open multimedia effort, and has recently been ratified by the IETF and is only awaiting RFC number assignment. See http://www.iana.org/assignments/media-types/application/ for confirmation.  When we requested application/x-ogg be added, we were told to come back when we had better credentials. Hopefully this will suffice. :-)  See all #17719 against apache 2.0.	Created an attachment (id=5488) Patched for mime.types to add application/ogg mime type.  As an update, our rfc's have been released. Please see http://ietf.org/rfc/rfc3534.txt or a description of the application/ogg mimetype.   http://ietf.org/rfc/rfc3533.txt documents the ogg file format itself. It's been three months with absolutely no response on this issue. What's the hold up? Please let me know if there's anything more that we need to do to support the inclusion. This is now fixed in CVS and will be in the 2.0.48 release. Sorry for the massive delay and thanks  for using Apache.			Dylan Neild	Erik Abele	Ralph Giles
17797	null	CLOSED		Max	1047080820000	1049462032000		mod_deflate ignores Content-Encoding: gzip(result is a twice compressed content) mod_deflate ignores 'Content-Encoding: gzip' which can be set from CGI script. Result will be twice compressed document.  It is possible to resolve using Apache configuration options but I think that it should be fixed.  Max.	In fact mod_deflate should not ignore that header...  ...oh well, content-encoding from CGI is put into err_headers_out, we should check for these in mod_deflate, too.  Thanks for your report. FYI: Fixed for the next release (2.0.46).			Andr?? Malo
17864	null	CLOSED		Andreas Leimbacher	1047378840000	1047450703000		table_clear() corrupts memory mod_ssl's table_clear() clears one bucket past the bucket array.  This is causes by an incorrect loop condition ( '<=' instead of '<' ).  Surprisingly, this bug does not exist in 1.3.27.  Correct (as in 1.3.27)    for (bucket_p = table_p->ta_buckets; bucket_p < bounds_p; bucket_p++) {  Wrong ( 2.0.44)   for (bucket_p = table_p->ta_buckets; bucket_p <= bounds_p; bucket_p++) {	Thanks for pointing it out. I've committed the changes to HEAD.  -Madhu			Madhusudan Mathihalli
18025	null	CLOSED		samuel	1047711780000	1052865016000		chinese default start page is broken error] [client 127.0.0.1] File does not exist: C:/Program Files/Apache  Group/Apache2/htdocs/index.html.tw.Big5	insufficient information Ah yeah, our type map is broken (last two entries). The charset is not correct, too. Fixed for the next release.			Andr?? Malo	Jeff Trawick
18101	null	RESOLVED		Francois Genolini	1047991200000	1101096863000		ServerRoot cannot be set to other folder Apache installed in C:/Program Files/Apache Group/Apache2 and default httpd.conf file says: ServerRoot 'C:/Program Files/Apache Group/Apache2'  Apache will not start if ServerRoot is set to any other folder (for example 'c:/MyWeb/Web'). I have tried to copy the whole contents of C:/Program Files/Apache Group/Apache2 to c:/MyWeb/Web but Apache still will not start.  This used to work (2.0.39 I seemm to remember).	'will not start' isn't a helpful description for the error. What happens exactly and what error messages will occur?  Thanks. 'Will not start' is not supposed to be helpful: it is an accurate description!  HEre are the steps:  1) start the apache service monitor.  2) Edit the apache httpd.conf file  3) Modify the ServerRoot as described  4) click the 'Restart' button on the Apache Service Monitor  5) a popup window is displayed, saying: Error The requested operation has failed!  The Apache error log has nothing related to this error  Therefore my original description was accurate and complete  QED Maybe accurate, but not helpful anyway ;-)  However, please do the following: - open your console and cd to the apache2-bin directory - type apache -k start  An error message should be written to the console. This message usually appears to be helpful :)  (Btw: Are you sure, you want to modify ServerRoot and not DocumentRoot?)  Thanks. ehm, instead of apache -k start, I meant to say apache -k restart. Thanks for your help.  Here is the error message:  Syntax error on line 13 of C:/Program Files/Apache Group/Apache2/conf/httpd.conf : Cannot load C:/MyWeb/Web/modules/mod_access.so into server: The specified module  could not be found.  I have copied the modules directory and Apache starts.  Rationale for modifying ServerRoot: The documentation for Apache says that ServerRoot is used to determine the base  directory for log files and configuration files. It never mentioned that it was also used as the base directory for binaries,  shared libraries and modules.  Maybe the docs need to be updated; but I would rather think this is a coding  error. I would assume that when Apache starts, it remembers where it starts from: the  eveidence for this is that Apache knows where to find the httpd.conf file  (located in ../conf). Therefore there should be no problem in accessing the modules in ../modules,  regardless of the setting for ServerRoot.  I believe that this used to be the behaviour before (2.0.39 I seem to remember). The code has benn modified wrongly, I would think (at least not in keeping with  the published specs as described in the docs). Thanks for your help.  Here is the error message:  Syntax error on line 13 of C:/Program Files/Apache Group/Apache2/conf/httpd.conf : Cannot load C:/MyWeb/Web/modules/mod_access.so into server: The specified module  could not be found.  I have copied the modules directory and Apache starts.  Rationale for modifying ServerRoot: The documentation for Apache says that ServerRoot is used to determine the base  directory for log files and configuration files. It never mentioned that it was also used as the base directory for binaries,  shared libraries and modules.  Maybe the docs need to be updated; but I would rather think this is a coding  error. I would assume that when Apache starts, it remembers where it starts from: the  eveidence for this is that Apache knows where to find the httpd.conf file  (located in ../conf). Therefore there should be no problem in accessing the modules in ../modules,  regardless of the setting for ServerRoot.  I believe that this used to be the behaviour before (2.0.39 I seem to remember). The code has benn modified wrongly, I would think (at least not in keeping with  the published specs as described in the docs). Ok, thanks for your update.  The documentation for Apache says that ServerRoot is _typically_ used to determine the base directory for log files and configuration files. (we should mention modules/ there also, right.)  Actually it is used to resolve any relative path (that's what it's supposed to). So if you want to keep your module files in the old path, you have to use absolute paths and everything is fine.  If it didn't work that way in older versions it must be a bug there ;-).  Why can't httpd take the location where it starts from? The answer is simple. On most systems (especially *x) there is no reliable way to determine this location.  I'm changing this report to be a docs enhancement.  Thanks for using Apache! A minor documentation update has been made to clarify this point. Committed revision 106145. Closing.			Andr?? Malo	Francois Genolini	Rich Bowen
18156	null	CLOSED		Ian Gulliver	1048100580000	1092817537000		Suexec runs as the VirtualHost user instead of the owner of the UserDir When executing CGI's inside a Userdir, Apache attempts to run the CGI at the SuexecUserGroup from the VirtualHost directive instead of the user who's directory we're looking at.  This trips the security protection in suexec and causes an Internal Server Error message.  Suexec logs something like:  [2003-03-19 18:57:32]: target uid/gid (1000/1000) mismatch with directory (1053/1053) or program (1053/1053)  (Where 1000/1000 is the SuexecUserGroup for the 'ares.penguinhosting.net' named virtual host, and 1053/1053 is the user/group of 'david' for the listed URL).  Apache 1 behaves properly in the same case.	I'm having the exact same problem. Running suexec in the document root is no problem, however, Apache is not sending the '~' to Suexec when a userdir is accessed. Are you actually using mod_userdir ONLY to serve these requests, or is there some kind of Alias/ScriptAlias/RewriteRule that is involved? I've got some Rewriterules, but they don't apply for the UserDir directive. This is my VirtualHost config:  <VirtualHost www.domain.nl:80>         SuexecUserGroup username group         ServerAdmin emailaddress          DocumentRoot '/home/sites/site1/web/'                 <Directory '/home/sites/site1/web'>                     Options Indexes FollowSymLinks MultiViews Includes +ExecCGI                     AllowOverride All                     Order allow,deny                     Allow from all                 </Directory>          ServerName www.domain.nl         ServerAlias *.domain.nl domain.nl          RewriteEngine On         RewriteRule ^/personal/?$       http://www.domain.nl:81 [L,R]         RewriteRule ^/siteadmin/?$      http://www.domain.nl:81 [L,R]         RewriteRule ^/admin/?$          http://www.domain.nl:81 [L,R]         RewriteRule ^/login/?$          http://www.domain.nl:81 [L,R]         RewriteRule ^/webmail/?$        http://www.domain.nl:81/webmail/ [L,R]         RewriteRule ^/fileman/?$        http://www.domain.nl:81/webmail/ [L,R]         RewriteOptions inherit         <Directory '/home/sites/site1/users/*/web'>             Options Indexes FollowSymLinks MultiViews Includes +ExecCGI             AllowOverride All             Order allow,deny             Allow from all         </Directory>         ErrorLog /home/sites/site1/logs/error.log         CustomLog /home/sites/site1/logs/web.log combined </VirtualHost>  In httpd.conf the following is set:  UserDir web  and my suexec -V output is:   -D AP_DOC_ROOT='/home/sites/'  -D AP_GID_MIN=100  -D AP_HTTPD_USER='www'  -D AP_LOG_EXEC='/usr/local/apache2/logs/suexec_log'  -D AP_SAFE_PATH='/usr/local/bin:/usr/bin:/bin'  -D AP_SUEXEC_UMASK=022  -D AP_UID_MIN=100  -D AP_USERDIR_SUFFIX='web'   Anything new regarding this bug? I'm facing EXACTLY the same problem on 2.0.49,  which renders it completely unusable for me. Apache 1 worked fine, it used User  and Group when no UserDir request was made, and used the correct user when a  UserDir request was made.  Please have a look at this soon, it prevents me from using 2.x :-( Attached is some system information that might be helpful.  My configure command-line: ./configure --enable-mods-shared=all --enable-ssl --enable-proxy --enable-suexec  --with-suexec-caller=nobody --with-suexec-docroot=/home   Output of suexec -V:  -D AP_DOC_ROOT='/home'  -D AP_GID_MIN=100  -D AP_HTTPD_USER='nobody'  -D AP_LOG_EXEC='/usr/local/apache2/logs/suexec_log'  -D AP_SAFE_PATH='/usr/local/bin:/usr/bin:/bin'  -D AP_UID_MIN=100  -D AP_USERDIR_SUFFIX='public_html'   Output of apachectl -V: Server version: Apache/2.0.49 Server built:   Apr 10 2004 13:17:23 Server's Module Magic Number: 20020903:7 Architecture:   32-bit Server compiled with....  -D APACHE_MPM_DIR='server/mpm/prefork'  -D APR_HAS_SENDFILE  -D APR_HAS_MMAP  -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)  -D APR_USE_SYSVSEM_SERIALIZE  -D APR_USE_PTHREAD_SERIALIZE  -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT  -D APR_HAS_OTHER_CHILD  -D AP_HAVE_RELIABLE_PIPED_LOGS  -D HTTPD_ROOT='/usr/local/apache2'  -D SUEXEC_BIN='/usr/local/apache2/bin/suexec'  -D DEFAULT_PIDLOG='logs/httpd.pid'  -D DEFAULT_SCOREBOARD='logs/apache_runtime_status'  -D DEFAULT_LOCKFILE='logs/accept.lock'  -D DEFAULT_ERRORLOG='logs/error_log'  -D AP_TYPES_CONFIG_FILE='conf/mime.types'  -D SERVER_CONFIG_FILE='conf/httpd.conf'   Relevant settings in httpd.conf: UserDir disabled UserDir disabled root [...] <Directory /home/*/public_html>      AllowOverride All      Options -Indexes MultiViews ExecCGI SymLinksIfOwnerMatch IncludesNoExec         Order allow,deny         Allow from all </Directory> [...] <Directory /home/sites/*/users/*/public_html>     AllowOverride All     Options -Indexes MultiViews ExecCGI SymLinksIfOwnerMatch IncludesNoExec     Order Deny,Allow     Allow from all </Directory>   Relevant settings in my included virtualhosts.conf: NameVirtualHost *:80  <VirtualHost *:80> ServerName my.main.domain UserDir disabled UserDir disabled root RewriteEngine on RewriteOptions inherit </VirtualHost> [...] <VirtualHost *:80> ServerName www.sub.domain.ofmine ServerAlias sub.domain.of.mine ServerAdmin my@root.address DocumentRoot /home/sites/s1234/users/u0001/public_html UserDir disabled UserDir disabled root UserDir enabled s1234u0003 [...some other enabled UserDirs...] SuexecUserGroup s1234u0074 s1234 RewriteEngine on RewriteOptions inherit [...some RewriteRules...] </VirtualHost> Anything new in here? This one is a really bad one :-( Perhaps someone could answer to the question regarding the scriptalias directives? Or better - attach the *full* config? I have attached my config. Is there some important part missing? It doesn't work with and without RewriteRules. 'm guessing this is a variation of the 'bug' (really documentation problem) with suexec + UserDir in Apache 2.0.x.  Basically, you cannot use the 'old style' scriptalias directives with user dirs and suexec.  Try this version of your user CGI bin directory setup:          <Directory ~ '/home/sites/site1/users/*/web'>             Options Indexes FollowSymLinks MultiViews Includes +ExecCGI             AllowOverride All             Order allow,deny             Allow from all             SetHandler cgi-script         </Directory>  Oh, you need to include the UserDir and SuExec modulea:  LoadModule userdir_module modules/mod_userdir.so LoadModule suexec_module modules/mod_suexec.so  And *don't* include any sort of scriptalias for your user's dirs.  LoadModule suexec_module modules/mod_suexec.so and LoadModule userdir_module modules/mod_userdir.so are activated in my httpd.conf.  However, your solution shown below does not help. :-( May I e-mail you my httpd.conf and my included virtualhosts.conf, so you can check it? Because of data privacy and security issues, I don't want to attach the full  configuration to this bug.  May I e-mail it to you privately?  Thanks! I'm not one of the Apache developers, just a fellow user of suexec.  I am not sure how much help I can give you.  I don't presently have an  Apache 2.0.x server installed and running anywhere at present, so I  cannot actually test anything either.  All I know is that    It is entirely possible that it is a real bug.  Maybe what you need to post is a stripped down version of your  httpd.conf and virtualhosts.conf files, ones that are minimually  suffientent to cause the problem, but which don't leak any real  (priviledged) data -- this way the developers can re-create your problem      and then come up with a working solution.  Hi there, and thanks for the quick reply ;-) If any of the developers could post to this bug (I haven't heard anything from them yet ;-( I'd happily provide them with my httpd.conf ;) Here's what you should do: Start with a default install of apache from httpd.apache.org, and then make the absolute minimum changes that are necessary to show the problem.  Then give us a list of the changes. Here it comes ;-)   System installed on:  Debian GNU/Linux Sarge x86   Non-FQDN hostname of the system tested on: floeff3.effenberger (sometimes mentioned in the configuration file)   Apache source code used:  http://www.artfiles.org/apache.org/httpd/httpd-2.0.49.tar.gz   Steps taken for compilation:  - apt-get install libssl-dev binfmt-support  - ./configure --enable-mods-shared=all --enable-ssl --enable-proxy --enable-suexec --with-suexec-caller=nobody --with-suexec-docroot=/home  - make  - make install  - addgroup site1  - adduser --shell /bin/false --ingroup site1 user1  - mkdir /home/user1/public_html  - chown user1:site1 /home/user1/public_html  - adduser --shell /bin/false --ingroup site1 user2  - mkdir /home/user2/public_html  - chown user2:site1 /home/user2/public_html  - Content of /home/user1/public_html/whoami.pl and /home/user2/public_html/whoami.pl:   #!/usr/bin/perl   print 'Content-type: text/plain/n/n';   system 'whoami';  - chown user1:site1 /home/user1/public_html/whoami.pl  - chmod 755 /home/user1/public_html/whoami.pl  - chown user2:site1 /home/user2/public_html/whoami.pl  - chmod 755 /home/user2/public_html/whoami.pl   Open http://floeff3 => 'user1' is being printed Open http://floeff3/~user2/ => Internal Server Error with  [2004-04-29 16:01:36]: target uid/gid (1002/1004) mismatch with directory (1003/1004) or program (1003/1004)   # id user1 uid=1002(user1) gid=1004(site1) groups=1004(site1)  # id user2 uid=1003(user2) gid=1004(site1) groups=1004(site1)   I have put the configuration changes I've made together in the attached patch file which you should use against /usr/local/apache2/httpd.conf  Please let me know if you need anything else. Thanks for taking the time. ;-) Created an attachment (id=11376) patch for the original httpd.conf file  Thanks, that's clearer.  But there is still some stuff which I assume is irrelevant to your problem, like the mod_rewrite directives and the UserDir disabled stuff.  Does your problem go away if you remove those?  Unfortunately, I don't have a unix system available to test on at the moment.  I've looked at the code, and it appears to me that when both SuexecUserGroup and mod_userdir is active, there is no defined ordering between the get_suexec_identity hooks.  So perhaps the userdir suexec stuff doesn't work at all if SuexecUserGroup is present.  In that case, simply fixing the hook ordering could fix the problem. Thanks for your fast reply! I've set the following lines (in the patch) to the httpd.conf defaults:  === -UserDir public_html +#UserDir public_html +UserDir disabled +UserDir disabled root [...] +RewriteEngine on +RewriteOptions inherit [...] +Userdir enabled user2 ===  I still get an Internal Server Error, so they don't seem to have anything to do with the problem. ;-)  Is there anything else you need or did I sent all information necessary to fix the bug? Here's a wild guess:  Index: mod_userdir.c =================================================================== RCS file: /home/cvs/httpd-2.0/modules/mappers/mod_userdir.c,v retrieving revision 1.52.2.4 diff -u -d -b -r1.52.2.4 mod_userdir.c --- mod_userdir.c       9 Feb 2004 20:53:19 -0000       1.52.2.4 +++ mod_userdir.c       29 Apr 2004 15:38:30 -0000 @@ -350,7 +350,7 @@        ap_hook_translate_name(translate_userdir,aszPre,aszSucc,APR_HOOK_MIDDLE);  #ifdef HAVE_UNIX_SUEXEC -    ap_hook_get_suexec_identity(get_suexec_id_doer,NULL,NULL,APR_HOOK_MIDDLE); +    ap_hook_get_suexec_identity(get_suexec_id_doer,NULL,NULL,APR_HOOK_FIRST);  #endif  }   If that isn't it, you'll have to wait for another developer to look at it, since I don't have the resources to do suexec testing. Thanks Joshua, this one seems to work! I've tested it locally, and I have no problems anymore! ;-)  Will this bugfix be incorporated in 2.0.50? I won't commit this myself, since I can't test it.  But another developer will hopefully pick it up.  This could be considered a non-compatible change, since there is a chance someone might be relying on SuexecUserGroup taking precedence of UserDir for suexec.  But this change should get us closer to the way it worked in 1.3, and it makes sense to me as the expected way things should work, so I think it should be committed. Okay :) Maybe you just have to make the change clear in the change log or add an option  for httpd.conf to choose between the 'new old' and the 2.0 default behaviour. Thanks again for your quick reply and great help, much appreciated! Where can I 'find' a developer to test and eventually contribute this to the CVS? :-) A workaround is to swap the order of the LoadModule lines for suexec and userdir.  I'll test Joshua's patch: it's hard to argue this is an incompatible change since the current behaviour is not defined so it's OK for 2.0 as well, I'd guess. Committed, will propose for backport.  Thanks for the report and thank you Joshua for the patch. Thanks a lot for implementing it! :-)			Andr?? Malo	Florian Effenberger	Hans	Joe Orton	Joshua Slive	Robert Heller
18332	null	CLOSED		Owen Rees	1048617660000	1049496566000		ErrorDocument CGI using Location: MUST also use Status. The custom error response documentation <http://httpd.apache.org/docs-2.0/custom-error.html> says that a CGI error document handler 'should' include a Status header, but if the script uses a Location: header it MUST also include a Status: 30x if the redirection is to have any effect. For example, if you want to hand off 404 errors to a different server this piece of (perl) script will work, but without the Status line, nothing appears to happen, and no errors are logged - the server sends the original 404 code to the client which then ignores the Location:.   $handoff = 'http://my.other.server/cgi-bin/from-old-server'; print 'Status: 301 Redirect permanent/n'; print 'Location: $handoff?url=$ENV{REDIRECT_URL}/n'; print '/n';	I've added a paragraph according to this issue.  Thanks.			Andr?? Malo
18348	null	CLOSED		Sander Holthaus	1048632360000	1083786385000		Errorlogging / STDERR from nph-cgi-scripts broken Non parsed header scripts are not able to log any errors or warnings to the  errorlog, while (almost) the same non-nph script will generate errors and  warnings for the same script.  example:   #!/usr/bin/perl -w use strict; $|=1; warn 'me'; print '$ENV{SERVER_PROTOCOL} 204 No Content/n'; print 'Server: $ENV{SERVER_SOFTWARE}/n'; print 'Date: $date/n'; exit;  will not log anything, while it should due to the warn in line 4.	Allegedly this scenario is handled by  http://www.apache.org/~trawick/mod_cgi.c  which handles the three I/O channels with the script in a more sane way, at least as unix-heads would see it.  Fixed on HEAD by extracting the relevant change from Jeff's mod_cgi.c (thanks Jeff!).  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/generators/mod_cgi.c?r1=1.162&r2=1.163  Backport of recent mod_cgi changes to 2.0 is here:  http://www.apache.org/~jorton/mod_cgi-2.0.diff			Jeff Trawick	Joe Orton
18443	null	CLOSED		Seairth Jacobs	1048830360000	1049653116000		 section is incorrect According to RFC2616 Section 14.1, specific types have a high precedence than  more general types at the same quality level:  ---begin_snippet--- Media ranges can be overridden by more specific media ranges or specific media  types. If more than one media range applies to a given type, the most specific  reference has precedence.    Accept: text/*, text/html, text/html;level=1, */*  have the following precedence:    1) text/html;level=1   2) text/html   3) text/*   4) */* ---end_snippet---  As a result, the example given:  text/html, text/plain, image/gif, image/jpeg, */*  would read as 'I prefer text/html, text/plain, image/gif, or image/jpeg.  If  none of those are available, then give me anything you might have.'  It is not necessary to give */* a lower quality level.  Technically, the  outcome will be the same.  But the assertion is incorrect to start with.	OK.  Thanks.  I've toned down that text so that it is no longer misleading.			Joshua Slive
18452	null	CLOSED		Skeuomorph	1048838160000	1049224517000		Garbled text in documentation Currently posted:          logfile           The path plus basename  of  the  logfile.   If  logfile           includes  any  Otherwise,  the  suffix  .nnnnnnnnnn  is           automatically added and is the time in  seconds.   Both           formats  compute  the  start time from the beginning of           the current period.  Found what appears to be the correct text in Tru64 Unix docs  Apache 'rotatelogs' man page:      logfile        The path plus basename of the logfile.  If logfile includes any %        characters, it is treated as a format string for strftime(3).        Otherwise, the suffix .nnnn is automatically added and is the time at        which the logfile was created.  Also, 'Severity' drop down on this bug submit page is missing 'Trivial'.	This is fixed in CVS and will be soon available on the website.  See: http://cvs.apache.org/viewcvs/httpd-2.0/docs/man/rotatelogs.8  Thanks for your report and for using Apache 2!			Erik Abele
18623	null	CLOSED		Christof Barth	1049308020000	1049494346000		ProxyBadHeader  directive not documented The rather new ProxyBadHeader directive is not documented. At least yields a search for 'ProxyBadHeader' on the apache site no results and I could not find it under the directives list.	Ah yeah, somehow it was forgotten. assigned ... The directive is now documented. You can find it online at <http://httpd.apache.org/docs-2.0/mod/mod_proxy.html#proxybadheader>.  Thanks for your care and thanks for using Apache.			Andr?? Malo
18628	null	CLOSED		Joshua Colvin	1049321100000	1069438513000		Obsolete comment re-committed *** proxy_util.c        9 Jun 2001 10:36:03 -0000       1.98 --- proxy_util.c        21 Sep 2001 09:04:19 -0000      1.99 *************** *** 290,298 ****         return 'Bad IP address in URL';       }    - /*    if (strchr(host,'.') == NULL && domain != NULL) -    host = pstrcat(p, host, domain, NULL); -  */       *urlp = url;       *hostp = host;  ---------------------------- revision 1.99 date: 2001/09/21 09:04:19;  author: martin;  state: Exp;  lines: +0 -3 Remove obsolete comment =============================================================================    But it was added back in later: =================================================================== RCS file: /home/cvspublic/apache-1.3/src/modules/proxy/proxy_util.c,v retrieving revision 1.100 retrieving revision 1.101 diff -b -B -c -r1.100 -r1.101 *** proxy_util.c        24 Sep 2001 20:14:27 -0000      1.100 --- proxy_util.c        18 Jan 2002 20:26:58 -0000      1.101 *************** *** 290,295 **** --- 290,298 ----           return 'Bad IP address in URL';       }  + /*    if (strchr(host,'.') == NULL && domain != NULL) +    host = pstrcat(p, host, domain, NULL); +  */       *urlp = url;       *hostp = host;  *************** .....  ---------------------------- revision 1.101 date: 2002/01/18 20:26:58;  author: chuck;  state: Exp;  lines: +585 -437 The rest of the proxy http 1.1 switch =============================================================================	Thanks for the research!  I've removed the code. 			Jeff Trawick
18649	null	CLOSED		Dan Harkless	1049365980000	1049370953000		--enable-layout broken in 2.0.45 In 2.0.45, --enable-layout no longer works.  The argument you give gets  incorrectly looked up in the ./srclib/apr/config.layout file rather than just  the ./config.layout file, and configure fails.  Same problem would likely occur  with ./srclib/apr-util/config.layout as well, if it were able to get that far.	A fix for this has been committed to 2.1-dev and will be suggested for merging into 2.0.46-dev.  Here is the fix:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/configure.in.diff?r1=1.246&r2=1.247  Thanks for your report, and I'm sorry that this was broken in 2.0.45.  The regression was discovered at the last minute, and due to the high severity of some of the issues resolved by 2.0.45 it was felt that it was best to get 2.0.45 out the door. this has now been merged into 2.0.46-dev. 			Jeff Trawick
18959	null	CLOSED		Andrew Fried	1050077640000	1092400753000		Apache finds old ap header files before new ones and compile fails I'm running a FreeBSD 5.0 'CURRENT' system.  When attempting to compile 2.0.45,  I'm receiving the following error:  /bin/sh /tmp/httpd-2.0.45/srclib/apr/libtool --silent --mode=compile gcc  -g - O2    -D_REENTRANT -D_THREAD_SAFE -DAP_HAVE_DESIGNATED_INITIALIZER   - I/tmp/httpd-2.0.45/srclib/apr/include -I/tmp/httpd-2.0.45/srclib/apr- util/include -I/usr/local/include -I. -I/tmp/httpd-2.0.45/os/unix -I/tmp/httpd- 2.0.45/server/mpm/prefork -I/tmp/httpd-2.0.45/modules/http -I/tmp/httpd- 2.0.45/modules/filters -I/tmp/httpd-2.0.45/modules/proxy -I/tmp/httpd- 2.0.45/include -I/tmp/httpd-2.0.45/modules/dav/main  -c /tmp/httpd- 2.0.45/server/exports.c && touch /tmp/httpd-2.0.45/server/exports.lo /tmp/httpd-2.0.45/server/exports.c:145: "ap_get_module_config' undeclared here  (not in a function) /tmp/httpd-2.0.45/server/exports.c:146: "ap_set_module_config' undeclared here  (not in a function) /tmp/httpd-2.0.45/server/exports.c:486: "ap_strchr' undeclared here (not in a  function) /tmp/httpd-2.0.45/server/exports.c:487: "ap_strchr_c' undeclared here (not in a  function) /tmp/httpd-2.0.45/server/exports.c:488: "ap_strrchr' undeclared here (not in a  function) /tmp/httpd-2.0.45/server/exports.c:489: "ap_strrchr_c' undeclared here (not in  a function) /tmp/httpd-2.0.45/server/exports.c:490: "ap_strstr' undeclared here (not in a  function) /tmp/httpd-2.0.45/server/exports.c:491: "ap_strstr_c' undeclared here (not in a  function) *** Error code 1  Stop in /tmp/httpd-2.0.45/server. *** Error code 1  Stop in /tmp/httpd-2.0.45/server. *** Error code 1  Stop in /tmp/httpd-2.0.45.	can you show your configure invocation, along with any env vars such as CFLAGS that might affect the build?  did you run buildconf or use the included configure script/libtool?  thanks!  The compilation was attempted using both the FreeBSD 'ports' script as well as  manually being downloaded, extracted, etc.  I made no changes to the  environment variable with the exception of specifying a prefix directory.  I  also attempted it without the prefix directory setting, same error message.  The contents of the systems 'make.conf' file is: # -- use.perl generated deltas -- # # Created: Tue Mar  4 15:19:35 2003 # Setting to use base perl from ports: PERL_VER=5.6.1 PERL_VERSION=5.6.1 PERL_ARCH=mach NOPERL=yo NO_PERL=yo NO_PERL_WRAPPER=yo   And my environment is: _       more make.conf  addsuffix argv    () cwd     /etc dirstack        /etc echo_style      bsd edit filec gid     0 group   wheel history 100 home    /root killring        30 loginsh mail    /var/mail/root owd     /root path     (/sbin /bin /usr/sbin /usr/bin /usr/games /usr/local/sbin /usr/local/bin /usr/X1 1R6/bin /root/bin) prompt  WEBSERVER#  prompt2 %R?  prompt3 CORRECT>%R (y|n|e|a)?  savehist        100 shell   /bin/csh shlvl   1 status  0 tcsh    6.12.00 term    vt100 tty     ttyp0 uid     0 user    root version tcsh 6.12.00 (Astron) 2002-07-23 (i386-intel-FreeBSD) options  8b,nls,dl,al,kan,sm,rh,color,dspm,filec  Finally, I used the builtin configure script.  I noticed a patch had been  published, so I also attempted patching the program, running buildconf and then  config.  Same error during compilation.  Good luck, and thanks for looking into this!   works for me on FreeBSD 5.0-RELEASE...  wget tarball tar -xzf httpd-2.0.45.tar.gz cd httpd-2.0.45 ./configure --prefix=/tmp/2045 (some autoconf complaints about permissions but everything else okay) make && make install  Hmmm...  Any chance you have apache header files in /usr/local/include from some previous install?  /usr/local/include is getting searched before /tmp/httpd- 2.0.45/include. My system did have older files located under /usr/local/include.  I removed  those files and the compilation worked flawlessly.  I've been using Apache for  six or seven years and never knew that it looked outside it's temp directory  when compiling.  I don't know if I feel more relieved or stupid...    Thank you VERY, VERY much.  Sorry to have wasted your time with my erroneous  bug report.  Andrew  This is something that at least a few people have hit.  Apache or apr-util or apr may need to look for include files in /usr/local/include, or other places where old Apache header files could have been installed, when using external libraries (zlib, berkeley db, openssl, whatever).  It would be nice if the search order for Apache was  apache-source-directories apr-include-directories apr-util-include-directories  (order not important for these first three)  followed by any directories needed for libraries used by apache or apr or apr-util.  That would get rid of this problem.  *** Bug 23485 has been marked as a duplicate of this bug. *** *** Bug 30208 has been marked as a duplicate of this bug. *** Fixed in HEAD by ensuring that the 'apache-source-directories' come first in INCLUDES, which should be sufficient to fix most of these cases. *** Bug 42357 has been marked as a duplicate of this bug. ***			Andrew Fried	Jean-Francois Gobin	Jeff Trawick	Joe Orton
19012	null	CLOSED		Tony Fan	1050354060000	1055903567000		mod_so can not be actived in AIX 5.1 Hi,        I tried to build Apache 2.0.45 in my AIX 5.1 system.  here is what I start to build: ./configure --enable-ssl=shared / --with-ssl=/usr/local/ssl / --enable-rule=SHARED_CORE / --enable-module=so  everything is working fine then I do make no error make install no error but when I relized mod_so doesn't work I went beck to check the config.log file. it is showed: .......... configure:14313: checking whether to enable mod_userdir configure:14351: result: yes (default) configure:14399: checking whether to enable mod_alias configure:14437: result: yes (default) configure:14486: checking whether to enable mod_rewrite configure:14524: result: no configure:14618: checking whether to enable mod_so configure:14656: result: configure:15020: checking whether byte ordering is bigendian ..........  somehow mod_so module can not be turned on  --Tony	Try --enable-so or --enable-modules=so  (Have I mentioned how annoying it is that you can --enable-whatever-you-want without getting an  error message; yes, I think I have.) Also, drop the --enable-rule=SHARED_CORE argument.  That too is Apache-1.3-style configure argument which means nothing to Apache 2.0.  (But I suspect you have mod_so anyway...  mod_so defaults to on for most systems (including AIX 5.1)...  Try ./httpd -l and see if mod_so.c is in the output.)  Also, there is a bug in the message generation.  As you noticed, nothing is printed in the expected position to say yes or no or shared.  Thank you for the information.  I recomplired Aapche,  I check httpd -l to make  sure I had mod_so,  but after I used JRun 4 connector to configure with Apache. here is the error I am getting. # ./apachectl start Syntax error on line 1037 of /usr/local/apache2/conf/httpd.conf: Cannot load /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so into server:   here is line 1037 from httpd.conf: LoadModule jrun_module /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so  this error most likely is mod_so doesn't work.  any ideal? Ehm no, the error probably says, that mod_jrun doesn't work with that httpd version.    Syntax error on line 1037 of /usr/local/apache2/conf/httpd.conf:   Cannot load /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so into server:    <here is the interesting part>  what is the interesting message? Unfortunately, some Apache modules don't build properly on AIX and an inability to load them is a frequent symptom.  See my fun at trying to get some Tomcat connectors to build properly  on AIX: http://www.apache.org/~trawick/tomcataix.html  Send me privately the output of 'dump -Tv mod_jrun20.so' and 'dump -Hv mod_jrun20.so' and I'll maybe have a guess as to why they won't load.  Here is result for dump -Tv mod_jrun20.so:  # dump -Tv /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so  /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so:                          ***Loader Section***                          ***Loader Symbol Table Information*** [Index]      Value      Scn     IMEX Sclass   Type           IMPid Name  [0]     0x00000000    undef      IMP     DS EXTref               . ap_add_cgi_va rs [1]     0x00000000    undef      IMP     DS EXTref               . ap_add_common _vars [2]     0x00000000    undef      IMP     DS EXTref               . ap_destroy_su b_req [3]     0x00000000    undef      IMP     DS EXTref               . ap_get_client _block [4]     0x00000000    undef      IMP     DS EXTref               . ap_log_error [5]     0x00000000    undef      IMP     DS EXTref               . ap_os_escape_ path [6]     0x00000000    undef      IMP     DS EXTref               . ap_rflush [7]     0x00000000    undef      IMP     DS EXTref               . ap_rwrite [8]     0x00000000    undef      IMP     DS EXTref               . ap_set_conten t_length [9]     0x00000000    undef      IMP     DS EXTref               . ap_setup_clie nt_block [10]    0x00000000    undef      IMP     DS EXTref               . ap_should_cli ent_block [11]    0x00000000    undef      IMP     DS EXTref               . ap_sub_req_lo okup_uri [12]    0x00000000    undef      IMP     UA EXTref   libc.a(shr.o) errno [13]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) close [14]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) socket [15]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) send [16]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) recv [17]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) setsockopt [18]    0x00000000    undef      IMP     UA EXTref   libc.a(shr.o) _system_confi guration [19]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) free [20]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) malloc [21]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strlen [22]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fopen [23]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strncasecmp [24]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) atoi [25]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strchr [26]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strtok [27]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fclose [28]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) memset [29]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) vsprintf [30]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) sprintf [31]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fwrite [32]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strncmp [33]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) tolower [34]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fread [35]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strdup [36]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) ftell [37]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fseek [38]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) time [39]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) gettimeofday [40]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strstr [41]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) srand [42]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) rand [43]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strerror [44]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) connect [45]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) inet_addr [46]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strcasecmp [47]    0x20000580    .data      EXP     RW SECdef        [noIMid] jrun_module [48]    0x200005b8    .data      EXP     RW SECdef        [noIMid] jrMetrics [49]    0x200005c0    .data      EXP     RW SECdef        [noIMid] VARIABLE_NAME S [50]    0x2000089c    .data      EXP     DS SECdef        [noIMid] loadServersFr omStore [51]    0x200008a8    .data      EXP     DS SECdef        [noIMid] mappingsTable New [52]    0x200008b4    .data      EXP     DS SECdef        [noIMid] mappingsTable Delete [53]    0x200008c0    .data      EXP     DS SECdef        [noIMid] init_jrun_req uest [54]    0x200008cc    .data      EXP     DS SECdef        [noIMid] retrieveServe rsFromServer [55]    0x200008d8    .data      EXP     DS SECdef        [noIMid] persistServer s [56]    0x200008e4    .data      EXP     DS SECdef        [noIMid] longerThan [57]    0x200008f0    .data      EXP     DS SECdef        [noIMid] removePathPar ms [58]    0x200008fc    .data      EXP     DS SECdef        [noIMid] jrunProxyNew [59]    0x20000908    .data      EXP     DS SECdef        [noIMid] startSync [60]    0x20000914    .data      EXP     DS SECdef        [noIMid] gtod [61]    0x20000920    .data      EXP     DS SECdef        [noIMid] tvToMillis [62]    0x2000092c    .data      EXP     DS SECdef        [noIMid] stopSync [63]    0x20000938    .data      EXP     DS SECdef        [noIMid] initSync [64]    0x20000944    .data      EXP     DS SECdef        [noIMid] getPropertyVa lue [65]    0x20000950    .data      EXP     DS SECdef        [noIMid] freePropertie s [66]    0x2000095c    .data      EXP     DS SECdef        [noIMid] describeError [67]    0x20000968    .data      EXP     DS SECdef        [noIMid] parseProperti es [68]    0x20000974    .data      EXP     DS SECdef        [noIMid] getSession [69]    0x20000980    .data      EXP     DS SECdef        [noIMid] addProperty [70]    0x2000098c    .data      EXP     DS SECdef        [noIMid] removePropert yByIndex [71]    0x20000998    .data      EXP     DS SECdef        [noIMid] removePropert y [72]    0x200009a4    .data      EXP     DS SECdef        [noIMid] setProperty [73]    0x200009b0    .data      EXP     DS SECdef        [noIMid] getPropertyVa lue3 [74]    0x200009bc    .data      EXP     DS SECdef        [noIMid] getPropertyVa lue2 [75]    0x200009c8    .data      EXP     DS SECdef        [noIMid] freePropertie s1 [76]    0x200009d4    .data      EXP     DS SECdef        [noIMid] parseProperti es1 [77]    0x200009e0    .data      EXP     DS SECdef        [noIMid] loadPropertie s1 [78]    0x200009ec    .data      EXP     DS SECdef        [noIMid] loadPropertie s [79]    0x200009f8    .data      EXP     DS SECdef        [noIMid] getServerId [80]    0x20000a04    .data      EXP     DS SECdef        [noIMid] getNextBuddy [81]    0x20000a10    .data      EXP     DS SECdef        [noIMid] freeSync [82]    0x20000c78     .bss      EXP     RW    BSS        [noIMid] jrun_rootdir [83]    0x00000000    undef      IMP     DS EXTref              .. apr_palloc [84]    0x00000000    undef      IMP     DS EXTref              .. apr_table_add [85]    0x00000000    undef      IMP     DS EXTref              .. apr_table_set [86]    0x00000000    undef      IMP     DS EXTref              .. apr_pstrdup [87]    0x00000000    undef      IMP     DS EXTref              .. apr_table_get [88]    0x00000000    undef      IMP     DS EXTref              .. apr_pstrcat [89]    0x00000000    undef      IMP     DS EXTref              .. ap_hook_post_ config [90]    0x00000000    undef      IMP     DS EXTref              .. ap_hook_child _init [91]    0x00000000    undef      IMP     DS EXTref              .. ap_hook_type_ checker [92]    0x00000000    undef      IMP     DS EXTref              .. ap_hook_handl er [93]    0x00000000    undef      IMP     DS EXTref              .. ap_run_http_m ethod [94]    0x00000000    undef      IMP     DS EXTref              .. apr_table_elt s [95]    0x00000000    undef      IMP     DS EXTref              .. apr_table_set n [96]    0x00000000    undef      IMP     DS EXTref              .. apr_pool_clea nup_register   -------------------------------------------------------------------------------- Here is a result for dump -Hv /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so:  # dump -Hv /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so  /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so:                          ***Loader Section***                       Loader Header Information VERSION#         #SYMtableENT     #RELOCent        LENidSTR 0x00000001       0x00000061       0x00000149       0x00000038  #IMPfilID        OFFidSTR         LENstrTBL        OFFstrTBL 0x00000004       0x000018a4       0x00000470       0x000018dc                           ***Import File Strings*** INDEX  PATH                          BASE                MEMBER 0      /usr/lib/threads:/usr/lib:/lib 1                                    libc.a              shr.o 2                                    . 3                                    .. dang it, I think it is a build problem related to the display issue you noted back at square one...  your DSO looks great  try this:  $ cd /path/to/httpd-2.0.45 $ grep HTTPD_LDFLAGS build/config_vars.mk  I bet the output is simply  HTTPD_LDFLAGS =   when it should be something similar to   HTTPD_LDFLAGS = -Wl,-uXML_Parse -Wl,-bE:/path/to/server/httpd.exp  The lack of the weird '-Wl,-bE:' option means that httpd doesn't export the Apache API to DSOs, subsequently leading to DSOs failing to load.  Depending on how mod_so gets enabled, the variable $enable_so may or may not get set, and if it isn't set then the right LDFLAGS for linking httpd don't get initialized.  If you verify that HTTPD_LDFLAGS is an empty string, here is a work-around that worked for me:  Add '--enable-so' to your Apache configure invocation, as in  make distclean && ./configure --enable-so --other-opts && make && make install  By explicitly turning on mod_so (using the Apache 2 option this time :) ), we avoid the bug. This has been fixed in 2.1-dev, and if nobody complains about the fix in the next few days I'll propose it for merging into 2.0.46-dev.  Until then, specify --enable-so.  I recompiled as your suggection.  after that I check: 1. config.log (I can see mod_so turned on YES) 2. HTTPD_LDFLAGS = -Wl,-uXML_Parse -Wl,-bE:/path/to/server/httpd.exp 3. httpd -l showed mod_so  but when I start up Aapche still got same error. # ./apachectl start Syntax error on line 1037 of /usr/local/apache2/conf/httpd.conf: Cannot load /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so into server:   plz send me off-line (trawick@apache.org) the output of   dump -Tv /path/to/new/httpd  (the one picked up by your still-failing ./apachectl start)  ISTR hearing off-line that the Apache build was corrected with the --enable-so work-around, and that further work was going to be done with the 3rd-party module build to see why it wasn't loading.  Re-open the PR if there is still a problem with httpd not exporting symbols. 			Andr?? Malo	Jeff Trawick	Joshua Slive	Tony Fan
19023	null	CLOSED		Sami Tikka	1050398520000	1050423112000		Multiple ProxyBlock entries will crash Apache Set up Apache 2.0.45 or earlier to function as a proxy server. Block more than one site with the NoProxy directive. Make the proxy serve a URL which does not match the blocked sites. Observe Apache die.  The problem was identified to routine ap_proxy_checkproxyblock. It has 3 nested loops. If the innermost loop is run to completion, uri_addr is set to NULL, which is then used on the next iteration of the outer loop. The patch below fixes the problem.  --- proxy_util.c\t14 Apr 2003 09:49:53 -0000\t1.3 +++ proxy_util.c\t14 Apr 2003 14:21:42 -0000\t1.4 @@ -1015,10 +1015,12 @@                               apr_sockaddr_t *uri_addr)  {      int j; +\tapr_sockaddr_t * src_uri_addr = uri_addr;      /* XXX FIXME: conf->noproxies->elts is part of an opaque structure */      for (j = 0; j < conf->noproxies->nelts; j++) {          struct noproxy_entry *npent = (struct noproxy_entry *) conf->noproxies->elts;          struct apr_sockaddr_t *conf_addr = npent[j].addr; +\t\turi_addr = src_uri_addr;          ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, r->server,                       'proxy: checking remote machine [%s] against [%s]', uri_addr->hostname, npent[j].name);          if ((npent[j].name && ap_strstr_c(uri_addr->hostname, npent[j].name))	Err... my mistake... The bug happens when iterating the conf->noproxies table, which is initialized from ProxyBlock directive, not NoProxy like I claimed before. Otherwise the previous report is accurate. Patch applied to v2.0.46 and v2.1.0 			Graham Leggett	Sami Tikka
19084	null	CLOSED		Nojan Moshiri	1050515940000	1052485239000		Commenting convention in util_ldap.c and mod_auth_ldap.c incompatible with some compilers We're seeing increasing incidents were comments in C code are using // instead of '/* */' which is incompatible with Sun WorkShop compilers.  We can modify this through flags or just fixing the code manually, but it just seems like it would be nice if commenting was consistent and used /* */ in all cases.  This is a very minor annoyance but would be unfortunate if it kept expanding to other bits of the code.  Specifically, in util_ldap.c Line 444: change //l=NUL;L to:  /* l = NULL; */  and mod_auth_ldap.c line 156 I believe.  Thanks	   Never fear, these are absolute violations of our style guide.    I will go axing this weekend if nobody has beaten me to it.   fix committed, thanks!  the fix will be in 2.0.46			Jeff Trawick	Will Rowe
19175	null	CLOSED		Jonas	1050792720000	1052100508000		Two errorcodes point to same errordocument Minor typo found in httpd.conf  Errorcodes 415 and 503 points to same file.  #    ErrorDocument 415 /error/HTTP_SERVICE_UNAVAILABLE.html.var #    ErrorDocument 503 /error/HTTP_SERVICE_UNAVAILABLE.html.var	Changed the entries.  Thanks for your care and thanks for using Apache!			Andr?? Malo
19207	null	CLOSED		Matthew Darwin	1050974760000	1051023469000		Redirection broken under IPv6 http://[3ffe:b00:4041:ace0:260:f8ff:fe03:bc9]/resources should redirect to http://[3ffe:b00:4041:ace0:260:f8ff:fe03:bc9]/resources/  (add slash).  Intstead it seems to redirect to: http://3ffe:b00:4041:ace0:260:f8ff:fe03:bc9/resources/  (remove square brackets and add slash).  This, of course, does not resolve.	Created an attachment (id=5943) proposed patch for PR 19207 (build URL from IPv6 literal)  Please try the attached patch and report back.  Thanks for your report!  Issue is resolved with given patch on Apache/2.0.45. Thanks for the quick feedback.  The fix you tested has been committed to Apache 2.1-dev.  If the fix doesn't  prove to be problematic to others, I'll propose it for merging into the  next stable release (e.g., 2.0.46).			Jeff Trawick	Matthew Darwin
19242	null	CLOSED		Mike	1051064820000	1068212996000		Problem Reverse Proxying HTTPS site We are currently having an issue where we are reverse proxying an HTTPS site  using Apache.  Every second request to the site (via the rev proxy) fails with  a 500 Internal Server Error.  I have done various debugging such as snoops,  trusses and debug apache logging.  What seems to happen is the first (successful) request works as expected,  however when the second request is sent, the SSL session between the client and  proxy is set up okay, but the SSL connection between the proxy and backend  server has problems.  Basically it (the proxy) sets up the TCP session okay,  sends an SSL Client Hello, but then almost straight away sends a FIN.  I then looked at the apache error log, with full debugging enabled to see why  the proxy would send a client hello, and then straight away send a FIN.  It  seems that there is an issue with an SSL BIO being logged.  It says that 0/7  bytes are being read from the BIO whenever the connection is failing.  However,  when there is a successful connection it reads 7/7 bytes at this same part of  the conversation.  I have also done a truss of a successful vs unsuccessful connection.  When  successful, the httpd process is doing a read, getting an 'Err#11 Eagain'  error, doing a poll, redoing the read, but this time without error.  However on  an unsuccessful connection, the httpd process does the same initial read, gets  the same 'Err#11 Eagain' error, but does not do the poll or reread.   I have verified this exact same behaviour on the following: Solaris 2.6 with Apache 2.0.44 OpenSSL 0.9.7 Solaris 8 with Apache 2.0.44 OpenSSL 0.9.7 (32bit) Solaris 8 with Apache 2.0.45 OpenSSL 0.9.7a (32bit) Solaris 8 with Apache 2.0.45 OpenSSL 0.9.7a (64bit)  I have also tried on both a SunBlade 100 and E450 platform, each with identical  results.  I have tried both prefork and worker mpms with identical results.  I have found that the only workaround (which is very ugly) is to set the  MaxRequestsPerChild to 1.    I have also played with virtually every setting I can think of, particularly  the SSLMutex and AcceptMutex settings.  Nothing other that the above workaround  seems to affect this problem.  Any ideas would be greatly appreciated?	Sorry - forgot the build info..  Server version: HTTPD/1.0.0 Server built:   Apr  8 2003 20:01:30 Server's Module Magic Number: 20020903:0 Architecture:   64-bit Server compiled with....  -D APACHE_MPM_DIR='server/mpm/prefork'  -D APR_HAS_SENDFILE  -D APR_HAS_MMAP  -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)  -D APR_USE_PROC_PTHREAD_SERIALIZE  -D APR_USE_PTHREAD_SERIALIZE  -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT  -D APR_HAS_OTHER_CHILD  -D AP_HAVE_RELIABLE_PIPED_LOGS  -D HTTPD_ROOT='/opt/apache'  -D SUEXEC_BIN='/opt/apache/bin/suexec'  -D DEFAULT_PIDLOG='logs/httpd.pid'  -D DEFAULT_SCOREBOARD='logs/apache_runtime_status'  -D DEFAULT_LOCKFILE='logs/accept.lock'  -D DEFAULT_ERRORLOG='logs/error_log'  -D AP_TYPES_CONFIG_FILE='conf/mime.types'  -D SERVER_CONFIG_FILE='conf/httpd.conf' Created an attachment (id=6299) Initialise the 'block' and 'mode' members of bio_filter_in_ctx_t  The problem was eventually tracked down. I traced it back to the  'block' member of the 'bio_filter_in_ctx_t' structure not being initialized before being used. So I added initializatoins for the 'block' member and the 'mode' member (also not initialized but didn't contribute to our problem) to the 'ssl_io_input_add_filter' function.  Of interest, the unitialized values ended up being bad after a SSL connection to a MicroSoft ISA server. The ISA server doesn't send a 'close_notify' at the end of the session.     David, the issue with your patch is that we properly initialize within   the input filter, but never properly initialized the blocking mode in   the output filter.  The output filter must always block for a complete   handshake or other activity, so you will find the appropriate patches   with modules/ssl/ssl_engine_io.c rev 1.106, credited to both your initial   efforts and my patch.    This is not yet backported.  Would you test the attached patch against your   Apache 2.0 build and confirm the patch resolves your problem? The fixes for this were included in 2.0.48. *** Bug 20785 has been marked as a duplicate of this bug. ***			David Deaves	Joe Orton	Mike	Will Rowe
19304	null	CLOSED		Bradley Schwoerer	1051241520000	1085155123000		MODLDAP_SHMEM_CACHE location Just as an FYI.  Could it be stated for windows (or all OSs) in the  documentation that the /tmp folder needs to be created on the drive that apache  is installed on.  This is an issue because by default windows does not have a  tmp folder in the root of the drive.  Another solution would be to make a  config option for the location.  If someone would like I could take a stab at  coding that option.	Another option would be to put this under the logs sub-directory like many  other Apache MM-like usages do. This appears to be a duplicate of 20242. *** Bug 20242 has been marked as a duplicate of this bug. *** No, we're trying to deprecate the usage of the logs dir for anything but logging. It should use the localstatedir, it being, after all, local state. Where is localstatedir and is it in fact guaranteed to exist (like the logs dir  is)?  [For now I've patched my Apache 2.0.46 to put this in logs, until a better home  which is guaranteed to exist 'out-of-the-box' (without additional  configuration) can be found for it.] Additionally:  Whatever localstatedir is supposed to be, using a hard-coded absolute path is a  non-starter.  Why?  Though it is certainly not recommended, there are times  where one must run 2 Apache's on one system (and even on one drive on Windows).  Thus the path use should be configurable or relative to the Apache installation  directory.  The latter is easy and relatively foolproof.  If 'logs' is  verboten, then how about introducing a standard 'tmp' directory in the Apache  layout (complete with proper permission assignment in the binary installer,  etc) and using it?  Until that's done, I'll stick with using logs... Created an attachment (id=6969) mod_ldap shared mem location patch  this patch add a new directice LDAPSharedMemCache. with it you can specify the location of the shared mem cache within your httpd.conf enabling the PatchAvailable keyword updated doc on submitting patches is at http://httpd.apache.org/dev/patches.html  Does the LDAPSharedCacheFile directive solve this problem?  Yes the directive fixes the problem			Bradley Schwoerer	Graham Leggett	Jeff Trawick	Jess Holle	Markus Herzog	Thom May
19317	null	CLOSED		Sami Tikka	1051268700000	1088491563000		Proxy makes browser report redirection limit exceeded Configure Mozilla to use Apache as a proxy. Access the URL. Mozilla makes repeated requests and finally pops up a dialog saying: 'Redirection limit for this URL exceeded. Unable to load the requested page.'  I suspect the problem is caused by mod_proxy encoding the tilde characters in the URL. Watching the HTTP traffic with and without the proxy reveals that Mozilla sends the tilde unencoded and Apache encodes it with the corresponding percent sequence, which the remote website seems to find confusing. The website keeps sending redirections to the browser until the browser gives up.  I believe Apache proxy should send the URL in exactly the same format it received it. This might violate the RFC, but it would minimize interoperability problems like this.	Patch committed to HEAD; c.f. bug 15207			Nick Kew
19355	null	CLOSED		Geoffrey Young	1051404540000	1067811288000		mod_include allows invalid ETag headers this bug was first reported to dev@httpd.apache.org  http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=105120818606501&w=2  mod_include has an ETag bug when activated using XBitHack Full.  in general, default_handler generates an ETag header for documents it serves.  because embedded SSI tags have the ability to alter the content of a document, mod_include strips outgoing ETag headers from responses it enters.  however, the method by which mod_include strips these headers is insufficient in cases where default_handler decides a 304 is warranted.  consider the following series of requests when XBitHack is activated for a document in DocumentRoot (uninteresting headers snipped for brevity)  GET /ssi.html HTTP/1.1  HTTP/1.1 200 OK Last-Modified: Thu, 24 Apr 2003 16:50:50 GMT  -------------  GET /ssi.html HTTP/1.1 If-Modified-Since: Thu, 24 Apr 2003 16:50:50 GMT  HTTP/1.1 304 Not Modified Last-Modified: Thu, 24 Apr 2003 16:50:50 GMT ETag: '35157-5f-4861ce80'   while mod_include removes the ETag header from the first request, default_handler generates an (almost always invalid) ETag on the subsequent 304.  the below patch seems to be a better way for mod_include to handle ETag generation (or, rather, supression).   Index: modules/filters/mod_include.c =================================================================== RCS file: /home/cvspublic/httpd-2.0/modules/filters/mod_include.c,v retrieving revision 1.233 diff -u -r1.233 mod_include.c --- modules/filters/mod_include.c\t3 Feb 2003 17:53:01 -0000\t1.233 +++ modules/filters/mod_include.c\t24 Apr 2003 17:46:13 -0000 @@ -3338,6 +3338,12 @@          f->r->no_local_copy = 1;      }       +    /* Don't allow ETag headers to be generated - see RFC2616 - 13.3.4. +     * We don't know if we are going to be including a file or executing +     * a program - in either case a strong ETag header will likely be invalid. +     */ +    apr_table_setn(f->r->notes, 'no-etag', 1); +      return OK;  }   @@ -3407,14 +3413,13 @@       */      apr_table_unset(f->r->headers_out, 'Content-Length');   -    /* Always unset the ETag/Last-Modified fields - see RFC2616 - 13.3.4. +    /* Always unset the Last-Modified fields - see RFC2616 - 13.3.4.       * We don't know if we are going to be including a file or executing       * a program which may change the Last-Modified header or make the        * content completely dynamic.  Therefore, we can't support these       * headers.       * Exception: XBitHack full means we *should* set the Last-Modified field.       */ -    apr_table_unset(f->r->headers_out, 'ETag');        /* Assure the platform supports Group protections */      if ((*conf->xbithack == xbithack_full)	Well, fixed in 2.1 and proposed for backport. I've slightly modified your patch and used  apr_table_setn(f->r->notes, 'no-etag', '');  because the '1' pointer is not really portable and may cause bus errors on weird systems.  Thanks.			Andr?? Malo
19405	null	CLOSED		Co-Advisor	1051567140000	1075151518000		corruption of multiline response headers Looks like a possible RFC 2616 MUST violation.  A multiline response header is getting corrupted by the proxy when forwarded to the client. The header is using 'CRLF SP' or 'CRLF HT' LWS sequences to mark the start of the next line. See X-Multiline response header in the attached trace.  FWIW, similar request headers are handled correctly, only response headers seem to be corrupted. Also, response headers with just two lines are handled correctly, only long headers are corrupted.  See attached trace(s) for details and ways to reproduce the violation mentioned above.  Test case IDs in the trace link to human-oriented test case description and RFC quotes, if available.	Created an attachment (id=6068) test case trace -- 17-line response header  Thanks for the excellent report - this is now fixed in HEAD. *** Bug 34975 has been marked as a duplicate of this bug. ***			Co-Advisor	Joe Orton
19439	null	RESOLVED		Co-Advisor	1051646580000	1191912737000		proxy MUST append Via in responses Looks like a possible RFC 2616 MUST violation. The proxy inserts its Via information in the middle of the Via response header list instead of appending it at the end.  This violation does not happen when all old Via field-values are listed within one header (single field-name).  Also, the proxy seems to handle request headers correctly; only response headers are affected.  See attached trace(s) for details and ways to reproduce the violation mentioned above.  Test case IDs in the trace link to human-oriented test case description and RFC quotes, if available.	Created an attachment (id=6079) test case trace (3 old Vias in response)  Created an attachment (id=6080) test case trace (3 old Vias in request)  Created an attachment (id=14098) Patch  The problem is solved by adding this single line.  If a request gets to the server this function is called, and the header fields are pooled. This effects the via-fields as can be seen in the request-TestCase. If a response returns to the proxy server, this polling wasn't done, now it will be. Indeed, httpd-2.0.54 patched with the patch #14098  merges all Via response headers into one, appends its own Via, and passes the test case.  Fixed in r583155			Co-Advisor	Nick Kew	Robert
19512	null	CLOSED		Ben Laurie	1051785780000	1051912543000		s no error What it says on the tin...	This is not a bug. This behavior is documented at http://httpd.apache.org/docs/mod/core.html#allowoverride:  'Note: AllowOverride is only valid in <Directory> sections, not in <Location> or <Files> sections...'  Thanks for using Apache. That doesn't make it not a bug! If a configuration directive is used in a context in which it doesn't work, then an error should occur. <Location> and <Files> are caught with a warning now. <Directory[Match| ~]> is fun. I have no idea how to determine these cleanly.			Andr?? Malo	Astrid Ke??ler	Ben Laurie
19611	null	CLOSED		Cris Perdue	1051903920000	1052142016000		ssl.conf DocumentRoot does not match httpd.conf The generated ssl.conf and httpd.conf files each define DocumentRoot, but they do it differently, and unless the installation is built to make the DocumentRoot be ServerRoot/htdocs, they will not match. until one of them is hand-edited.  Apparent fixes would be to either generate DocumentRoot in ssl.conf to be the same as in httpd.conf, or perhaps better, to omit the DocumentRoot line entirely from ssl-std.conf.   cris@crisp4 httpd-2.0.45]$ grep DocumentRoot docs/conf/ssl-std.conf DocumentRoot '@@ServerRoot@@/htdocs'  [cris@crisp4 httpd-2.0.45]$ grep DocumentRoot docs/conf/httpd-std.conf.in DocumentRoot '@exp_htdocsdir@'	I'm just about to commit a fix for this; updating ssl-std.conf to use explicit paths. Fix commited, should be available in the next version of apache2. Thanks for the bug report!			Thom May
19626	null	CLOSED		Elmar Hoffmann	1052004480000	1052866390000		MIME-type rewriting of the actually returned MIMI-type does not work On Apache 1.3.27 I successfully use the following to set the MIME-type of XHTML files to text/html instead of the default application/xhtml+xml for browsers that can't handle the latter:  RewriteCond %{REQUEST_FILENAME} '/.xhtml$'                      [NC] RewriteCond %{HTTP_ACCEPT}      '!application/xhtml/+xml'       [OR] RewriteCond %{HTTP_ACCEPT}      'application/xhtml/+xml/s*;/s*q=0([^.]|$)' RewriteRule .*                  -                               [PT,T=text/html]  On Apache 2.0.44 and 2.0.45 this however does not work, ie. the XHTML files are always delivered with a Content-Type of application/xhtml+xml. I get the following rewrite log when simply fetching /index.xhtml with wget:  ::1 - - [08/Apr/2003:23:00:46 +0200] [wren.elho.net/sid#811a9d8][rid#846cdd8/initial] (4) RewriteCond: input='/index.xhtml' pattern='/.xhtml$' => matched ::1 - - [08/Apr/2003:23:00:46 +0200] [wren.elho.net/sid#811a9d8][rid#846cdd8/initial] (4) RewriteCond: input='*/*' pattern='!application/xhtml/+xml' => matched :1 - - [08/Apr/2003:23:00:46 +0200] [wren.elho.net/sid#811a9d8][rid#846cdd8/initial] (2) remember /index.xhtml to have MIME-type 'text/html' ::1 - - [08/Apr/2003:23:00:46 +0200] [wren.elho.net/sid#811a9d8][rid#846cdd8/initial] (1) pass  through /index.xhtml  This shows that the conditions work and the RewriteRule gets applied,                               but Apache either seems to 'forget' to actually set the MIME-type to                                text/html or something (some filter?) happening after mod_rewrite set                               it, sets it back again.                                                                             As for possibly interfering filters, disabling mod_deflate and                                      mod_headers didn't change anything.	It *may* work if you permute the LoadModule directives of mod_rewrite and mod_mime. Final fix is in progress.  Thanks for the report and thanks for using Apache. FYI: The fix has been merged into the stable tree and will be in the next release (2.0.46).			Andr?? Malo
19688	null	CLOSED		Marc M. Adkins	1052187180000	1095004368000		ap_fputs, ap_fputc, ap_fwrite pass wrong filter pointer to ap_filter_flush? Documentation for ap_fputc, etc. states that the filter argument is 'the filter  doing the writing'.  However, this filter argument is sent as the context for  ap_filter_flush via lower-level apr_ routines.  If an overflow occurs and  ap_filter_flush is called then the filter pointer is used as the target for  ap_pass_brigade by ap_filter_flush.  The result is that the brigade is passed  back to the originating filter, resulting in an infinite loop or other  nastiness.  EITHER the documentation in the source files needs to be changed to state that  the filter argument is 'the NEXT filter to which data should be passed in the  event of an overflow' OR each of the macros ap_fputc, ap_fputs, and ap_fwrite  needs to pass f->next instead of f as the context for any callbacks to  ap_filter_flush.  This can be re-created by building an output filter that generates over 8K of  data via the named macros.  Pass in the output filter's pointer (passed to the  filter handler) and see the bad thing.  Pass in the next filter and see it work  OK.  If this is a documentation glitch (including my misunderstanding it as written)  then it is minor.  If the doc (and my understanding thereof) is correct and the  macros need changing then it is major, as it prevents output filters which send  out more than 8K at a whack from functioning properly.	Somewhat belatedly I realized I should look for examples within the Apache code  body.  I found a call to ap_fwrite in server/protocol.c which passes f->next.   So the answer here is probably 'fix the documentation' (if not 'Marc you're an  idiot' ;).  I went back to Ryan Bloom's 09/2001 article on writing output filters  (http://www.onlamp.com/pub/a/apache/2001/09/13/apache_2.html) and it states  very clearly that the filter argument to all of these routines is filter- >next.  I had read this article, but apparently not with enough attention to  detail.  Then I went to the documentation line I quoted above in the source and  confused myself.  Sorry for registering a bug on this.  I still believe the doc should be fixed  and it is in fact taken from the code (as it should be).  I'm willing to do it  myself and submit diffs if requested.  Mea culpa, mea culpa, mea culpa. Diffs would be cool.  Attach em and I will look at committing them :) Definitely a documentation bug.  To change the code will break more-or-less every existing filter.  I'll do something with it if noone else gets there first. Committing documentation fix in CVS			Marc M. Adkins	Nick Kew	Paul Querna
19699	null	CLOSED		Ralf Hauser	1052229720000	1052417901000		Options docs should have more links When setting this in a file, e.g. a .bashrc etc. will not be listed. Say that it can't be done or what must be done to enable it. Thx	Please can you expand your description - the current bug report makes very little sense to me. In particular, explain exactly what you were trying to do, and which documentation you believe is incorrect or not full enough. OK, I have a directory with  rhauser@rhauserPCGF590K:~> ls -lart $m4d/public/tilde/ total 22 drwxr-xr-x    8 rhauser  mkgroup         0 Feb  5 06:19 .. drwxr-xr-x    3 rhauser  mkgroup         0 Mar 10 14:01 . drwxr-xr-x    2 rhauser  mkgroup         0 Mar 10 14:01 CVS -rw-r--r--    1 rhauser  mkgroup        79 Mar 10 14:49 .htaccess -rw-r--r--    1 rhauser  mkgroup       452 Mar 11 10:51 README.txt -rw-r--r--    1 rhauser  mkgroup      7125 Mar 24 14:13 ftl.el -rw-r--r--    1 rhauser  mkgroup      5530 Apr  4 13:14 .tcshrc -rw-r--r--    1 rhauser  mkgroup      3709 Apr 25 08:27 .bashrc -rw-r--r--    1 rhauser  mkgroup      2512 May  5 18:25 .emacs rhauser@rhauserPCGF590K:~>  .htaccess only contains one line:    Options +Indexes  When looking at it through apache,  I get only  <<Index of public/tilde   Name                     Last modified      Size  Description Parent Directory                              -     ftl.el                   06-May-2003 08:46  7.0K    Apache/2.0.40 Server at www.mydomain.com Port 443>> Check your httpd.conf for this line: IndexIgnore .??* *~ *# HEADER* README* RCS CVS *,v *,t  And see: http://httpd.apache.org/docs-2.0/mod/mod_autoindex.html#indexignore Thx - appears to work. Why 'invalid' - how about adding the valuable link you provided here also to the documentation (as it is hypertext, shouldn't cross-references be easy and welcome)? Ok.  There should be links there to mod_autoindex (for Indexes) and mod_cgi (for ExecCGI) and mod_include (for Includes). Fixed in cvs.			Joshua Slive	Ralf Hauser	Thom May
19753	null	CLOSED		Ryan O'Neill	1052362380000	1058025670000		Local exploit denial of service using DirectoryIndex in .htaccess In a directory configured with AllowOverride All in httpd.conf, this one line in a .htaccess will cause (what i perceive to be) an infinite loop in a single httpd process (using 100% cpu):  DirectoryIndex .  Subsequent reloads will cause more processes to start using as much cpu as they can muster.  My load starts going up and up and i imagine everything will start crashing eventually (if i don't take care of it by killing apache).  I'm running FreeBSD 4.8-STABLE with apache-2.0.45 installed from ports.	Fixed in 2.0.47. Thanks for the report, but a word for the future anyway: please address security related issues to security@apache.org.  Thanks.			Andr?? Malo
19794	null	CLOSED		Sander Holthaus	1052477040000	1071250381000		Apache does not send Expire-headers when requesting / When requesting a page like this:         GET / HTTP/1.1 Apache does not send an expire-header  When requesting it like this (same document as above):         GET /index.html HTTP/1.1 it does.  Configuration of the expire-header is done by MIME-type.          ExpiresByType text/html A86400	This PR has been fixed in the 2.1-dev branch and has been suggested for backporting to the 2.0 stable branch. Thank you for using Apache and for submitting this report.			Paul J. Reder
19849	null	CLOSED		Glenn Nielsen	1052746380000	1056399652000		If the mod_cgid daemon process dies it is never restarted System, Sun Netra T1, Solaris 7, Apache 2.0.45 with worker MPM.  When stress testing a binary cgi the mod_cgid daemon would die. After it had died Apache would detect and log that it had died with this message in the error_log, 'No such process: cgid daemon is gone; is Apache terminating?'.  It does not attempt to restart the cgi daemon process again so all subsequent CGI requests fail.  Apache 2 with the worker MPM for CGI would be more robust if mod_cgid could restart its child daemon process if it dies.	I have done some more research.  When the cgid_daemon dies I see the following error message, the pid is for the cgid_daemon:  [Wed May 28 11:05:59 2003] [notice] child pid 24470 exit signal Broken pipe (13)  I added some debug logging to the cgid_maint function in mod_cgid.c.  When the cgid_daemon dies with a broken pipe cgid_maint logged the following:  [Wed May 28 11:05:59 2003] [error] cgid_maint [Wed May 28 11:05:59 2003] [error] cgid_maint APR_OC_REASON_DEATH [Wed May 28 11:05:59 2003] [error] cgid_maint [Wed May 28 11:05:59 2003] [error] cgid_maint APR_OC_REASON_UNREGISTER [Wed May 28 11:05:59 2003] [error] cgid_maint DONE [Wed May 28 11:05:59 2003] [error] cgid_maint DONE  The code for doing a graceful restart is triggered when APR_OC_REASON_LOST is the reason, but this is never received by cgid_maint.  Here are all the log entries when I reproduced this: [Wed May 28 11:05:12 2003] [notice] Apache/2.0.45 (Unix) mod_ssl/2.0.45 OpenSSL/0.9.7a mod_jk/1.2.3 configured -- resuming normal operations [Wed May 28 11:05:12 2003] [info] Server built: May 15 2003 21:22:19 [Wed May 28 11:05:57 2003] [error] [client 207.160.133.9] Premature end of script headers: counterdate.cgi [Wed May 28 11:05:57 2003] [error] [client 207.160.133.9] unable to include '/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html [Wed May 28 11:05:57 2003] [info] (32)Broken pipe: core_output_filter: writing data to the network [Wed May 28 11:05:58 2003] [info] (32)Broken pipe: core_output_filter: writing data to the network [Wed May 28 11:05:58 2003] [info] (32)Broken pipe: core_output_filter: writing data to the network [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of script headers: counter.cgi [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include '/cgi/counter.cgi' in parsed file /export/home/moxp/www/www/index.html [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of script headers: counterdate.cgi [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include '/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of script headers: counterdate.cgi [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include '/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of script headers: counterdate.cgi [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include '/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of script headers: counterdate.cgi [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include '/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of script headers: counter.cgi [Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include '/cgi/counter.cgi' in parsed file /export/home/moxp/www/www/index.html [Wed May 28 11:05:59 2003] [notice] child pid 24470 exit signal Broken pipe (13) [Wed May 28 11:05:59 2003] [error] cgid_maint [Wed May 28 11:05:59 2003] [error] cgid_maint APR_OC_REASON_DEATH [Wed May 28 11:05:59 2003] [error] cgid_maint [Wed May 28 11:05:59 2003] [error] cgid_maint APR_OC_REASON_UNREGISTER [Wed May 28 11:05:59 2003] [error] cgid_maint DONE [Wed May 28 11:05:59 2003] [error] cgid_maint DONE [Wed May 28 11:05:59 2003] [error] [client 207.160.133.9] (3)No such process: cgid daemon is gone; is Apache terminating?: /export/home/moxp/www/cgi/counter.cgi  Attached is a patch which will restart the cgid daemon if it dies. At first I tried doing a server restart like the cgid_maint code had originally been setup to do, ( kill(getpid(), AP_SIG_GRACEFUL); ) but after  an apache restart from cgid_maint I saw a number of the following warning messages. cgid worked fine though.  [Wed May 28 10:49:42 2003] [warn] long lost child came home! (pid 21018) [Wed May 28 10:49:42 2003] [warn] long lost child came home! (pid 21019)  So I wrote a patch that would just restart the cgid daemon rather than restart apache itself.  This patch seems to work fine. Created an attachment (id=6553) patch to restart cgid daemon if it dies  A final note.  We started upgrading some of our production Sun Solaris servers to Apache 2 seven weeks ago  Two of those servers have had the cgid daemon die at once during the seven week period.  This resulted in cgi's failing until our customers notified us of the problem.  We then had to restart or stop/start apache.  The patch I sumbitted will automatically restart the cgid daemon so that only a few cgi requests fail rather coninuous failure until restart or stop/start of apache. Thanks for your patch, and hopefully it will get reviewed/committed soon.  I wanted to mention that if you're running into any problems with cgid, you need to apply this patch:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/generators/mod_cgid.c.diff?r1=1.150&r2=1.151  That fixes a simple bug with horrendous consequences, including the murder of the cgid daemon process (with the sigpipe in the library).  patch committed, thanks!!!!!  I'll propose it for merging into the stable branch (2.0.47-dev).  *** Bug 22483 has been marked as a duplicate of this bug. *** *** Bug 23533 has been marked as a duplicate of this bug. ***			Glenn Nielsen	Jeff Trawick
19913	null	CLOSED		Tsuyoshi SASAMOTO	1052896140000	1053126960000		 should be checked 'r->content_encoding' should be checked to avoid compressing a compressed file, when an internal redirection occurs by mod_negotiation/mod_rewrite, or '*.{html,txt,etc}.gz' is requested directly.  --- httpd-2.0/modules/filters/mod_deflate.c     Wed Mar 12 03:11:33 2003 +++ httpd-2.0/modules/filters/mod_deflate.c     Wed May 14 14:55:40 2003 @@ -340,6 +340,12 @@              encoding = apr_table_get(r->err_headers_out, 'Content-Encoding');          }   +        if (r->content_encoding) { +            encoding = encoding ? apr_pstrcat(r->pool, encoding, ',', +                                              r->content_encoding, NULL) +                                : r->content_encoding; +        } +          if (encoding) {              const char *tmp = encoding;	Yes, you're right. I've just committed your patch and proposed it for backport into the stable branch.  Thanks for your report and thanks for using Apache.			Andr?? Malo
19954	null	RESOLVED		Chris Conti	1053008340000	1164610175000		[PATCH] HTTP tunneling through reverse proxy does not always work [PATCH] Enable HTTP tunneling for streaming data where data is less than the  buffering size  Synopsis: Optionally disable buffering in mod_proxy  We ran into a situation where a command-response protocol was being tunneled through HTTP (2 sockets 1 is an HTTP GET, the other an HTTP POST) that failed when passed through an Apache reverse proxy.  When the data passing from  the server < AP_MIN_BYTES_TO_WRITE (8000 decimal) then the bucket brigade buffers the data instead of passing it on.  The guts of the patch are basically appending a flush bucket after every read(unless there is already an EOS) if the ProxyWriteThrough directive is set to On   --------------------------------------------------------- Chris Conti cmconti@mindspring.com chris.conti@xcellenet.com  diff -u /ApacheSrc/httpd-2.0.45/modules/proxy/proxy_http.c /ApacheSrc-orig/httpd-2.0.45/modules/proxy/proxy_http.c --- /ApacheSrc/httpd-2.0.45/modules/proxy/proxy_http.c  2003-05-02 16:22:53.000000000 -0400 +++ /ApacheSrc-orig/httpd-2.0.45/modules/proxy/proxy_http.c     2003-02-03 10:31:50.000000000 -0500 @@ -956,18 +956,6 @@                          /* signal that we must leave */                          finish = TRUE;                      } - -                    /* do we need to always send the data? */ -                    if (conf->write_through  && !finish){ -                        apr_off_t readbytes; -                        apr_brigade_length(bb, 0, &readbytes); - - -                        if(0 != readbytes){ -                            apr_bucket *e = apr_bucket_flush_create(c->bucket_alloc); -                            APR_BRIGADE_INSERT_TAIL(bb, e); -                        } -                    }                       /* try send what we read */                      if (ap_pass_brigade(r->output_filters, bb) != APR_SUCCESS) {   diff -u /ApacheSrc/httpd-2.0.45/modules/proxy/mod_proxy.h /ApacheSrc-orig/httpd-2.0.45/modules/proxy/mod_proxy.h --- /ApacheSrc/httpd-2.0.45/modules/proxy/mod_proxy.h   2003-04-29 09:20:12.000000000 -0400 +++ /ApacheSrc-orig/httpd-2.0.45/modules/proxy/mod_proxy.h      2003-02-03 10:31:50.000000000 -0500 @@ -201,8 +201,6 @@        bad_body      } badopt;                   /* how to deal with bad headers */      char badopt_set; -    int  write_through; -    char write_through_set;   } proxy_server_conf;    diff -u /ApacheSrc/httpd-2.0.45/modules/proxy/mod_proxy.c /ApacheSrc-orig/httpd-2.0.45/modules/proxy/mod_proxy.c --- /ApacheSrc/httpd-2.0.45/modules/proxy/mod_proxy.c   2003-04-29 09:20:12.000000000 -0400 +++ /ApacheSrc-orig/httpd-2.0.45/modules/proxy/mod_proxy.c      2003-02-22 11:38:14.000000000 -0500 @@ -503,8 +503,6 @@      ps->timeout_set = 0;      ps->badopt = bad_error;      ps->badopt_set = 0; -    ps->write_through = 0; -    ps->write_through_set = 0;      return ps;  }  @@ -532,7 +530,6 @@      ps->preserve_host = (overrides->preserve_host_set == 0) ? base->preserve_host : overrides->preserve_host;      ps->timeout= (overrides->timeout_set == 0) ? base->timeout : overrides->timeout;      ps->badopt = (overrides->badopt_set == 0) ? base->badopt : overrides->badopt; -    ps->write_through = (overrides->write_through_set == 0) ? base->write_through : overrides->write_through;       return ps;  } @@ -816,16 +813,6 @@      psf->req_set = 1;      return NULL;  } -static const char* -    set_proxy_writethrough(cmd_parms *parms, void *dummy, int flag) -{ -    proxy_server_conf *psf = -    ap_get_module_config(parms->server->module_config, &proxy_module); - -    psf->write_through = flag; -    psf->write_through_set = 1; -    return NULL; -}  static const char *      set_proxy_error_override(cmd_parms *parms, void *dummy, int flag)  { @@ -1079,8 +1066,6 @@       'This overrides the server timeout'),      AP_INIT_TAKE1('ProxyBadHeader', set_bad_opt, NULL, RSRC_CONF,       'How to handle bad header line in response: IsError | Ignore | StartBody'), -    AP_INIT_FLAG('ProxyWriteThrough', set_proxy_writethrough, NULL, RSRC_CONF, -     'on if the data should be not be buffered'),       {NULL}  };	add patchavailable keyword. Your patch looks reversed.  You might also want to 'attach' it rather than pasting it in, since the line-wrapping makes your patch very hard to apply. The preferred mechanism would be to AUTOMATICALLY send down a flush bucket if a non-blocking read returns EAGAIN.  No configuration directive would be necessary.  The simplistic algorithm would be    done = 0;   while (!done) {     rv = ap_get_brigade(APR_NONBLOCK_READ);     if (APR_STATUS_IS_EAGAIN(rv)) {         pass flush bucket down output filter chain;         rv = ap_get_brigade(APR_BLOCK_READ);     }     if (rv != APR_SUCCESS) {         done = 1;         break;     }   }  The content-length filter does this, though with a slightly more complicated and optimized algorithm.  In what context do you intend the algorithm to be used?  In proxy_http.c in  place of the change I proposed?   I would think that ordinarily a reverse proxy would want the caching behavior.   Only when tunneling dynamic content would you want to disable the caching.  In  our case, the back end server withholds sending more data until a response is  received on a different socket.  When I originally was researching this I came  across references to people having a similar issue tunneling streaming  multimedia. The logic to hold on to output until we get 8K is not intended to be caching behavior, but instead to send out full packets so that we don't abuse the network.  But if we don't pass flush buckets down at the right time, it breaks some applications that need to send output to the client a piece at a time.  A flush bucket should be passed down when we've read some output but we find out that another read would block.  At this point it is safe to assume that the CGI/origin-server/whatever is not going to generate more output for a while and the output generated so far should be flushed to the client.  This is fixed on HEAD using the method Jeff suggested:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/proxy/proxy_http.c?r1=1.201&r2=1.202  *** Bug 33029 has been marked as a duplicate of this bug. *** Created an attachment (id=19034) patch for httpd-2.0.59  (In reply to comment #8) > Created an attachment (id=19034) [edit] > patch for httpd-2.0.59 >   Guess you provided the reverse patch :-). Furthermore I do not think that this works. The same code does not work in 2.2.x as all non blocking reads are converted to blocking reads somewhere down in the call chain (currently cannot remember where) and thus the conditions in the if clause causing a flush bucket to be added never become true. This is no fault of the proxy code. Either the problem somewhere down the call chain needs to be fixed what seems to be a larger task or we need to use a poll approach here similar to the one currently used in mod_proxy_ajp on the trunk (aka autoflush property of a proxy worker).  After more testing... The patch does not work if Transfer-Encoding is chunked. (See modules/http/http_protocol.c around line 870). Created an attachment (id=19075) patch for httpd-2.0.59 (works also with TE chunked).  Also patch http-protocol to allow the correct to work with TE chunked. From first glance this looks good. Mind to produce a patch against trunk, such that it can be committed and follow the usual backporting process? Created an attachment (id=19091) patch for htttpd-trunk  patch for htttpd-trunk (06/11/2006). +1 on the patch The issue with the chunk filter is a separate issue to the bug in the proxy which was tracked here so please open a new PR if you want that bug tracked. Backported to 2.2.x as r602679 (http://svn.apache.org/viewvc?rev=602679&view=rev).			Chris Conti	Jeff Trawick	Jim Jagielski	Joe Orton	Joshua Slive	Ruediger Pluem	jfclere
20111	null	RESOLVED		Sander Holthaus	1053521700000	1101143297000		CGI-script can break error-log When debugging a cgi perl script, all cgi-error-logging broke down. The script  worked flawlessly, but the parameters it outputted through warn's were not  logged.. A graceful or restart did not fix the issue, I had to stop and start Apache to  get it all going again. The strange thing is that only output from cgi's was  broken, 404's were still logged.  I stumbled against this problem a few versions ago too, but was never able to  reproduce the problem.	It seems that stop - start doesn't help either, you need to change the error- logfile (forgot that I did that, sorry). OK, figured it out. The errorlog does not seem to break (eg. other cgi-scripts  and stuff can write to it, no restart neccesary), the bug is caused something I  didn't look at (since is worked in previous versions).  The error-log does not seem to be outputted when writing out a Location header. My script ends with:  print 'Location http://www.mysite.com/succes.html/n/n';  exit;  This code worked up to 2.0.43, but as of 2.0.45 it doesn't. If I quote out this  line I get an error 500 (since nothing is outputted to the browser), but  everything gets written to the error-log.  Was that using an nph- script?  Bug 18348 concerns loss of stderr output from nph- scripts. Ah, no, you had tracked it down correctly.  This is harder to hit with 2.0.50 and later which have the 'CGI bucket' changes, but the remaining case is fixed on the trunk:  http://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/modules/generators/mod_cgi.c?rev=106195&r1=106103&r2=106195  Thanks for the report.			Joe Orton	Sander Holthaus
20183	null	CLOSED		Marcus Janson	1053693840000	1082061841000		ErrorDocument screws up proxied responses other than 200 OK Hi!  In my project we use Apache 2.0.45 as front-end to proxy certain requests to a  backend HTTP server. We also use the ErrorDocument feature of Apache for  predefined error pages.   When using range requests and ErrorDocument in conjunction we see some strange  behaviour, all 20* responses from the backend HTTP server other than 200 OK are  handled as errors by Apache. When the backend HTTP server for example returns a  206 PARTIAL CONTENT the Apache returns the ErrorDocument to the user. This behaviour has been verified by running telnet to port 80 on both Apache  and the HTTP backend server.  I had a quick peek in the code for proxy_http.c and I think I found what's  causing this problem:  (line 984-987) .. if ( conf->error_override ) {     /* the code above this checks for 'OK' which is what the hook expects */     if ( r->status == HTTP_OK)         return OK; ..  I changed the r->status == HTTP_OK to check for 200-206 HTTP responses,  compiled and it seems to work now.   Cheers  /Marcus Janson <-- tre.se -->	Thanks for tracking that down; I've committed a complete fix here:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/proxy/proxy_http.c?r1=1.183&r2=1.184 I'm reopening this because I'm running into a similar related issue.  I'm using rewrite rules and proxying along with an ErrorDocument to do a load  balancing configuration with failover when the proxy request fails.  If the  proxy can't hit the server and returns a 502, I use an ErrorDocument to force a  redirect to the same URL after changing a cookie that tells it to try another  server out of a rewrite map.   The problem is that the 302 redirect is being treated as an error and  subsequent requests never reach my ErrorDocument handler.  When I read this  report it sounds as if the patch was to treat anything other than 2xx as an  error.  Is a redirect truly an error?  If so, then the only way I can achieve  what I'm attempting is to send a 200 response with a META-REFRESH tag.   I believe the code in http_request.c in ap_die() has the same issue where it  checks if r->status != HTTP_OK. I'm recanting my comments below.  The error I encountered was due to a bad  rewrite rule that generated an additional 502 in the ErrorDocument script.  The  302's are being treated correctly.  Thanks and sorry for reopening this one. 			Byron Guernsey	Joe Orton
20195	null	CLOSED		Liyang HU	1053711840000	1058292068000		per-dir prefix stripping broken without trailing slash Hi,  Say I have the following in my /DocRoot/foo/.htaccess:    RewriteRule (.*) http://another.site/$1 [last,redirect=permanent]  According to the comments around line 1940 of mod_rewrite.c, the local prefix should be stripped from the URI before matching against the pattern. Indeed, http://my.site/foo/bar does get redirected to http://another.site/bar . However, if one tries to access http://my.site/foo , the string comparison in the code fails, resulting in the full path being matched against the pattern. i.e. http://my.site/foo is redirected to http://another.site//DocRoot/foo .  A temporary fix is to special-case this condition in the rewrite rules:    RewriteRule /DocRoot/foo http://another.site/ [last,redirect=permanent]  though this is hardly elegant.  Thanks, /Liyang	Fixed in 2.1 and proposed for inclusion into the 2.0 stable branch.  Thanks for your report and thanks for using Apache!			Andr?? Malo
20372	null	RESOLVED		Fabio Wakim Trentini	1054329180000	1088491863000		t work with reverse proxy The new directive AllowEncodedSlashes doesn't work using apache 2.0.46 as a  reverse proxy configuration, look at the example below:  bash-2.05a# grep AllowEncodedSlashes httpd.conf AllowEncodedSlashes On  bash-2.05a# grep 'returning 404' errorlog_80 |tail -1 [Fri May 30 17:58:56 2003] [info] [client x.x.x.x] found %2f (encoded '/') in  URI (decoded='/blahblah'), returning 404, referer: http://blahblah.com   I'm using something like this:     RewriteEngine   on     RewriteRule     ^(.*)$     $1 [P,L]   Thanks in advance,  Fabio.	Fixed in HEAD; c.f. bug 15207			Nick Kew
20558	null	CLOSED		Dave Hodder	1054921500000	1061131390000		Support XUL and Ogg media types in default install Please add Ogg and XUL entries to mime.types:      application/ogg\t\t\togg     application/vnd.mozilla.xul+xml\txul  The Ogg media type is registered at <http://www.rfc-editor.org/rfc/rfc3534.txt>.  The Ogg Bitstream Format is a general, freely-available standard for transporting multimedia content; for example, Ogg Vorbis audio.  The XUL media type is registered at <http://www.iana.org/assignments/media-types/application/vnd.mozilla.xul+xml>.  XUL is the XML-based User interface Language, initially developed for use in the Mozilla browser/groupware suite.  Thank you,  Dave	Both suggested media types were already added to the 1.3, 2.0 and 2.1-dev tree some time ago. The entry for the XUL media type is missing it's file extension.  Can it please be changed from:      application/vnd.mozilla.xul+xml  ... to:      application/vnd.mozilla.xul+xml\txul  Many thanks. I've added the extension (.xul) to all three trees now. Thanks for the hint.			Dave Hodder	Erik Abele
20617	null	CLOSED		Jesse Pelton	1055180280000	1076953229000		) returns wrong buffer size Line 586 adds two bytes to the length of each header string to allow for characters that will be added when the string is formatted:              len += strlen(elts[i].key) + strlen(elts[i].val) + 2;  This is consistent with the commentary that precedes it, however, line 598- 602 actually add three bytes to the header string:              *(((char*)buf_data)++) = ':';             *(((char*)buf_data)++) = ' ';             strcpy(buf_data, elts[i].val);             ((char*)buf_data) += strlen(elts[i].val);             *(((char*)buf_data)++) = '/n';  Net result: buf_size is one byte per row too small.  GetServerVariable() is typically called once with a NULL buffer to establish the required buffer size, then called again with a newly allocated buffer of the appropriate size.  This isn't possible if the first call returns too small a size.  The fix is simple: change '2' to '3' in line 586.	Forgot to mention the file: this is in mod_isapi.c. Created an attachment (id=6740) Trivial patch  Note that the patch is not needed if the patch for bug 20656 is applied. enabling the PatchAvailable keyword updated doc on submitting patches is at http://httpd.apache.org/dev/patches.html  patch committed to Apache 2.1-dev, will propose for backport to stable branch soon  thanks!    +1 here to backport, thanks Jesse.			Jeff Trawick	Jesse Pelton	Will Rowe
20619	null	CLOSED		Jesse Pelton	1055180640000	1076953898000		s last character Lines 726-730 of mod_isapi.c read:          newstat = apr_palloc(cid->r->pool, statlen + 9);         strcpy(newstat, 'Status: ');         apr_cpystrn(newstat + 8, stat, statlen);         stat = newstat;         statlen += 8;  Because apr_cpystrn() reserves a byte for a terminal null and statlen is the length of the status string to be copied, the final character of the status string is replaced with a null when it is copied to newstat.  The apr_palloc() call allocates sufficient space for the entire status string plus a terminal null, so I think the only change required is in line 728:          apr_cpystrn(newstat + 8, stat, statlen + 1);	Created an attachment (id=6741) Trivial patch  *** Bug 21302 has been marked as a duplicate of this bug. *** enabling the PatchAvailable keyword updated doc on submitting patches is at http://httpd.apache.org/dev/patches.html  thanks for the patch!  committed to 2.1-dev, will suggest shortly that it be merged into the stable branch     +1 on purusing the patch.  I believe(d) that we handled this header using   the statlen bytecount, so as a counted string the trailing null was not   important.  But trusting your patch :)  Thank you.			Jeff Trawick	Jesse Pelton	Ludek Reinstein	Will Rowe
20656	null	CLOSED		Jesse Pelton	1055270520000	1076954340000		' If you ask GetServerVariable() for multiple header fields by specifying 'ALL_HTTP' or 'ALL_RAW' as variable_name, each field is terminated with LF.  This differs from the behavior of IIS, which returns fields compliant with RFC2616 (CRLF terminators).  For once I'd argue that IIS got it right and is in compliance with the spec.	Created an attachment (id=6742) Trivial patch  enabling the PatchAvailable keyword updated doc on submitting patches is at http://httpd.apache.org/dev/patches.html  I'd like to see this patch (and those for 20617 and 20619) applied.  All three patches are simple, and I think they're correct and fix errors in the mod_isapi implementation.  Is there anything I can do to facilitate this?  Should I:  - further explain why I believe mod_isapi is currently broken? - bring the patches to someone else's attention? - add votes or keywords? - change priority or severity? - prepare the patch differently?  (I think I got it right.) - provide test code that demonstrates each problem (assuming it's feasible)?  These bugs haven't actually been assigned to anyone; do you need a mod_isapi maintainer?  (Hmm... http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=106854151316221&w=2 may explain a good deal.  Sounds like Bill is just plain busy.) I've looked at the patches previously and ISTR that they looked reasonable to me.  But with zero experience in ISAPI-land I thought it would be best if wrowe have a look ;)  But it is time to move forward, so I'll go through them again and commit what I'm reasonable sure of to Apache 2.1-dev and suggest for a backport.  Thanks for the ping ;)  Sounds good.  Please let me know if you find anything that gets in the way of checking them in; I'm happy to do what I can do address any problems.  The backport should be trivial, since the trunk and 2.0 branch have been kept in sync to the extent possible.  I imagine the real question is whether the maintainers are comfortable with the changes. patch committed to 2.1-dev, thanks!!  will propose shortly that it be merged to the stable branch     +1 on backport here ... if you validated against IIS.  Since ISAPI is an   abandoned API, pretty much defined by 'whatever it is IIS does', I can go   along with this patch.    It might confuse someone on a non-Win32 mod_isapi - but since crlf is   consistent in HTTP headers, I'll agree with Jesse here.  Thanks again :) You're welcome!  I'm glad to see this getting in.  I bumped up against this when header parsing code that worked under IIS didn't work under mod_isapi.  I generated the patch from the change I made to mod_isapi to send headers that I could parse - that is, headers similar to the ones I got from IIS.  I think that's about as much validation as is possible under the circumstances.  (Barring risking your legal neck by looking for IIS source in the recently leaked Windows code, that is.)  Out of curiosity, do you know if anyone is successfully using mod_isapi on a non-Win32 platform? Any progress on backporting this patch and the ones for 20617 and 20619?  It has been a couple of months since 2.0.49 came out; it would be nice if these could make it into 2.0.50, whenever that happens. All three patches have two votes for backport, awaiting one more :(  For any developers who see this, please consider these merge requests in the STATUS file.  No special mod_isapi knowledge necessary.      * mod_isapi: GetServerVariable('ALL_RAW') returned the wrong buffer       size.  PR 20617  [Jesse Pelton <jsp pkc.com>]         http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/arch/win32/mod_isapi.c?r1=1.96&r2=1.97       +1: trawick, stoddard                                                                                                           * mod_isapi: send_response_header() failed to copy status string's       last character.  PR 20619.  [Jesse Pelton <jsp pkc.com>]       http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/arch/win32/mod_isapi.c?r1=1.97&r2=1.98       +1: trawick, stoddard                                                                                                           * mod_isapi: GetServerVariable returned improperly terminated header       fields given 'ALL_HTTP' or 'ALL_RAW'.  PR 20656.       [Jesse Pelton <jsp pkc.com>]       http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/arch/win32/mod_isapi.c?r1=1.98&r2=1.99       +1: trawick, stoddard 			Jeff Trawick	Jesse Pelton	Will Rowe
20874	null	RESOLVED		jfclere	1055947860000	1118788667000		apxs -q EXTRA_INCLUDES gives an error I have: +++ /bin/ksh /opt/SMAWoIS/apache20/build/libtool --silent                            $ /opt/SMAWoIS/apache20/sbin/apxs -q EXTRA_INCLUDES                              Use of uninitialized value in concatenation (.) or string at /opt/SMAWoIS/apache 20/sbin/apxs line 275.                                                           +++  The problem is due to following line in buid/config_vars.mk:  EXTRA_INCLUDES = -I/home/jfclere/openIS/work/httpd-2.0.46/srclib/apr/include -I/home/jfclere/openIS/work/httpd-2.0.46/srclib/apr-util/include -I/home/jfclere/openIS/work/httpd-2.0.46/srclib/apr-util/xml/expat/lib -I. -I$(top_srcdir)/os/$(OS_DIR) -I$(top_srcdir)/server/mpm/$(MPM_SUBDIR_NAME) -I$(top_srcdir)/modules/http -I$(top_srcdir)/modules/filters -I$(top_srcdir)/modules/proxy -I$(top_srcdir)/include -I/opt/SMAWoIS/openssl/include/openssl -I/opt/SMAWoIS/openssl/include -I$(top_srcdir)/modules/dav/main  The $(var) are not handled correctly in apxs: +++             $val =~ s/[()]//g;             $result .= eval 'qq($val)' if defined $val;             $result .= ';;';             $ok = 1; +++	Thanks for the report; now fixed on the trunk.  http://svn.apache.org/viewcvs?rev=190392&view=rev 			Joe Orton
20944	null	CLOSED		Neil Fraser	1056104040000	1058195619000		t set all CGI variables Under normal cicumstances, when mod_ext_filter is called there are only 11 environment variables set.  Among the missing ones is HTTP_REFERER.  However, when mod_ext_filter is called on an SHTML file, the full set of 37 environment variables set.	Note that mod_include sets additional variables in case the SSI file itself causes a script to be executed, hence the difference in available variables based on whether or not your external filter was processing the result of mod_include.  plz try the patch that is forthcoming  Created an attachment (id=7262) add call to ap_add_common_vars()  > plz try the patch that is forthcoming  Perfect!  This bug was completely blocking my project with no workaround possible.  Thank you very much for fixing this.  The project in question is here:   http://neil.fraser.name/software/highlighter/ fix committed to 2.1-dev, proposed for merging into 2.0.48-dev  Thanks for your report, and thanks for using Apache!  (cute tool, and its nice to see mod_ext_filter put to such use!)  *** Bug 22556 has been marked as a duplicate of this bug. ***			Jeff Trawick	Neil Fraser
21085	null	CLOSED		Glenn Nielsen	1056554340000	1056909273000		ab - null pointer when parsing incomplete response ab can fail due to a null pointer when there is an incomplete response.  A patch will be attached.	Created an attachment (id=6973) ab - patch null pointer when parsing a partial response  Fixed in 2.1 and proposed for backport.  I've added another sanity check before committing. The piece of code now looks:  [...] \t    /* check response code */ \t    part = strstr(c->cbuff, 'HTTP');\t/* really HTTP/1.x_ */             if (part && strlen(part) > strlen('HTTP/1.x_')) {                 strncpy(respcode, (part + strlen('HTTP/1.x_')), 3);                 respcode[3] = '/0';             }             else {                 strcpy(respcode, '500');             }  \t    if (respcode[0] != '2') { [...]  Thanks for your patch!			Andr?? Malo	Glenn Nielsen
21100	null	CLOSED		Sander Holthaus	1056589440000	1056905345000		FreeBSD-section is missing in the config.layout file In the config.layout-file, used by the configure-script to set locations for  various files, the FreeBSD-layout is missing. It is present in the FreeBSD-port  version of the file however. But if somebody would like to build Apache 2 on FreeBSD without using the ports  (I for example since Apache 2 + SSL does not compile from ports on my box  anymore) and uses --enable-layout=FreeBSD, installation will fail...	That is certainly not a blocker. It would be helpful, if you could provide a patch for the layout file.  Thanks. <Layout FreeBSD>   prefix:        /usr/local   exec_prefix:   ${prefix}   bindir:        ${exec_prefix}/bin   sbindir:       ${exec_prefix}/sbin   libexecdir:    ${exec_prefix}/libexec/apache2   mandir:        ${prefix}/man   sysconfdir:    ${prefix}/etc/apache2   datadir:       ${prefix}/www   installbuilddir: ${prefix}/share/apache2/build   errordir:      ${datadir}/error   iconsdir:      ${datadir}/icons   htdocsdir:     ${datadir}/data   manualdir:     ${prefix}/share/doc/apache2   cgidir:        ${datadir}/cgi-bin   includedir:    ${prefix}/include/apache2   localstatedir: /var   runtimedir:    ${localstatedir}/run   logfiledir:    ${localstatedir}/log   proxycachedir: ${datadir}/proxy   infodir:       ${exec_prefix}/share/info </Layout>  Not 100% sure if this also works for FreeBSD 5 though.  Kind regards, Sander Holthaus Fixed in 2.1 and proposed for backport to 2.0.  (added libdir as exec_prefix/lib)			Andr?? Malo	Sander Holthaus
21160	null	CLOSED		David Tonhofer	1056769440000	1076412197000		SSL certificate chain handling suddenly fails to work properly There is as yet not much information here, I will have to try a few things first (next week, not today it's about 05:00). But here is what happens:  Apache has been configured with three IP-based virtual servers on three different IP addresses. On each of these addresses, we have an SSL server, thus three SSL servers in total.   One with a self-signed root CA certificate   ROOT->C1->SSL virtual host Two with an 'official' CA certificate        ROOT->C1->C2->SSL virtual host  Everything has been configured, Apache has been happily chugging along...  But then...  After a restart, Apache goes through the SSL virtual servers and asks the password for each of the three private keys (good). After this, it fails (bad) with the following error in the error log:  'Failed to configure CA certificate chain!'  (Some additional info would have been of use, too)  The weird thing is that the configuration for SSL had not changed at all. Thus the production server was suddenly dead in the water w/o reason.  Also, each of the SSL virtual servers work if they are the only ones in the config file. Certain pairs also work, but not all.  Finally, 'openssl verify' does not find anything amiss with the CA chains.  So, that's all for now. More to follow (hopefully)  What is this server:  Apache/2.0.45 + mod_ssl/2.0.45 + OpenSSL/0.9.7b   on a RH7.3 OS with gcc-2.96-110 and glibc-2.2.5-39	As promised, more information (I am actually keeping my word for once, wow!):  I finally got it to work, though why it *does* work is a mystery.  First, some info on what does not work:  I tried the three SSL virtual servers pairwise. On each occasion, Apache startup failed. I got the ide of setting the verbosity level to debug ('LogLevel Debug'), thus we find the following in the logfile, in case all three SSL virtual servers are configured:  [Mon Jun 30 23:03:31 2003] [info] Init: Initializing OpenSSL library [Mon Jun 30 23:03:31 2003] [info] Init: Seeding PRNG with 648 bytes of entropy [Mon Jun 30 23:03:31 2003] [info] Loading certificate & private key of SSL-aware server [Mon Jun 30 23:03:31 2003] [info] Init: Requesting pass phrase via builtin terminal dialog [Mon Jun 30 23:03:38 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA private key - pass phrase requested [Mon Jun 30 23:03:38 2003] [info] Loading certificate & private key of SSL-aware server [Mon Jun 30 23:03:38 2003] [info] Init: Requesting pass phrase via builtin terminal dialog [Mon Jun 30 23:03:47 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA private key - pass phrase requested [Mon Jun 30 23:03:47 2003] [info] Loading certificate & private key of SSL-aware server [Mon Jun 30 23:03:47 2003] [info] Init: Requesting pass phrase via builtin terminal dialog [Mon Jun 30 23:03:54 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA private key - pass phrase requested [Mon Jun 30 23:03:54 2003] [info] Init: Wiped out the queried pass phrases from memory [Mon Jun 30 23:03:54 2003] [info] Init: Generating temporary RSA private keys (512/1024 bits) [Mon Jun 30 23:03:54 2003] [info] Init: Generating temporary DH parameters (512/1024 bits) [Mon Jun 30 23:03:54 2003] [debug] ssl_scache_dbm.c(422): Inter-Process Session Cache (DBM) Expiry: old: 0, new: 0, removed: 0 [Mon Jun 30 23:03:54 2003] [info] Init: Initializing (virtual) servers for SSL [Mon Jun 30 23:03:54 2003] [info] Configuring server for SSL protocol [Mon Jun 30 23:03:54 2003] [debug] ssl_engine_init.c(436): Creating new SSL context (protocols: SSLv2, SSLv3, TLSv1) [Mon Jun 30 23:03:54 2003] [debug] ssl_engine_init.c(611): Configuring permitted SSL ciphers [ALL:!IDEA:!ADH:EXPORT56:EXPORT40:!NULL:+HIGH:+MEDIUM:+LOW] [Mon Jun 30 23:03:54 2003] [error] Failed to configure CA certificate chain!  I will spare you the pairs, it's the same...  I then tried each of the SSL virtual servers alone. In each case,  startup was a success:  [Mon Jun 30 23:03:31 2003] [info] Init: Initializing OpenSSL library [Mon Jun 30 23:03:31 2003] [info] Init: Seeding PRNG with 648 bytes of entropy [Mon Jun 30 23:03:31 2003] [info] Loading certificate & private key of SSL-aware server [Mon Jun 30 23:03:31 2003] [info] Init: Requesting pass phrase via builtin terminal dialog [Mon Jun 30 23:03:38 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA private key - pass phrase requested [Mon Jun 30 23:03:38 2003] [info] Loading certificate & private key of SSL-aware server [Mon Jun 30 23:03:38 2003] [info] Init: Requesting pass phrase via builtin terminal dialog [Mon Jun 30 23:03:47 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA private key - pass phrase requested [Mon Jun 30 23:03:47 2003] [info] Loading certificate & private key of SSL-aware server [Mon Jun 30 23:03:47 2003] [info] Init: Requesting pass phrase via builtin terminal dialog [Mon Jun 30 23:03:54 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA private key - pass phrase requested [Mon Jun 30 23:03:54 2003] [info] Init: Wiped out the queried pass phrases from memory [Mon Jun 30 23:03:54 2003] [info] Init: Generating temporary RSA private keys (512/1024 bits) [Mon Jun 30 23:03:54 2003] [info] Init: Generating temporary DH parameters (512/1024 bits) [Mon Jun 30 23:03:54 2003] [debug] ssl_scache_dbm.c(422): Inter-Process Session Cache (DBM) Expiry: old: 0, new: 0, removed: 0 [Mon Jun 30 23:03:54 2003] [info] Init: Initializing (virtual) servers for SSL [Mon Jun 30 23:03:54 2003] [info] Configuring server for SSL protocol [Mon Jun 30 23:03:54 2003] [debug] ssl_engine_init.c(436): Creating new SSL context (protocols: SSLv2, SSLv3, TLSv1) [Mon Jun 30 23:03:54 2003] [debug] ssl_engine_init.c(611): Configuring permitted SSL ciphers [ALL:!IDEA:!ADH:EXPORT56:EXPORT40:!NULL:+HIGH:+MEDIUM:+LOW] [Mon Jun 30 23:03:54 2003] [error] Failed to configure CA certificate chain!  I figured I would continue with a pair of servers and whittle down the SSL config file until things began to work. This actually paid off!  It turns that the presence of this block seems to be confusing:    <Files ~ '/.(cgi|shtml|phtml|php3?)$'>       SSLOptions +StdEnvVars   </Files>   <Directory '/usr/local/apache2/cgi-bin'>       SSLOptions +StdEnvVars   </Directory>  I had this block in each of the three SSL virtual servers, taken from the original file coming with Apache. I commented it out in one (1) of the three.  Lo and behold! It works! Now the passphrase dialog spits out an error after having asked for the 2nd passphrase. This however, does not prevent it from reading the third passpharse. It is also a Good Sign, because whenever this error shows up, the webserver will be able to configure itself:   Server www.m-plify.com:443 (RSA) Enter pass phrase:  Server rei1.m-plify.net:443 (RSA) Enter pass phrase:1024:error:0D094068:asn1 encoding routines:d2i_ASN1_SET:bad tag:a_set.c:179: 1024:error:0D0680A8:asn1 encoding routines:ASN1_CHECK_TLEN:wrong tag:tasn_dec.c:939: 1024:error:0D07803A:asn1 encoding routines:ASN1_ITEM_EX_D2I:nested asn1 error:tasn_dec.c:304:Type=RSA 1024:error:0D09A00D:asn1 encoding routines:d2i_PrivateKey:ASN1 lib:d2i_pr.c:96:   I'm completely at a loss to explain a relationship between the configuration instructions above and SSL certificate chain configuration, sorry....but that's what happened. Naah, forget what I said about the workaround. The exact same file that earlier worked now fails to work (yeah, its the fscking SAME file). This must have to do with the moon phases! OMG...  I have tried with Apache 2.0.46. There were 3 successfull starts and 1  unsuccessful one. Not too bad. I swear I will give up all this Computer Crap and I'm gonna raise sheep in New Zealand!  Anyway, that's it for now. -OO- Same problem here.  A configuration with a certificate chain and two virtual hosts worked on one system (always) but failed on another (always).  On the system where it failed, removing one of the virtual hosts fixed the problem.  Setup: Apache 2.0.46 + OpenSSL 0.9.6i Success system: Gentoo Linux Failure system: RedHat Advanced Server  I'm not sure whether it is related to the OS vendor.  Will do some more checks when I get the time. I have tried with Apache 2.0.47 and openssl-0.9.7b. Same problem.  And the workaround is (tadaa!):  DO NOT ENCRYPT THE SERVER PRIVATE KEYS.  Arf! There is a bug which means the OpenSSL error stack is not cleared: I thought this was a purely cosmetic issue (it causes the error dumps you see during pphrase entry), but in fact it may well be the cause of this bug:  Can anyone who can reproduce this try the following patch:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_pphrase.c?r1=1.44&r2=1.45  I was able to reproduce the 'Failed to configure CA certificate chain' error message.  I started Apache and entered a wrong passphrase for the private key and got 'Error: Pass phrase incorrect (5 more retries permitted).'.  After that I entered the correct passphrase and got 'Ok: Pass Phrase Dialog successful.'.  Then Apache failed to start (the other virtual hosts probably) and the error log contained the certificate chain error.  When I enter the correct passphrase from the beginning everything works allright.  Then I patched the server with the patch given below and retested like above.  Apache now started succesfully.  So it seems that this error stack clearing really is more than only cosmetic :)). Wonderful, thanks Kris.  I've proposed the fix for inclusion in the next 2.0 release.  Thanks for the reports. *** Bug 13585 has been marked as a duplicate of this bug. *** *** Bug 29496 has been marked as a duplicate of this bug. ***			David Tonhofer	Joe Orton	kris.verbeeck@advalvas.be
21285	null	CLOSED		Massimo Torquati	1057168080000	1071782877000		(mem) cache size becomes negative causing segfault Short description:  (mem) cache size becomes negative in some circumstances (caching dynamic objects, small cache size, at least two threads), later causing wrong behaviour and segfault in the cache_insert functions.  Detailed description:  If our understanding of the code is correct, dinamically generated objects are first inserted in the cache as temporary objects with a default size. In the function write_body (in mod_mem_cache.c) to resize a temporary object after it has been completed, it is first removed from cache, and then it is re-inserted with its correct size. This operation is performed withouth checking if the removed object is still present  in the cache. Suppose another thread has removed the temporary object from the cache because of a capacity miss in cache_insert functions (cache_cache.c).  Then you can remove an object of different  size and adjust the cache size in a wrong manner eventually producing a  negative cache size.  A negative cache size quickly produces a segfault in cache_insert().	The problem shows up on only with dynamic object generation. We have tested it using PHP and a small number of simple http clients.  How to reproduce the problem:  Send object requests from some (2-3) clients (I wrote a simple client that at max rate possible connect to server, post a GET request, read reply and close the connection) to a simple php script (code follows) with the cache object count very very small (Es. : MCacheMaxObjectCount 50).   The script produces different small objects (a few bytes in size) based on an input variable (pippo.php?variabile=1234). If you look at the cache size after some time you see it decrease to zero and become negative. Eventually, some of the threads die because of a segfault.  -------- Apache (2.0.46) configure command -------------  ./configure --with-mpm=worker --prefix=/apache-test/ --enable-mods-shared=all --enable-so --enable-cache=shared --enable-mem_cache=shared   ----- Cache configuration -------------  # # Sample Cache Configuration # <IfModule mod_cache.c> <IfModule mod_mem_cache.c> CacheEnable mem / CacheDefaultExpire 1000 CacheMaxExpire 3000 CacheIgnoreCacheControl Off CacheIgnoreNoLastMod    On MCacheSize 2000 MCacheMaxObjectCount 50 MCacheMinObjectSize 1 MCacheMaxObjectSize 1048576 </IfModule> </IfModule>  ---- php script code (pippo.php) ---- <?php  header('Expires: Mon, 26 Jul 2005 05:00:00 GMT'); echo '<head>  </head>'; echo '<html> <br> html part <br> </html>'; if (isset($_GET['variabile'])) {  echo 'mi hai passato '.$_GET['variabile']; } else { echo 'non mi hai passato niente'; } ?> Created an attachment (id=7067) proposed patch for bug 21285 and bug 21287  The patch corrects the bugs 21285 and the bug 21287.   I think there are cleaner ways to remove bug 21285; perhaps the simplest one is to mark temporary objects in the cache as not removable. This clearly has consequences on the removing algorithm as well, though.  In the meanwhile, the patch I propose works well to eliminate the problem, and has been extensively tested in the same settings with version 2.0.44 and 2.0.46 . We have not tested if there are interactions with other cache modules (e.g. mod_disk_cache). enabling the PatchAvailable keyword updated doc on submitting patches is at http://httpd.apache.org/dev/patches.html  Created an attachment (id=9525) fix the defect w/o touching the pq functions  Fixed with this patch to Apache 2.1. Will port to an upcoming release of 2.0 (2.0.49?) http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/experimental/mod_mem_cache.c?r1=1.99&r2=1.100			Bill Stoddard	Jean-Jacques Clar	Jeff Trawick	Massimo Torquati
21287	null	CLOSED		Massimo Torquati	1057168980000	1071782898000		no mutex lock protection in decrement_refcount There are no mutex lock protection in decrement_refcount if it is defined USE_ATOMICS.  I think you simply forgot the mutex in function decrement_refcount.  There is a race condition in the cleanup_cache_object when two threads  are trying to clean-up the same object which is no longer referenced in the cache. I found this problem while looking for the bug 21285. The proposed patch fix the problem.	Created an attachment (id=9549) extracted from patch in bug 21285, also mutex lock protection in remove_url  just adding the PatchAvailable keyword... Fixed with this patch to Apache 2.1. Will port to an upcoming release of 2.0 (2.0.49?) http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/experimental/mod_mem_cache.c?r1=1.99&r2=1.100			Bill Stoddard	Erik Abele	Jean-Jacques Clar
21370	null	CLOSED		keilh	1057584360000	1058789503000		 is configured a FreeMemoryRead occurs in the case of a MSI5.0 browser and enabled Keep-Alive Description:  If 'SSLVerifyClient' is configured for some location, mod_ssl is starting a re-negotiation of the SSLconnection in the function 'ssl_io_filter_connect(..)' A MSIE Internet Explorer is handling that kind of re-negotiation in  the following way: a) he is finishing the current handshake (see logfile) b) afterwards he is starting a new handshake, now presenting a     client certificate  So the whole situation is handeld by mod_ssl in the following way: 1) mod_ssl is starting a re-negotiation 2) the client does not finish the handshake (see a) ) 3) mod_ssl is freeing the SSL struct using 'SSLfree(..)'    (By that also the allocated BIO's will be freed) 4) the browser is starting a new handshake (see b) ), using the same    TCP connection (Keep-Alive is enabled) and so the already     freed SSL struct and BIO's will be used by mod_ssl    (Due to the fact that it is bound to the conn_rec struct)  I.e. mod_ssl is reading already freed memory.  We have proven is using a (purify Version 2002a.06.00 an Solaris 2.8)   Fix: If the handshake is failing in 'ssl_io_filter_connect(..)' the connection  will be aborted.  Due to stability the pointer's to the BIOS will be reset in  in 'ssl_filter_io_shutdown(..)' and check in 'ssl_filter_write(..)' We have tested the fix again with the same memory access checker.   Log-Message: [Wed Jul 02 19:07:21 2003] [info] Requesting connection re-negotiation [Wed Jul 02 19:07:21 2003] [info] Awaiting re-negotiation handshake [Wed Jul 02 19:07:21 2003] [error] Re-negotiation handshake failed: Not accepted by client!?  Diff: diff -c -r1.2 -r1.3 *** ssl_engine_io.c     2003/04/16 14:14:39     1.2 --- ssl_engine_io.c     2003/07/03 11:36:24     1.3 *************** *** 780,789 ****                                        apr_size_t len)   {       ssl_filter_ctx_t *filter_ctx = f->ctx; !     bio_filter_out_ctx_t *outctx =  !            (bio_filter_out_ctx_t *)(filter_ctx->pbioWrite->ptr); !     int res;          /* write SSL */       if (filter_ctx->pssl == NULL) {           return APR_EGENERAL; --- 780,795 ----                                        apr_size_t len)   {       ssl_filter_ctx_t *filter_ctx = f->ctx; !       bio_filter_out_ctx_t *outctx = NULL; !       int res;    +       /* 2.7.2003/hk,mv: BIOS has been freed*/ +       if (filter_ctx->pbioWrite == NULL) { +               return APR_EGENERAL; +       } +  +     outctx = (bio_filter_out_ctx_t *)(filter_ctx->pbioWrite->ptr); +        /* write SSL */       if (filter_ctx->pssl == NULL) {           return APR_EGENERAL; *************** *** 999,1004 **** --- 1005,1014 ----       sslconn->ssl = NULL;       filter_ctx->pssl = NULL; /* so filters know we've been shutdown */    +       /* 2.7.2003/hk,mv: BIOS is freed reset the pointers*/ +       filter_ctx->pbioRead = NULL; +       filter_ctx->pbioWrite = NULL; +        return APR_SUCCESS;   }    *************** *** 1112,1117 **** --- 1122,1129 ----               inctx->rc = APR_EGENERAL;           }    +               /* 2.7.2003/hk,mv: handshake failed, close the connection */ +               c->aborted=1;           return ssl_filter_io_shutdown(filter_ctx, c, 1);       }    *************** *** 1153,1158 **** --- 1165,1172 ----                            error ? error : 'unknown');               ssl_log_ssl_error(APLOG_MARK, APLOG_INFO, c->base_server);    +                       /* 2.7.2003/hk,mv: no client cert, close the connection */ +                       c->aborted=1;               return ssl_filter_io_shutdown(filter_ctx, c, 1);           }       }	Created an attachment (id=7121) memory access checker output  Thanks very much for the report and patch; a variant of the patch has been committed to CVS. *** Bug 22832 has been marked as a duplicate of this bug. ***			Joe Orton	keilh
21371	null	CLOSED		Mark Webb	1057584480000	1063716229000		apache not passing certificate chain to servlet or CGI I have been working on a site that enforces mutually authenticated SSL using apache 2.0.46. I have compiled it from source using the following commands passed to the ./configure script:  ./configure --enable-so --enable-ssl --with-ssl=/usr/local/ssl  /usr/local/ssl contains openssl version 0.9.7b which I compiled from source using the default build configuration. I have tried both servlets and cgi and all I can get is the user certificate, not the certificate chain.  I have tried looking at the mod_ssl code, and cannot figure out why the +ExportCertData directive will only tell apache to forward on the user certificate, not the chain.	This is all Greek to me (i.e., it would take me a long time to figure out how to test), but it looks like there is an off-by-one error in ssl_engine_vars.c that messes up the lookup of the cert chain info.  I'll attach a patch to test in just a sec.  The latest mod_ssl for Apache 1.3 has this change too.  I'd wager that backtracking that line of code in prior releases of the original mod_ssl would show that it got fixed after we imported it into Apache 2.0.  Created an attachment (id=7231) proposed fix for cert chain variable problem  The patch posted previously has been committed to Apache 2.1-dev and proposed for merge to 2.0.48-dev.  I tried the patch and got the same results.  I do not think that the patch fixed the problem. Then I suppose more changes are required :(  The change in the patch corrected a blatant error which has also been fixed in the mod_ssl project for 1.3.  Do you have any setup hints for testing this scenario?  Perhaps you can point to some documentation?  This is what I do...  to compile apache(2.0.47).  I am using openSSL 0.9.7b, compiled from source, and installed in /usr/local/ssl. ./configure --enable-so --enable-ssl --with-ssl=/usr/local/ssl gmake  gmake install  to configure apache create a test cert for apache, set up ssl.conf properly. open browser, point to test-cgi. observe that certificate chain is not listed in the output.  This proves to me that the certificate chain is not being passed to the CGI, and therefore would not be passed to a servlet either.  I am most interested in getting apache to pass the entire certificate chain to a servlet, but am using cgi's to test with right now.  This is because it is easier to test, and takes the tomcat connector stuff out of the equation.  Please let me know what more help I may be. I'm stuck at the point of getting a certificate chain passed from the client.  (No idea how to do that yet :) ).  I see SSL_CLIENT_CERT being set but with the following patch to one of the mod_ssl files I see that OpenSSL is telling mod_ssl that there are zero certificates in the chain.  Try testing with this patch to see if OpenSSL has provided mod_ssl with a chain. If it hasn't, you'll see something like I did:  [debug] ssl_engine_kernel.c(1064): [client 9.65.78.133] got peer certificate chain (0/8245458/8252f50)  where the 0 after 'chain (' is the number of certificates in the chain returned by OpenSSL...  Index: modules/ssl/ssl_engine_kernel.c =================================================================== RCS file: /home/cvs/httpd-2.0/modules/ssl/ssl_engine_kernel.c,v retrieving revision 1.82.2.6 diff -u -r1.82.2.6 ssl_engine_kernel.c --- modules/ssl/ssl_engine_kernel.c     16 May 2003 18:12:18 -0000      1.82.2.6 +++ modules/ssl/ssl_engine_kernel.c     16 Jul 2003 17:28:03 -0000 @@ -1059,6 +1061,9 @@          apr_table_setn(env, 'SSL_CLIENT_CERT', val);           if ((peer_certs = (STACK_OF(X509) *)SSL_get_peer_cert_chain(ssl))) { +            ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r, +                          'got peer certificate chain (%d/%pp/%pp)', +                          sk_X509_num(peer_certs), peer_certs, ssl);              for (i = 0; i < sk_X509_num(peer_certs); i++) {                  var = apr_psprintf(r->pool, 'SSL_CLIENT_CERT_CHAIN_%d', i);                  val = ssl_var_lookup(r->pool, r->server, r->connection, @@ -1067,6 +1072,10 @@                      apr_table_setn(env, var, val);                  }              } +        } +        else { +            ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r, +                          'SSL library returned no peer certificate chain');          }      }   Confirmed fixed in 2.0.46 + Jeff's off-by-one patch.  Mark, you did have 'SSLOptions +ExportCertData' set in the right context?  (Mozilla doesn't seem to send the CA certs included in an imported PKCS#12 ccert for me, neither will 'openssl s_client'; maybe MSIE does it, I had to hack my own code to reproduce this)			Jeff Trawick	Joe Orton	Mark Webb
21443	null	CLOSED		Frank Migge	1057777380000	1073991446000		compilation of mod_auth_db.c fails for Berkeley DB version 4 Symptom: Fatal compilation error --------------------------------  [inet-hq01:/tmp/apache_1.3.27/src/modules/standard]>make gcc -c -I../../../../mm-1.3.0 -I../../os/unix -I../../include - I/usr/local/ssl/include  -DSOLARIS2=280 -DMOD_SSL=208114 -DEAPI -DEAPI_MM - DUSE_EXPAT -I../../lib/expat-lite "../../apaci" mod_auth_db.c mod_auth_db.c: In function "get_db_pw': mod_auth_db.c:176: warning: passing arg 2 of pointer to function from  incompatible pointer type mod_auth_db.c:176: warning: passing arg 4 of pointer to function makes pointer  from integer without a cast mod_auth_db.c:176: too few arguments to function *** Error code 1 make: Fatal error: Command failed for target "mod_auth_db.o'  Cause: The following code in mod_auth_db.c (starting line 173): ---------------------------------------------------------------  #if defined(DB3) || defined(DB4)     if (   db_create(&f, NULL, 0) != 0         || f->open(f, auth_dbpwfile, NULL, DB_HASH, DB_RDONLY, 0664) != 0) {   Reason: missing second argument on the DB open() call as defined in the ----------------------------------------------------------------------- v. 4 docu: (see http://www.sleepycat.com/docs/ref/simple_tut/open.html) -----------------------------------------------------------------------          if ((ret = dbp->open(dbp,             NULL, DATABASE, NULL, DB_BTREE, DB_CREATE, 0664)) != 0) {   Solution: Replace lines 173-175 with the code below: ----------------------------------------------------  #if defined(DB4)     if (   db_create(&f, NULL, 0) != 0         || f->open(f, NULL, auth_dbpwfile, NULL, DB_HASH, DB_RDONLY, 0664) != 0)  { #elif defined(DB3)     if (   db_create(&f, NULL, 0) != 0         || f->open(f, auth_dbpwfile, NULL, DB_HASH, DB_RDONLY, 0664) != 0) {	Confirmed also on Linux. Doesn't appear to inhibit building with DB 4.0.14, at least as supplied by default with Red Hat 9, but does cause problems with the version supplied with Fedora Core (Severn; 0.95) Test 3, which is DB 4.1.25. Confirmed on Red Hat Enterprise Linux Advanced Server 3, using db4-4.1.25-8 from the system RPMs.  The patch listed previously works.  This while attempting to compile apache-1.3.29. Thanks for the report: that change would break with DB 4.0; committed this for the next 1.3 release which works with both 4.0 and >=4.1:  http://cvs.apache.org/viewcvs.cgi/apache-1.3/src/modules/standard/mod_auth_db.c?r1=1.50&r2=1.51 *** Bug 26294 has been marked as a duplicate of this bug. ***			Ari Gordon-Schlosberg	Erik Abele	Joe Orton	Tim Jackson
21492	null	RESOLVED		sebastien gautrias	1057914060000	1096393309000		Bad file size in disk cache for large css files Overview Description :  Some css size are not good into httpd cache disk.  Here my cache configuration :  <IfModule mod_cache.c> \t<IfModule mod_disk_cache.c> \t\tCacheRoot /cacheproxy/CR844-Production-SSL \t\tCacheSize 100000 \t\tCacheEnable disk / \t\tCacheDirLevels 1 \t\tCacheDirLength 2 \t\tCacheMaxExpire 86400 \t\tCacheDefaultExpire 7200 \t\tCacheForceCompletion 100 \t</IfModule> </IfModule>  And the results of my observations (we have 5 urls for the same file, because we use dispatching into url) :  Normal size : 43648 bytes (43648 Jul 10 18:39 feuille.css)  Into the Httpd cache disk (bytes) : The header Content-Length is always : 43648 Into the disk (size in bytes) : (we have only write the affinity) - /g1/ssl/css/feuille.css --> \t25716 ===> KO - /g1_k/ssl/css/feuille.css -->\t43648 ===> OK - /g1_l/ssl/css/feuille.css -->\t43648 ===> OK - /g1_m/ssl/css/feuille.css -->\t28476 ===> KO - /g1_n/ssl/css/feuille.css -->\t43648 ===> OK   Steps to Reproduce: This problem is not reproducible.  Actual Results: The navigator show some page with css file not complete ==> Bad posting  Expected Results: Good file size into disk cache  Build Date & Platform: Apache 2.0.46 build on AIX 5.1 FP3, H70 server 64 bits, compiled with gcc 3.2.3, Apache 32 bits  Additional Builds and Platforms: Apache 2.0.45 on AIX 5.2, p610 server 64 bits, compiled with XLC  6.0.0.5, Apache 64 bits	Created an attachment (id=7239) .header and .data files  I guess my problem is the same. I use mod_disk_cache to cache static files delivered by Tomcat via mod_jk. Unfortunately you did not write if you are caching local files or remote files (delivered by mod_jk, mod_proxy or something similar).  I noticed that when you abort the download of a file which should be cached and whos origin is on a remote server, the partly downloaded file gets cached. The second request for this file only delivers the partly cached file and thus leads to the problems described by you. In my case the problem showed up by incomplete jpg pictures.  The reason for this behaviour can be found in mod_disk_cache. mod_disk_cache does not notice that a request has been aborted. I wrote a small patch (against 2.0.50) that drops the partly cached file if the connection has been aborted.  Unfortunately the CacheForceCompletion of mod_cache is not implemented right now such that nearly completely downloaded files get lost for the cache. But this is better than delivering only parts of the files in the following requests. Created an attachment (id=12516) Proposed Patch  Can you please test this in 2.0.51?  Lots of fixes for mod_disk_cache were made. I checked this with 2.0.51 and it is only partially fixed. It should work with local files, but it does not work if the length of the content to be cached is unknown and the file is large as it is the case if you cache large dynamic content originally created by Tomcat. And this is what I am doing. I try to lower the load on the Tomcats by caching large files generated by Tomcat that are valid for some time via mod_cache on the webserver.   The problem is that in this case we get to line 663 of mod_disk_cache.c as the condition in line 661 is true in any case (content written completely to file or only partially because the connection has been aborted). So this operation is handled as successful caching of the request in any case even if the content was only saved partially.   Nevertheless the changes to mod_disk_cache provide an better environment now for the needed changes so I provide an updated version of my patch for 2.0.51. Created an attachment (id=12847) Patch for 2.0.51  A variant of the 'patch for 2.0.51' has been committed to HEAD as modules/experimental/mod_disk_cache.c rev 1.64.  Thanks! Backported to v2.0.53. 			Graham Leggett	Justin Erenkrantz	Paul Querna	R??diger Pl??m	sebastien gautrias
21495	null	CLOSED		Kai Seidler	1057922400000	1064913952000		ab blocks in 2.0.47 After installaing 2.0.47 ab doesn't work any more: it blocks after connecting to remote machine:  > This is ApacheBench, Version 2.0.40-dev <$Revision: 1.121.2.1 $> apache-2.0 > Copyright (c) 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ > Copyright (c) 1998-2002 The Apache Software Foundation, http://www.apache.org/  > Benchmarking www.XXXX.com (be patient)...  until getting a:   > Benchmarking www.XXXX.com (be patient)...apr_poll: The timeout specified has expired (70007)  Stracing ab says:  > connect(3, {sin_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr('217.9.XXX.XXX')}}, 16) = -1 EINPROGRESS (Operation now in progress) > gettimeofday({1057921957, 161482}, NULL) = 0 > poll( <unfinished ...>  I 'Ctrl-C'ed here.  I assume it's not a matter of ab but a problem in one of the apr-shared libs ab is using: libaprutil-0.so.0 or libapr-0.so.0. If I use the libs from 2.0.46 the ab from 2.0.47 works fine.  Hoping this is a real bug and not just a problem of my system. I tested it with SuSE 8.1 and Debian 2.0.  Greetings from Germany, Kai Seidler	I can verify this problem with ab from Apache 2.1-dev on RedHat 8.  Interestingly, apr_poll() hasn't changed in some time.  And yet ab hasn't changed its use of socket I/O in some time either.  Go figure :)  Apparently the use of poll in ab is broken, as polling only for POLLIN is only going to catch failures to connect.  Give this a spin (it works for me).  Index: ab.c =================================================================== RCS file: /home/cvs/httpd-2.0/support/ab.c,v retrieving revision 1.126 diff -u -r1.126 ab.c --- ab.c        10 Jul 2003 19:16:35 -0000      1.126 +++ ab.c        11 Jul 2003 11:32:52 -0000 @@ -1268,7 +1268,7 @@             c->state = STATE_CONNECTING;             c->rwrite = 0;              new_pollfd.desc_type = APR_POLL_SOCKET; -            new_pollfd.reqevents = APR_POLLIN; +            new_pollfd.reqevents = APR_POLLIN | APR_POLLOUT;              new_pollfd.desc.s = c->aprsock;              new_pollfd.client_data = c;             apr_pollset_add(readbits, &new_pollfd);  I rarely use ab myself, and the only testing of it that I did personally over the last few releases has been over loopback, where I assume the connect completed synchronously and we didn't need to poll() until it completed.  Yes, it works for me as well. Thanks a lot, Jeff! For the record:  While the patch I posted apparently makes it work, it is something of a kludge.  ab in 2.0.46 worked because of the way that apr_connect() was broken for purely non-blocking sockets.  One would think that the poll condition between the initial connect call and when we know we've successfully found a partner would be simply POLLOUT, but it doesn't work unless you have POLLOUT|POLLIN because the connect state is used for more than just getting connected to the desired remote part.  Another issue is that we don't reissue the connect to find out whether or not it worked.  But that isn't so easy because connect state is overloaded with some SSL setup.  Maybe the kludge isn't so bad, since it may be some time before somebody feels like cleaning house in ab and potentially breaking something else :)  *** Bug 22686 has been marked as a duplicate of this bug. *** A fix for this will be in 2.0.48. 			Jeff Trawick	Kai Seidler
21523	null	CLOSED		John Huong	1057948320000	1069453548000		mod_deflate compresses content wrongly Based on http://nagoya.apache.org/bugzilla/show_bug.cgi?id=9222  mod_deflate shouldn't do anything when let's say my PHP script outputs with the header;  Content-Encoding: deflate  Unfortunately, I've noticed that it still does it occasionally.  Here's part of the transmission that I've managed to log. Begin client request: POST http://cimserv.1stsi.com/fans/dsasoapserver.php Accept: text/xml Accept: multipart/* Accept-Encoding: deflate User-Agent: SOAP::Lite/Perl/0.55 Content-Encoding: deflate Content-Length: 327 Content-Type: text/xml; charset=utf-8 SOAPAction: 'http://cimserv#check'  <snip out contents of requests>  Begin server response: HTTP/1.1 200 OK Connection: Close Date: Fri, 11 Jul 2003 16:29:13 GMT Server: NuSOAP Server v0.6.4 Vary: Accept-Encoding Content-Encoding: deflate, gzip Content-Length: 267 Content-Type: text/xml; charset=UTF-8 Client-Date: Fri, 11 Jul 2003 16:31:04 GMT Client-Peer: 172.16.104.14:80 Status: 200 OK X-Powered-By: PHP/4.3.2  <snip out the contents of response>   One thing is for sure, I definitely didn't add ', gzip' to the server's response. Strange thing though... it happens on and off.	First: please try 2.0.47, which contains some further fixes. Second: I can't believe, that mod_deflate compresses gzip if Accept-Encoding: contains no gzip. I'd guess the compression takes place somewhere else. Hi, sorry for the cross post. Anyway I'm sure it is a mod_deflate problem as  everything works fine for the last 5 hours after I try the work around as  describe in bug 9222. My problem would normally appear every now and then  within an hour or two. I will try Apache 2.0.47 later on and see if I get the  same problem. Ok I've upgraded to 2.0.47 this morning. I've done the tests with 5 SOAP::Lite  clients sending 500 various types of requests(both valid and errorneous) each  and without any special setenvif settings, and none of the server responses are  gzipped. Looks great. Just curious, how come the 2.0.47 release didn't mention  anything about fixing mod_deflate.. or was this problem attributed to other  Apache components? Thanks. Oops... In fact,the changes were made in 2.0.46. Strange. This points to other sources of error as well, IMHO. I'll close the report for now. Don't hesitate to reopen it, if there are further issues.  Thanks for using Apache! Created an attachment (id=7491) Loop test log file  Looks like I spoke too soon. I'm attaching the complete log file of my most recent loop test.  Hmm. The point is, mod_deflate only gets active, if the filter (DEFLATE) is added *and* Accept-Encoding contains the gzip token. Did you add the filter somehow? What's the particular configuration? Here are my settings for the filters.  <Directory />     Options FollowSymLinks     AllowOverride None Order Deny,Allow  Deny from all  AddOutputFilterByType DEFLATE text/html text/plain text/xml AddOutputFilterByType DEFLATE application/ms* application/vnd*  application/postscript </Directory>  # DeflateFilterNote Input instream DeflateFilterNote Output outstream DeflateFilterNote Ratio ratio   LogFormat '%h %l %u %t /'%r/' %>s %b /'%{Referer}i/' /'%{User-Agent}i/' In:% {instream}n Out:%{outstream}n:%{ratio}npct' comdef  Oh by the way.. the workaround in bug 9222 doesn't work either... the problem  still happens intermittently. Well, and it does actually log instream/outstream/ratio for these requests? I'll attach the access logs once I return from work. Here is the line in the access log that matches the last entry in the attached  log file.  127.0.0.1 - - [23/Jul/2003:08:07:50 +0800] 'POST /testsoap.php HTTP/1.1' 200  268 '-' 'SOAP::Lite/Perl/0.55' In:245 Out:250:102pct Just to separate the two separate issues here:  1) if you think that mod_deflate is gzip-encoding a response where the request did not have 'gzip' in an Accept-Encoding header, can you attach a network trace against 2.0.47, or a log which includes the input and output headers (e.g a CustomLog with '%{accept-encoding}i {content-encoding}o'  2) mod_deflate will indeed gzip-encode a response which already has Content-Encoding: deflate (given Accept-Encoding: gzip in the request, etc); this is a different issue. Ok I just tried what was recommended.. and I hit it again. Here is the output  of the log.  127.0.0.1 - - [25/Jul/2003:23:35:52 +0800] 'POST /testsoap.php HTTP/1.1' 200  268 '-' 'SOAP::Lite/Perl/0.55' In:245 Out:250:102pct 'deflate' 'deflate, gzip'  Here's the logformat from my httpd.conf  LogFormat '%h %l %u %t /'%r/' %>s %b /'%{Referer}i/' /'%{User-Agent}i/' In:% {instream}n Out:%{outstream}n:%{ratio}npct /'%{Accept-Encoding}i/' /'%{Content- Encoding}o/'' comdef Created an attachment (id=7518) accept-encoding parsing fix  I may be on a wild goose chase, but can you try that patch? Sorry, unfortunately I don't have any compilers with me right now on my Windows  system and at home. Is there something like a nightly build I could run my  tests against? Any chances of this being fixed in 2.0.48? Ha, Joe, you've found the problem! We skip the /0 delimiter and search somewhere in the memory... Therefore it occurs *sometimes*. I've finally committed a fix to 2.1 and proposed it for backport.  Thanks! already fixed in 2.0.48 :)			Andr?? Malo	Jeff Trawick	Joe Orton	John Huong
21539	null	CLOSED		John Lim	1058046540000	1058049437000		' At the very top of the document:  'This document describes what a Multi-Processing Module is and how they are  using by the Apache HTTP Server.'  I think 'using' should be replaced with 'used'?  Also present in http://httpd.apache.org/docs-2.0/mpm.html.  It seems like an obvious error (to me at least), which would make me think it  would have been been already reported, but I searched the bug DB a couple of  times and could not locate an entry, so hopefully I'm not duplicating someone  else's report. :)	This is fixed in CVS now and will be on the website soon. Thanks.			Erik Abele
21648	null	CLOSED		Glenn Nielsen	1058357460000	1071354089000		 error message on restart A 'piped log program '(null)' failed unexpectedly' error message for each configured piped log is reported when you do an apache restart.  Looking at the source, this is expected on a restart.  Logging it gives the impression something is breaking.  Attached will be a small patch to prevent this from being logged on a restart.	Created an attachment (id=7328) Remove piped log program '(null)' failed unexpectedly error on apache restart  FYI... this can happen at apachectl stop too*... another PR, another patch which should close this hole as well :)  incidentally, part of this other patch is some infrastructure to get your marvelous cgid restart patch working with prefork, which in turn will let us merge it to stable  *whether any of this happens seems to be timing related...  number of piped loggers, OS, MPM, each are inputs to a function I cannot understand that determines if this bogosity occurs  Fix committed to 2.1-dev.  Hopefully it can be committed to stable branch before too terribly long. 			Glenn Nielsen	Jeff Trawick
21668	null	CLOSED		Jesse Tie-Ten-Quee	1058396340000	1067727873000		Lack of table row when SurpressIcon is enabled with HTMLTable. When 'HTMLtable' is used along with 'SuppressIcon' in an IndexOptions the html output will be lacking a table row it would have had 'SuppressIcon' not been enabled.  This is caused by the hardcoding of table row inside the SUPRESS_ICON if statement.  I've moved it outside, so that no matter which options are used when an TABLE_INDEXING is used, you will have a table row.  [hence outputing proper HTML/table code]	Created an attachment (id=7338) Patch to fix bug.  Fixed in 2.1 and proposed for backport into the 2.0 stable branch.  Thanks for your report and thanks for using Apache!			Andr?? Malo	Jesse Tie-Ten-Quee
21726	null	CLOSED		S??nke Tesch	1058612700000	1058999804000		mod_negotiation multiviews description is inaccurate Following setup:  AddType text/html .html AddOutputFilter INCLUDES .ssi Options +multiviews  The file test.html.ssi is served fine as expected if requested by its exact URL /test.html.ssi, but a 404 will be returned if it is requested by /test.html or /test. The error_log just says     Negotiation: discovered file(s) matching request: /bla/test (None could be negotiated).  (if requested by /test, would be /bla/test.html if requested by /test.html). This message BTW doesn't make any sense to me, how can files be discovered that do not exist?  This happens only if a file extension is mapped to a handler or filter only. The default SSI setup with both text/html and INCLUDES mapped to .shtml works.  I initally discovered this while trying to get content negotiation working with different PHP output types like style.css.php or index.html.php. Some browsers request _exactly_ what they expect, so using AddType to link .php to text/html or -even worse IMHO- application/x-php-whatever does not work with files different than text/html or even text/html in the later case (which is unfortunatly the standard, recommended PHP setup). And apart from that it doesn't make any sense to me to declare .php internally as text/html (or whatever other type) anyway if the script in fact outputs a PNG image.  Nevertheless, this bug is not related to PHP, as seen with the SSI example above. Just wanted to point out that there is a justified use for this.  This bug might be related to #16328.	Hmm, did you try using the MultiViewsMatch directive? I bet this will solve that problem. MultiViewsMatch works, thanks. Maybe Apache 2's defaults should follow more closely to the paths Apache 1 set? hmm. IIRC that was a design decision, because of *better* defaults...  There is also ia note at <http://httpd.apache.org/docs-2.0/upgrading.html>. Should we place it additionally somewhere else? About the 'better defaults': I do agree that selecting forgotten .old or .bak files by negotiation is surely not what the site maintainer wants, but if there is something (read: handler or filter) mapped to an extension, why not choose it? Looks to me like the developers did a step too far, instead of selecting too much, negotiation now selects too few. And that 'too much' wasn't a big problem anyway (IMHO of course:).  But apart from that, a short note about the changed behaviour on the mod_negotiation page would be helpful. Maybe I should add that any description of the new behaviour _at all_ would be nice. There's not a single word in the mod_negotiation docs about excluding handlers/filters and un-MIME-fied files by default; nutpickers could even argue that the current Multiviews description is wrong as it just lists the 'client's requirements', which 'to handle or not to handle' is surely not part of :)  A 'See also: MultiViewsMatch' should be there, too.  Mmh, reopening as documentation bug. In a large part I agree with you.  But the idea behind the change is that mod_negotiation is meant for content-negotiation.  Using MultiViews to omit the extension really has very little to do with negotiation.  But I'll go add a couple notes to the docs to improve this.  Thanks for using Apache!			Andr?? Malo	Joshua Slive	S??nke Tesch
21737	null	CLOSED		rcs	1058681580000	1062765865000		cgi process defunct cgi process are not being closed and end up in a zombie state untill parent process is terminated. This has been observed on move then 5 servers.	Created an attachment (id=7406) reverse what happened in 1.3.28  I've been having the same problem.  Please try that patch I attached.   The problem is that when running under suexec you cannot send the process sigterm since apache and the script are running with diffrent uids.  Apache 1.3.28 beleives the process is dead because the kill failed and sets p_kill_how=kill_never.  It really should look for -ESRCH. Created an attachment (id=7407) instead of reverse ... fix  The second patch implements a fix instead of reverting things back to the way 1.3.27 handled things. This probably should be critical as it causes servers to crash. *** Bug 21739 has been marked as a duplicate of this bug. *** I don't think the patch works (either of them). Still got new defuncts. However I tested on one server only. sorry about severity change, new to bugzilla.  (altho I haven't experience any crushs on 7 servers some with multiple instances of apache). Can you get it to reliably create a defunct process by doing the following?  > a) Put a this script in your cgi-bin > --cut here-- > #!/usr/bin/php > <?php phpinfo(); ?> > --cut here-- >  > b) Go to it your web browser.  Click reload over and over again (this > will eventually cause a sigpipe).  >  > c) watch the zombies build up The problem is fixed, I forgot I had another apache on that server. sorry for extra work I caused. Just to confirm, the patched apache is working correctly? *** Bug 21746 has been marked as a duplicate of this bug. *** I'm not sure now. I manualy patched (with the second patch) few servers and they look fine, one cpanel server (with the first patch) still defuncts. not sure yet if it's me of the patch. second cpanel defuncts. second patch also defuncts. so to sum it, the patches don't work. I can create a defunct process with the script above and get it about 80% of the time. The defunct process is gone very quickly now. You should probably still get defunct processes (the same thing happens in 1.3.27 and below), but they shouldn't exist for more then 5 or so seconds cause there is still a wait time between the time sigpip is recieved and the timeout.  This should be ok though. > You should probably still get defunct processes (the same thing happens in > 1.3.27 and below), but they shouldn't exist for more then 5 or so seconds  cause > there is still a wait time between the time sigpip is recieved and the  timeout.  Oh no! The defunct-processes won't clean automaticly! John:  do you still see them lingering after using the patch? Just so you know, we (the dev team) have seen this bug report and are looking into it.  Thanks  for the detailed investigation!  The patch does not help! This appears to be the modified PHP-suexec patch you have that is broken.  Note  this is likely only a problem for users that use Cpanel and the Apache version  with the newly updated alloc.c patch--looking at it, it is a source of more  problems.  You are looking in the wrong place.  The php-suexec patch that I've  modified myself and use with Apache 1.3.28 does not suffer from these problems  at all.  I believe that is the cause of your problems and your alloc.c patch  causes more (look at the modifications to see why!)  Maybe I'm wrong, but this  is how it appears looking at the patch and the alloc.c patch as well seems to  cause yet more issues. I.e., it's ignoring -USR1 hup's and so on, which is also conflicting with your  control panel on new account set ups and so on, which is causing more users to  submit reports about this version of Apache having this bug, which beyond the  PHP-SuEXEC patch and the messed up alloc.c patch, doesn't exist (*from what I've  seen*--I may be wrong, but it _is_ a source of additional problems). While I have actually been able to confirm this on .28 with the PHP-suexec patch  under specific circumstances--I am not able to reproduce the problem for .28 nor  .27 without that patch being implemented.  Has anyone experienced this issue that is not using the PHP suexec patch from  http://www.localhost.nl/patches/ (or a similar source), be it a modified version  of this patch or not?  I.e., the problem exists on installs without this?  I've  not been able to reproduce it without this patch being implemented.  Either way, the alloc.c patch is not the solution, at least not a complete  solution and opens up other problems, with some tests.  More information about  that later, if it's needed. Not sure why the comments I added is not in.  I can confirm the problem as well. My setup is stock apache1.3.28 (no php-suexec path) with modssl 2.8.15-1.3.28 and php 4.3.2. A simple test script that only display 'hello world' will stay as a defunct process owned by the suExec user. The defunct process only went away after a restart of the apache processes. Odd, I've not been able to recreate this on non 'PHP for CGI w/ SuEXEC' patched  systems, but I sincey you experience it as well, I personally assume it relates  to CGI and SuEXEC.  Has anyone confirmed this on non-SuEXEC enabled installs? I'm not sure why the first patch would cause USR1 not to work.  The patch just reverts parts of alloc.c to 1.3.27.    I was mistaken.  This was not related.  The patch did cause other problems  though.  I will attempt to recreate the problem in various ways and report it in  the very near future.  However, since this doesn't seem to be the overall  solution and more of a quick fix, I suppose there's no need. Which patch are you using?  The first one or the second one.    I've reviewed the second one:  http://nagoya.apache.org/bugzilla/showattachment.cgi?attach_id=7407  and I can't see how it could cause a problem.   I'm not so sure about the first one though. I confirm the bug for Apache 1.3.28/mod_ssl-2.8.15-1.3.28/php-4.3.1 running on OpenBSD 3.2. The fix (7407) seems to be working here. I applied the patch 7407 and it seems to fix the problem. Now the suEXEC process no longer stayed in zombie state. *** Bug 21926 has been marked as a duplicate of this bug. *** with the second patch:  http://nagoya.apache.org/bugzilla/showattachment.cgi?attach_id=7407  seems to be ok.  I got some defunct process butthey are killed in few seconds. Looks good, thanks.  We had severe zombie problems as well after upgrading to 1.3.28 (on Solaris  2.8). Compiling with the second (7407) patch solved the zombie problem for us  as well. This second 'patch' is just reverting back to the alloc.c file for .27 instead  of .28.  Has anyone noted any impact due to this?  This does seem to help, but  not completely remove the issue.  Also, bypassing the function(s) in .28--does  this matter?  It seems to be a logic error. The first patch is the one that revents, the second one is the one that should fix the problem with keeping the current logic. s/revents/reverts (gee 1am) I meant first, not second. :-) What will happen with this patch in the future? Will this be part of 1.3.29 or  will it become an official patch? We like to know that before we start  upgrading all our other apache 1.3.27 instances. Though I am not the person that would authorize anything as official or have  any control over what Apache does, and I don't personally assume this would be  implemented in .29 or be official (what do I know), I still recommend you  upgrade to .28 and implement this patch if you find you have to (or create some  solution yourself that maybe you feel more comfortable with otherwise).  You  don't want to stick with .27 at this point anyway. For me, patch 7407 works like a dream. I have yet to see any zombie processes  with my PHP script or with the 'phpinfo()' script mentioned above. Before, I  could reproduce the zombies quite easily - about 50% of the time with my script  and 100% of the time with the 'phpinfo()' script.  BTW, I'm not using any 'PHP-suexec' patch. Hi Jordan,  I'm curious, do you have suexec enabled?  If so, do you have this problem  without it enabled? Sorry if that sounded obvious to ask, given the history of the reports. :-) Yes, I use suexec.  I just tested the phpinfo() script on a virtual site that does NOT use suexec,  and I get no zombies while holding down the browser's Refresh key (F5 in  Internet Explorer).  When the same script is run on a suexec site, I get about 10 zombies per second  (great potential for DoS?). Patch 7407 fixes this for me. How about on a build without suexec compiled in as an option, rather than a  site without it enabled on a build that has it?  I'm just testing out a few  thoeries that likely have little to do with your problem, but I'd like to see if  anyone sees this on a non-suexec build... and if so, how long they take to die  off.  If you don't mind anyway.  Thanks. I tested the phpinfo() script on a 1.3.28 server that doesn't have suexec  compiled in, and got no zombies. Ralf S. Engelschall posted a different patch on apache-http-dev: http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=105952652425849&w=2  Is that patch better than 4707?  Either one should work just as well Yes, it would be a better overall patch, though, as he stated himself, the  original one works, but could be improved--which it seems it was.  I'd recommend  using this other patch by Ralf overall. The FreeBSD port apache13-modssl (Apache 1.3.28 + ModSSL 2.8.15) has been  updated to include the 4707 patch. My server with heavy CGI (Perl and PHP) was  creating zombies left and right, about 5000/hour.  I like the 4707 patch. It made me happy again. This patch does not work for me. I'm using suEXEC, mod_ssl compiled as a DSO, mod_frontpage_mirfak, mod_gzip, mod_pointer, and mod_throttle, all compiled as DSO modules. I should note that the patch given on the mailing list works fine. This is the patch that actually got committed (yesterday):  http://cvs.apache.org/viewcvs.cgi/apache-1.3/src/main/alloc.c.diff?r1=1.145&r2=1.146  It is slightly different than the patches that were posted to the mailing list, but it addresses all known concerns.   I applied the patch for alloc.c as is in the CVS tree to a APACHE_1_3_27 source.  I failed to correct  the problem for me under Mac OS X 10.3... investigating further... I have confirmed, this condition still exists on Mac OS X 10.3 with this patch.  I patched the 1.3.28  sources (I erred in my comment above).  And was still able to reproduce this.  I did extensive further testing and found that both Mac OS X, and FreeBSD violate the POSIX  specification for kill() and return ESRCH, when sending a signal to a zombie process.  This violation introduces a race condition with this patched code, as a process could finish (become  zombie) after the NEED_WAITPID 'waitpid' cleanup, but before the ap_os_kill() call and thus return  ESRCH, be marked as kill_never, and then never be cleaned up.  Although it is my hope that Mac OS X 10.3 final will have fixed this error.  Apache is still left with  an interoperability problem on Mac OS X 10.2 and likely FreeBSD (as they share this same  violoation).  I have attached my program 'main.c' which tests for this phenomenon. Created an attachment (id=8055) A program to test errno after signal to zombie process.  Thinking about this a little more... I think there are two options here:  1.  Come up with a solution, not dependant on this behaviour of kill...  (moving the waitpid to after  the kill call should be sufficient?)  2.  Add a configure.in rule to check for the POSIX compliance to kill and conditionally deal with it's  compliance or non-compliance accordingly.  There may be other systems (besides OS X and  FreeBSD) which have this ESRCH behaviour when sending to zombies... Here is a 'hack' which fixes the problem on Mac OS X (likely FreeBSD as well).  -           if (ap_os_kill(p->pid, SIGTERM) == -1) { +           if ( (ap_os_kill(p->pid, SIGTERM) == -1) && (errno == ESRCH) ) { +               // in case ESRCH means 'zombie'. +                waitpid(p->pid, (int *) 0, 0); Unless I'm mistaken, can't kill return EPERM for setuid processes?  Wouldn't that also leak? Another data point: I received an e-mail from a Tru64 user indicating that the patch as committed failed there too, and that Ralf's patch worked fine. Because of the bogusness of how some OSs handle errors from KILL, I've changed us to simply kill  and wait. 			147099.vserver.de	Ari Pollak	Christian Noack	Cliff Woolley	Eric Seidel	Erin Fortenberry	EvE	J. Nick Koston	Jeff Trawick	Jim Jagielski	John	Jordan Russell	Mads Toftum	Ruud van Melick	Tim Greer	cheewai	rcs	tchesmeli
21743	null	CLOSED		T. Chan	1058719680000	1058792220000		s LanguagePrioriy does not match languages in AddLanguage In docs/httpd-std.conf and docs/httpd-win.conf, there are several lines:  AddLanguage he .he ... AddLanguage nn .nn ... AddLanguage cs .cz .cs AddLanguage ru .ru AddLanguage zh-CN .zh-cn AddLanguage zh-TW .zh-tw AddLanguage hr .hr  and later:  LanguagePriority en da nl et fr de el it ja ko no pl pt pt-br ltz ca es sv tw  The languages he, nn, cs, ru, zh-CN, and hr don't exist in LanguagePriority (arguably not a bug).  Also, the language zh-TW is incorrectly labelled tw in LanguagePriority (a bug).	Fixed in CVS.  Thanks for your care and thanks for using Apache!			Andr?? Malo
21779	null	CLOSED		Roy Gibbons	1058813820000	1073769763000		Need to reject malformed href strings send by webdav client I have encountered two problems in using the Web Folders in XP Pro to manipulate files hosted on a webdav-enabled webserver.  The server is apache2.0.47 with the mod_dav modules and runs under linux.  The first problem is that XP does not escape the '#' character with a '%23' as part of the path segment.  This is a MicroSoft bug in XP as the Win2K version seems to be better behaved.  The more serious problem is that the Apache server does not reject such a request and but processes it with some nasty results.  In the following example, an authorized client/user has DELETE priviledges on the webdav server.  The test file is  called '/websites/davtest/#dav_test.html' which is a valid filename in linux, unix and MacOS worlds but not in Windows.  When the DELETE submission is made by a Cadaver client or a Win2K client, the following command is issued to the server     'DELETE /websites/davtest/%23dav_test.html HTTP/1.1' everything works as it should.  However, when a DELETE submission is made by XP Pro, the server receives     'DELETE /websites/davtest/#23dav_test.html' which is doesn't escape the # character.  The server accepts the command and proceeds to delete the following     #23dav_test.html     all files in the /davtest directory     the parent directory (davtest).  A server-based solution seems to be in order.  Thanks	Thanks for the report - it is simple enough to reject these requests. *** Bug 22023 has been marked as a duplicate of this bug. *** I have a simple patch for this, where it checks non-null condition for 'r->parsed_uri.fragment'. If its not NULL, it rejects the request with 403 response and log a message. (Currently its for DELETE and MOVE which are most harmful in such cases)  Should I post it for review, if anybody haven't put up a fix yet :) Created an attachment (id=9857) Patch to fix this bug (rejects requests with uri fragments)  PatchAvailable Ahmit, thanks for adding PatchAvailable but this belongs into the Keywords field :-) I know PatchAvailable is from keyword list. And I thought one suppose to put that keyword after submitting patch. Isnt this right ?  Sorry this is my only second patch, so please excuse me if I have done something terribly wrong. :) Thanks for the patch and report, a version of your patch was committed to the 2.1 tree and proposed for backport to the next 2.0 release.			Amit Athavale	Erik Abele	Joe Orton	Joshua Slive
21830	null	CLOSED		Robert Siemer	1058976060000	1058999566000		LanguagePriority has effect with HTTP/1.1 /manual/mod/mod_negotiation.html#languagepriority:  'Correctly implemented HTTP/1.1 requests will mean this directive (LanguagePriority) has no effect.'  Untrue. HTTP/1.1 does not forbid request without setting language priorities. Further it is even allowed to ommit q-values oder give several languages with the same q-value. In these cases LanguagePriority has effect.  I suggest discarding this sentence.	*** Bug 21829 has been marked as a duplicate of this bug. *** I was asked for more explanation...  The issue is a documentation bug. The documentation is wrong because a 'correctly implemented HTTP/1.1 request' could still get a response which is different for different 'LanguagePriority' settings.  GET / HTTP/1.1 Host: httpd.apache.org  is a correct HTTP/1.1 request and does not differ from HTTP/1.0 in Content Negotiation aspects...  Robert I think you're nit-picking a little.  But yes, in 2.0 sometimes LanguagePriority does have an effect, even with a properly configured HTTP/1.1 client.  I'll fix it.  Thanks for using Apache!			Andr?? Malo	Joshua Slive	Robert Siemer
21873	null	CLOSED		Sagara Wijetunga	1059107820000	1059158164000		point 4 under the  The point 4 (Does the target program have an unsafe hierarchical reference?) under the ???suEXEC Security Model??? of the ???suEXEC Support documentation??? (http://httpd.apache.org/docs-2.0/suexec.html).   It not clear whether you are referring to the CGI program???s path or program???s content or both.    Existing rule: 4.  Does the target program have an unsafe hierarchical reference?  Does the target program contain a leading '/' or have a '..' backreference? These are not allowed; the target program must reside within the Apache webspace.   The above would be better written as follows:  4. Does the target CGI program???s path have an unsafe hierarchical reference?  Does the target CGI program???s path contain a leading '/' or have a '..' backreference? These are not allowed; the target CGI program must reside within the suEXEC's docroot (--with-suexec-docroot=DIR).	This is 'fixed' in both, the 2.0 and 2.1 versions of the documentation and should be on the website  soon. Thanks for using Apache.			Erik Abele
21874	null	CLOSED		Sagara Wijetunga	1059108720000	1059158151000		point 13 under the  The point 13 (Is the directory within the Apache webspace?) under the ???suEXEC Security Model??? of the ???suEXEC Support documentation??? (http://httpd.apache.org/docs-2.0/suexec.html) is very confusing.  Existing rule: 13. Is the directory within the Apache webspace?  If the request is for a regular portion of the server, is the requested directory within the server's document root? ???  It would be better written as follows: 13. If the request is for a regular portion of the server, is the requested directory within the suEXEC's docroot (--with-suexec-docroot=DIR)???????	This is 'fixed' in both, the 2.0 and 2.1 versions of the documentation and should be on the website  soon. Thanks for using Apache.			Erik Abele
21944	null	CLOSED		Markus Wennrich	1059420420000	1074877290000		nph- streaming not working properly with SSL I've got trouble to get CGI:IRC running with SSL. Without SSL it works fine, but if I use https:// the streaming is broken.  For normal http:// (without SSL) this was fixed in #8482 (http://nagoya.apache.org/bugzilla/show_bug.cgi?id=8482)  Maybe it's the same kind of problem in a different part of the code?    http://www.schoko.org/cgi-bin/cgiirc/irc.cgi --> works   https://www.schoko.org/cgi-bin/cgiirc/irc.cgi --> doesn't work  With apache 1.3x both worked fine.	Created an attachment (id=7772) Minimal example of problem with SSL & nph  I think I'm seeing the same problem under Solaris 2.6. I've attached a  minimalist Perl script that demonstrates the problem; run under a non-SSL  server, it redirects immediately to the home page, whereas running it under an  SSL server causes it to wait for the sleep to terminate before doing the  redirect. Could be a buffering issue somewhere?  The SSL streaming problem still exists in 2.0.48 under Solaris 2.6.  Confirmed on Linux too, thanks for the reports. The fix is checked in to HEAD:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.113&r2=1.114  and will be proposed for backport for the next 2.0 release.  Thanks a lot for the report. Yes, confirmed, the patch works. Thanks a lot! :-)			Joe Orton	Markus Wennrich	softspt@gchq.gsi.gov.uk
21964	null	CLOSED		Yonatan	1059487980000	1059490322000		Error in LimitExcept Sample The Sample is <LimitExcept POST GET> Require valid-user <LimitExcept>   Where it should obviously be <LimitExcept POST GET> Require valid-user </LimitExcept>	Thanks, it's fixed now in CVS for the 2.0 and 2.1 versions of this document (and also for the  German translation) and should be on the website soon.			Erik Abele
22030	null	RESOLVED		Brandon Black	1059679920000	1097735043000		4097+ bytes of stderr from cgi script causes script to hang If a cgi script under mod_cgi outputs more than 4096 bytes of stderr before it  finishes writing to and closing its stdout, the write() inthe cgi script  containing the 4097th byte of stderr will hang indefinitely, hanging the  script's execution.  This appears to be cause by the fact that mod_cgi reads all stdout output  first, and then begins reading stderr output.  APR's file_io which is handling  the streams will only buffer 4096 characters before further writes by the  script to stderr will hang, waiting for mod_cgi to read some of the data from  the stream via APR file_io.  This occured for me where a perl cgi script was producing a large volume of  harmless warning messages to ssl_error_log before it got to the part of it's  execution where it actually wrote the stdout output, and causing the script to  hang and produce no output to the end user.  Below is a test script to  demonstrate:  #!/usr/bin/perl # 24x170 = 4080 bytes to stderr foreach my $x (1..24) {   print STDERR 'X' x 169 . '/n'; } # + 17 more bytes, putting us at 4097 # Delete one char from the print below to make # it work again print STDERR '0123456789ABCDEF/n'; # Our actual script output, which never comes print 'Content-type: text/plain/n/nASDF/n';	*** Bug 22318 has been marked as a duplicate of this bug. *** *** Bug 22900 has been marked as a duplicate of this bug. *** This DoS vulnerability has been tickin me off for two months now.  The CGI is blocked on a write() to stderr trying so hard to shove the packet  down Apache's throat and httpd is blocked waiting for something from the CGI's  stdout, which will never happen until that stderr is consumed, which also  never happens.  My system gets hundreds of processes with httpd and the CGI script deadlocked  with each other because if this issue.  I have to restart apache regularly to  avoid grinding the server to a pulp from wasted processes or 'Out of memory'  errors. But mostly it just reaches MaxClients all the time which prevents new  hits from being allowed (thus creating a DoS on my machine).  I'm surprised mod_cgi was already known to be borked in this way and not  repaired yet in the cvs source tree.  Anyone with cvs write access to the httpd repository, I'm begging you to try  to fix this.    I bricked over modules/generators/mod_cgi.c with Jeff Trawic's version:    http://www.apache.org/~trawick/mod_cgi.c    And suddenly all the problems vanished on my linux box.  Thank you Jeff!    Is there any reason why this is not incorporated into the httpd trunk source  tree?  Does it break non *NIX platforms?  If so, would it be appropriate to at  least do something like the following:    #ifdef LINUX  (new version)  #endif  #ifndef LINUX  (old version)  #endif    Rolling back to Apache 1.3.28 also eliminates all these problems, but I cannot  keep running 1.3.x because I need to use the new version of mod_php which is  not supported as well on the old apache.    Diff the old mod_cgi and new mod_cgi leads to a number of changes.  It would be great if we could  get an idea from the developers any pitfalls they may see with going up with the new mod_cgi.  Is  it safe to run on production?? Yes, the files seem quite different.  So many changes in fact that I got too  bored (or lazy) to review everything.  I just used blind faith and replaced  the whole file.  I'm not sure if anyone is using it on production, but it  certainly works fine on my development system.  I am going to roll it out on  my production system now.  It can't be any worse than the old one!  FYI: I just figured out how to buttwag around this bug until it can be  repaired.  Just force everyone to put this line at the top of all the perl  scripts:    use IO::Handle; STDERR->blocking(0);    Everything after the first 4096 bytes to stderr will be dropped, but at least  the server never falls into deadlock between the httpd and the CGI script.     That's a great idea, maybe I can put that in CGI.pm or something.  But I have over 2000 perl  scripts!! :-)   problems with ~/trawick/mod_cgi.c:  1) buffers up the response, which is really uncool and breaks with cgis that need to flush or which write huge responses  the code to parse http headers written by the cgi needs to be changed to get rid of the buffering  handle_script_stdout() needs to know when we've seen all the headers, then process them, then set ctx->headers_processed  2) doesn't work on the ever-lame win32  groan  3) needs the last few fixes to mod_cgi integraded  4) doesn't help mod_cgid, which is needed by threaded MPMs  5) isn't tested a whole lot  but of course you folks are helping with that  --/--  The main problem to attack is #1...  with that solved, everything else is not so hard, other than Win32, which doesn't have to be solved.  I'll try to attack #1 now that I see some interest in it.  Alternately, somebody else play with it in a debugger and see what I mean about needing to recognize when we've read the entire response header from the CGI and can get into the simple mode where we pass all output down the filter chain as soon as we read it. *** Bug 10515 has been marked as a duplicate of this bug. *** *** Bug 23473 has been marked as a duplicate of this bug. *** This bug was issued as an Apache DOS vulnerability in a Symantec Security release yesterday. They  cite going with the latest CVS release as a workaround.    Jeff can you provide some guidance on whether  http://www.apache.org/~trawick/mod_cgi.c or  the latest CVS rev will be the most stable release.  I notice several diffs between the CVS version  and the one in your home dir.  Thanks! There is no fix in CVS for this problem.  There is no stable mod_cgi[d] that handles 4097+ bytes from stderr mixed in with stdout processing.  I don't recommend using any of the code in http://www.apache.org/~trawick/ in a production environment.  I just uploaded jcgi.tar to www.apache.org/~trawick/.  Module was renamed to mod_jcgi so that hopefully it doesn't get confused with real code from CVS. This has fewer big picture problems than the mod_cgi.c hacks I had before, and of course anyone is free to play with it and comment.  See included STATUS file for some notes.  For production users: if your CGI spews gobs of stuff to stderr, change the CGI for now.  For folks debugging CGIs and want to have them temporarily spew gobs of stuff to stderr, play with the hacked up version mentioned here and send me testcases for stuff that doesn't work.  As always, anybody should feel free to make alternate changes to the real mod_cgi[d] and submit patches to dev@httpd.apache.org.  I raised this bug a long while back (Sep 25, 2002, actually: http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=103291952019514&w=2) and suggested a new 'CGI bucket' type that kept both stdout and stderr descriptors from the CGI process. When the bucket read() function is called, it would select() across both descriptors. Content from stdout would spawn a new bucket, and content from stderr would be logged.  Then wrowe went off with a crazy super-solution which caused a total loss of focus on the practical problems.  My suggestion still stands: have mod_cgi(d) inject a new CGI_BUCKET into the filter stack which can drain both streams. No more hangs. Ever. No buffering. Works for both cgi implementations. Works on Windows (presumably, since we're using standard apr functions to poll across the two descriptors). mod_cgid does not have this particular hang problem because the script's stderr refers directly to the error log.  Note that mod_cgid has some other issues with error log, but they are of lesser significance.  The two I can think of are:  + writing to syslog doesn't work + the main error log is always used, instead of the vhost-specific error log  (there are entries in this bug database already for these issues)  Regarding Greg's comments about a special CGI bucket type being produced by mod_cgi:  There is another issue to solve with mod_cgi[d] that exists in 1.3 as well: hangs will occur if all body data isn't read first, before the script starts producing output.  Clearly this isn't something that many scripts have encountered, but solving this enables some interesting CGI behavior.  My own work on this problem has been to handle all three channels (script's stdin -- request body, stdout, and stderr) right in mod_cgi.  Sending a special CGI bucket down the filter chain to solve the stdout/stderr problem doesn't deal with writing request body to the script as the script can handle it.  With the I/O handled directly in mod_cgi, an extra channel doesn't need a different model.  An unfortunate problem to solve regardless of where stderr is read is that APR doesn't support polling on pipes on Win32.  In the long term hopefully some Win32 gurus will provide a workable solution, but in the short term special handling is required.  (See APR_FILES_AS_SOCKETS.)  For what it's worth, this is proving to be a real problem for us attempting to migrate to apache 2.0 from 1.3 on UNIX (linux).  Is anyone actively looking at this or has it fallen off the radar? Carl, you can try http://www.apache.org/~trawick/jcgi.tar  Thanks Jeff, is this likely to make it into 2.0.49?  I'm pretty keen on sticking to production releases on our production servers :) definitely not going to make it to 2.0.49 *nod*.  This ticket's been open for some time now (some 4 months), do you know if/when it may be fixed in the release?  2.0.50? :) Is there any news at all on when this bug might get fixed please? Thanks. Scroll up from the bottom of the PR to find an alternate mod_cgi which has a redesigned interaction with the script.  Little or no feedback on that so far.  Thanks Jeff. I gave jcgi a very quick spin a couple of months ago but didn't manage to make it work (although I didn't try that hard at the time). I will try again sometime soon and see if I have any more luck.  How urgent is fixing this bug viewed as by those who are actively working on Apache? Obviously to me it seems pretty important because it breaks all my scripts (although I'm sure that it could be argued that my scripts are at fault for sending so much to stderr) but I don't really have that much knowledge of the internals of Apache and what other issues are outstanding against it at the moment. Are we likely to see a proper fix for this included in a production release in the foreseeable future or will work arounds within scripts and fixes like Jeff's be the norm for now? I have to agree with Jeff.   Having the server to hang with no explanation when your error output reaches some magic threshold is hopeless broken. It is the type of problem that won't show up in testing, but will break after deployment.   This is a 'I can't trust Apache 2.0' problem. >How urgent is fixing this bug viewed as by those who are actively working on Apache?  Emperical evidence would suggest that it is not very important.  >Are we likely to see a proper fix for this included in a production >release in the foreseeable future or will work arounds within scripts >and fixes like Jeff's be the norm for now?  I have no idea about the first question.  The answer to the second question is, in general, no.  This particular situation is one which requires a complete redesign of how mod_cgi interacts with scripts.  I have made a set of code available which for Unix has a design that should solve this problem, it works for my testcases, etc.  Another unusual example: 2.0.49 provided an overhaul of mod_include with completely new parsing engine and a number of existing problems resolved.  For quite a while, people with 2.0.x  mod_include problems were asked to try this alternate implementation.  After a relatively long time it was merged into 2.0.x for the 2.0.49 release.  If somebody has time/energy to move the ball forward they can offer their own solution or try out what I have and offer feedback.  If somebody does not have time/energy to help move the ball forward they can always buy commercial support for Apache or an Apache-based server and complain to the vendor that it does not meet their requirements.  Or modify scripts to redirect stderr or not output so much stuff to stderr. My lame workaround has been to start all my CGIs by re-opening STDERR to a plain file: open(STDERR, '>>/tmp/error.log').  Yuck.  Without that hack, this is bug a show-stopper for me too - there's no way I could deploy httpd2 on a system with CGIs I don't 100% trust (e.g. the shared webserver we virtualhost all our customer's webs on). How about taking the simpler 'CGI bucket' approach for a lower risk change to incorporate into 2.0 than the fundamental rewrite:  - fix just the regression since 1.3 (not the issue of handling stdin too) - simple #if APR_FILES_AS_SOCKETS to avoid breaking Win32  I have a patch to implement this based largely on mod_jcgi and the existing apr_buckets_pipe.c. Implementation of CGI bucket:  diff against HEAD: http://www.apache.org/~jorton/mod_cgi-HEAD.diff drop-in replacement for 2.0 mod_cgi.c: http://www.apache.org/~jorton/mod_cgi.c  one known issue: fail gracefully if script closes both stderr and stdout  Further testing welcome. Any reason not to commit to HEAD and get more eyes on it?  (I'll try to do some detailed testing in next 36hr either way.)  OK can do, will resolve that last issue first though. Joe, you're a total genious!  I patched my httpd.spec file as follows:    ---- snip ----  ===================================================================  --- httpd.spec  18 Nov 2003 00:52:34 -0000      1.16  +++ httpd.spec  16 Apr 2004 02:27:23 -0000  @@ -33,6 +33,8 @@   Source31: migration.css   Source32: html.xsl   Source33: README.confd  +# Add Joe Orton's awesome CGI Bucket feature so large STDERR output won't  choke anymore!  +Patch0: http://www.apache.org/~jorton/mod_cgi-HEAD.diff   # build/scripts patches   Patch1: httpd-2.0.40-apctl.patch   Patch2: httpd-2.0.36-apxs.patch  @@ -128,6 +130,9 @@   fi      %build  +  +patch modules/generators/mod_cgi.c < $RPM_SOURCE_DIR/mod_cgi-HEAD.diff  +   # update location of migration guide in apachectl   %{__perl} -pi -e 's:/@docdir/@:%{_docdir}/%{name}-%{version}:g' /          support/apachectl.in  ---- snap ----    And then I rebuilt the package and upgraded the rpm.  (I couldn't use the  standard rpm '%patch' because I think Joe forgot to include the  'http-2.0.49/modules/generators/' prefix in the diff headers in his patch  file.)  After restarting, all my problems immediately disappeared.  I'm  putting this on my PRODUCTION servers right now.  (I never close STDERR in any  of my CGIs anyway.)    Thank you!    For what it's worth the patch seems to work fine for me. My CGI scripts now generate the error_log text I would expect and the output appears in the browser as expected with no delays. Will this fix (or a patch based upon it) get worked into a proper release sometime in the future?  Thanks Joe!  Alec Thanks for testing it out.  This will go into a future 2.0 release only if enough developers have confidence it is suitable for a 2.0 release: the more reports of successful testing here the more confidence will be inspired. The fix for this is now committed to HEAD, but needs more testers.  http://www.apache.org/~jorton/ has:  - mod_cgi.c - a drop-in replacement for the 2.0.49 mod_cgi.c - mod_cgi-2.0.diff - a diff against the 2.0 mod_cgi.c  Please post any additional results from testing here. The trivial testing I have done so far on RHEL ES 3 with Interchange 5 (which is CGI intensive) shows that this patch works perfectly. *** Bug 28816 has been marked as a duplicate of this bug. *** This has been marked as closed, but is there any news on which release of httpd2 that the fix will land in? It requires one more developer vote for inclusion in a future 2.0 release.  The more people who test it, the better: there are 14 people on the CC list for this bug but only 3 have taken the time to test out the patches so far. *** Bug 28025 has been marked as a duplicate of this bug. *** *** Bug 29533 has been marked as a duplicate of this bug. *** This is committed for 2.0.50 now.  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/generators/mod_cgi.c?r1=1.148.2.7&r2=1.148.2.8 Thank you Joe!  I've been needing this fix for a long time.    -- Rob  *** Bug 28656 has been marked as a duplicate of this bug. *** *** Bug 20866 has been marked as a duplicate of this bug. *** *** Bug 23528 has been marked as a duplicate of this bug. *** *** Bug 19315 has been marked as a duplicate of this bug. *** I just tried version 2.0.52 and this problem persists.  I am running  Redhat 9.   David, please open a new bug describing the problems you have with 2.0.52, include  a reproduction case if possible.  The bug covered here was fixed in 2.0.50. I have entered a new bug, 39342, that I believe is related to this. In that case, mod_cgi is writing a large amount of data to stdout before attempting to read from stdin, which contains a large POST.			Alec Edworthy	Andr?? Malo	Carl Brewer	Dave Evans	David Trusty	Greg Stein	Jeff Trawick	Joe Orton	Joshua Slive	Nic Doye	Nojan Moshiri	Rob Brown	Wayne Scott	dougapache@claar.org
22061	null	RESOLVED		Eloi Granado	1059754380000	1104427460000		About alias mapping the / Where it states:  'We just redirect the URL / to /e/www/. While is seems trivial it is actually trivial with  mod_rewrite, only. Because the typical old mechanisms of URL Aliases (as provides by  mod_alias and friends) only used prefix matching. With this you cannot do such a  redirection because the DocumentRoot is a prefix of all URLs.'    Actually, I did try this time ago. Redirecting / did segfault the httpd process, but  RedirectMatch ^/$ did work perfectly.    Just my 2cents. :P	First of all, you're using a very old version of Apache, please try again with 1.3.28. Secondly we need more information, especially the exact configuration you used to provoke the segfault. I think he's just complaining about an innaccuracy in the rewriteguide. It was written before the RedirectMatch directive existed, so it thinks there is no other way to redirect a single URL-path like '/'. Just as Joshua Slive has stated, I was 'complaining' about an inaccuracy in the  documentation (this is the reason for me putting it in the documentation component  :P).    The version that did segfault was definitively prior to 1.3.28. Cannot send the  config-files, as I found it on a bank I worked for. I remember using the version 1.3.19  (and maybe later the 1.3.21-22). I didn't give it any importance because I thought  aliasing the / was a silly thing I shoudn't have attempted to do :P.  While redirecting / does indeed cause a loop, I can't get it to segfault. The rewrite guide, although in need of some work, on this point pretty clearly says 'don't do that', so doesn't seem inaccurate to me. In the absence of further data, I'm inclined to close this as part of my effort to clear away old and obsolete bug reports.  Thanks. Just as Joshua Slive pointed and confirmed, the bug report had nothing to do   with the segfaults. It was about an inacurate statement in a documentation   page (that, by the way, has not been corrected).      Anyway, I'll just add some comments on the segfault thing.       I remember Apache segfaulted on those Solaris (may be version 7) servers in   two cases:   - Redirecting the / (as I stated, a silly thing to do).   - An old/unused child being killed by the master process. The child died from   segfault instead of sigterm.      Those segfaults may certainly be caused by some factors external to Apache.   The Apache versions used were certainly old even then, because they were the   only ones supported by BEA Weblogic and Vignette. The OS version wasn't the   latest, either. I'm sorry of neither being able to reproduce them, nor to try   it with recent versions of Apache.  Thanks for the additional clarification. I think I understand what you're getting at. Does the following satisfy what you're looking for? :  Index: rewriteguide.xml =================================================================== --- rewriteguide.xml    (revision 123574) +++ rewriteguide.xml    (working copy) @@ -180,20 +180,21 @@          <dt>Solution:</dt>            <dd> -          <p>We just redirect the URL <code>/</code> to -          <code>/e/www/</code>. While is seems trivial it is -          actually trivial with <module>mod_rewrite</module>, only. -          Because the typical old mechanisms of URL <em>Aliases</em> -          (as provides by <module>mod_alias</module> and friends) -          only used <em>prefix</em> matching. With this you cannot -          do such a redirection because the <directive module='core' -          >DocumentRoot</directive> is a prefix of all URLs. With -          <module>mod_rewrite</module> it is really trivial:</p> - +          <p>We redirect the URL <code>/</code> to +          <code>/e/www/</code>: +          </p> +           <example><pre>  RewriteEngine on  RewriteRule   <strong>^/$</strong>  /e/www/  [<strong>R</strong>]  </pre></example> + +    <p>Note that this can also be handled using the <directive +    module='mod_alias'>RedirectMatch</directive> directive:</p> + +    <example> +    RedirectMatch ^/$ http://example.com/e/www/ +    </example>          </dd>        </dl>  Perfect. That is just what I meant with the bug report :) Thank you for the  patience.  Documentation patch applied. Thanks, Eloi.			Eloi Granado	Joshua Slive	Mads Toftum	Rich Bowen
22104	null	CLOSED		Tim Robbins	1059994620000	1073566729000		mod_deflate does not change Content-Length, breaks DAV file upload via PUT Although it is well documented that mod_deflate does not modify the Content- Length header when decoding a gzip-compressed message body, the incorrect value  seems to confuse mod_dav -- when I try to upload a compressed message body with  the PUT method, mod_dav returns a 400 Bad Request error, and this message  appears in the log:  [Mon Aug 04 19:49:25 2003] [error] [client 192.168.0.144] An error occurred  while reading the request body.  [400, #0]  To test, I'm PUT'ing the output of 'echo test | gzip -9c'. What happens is that  dav_method_put()'s first call to ap_get_client_block() returns 5 (strlen ('test/n')), but then it calls ap_get_client_block() again, and it returns -1  to signal an error. I believe this is because it's expecting more data.  I'm not sure how to solve this problem. It's probably not a great idea to  buffer the whole body in memory then fix up the Content-Length header after  decompressing it all, so perhaps mod_deflate could fake up a 'chunked'-encoded  body, putting each block of data returned from zlib into a new chunk, and  signalling EOF with a 0-length chunk. I'm not familiar with the internals of  the Apache httpd, so I'm not sure.  I'm filing this as 'Enhancement' because although the problem is documented, it  would be really nice to be able to use PUT requests w/ gzip-compressed bodies.	mod_dav should use bucket brigades when reading PUT data, then all should be fine.  So changing component to mod_dav and accept this as a bug.  Thanks for the report. Created an attachment (id=7641) Patch to make mod_dav use bucket brigades when handling PUT requests  Thanks for the suggestion to use bucket brigades -- I've got compressed uploads  at least partly working now, but it seems to choke on large requests: [Mon Aug 04 23:21:13 2003] [error] [client 192.168.0.144] (55)No buffer space  available: Could not get brigade.  [500, #0]  There are other things I'm not quite sure about in the patch, but I thought I'd  upload it just to get the ball rolling. Created an attachment (id=7642) Call apr_brigade_cleanup() to avoid running out of buffer space  Created an attachment (id=7643) clean patch I wrote in the meantime :)  Yeah, it was probably the missing cleanup. Can you try my patch nevertheless?  If it works, I'm going to commit it in 2.1 and propose it for backport. This seems to work, thanks! I haven't performed exhaustive testing; I uploaded  a 15MB file, both with and without gzip compression, and verified that the  files were identical and had the same md5sum as the original file. It's essentially the same patch as yours :)  Thanks for testing so far, I'm going to commit now. fix already committed to Apache 2.1-dev...  sounds like we need to consider it for merge to 2.0.next It's considered already, but the review you know ... :-)) Backport now in 2.0 tree courtesy of Justin...			Andr?? Malo	Jeff Trawick	Joe Orton	Tim Robbins
22203	null	CLOSED		Arno Bakker	1060248060000	1060266052000		util_ebcdic.h not properly includable from C++ The closing } for the extern 'C' { statement at the beginning is not in the  right place, it should go before the last #endif /* !APACHE_UTIL_EBCDIC_H */ g++ don't like this.	Fixed in 2.1 and proposed for backport into the 2.0 branch.  Thanks for the report and thanks for using Apache.			Andr?? Malo
22259	null	CLOSED		Bill Marrs	1060366380000	1060809987000		deflate generates error when called with no data This bug was orignally reported against mod_perl, but was traced down to a  problem in mod_deflate.    If a print '' is done from a mod_perl script which mod_deflate active, the page  output terminates and and error like this produced:  [error] 673: ModPerl::RegistryBB: 20014:Error string not specified yet  at /var/www/perl/test.pl line 6.  Here is a patch (coded by Stas Bekman stas@stason.org)  Index: modules/filters/mod_deflate.c =================================================================== RCS file: /home/cvs/httpd-2.0/modules/filters/mod_deflate.c,v retrieving revision 1.26.2.5 diff -u -r1.26.2.5 mod_deflate.c --- modules/filters/mod_deflate.c       17 May 2003 18:27:43 -0000      1.26.2.5 +++ modules/filters/mod_deflate.c       5 Aug 2003 06:37:59 -0000 @@ -529,9 +529,11 @@            if (APR_BUCKET_IS_FLUSH(e)) {              apr_bucket *bkt; -            zRC = deflate(&(ctx->stream), Z_SYNC_FLUSH); -            if (zRC != Z_OK) { -                return APR_EGENERAL; +            if (ctx->stream.avail_in > 0) { +                zRC = deflate(&(ctx->stream), Z_SYNC_FLUSH); +                if (zRC != Z_OK) { +                    return APR_EGENERAL; +                }              }               ctx->stream.next_out = ctx->buffer	The original patch is now committed, should be in effect with 2.0.48			Stas Bekman
22299	null	CLOSED		Geoffrey Young	1060608000000	1075491944000		ITERATE and ITERATE2 prototypes incorrectly handle DECLINE_CMD this bug was first reported to httpd-dev  http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=106011202900899&w=2  currently, using DECLINE_CMD to override config directives has a limitation - you can't override ITERATE or ITERATE2 prototypes properly. what ends up happening is that DECLINE_CMD is returned for the first argument, but then Apache skips over your module for all subsequent arguments.  the only way around this (that I was able to figure out, that is) is to use RAW_ARGS when overriding these prototypes and do the parsing yourself.    attached is a patch that fixes this, keeping ITERATE and ITERATE2 focused on the current module until the argument list is exhausted.  --Geoff    Index: server/config.c =================================================================== RCS file: /home/cvspublic/httpd-2.0/server/config.c,v retrieving revision 1.164 diff -u -r1.164 config.c --- server/config.c\t17 Feb 2003 07:04:50 -0000\t1.164 +++ server/config.c\t5 Aug 2003 19:26:59 -0000 @@ -697,7 +697,7 @@                                void *mconfig, const char *args)  {      char *w, *w2, *w3; -    const char *errmsg; +    const char *errmsg = NULL;        if ((parms->override & cmd->req_override) == 0)          return apr_pstrcat(parms->pool, cmd->name, ' not allowed here', NULL); @@ -797,11 +797,14 @@        case ITERATE:          while (*(w = ap_getword_conf(parms->pool, &args)) != '/0') { -            if ((errmsg = cmd->AP_TAKE1(parms, mconfig, w))) + +            errmsg = cmd->AP_TAKE1(parms, mconfig, w); + +            if (errmsg && strcmp(errmsg, DECLINE_CMD) != 0)                  return errmsg;          }   -        return NULL; +        return errmsg;        case ITERATE2:          w = ap_getword_conf(parms->pool, &args); @@ -812,11 +815,14 @@                                 cmd->errmsg ? ', ' : NULL, cmd->errmsg, NULL);            while (*(w2 = ap_getword_conf(parms->pool, &args)) != '/0') { -            if ((errmsg = cmd->AP_TAKE2(parms, mconfig, w, w2))) + +            errmsg = cmd->AP_TAKE2(parms, mconfig, w, w2); + +            if (errmsg && strcmp(errmsg, DECLINE_CMD) != 0)                  return errmsg;          }   -        return NULL; +        return errmsg;        case FLAG:          w = ap_getword_conf(parms->pool, &args);	added PatchAvailable keyword  --Geoff ouch, I didn't search for any UNCONFIRMED reports when attempting to enable the PatchAvailable keyword as appropriate :( sorry, I assumed that non-core people were supposed to enter bugs as UNCONFIRMED until some core developer confirmed it.  of course, I confirmed it, but I have insufficient karma ;) fixed in 2.1  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/config.c?r1=1.168&r2=1.169			Geoffrey Young	Jeff Trawick
22348	null	CLOSED		Jari Aalto	1060692480000	1061829640000		 into + At the documentation page http://httpd.apache.org/docs-2.0/urlmapping.html  There is example:    ScriptAliasMatch ^/~([a-zA-Z0-9]*)/cgi-bin/(.*) /home/$1/cgi-bin/$2  Which might better use +  instead of * You might want to check other examples as well.  Jari	Good point.  I'll fix that.  Thanks.			Joshua Slive
22529	null	RESOLVED		Andrea Rossignoli	1061230020000	1185956240000		RewriteRule problem when the URI is the same as the document root Hi there, let's suppose I have this inside my httpd.conf:  ... <VirtualHost *:80>     ServerAdmin webmaster@example.com     DocumentRoot /www/htdocs     ServerName example.com     ServerAlias www.example.com     ErrorLog /www/logs/error_log     CustomLog /www/logs/access_log common      RewriteEngine On     RewriteRule ^/something/from/?$ /www/htdocs/index.php [L] </VirtualHost> ...  That's work fine, but if I have this directory: /www/htdocs/www/htdocs/index.php a request for example.com/something/from  will be redirected internally to /www/htdocs/index.php and not /www/htdocs/www/htdocs/index.php  In pratice if I have a subdirectory path that is the same as my document root, the redirection is not working fine...in my opinion obviously.  BTW,     RewriteRule ^/something/from/?$ /index.php [L] will call /www/htdocs/index.php which is fine.   Hope it was clear :-).   Thank you, Andrea Rossignoli	Not a bug. It's by intention. This allows rewriterules to act like alias (mapping to a system path). You can avoid this by using the PT flag.  This however needs to be better documented.  Thanks for using Apache. Years later...  Documentation updated in trunk (but won't likely get back to 1.3).			Andr?? Malo	Joshua Slive
22684	null	CLOSED		Lumina	1061754360000	1091446292000		AddCharset default conf is wrong from latin5 to latin9 First install Apache. I take a look at httpd.conf  I found this : AddCharset ISO-8859-1  .iso8859-1 .latin1 AddCharset ISO-8859-2  .iso8859-2 .latin2 .cen AddCharset ISO-8859-3  .iso8859-3 .latin3 AddCharset ISO-8859-4  .iso8859-4 .latin4 AddCharset ISO-8859-5  .iso8859-5 .latin5 .cyr .iso-ru AddCharset ISO-8859-6  .iso8859-6 .latin6 .arb AddCharset ISO-8859-7  .iso8859-7 .latin7 .grk AddCharset ISO-8859-8  .iso8859-8 .latin8 .heb AddCharset ISO-8859-9  .iso8859-9 .latin9 .trk  The five last entries are wrong, it is NOT latin5 to latin9. You should instead use the following entries for latin charsets : AddCharset ISO-8859-1  .iso8859-1 .latin1 AddCharset ISO-8859-2  .iso8859-2 .latin2 .cen AddCharset ISO-8859-3  .iso8859-3 .latin3 AddCharset ISO-8859-4  .iso8859-4 .latin4 AddCharset ISO-8859-5  .iso8859-5 .cyr .iso-ru AddCharset ISO-8859-6  .iso8859-6 .arb AddCharset ISO-8859-7  .iso8859-7 .grk AddCharset ISO-8859-8  .iso8859-8 .heb AddCharset ISO-8859-9  .iso8859-9 .latin5 .trk AddCharset ISO-8859-10 .iso8859-10 .latin6 AddCharset ISO-8859-14 .iso8859-14 .latin8 AddCharset ISO-8859-15 .iso8859-15 .latin9 .latin0 AddCharset ISO-8859-15 .iso8859-16 .latin10  Source : http://www.iana.org/assignments/character-sets	Oups, I mean, last line is : AddCharset ISO-8859-16 .iso8859-16 .latin10 I'm going through the bug db to make sure patches are findable.  Please see  http://httpd.apache.org/dev/patches.html  The page you mentioned do not give a way to create a patch file when using  Windows XP : I just tried, and the command 'diff' does not exist.  I've downloaded version 2.0.48, and the bug is still there, three months after  submitting it.  The best I can do now is providing exact files and line numbers for version  2.0.48.  Affected Files : (<)C:/Program Files/Apache Group/Apache2/conf/httpd.default.conf (34949 octets) (<)C:/Program Files/Apache Group/Apache2/conf/httpd.conf (34949 octets)  719,723c719,727 < AddCharset ISO-8859-5  .iso8859-5 .latin5 .cyr .iso-ru < AddCharset ISO-8859-6  .iso8859-6 .latin6 .arb < AddCharset ISO-8859-7  .iso8859-7 .latin7 .grk < AddCharset ISO-8859-8  .iso8859-8 .latin8 .heb < AddCharset ISO-8859-9  .iso8859-9 .latin9 .trk --- > AddCharset ISO-8859-5  .iso8859-5 .cyr .iso-ru > AddCharset ISO-8859-6  .iso8859-6 .arb > AddCharset ISO-8859-7  .iso8859-7 .grk > AddCharset ISO-8859-8  .iso8859-8 .heb > AddCharset ISO-8859-9  .iso8859-9 .latin5 .trk > AddCharset ISO-8859-10 .iso8859-10 .latin6 > AddCharset ISO-8859-14 .iso8859-14 .latin8 > AddCharset ISO-8859-15 .iso8859-15 .latin9 .latin0 > AddCharset ISO-8859-16 .iso8859-16 .latin10  Just a note: I strongly suggest <http://unxutils.sourceforge.net/>. These are *very* helpful tools. Including diff and patch :-)  ...putting the issue on my todo Ok, now it is the third release of Apache that does not address this issue:  2.0.48, 2.0.49 and 2.0.50. How long does it need to fix an issue with a patch  available ? I mean, it is already 11 months I reported this mistake in the  default configuration... :) Fix committed to CVS. *** Bug 30682 has been marked as a duplicate of this bug. ***			Andr?? Malo	Jeff Trawick	Lumina	Nick Kew
22741	null	CLOSED		Gary E. Miller	1061955120000	1066914998000		Seg fault at ssl_engine_vars.c line 658 I get a seg fault in ssl_engine_vars.c line 658.  Here is part of the gdb back trace:  (gdb) run -X Starting program: /u3/local/apache2/bin/httpd -X [New Thread 16384 (LWP 1777)]  Program received signal SIGSEGV, Segmentation fault. [Switching to Thread 16384 (LWP 1777)] ssl_var_log_handler_c (r=0x83ed8d0, a=0x8274400 'version') at ssl_engine_vars.c:658 658         if (sslconn->ssl == NULL) (gdb) bt #0  ssl_var_log_handler_c (r=0x83ed8d0, a=0x8274400 'version') at ssl_engine_vars.c:658 #1  0x08085046 in process_item (r=0x83ed8d0, orig=0x83ed8d0, item=0x82741c8)     at mod_log_config.c:856 #2  0x080851c6 in config_log_transaction (r=0x83ed8d0, cls=0x8274d98, default_format=0x8214cc8)     at mod_log_config.c:919   The fix is simple in ssl_engine_vars.c:    static const char *ssl_var_log_handler_c(request_rec *r, char *a)   {       SSLConnRec *sslconn = myConnConfig(r->connection);       char *result;  +     if (sslconn == NULL) // check for bad return +        return NULL;      //        if (sslconn->ssl == NULL)          return NULL;	Thanks for the patch!  This has been committed to the 2.1 tree and will be proposed for backport to 2.0.			Joe Orton
22805	null	CLOSED		Radu Greab	1062101340000	1066588832000		file descriptors are erroneously closed In the message available at the mentioned URL, I describe a bug in Apache that sometimes blocks Bricolage, a mod_perl application.  The bug is caused by the recent work of adding proactive close functions to prevent file descriptors leaking to the child processes. Basically, in http_main.c, some calls of ap_note_cleanups_for_fd() were replaced with calls to ap_note_cleanups_for_socket_ex(), but ap_bclose() still calls ap_pclosef() which disarms the cleanup for files, not for sockets. Later, the cleanup for socket is invoked because it was not disabled and closes for the second time a file descriptor which may be already closed (no harm) or may be in use by someone else (the Bricolage problem).  I'm proposing a patch that: - in buff.c: modifies ap_bclose() so that on all platforms ap_pclosesocket() is called for sockets and ap_closef() is called for files; - in http_main.c:   - disarms a cleanup before ap_slack() because ap_slack() closes the socket      itself   - changes the level to critical for the error message issued when the fd_sets      test fails   - removes a kill_cleanup before ap_bclose() because it is redundant	Created an attachment (id=7989) proposed patch  FWIW, Radu wrote up a really good analysis of the problem here:    http://marc.theaimsgroup.com/?l=apache-modperl-dev&m=106200188613283&w=2 Fixed in 1.3.29 (ap_bclose changes only)			David Wheeler	Jim Jagielski	Radu Greab
23130	null	CLOSED		Bjorn Stabell	1063359660000	1063396671000		mod_cache does not cache content with valid Expires header [ Also reported for Apache 1.3.28 as BUG# 23129 ]  This bug was first reported by James Cooper in 1999  (http://archive.apache.org/gnats/4089), but was somehow never included.  Searching the web it is obvious that many people have found this bug through  the years, but none (except James) have reported it.  Instead, it's  become 'common knowledge' that for mod_proxy in Apache to cache content, it has  to have a Last-Modified header.  Just having an Expires header is not enough;  it will always result in a X-Cache: MISS  Last-Modified headers do not really make sense for dynamic content, so many  HTTP Accelerator plugins for dynamic websites only generate Expires headers,  assuming that it'll work fine, when it doesn't.  This patch should fix this deficiency for 2.0.47 (not heavily tested):  *** mod_cache.c-org\tFri Sep 12 15:44:36 2003 --- mod_cache.c\tFri Sep 12 15:44:41 2003 *************** *** 540,553 ****           reason = 'HTTP Status 304 Not Modified';       }       else if (r->status == HTTP_OK && lastmods == NULL && etag == NULL                 && (conf->no_last_mod_ignore ==0)) { !         /* 200 OK response from HTTP/1.0 and up without a Last-Modified !          * header/Etag             */           /* XXX mod-include clears last_modified/expires/etags - this            * is why we have an optional function for a key-gen ;-)             */ !         reason = 'No Last-Modified or Etag header';       }       else if (r->header_only) {           /* HEAD requests */ --- 540,554 ----           reason = 'HTTP Status 304 Not Modified';       }       else if (r->status == HTTP_OK && lastmods == NULL && etag == NULL  +              && (exps == NULL || exp == APR_DATE_BAD)                && (conf->no_last_mod_ignore ==0)) { !         /* 200 OK response from HTTP/1.0 and up without a Last-Modified, !          * Expires, or Etag  header            */           /* XXX mod-include clears last_modified/expires/etags - this            * is why we have an optional function for a key-gen ;-)             */ !         reason = 'No Last-Modified, Expires, or Etag header';       }       else if (r->header_only) {           /* HEAD requests */	I just committed a fix based on your patch to the 2.1-dev branch. I have submitted it for backporting to the 2.0-stable tree. Thank you for your submission and for using Apache. One request, could you use unified diff format in the future for any patches (diff -u). It is the standard format that we all use. Thanks.			Paul J. Reder
23287	null	RESOLVED		John N Armstrong	1064028960000	1186464125000		mod_deflate does not properly format decompressed request content mod_deflate is configured to decompress an inbound HTTP SOAP request (note: The Apache SOAP TCPTunnel/Monitor was used to capture the flows between the Apache proxy server and WebLogic):  POST /some/url HTTP/1.0 Host: localhost:1080 Content-Type: text/xml; charset=utf-8 Content-Length: 4727 SOAPAction: 'http://some.soap.action' Accept-Encoding: gzip,deflate Content-Encoding: gzip <SNIP: Compressed SOAP message/>  The HTTP request body (the SOAP request) is compressed in the gzip format.  mod_deflate does intercept and decompress the content.  Apache is also configured (using mod_proxy) to forward the request on to WebLogic. The request forwarded to WebLogic is as follows:  POST /some/url HTTP/1.1 Host: localhost:7101 Content-Type: text/xml; charset=utf-8 Content-Length: 4727 <== Note! SOAPAction: 'http://some.soap.action' Accept-Encoding: gzip,deflate Content-Encoding: gzip <== Note! <SNIP: Decompressed SOAP message />  mod_deflate should mdoify (or remove) the Content-Encoding header to reflect the fact that the content is NOT compressed, and should re-write the Content-Length header to reflect the actual length of the decompressed content.	Iit cannot change the content-length header, because the data is streamed. Hmm, I guess it's not really intended to decompress as a proxy. Can you try what happens, if you use mod_header's "RequestHeader unset' directive to remove the headers in question?  I think, mod_proxy should be changed, that if the content-length header is removed, it switches to chunked encoding.... duh, that is only possible with HTTP/1.1. Seems there's no simple solution to that problem.  I'm +1 anyway to remove the gzip token from Content-encoding.  Any other ideas? Yes, I think that mod_deflate is rarely used for decompression of the REQUEST -- it's almost always used for compression of the RESPONSE. And, the combination of mod_deflate and proxying the request to a back-end server appears to be problematic.  I tried using mod_headers and the RequestHeader unset command to remove the Content-Encoding: gzip and Content-Length: xxxx headers. The problem with this is that it causes mod_deflate to be be nop-op'ed because he doesn't recognize that the incoming request is compressed without the header.  I considered writing a filter to post-process mod_deflate's output and remove the headers, but that won't work either, because the output is being streamed (as you point out), and the headers will already have been written. Hmmm, ...  Can you not use (the mirror of) the workaround I used to recommend for mod_proxy_html before updating mod_deflate to support decompression of response data from a proxy?  Header unset Accept-Encoding  to tell the Client you don't want gzipped data?  I might actually fix this properly, but no promises. A related problem with servlet requests forwarded to Tomcat via mod_jk: request content gets decompressed, but I get an end of stream at (the original) Content-Length bytes from stream start, resulting in truncated decompressed content for the servlet.  I do not insist on removing 'gzip' from Content-Encoding or removing Content-Length. It's completely OK with me to just ignore Content-Length in my servlet and rely on the servlet request end of stream. Servlets have to be able to handle chunked requests anyway, so using Content-Length is not good style regardless of compression. It's also OK with me to ignore 'gzip' in Content-Encoding, as long as I know that Apache handles it for me. But it's not OK to get truncated content, I obviously do need full decompressed content in the servlet. (In reply to comment #4) > A related problem with servlet requests forwarded to Tomcat via mod_jk: request  I'm certain, this should be fixed in mod_jk. Could you open a bug report / feature  request at mod_jk's tracker? Opened http://issues.apache.org/bugzilla/show_bug.cgi?id=34526 William Barker from mod_jk marked 34526 'resolved, wontfix' and insists it's a mod_deflate problem. Would it be possible to have a direct discussion among the developers responsible for this functionality in mod_deflate and mod_jk? It's important to get it fixed, wherever the fixes may happen to be... Fixed in /trunk/ and proposed for backport http://svn.apache.org/viewvc?view=rev&revision=560689  This kind of thing needs round tuits.  But it's still been an inexcusably long time for a real bug. Understand. Well, better late than never, eh? I'd long-since moved on to other projects and forgotten  about this. ;-) Thanks for taking care of it. http://svn.apache.org/viewvc?view=rev&rev=563464 Any chance of a backport to Apache 2.2.x? (In reply to comment #11) > Any chance of a backport to Apache 2.2.x?  It is already backported to Apache 2.2.x. See Comment 10.			Andr?? Malo	Jess Holle	John N Armstrong	Michael Klepikov	Nick Kew	Ruediger Pluem
23416	null	CLOSED		Richard Safran	1064504220000	1065808559000		Non-existent directory in RewriteLog fails silently Running Gentoo Linux with Apache 2.0.47 (compiled from source). Migrating sites to new server.  copied vhosts entries from previous httpd.conf. Entry for RewriteLog referred to non-existent directory (from the old server). Apache failed to start and did not report any errors on the command line or in Apache or server logs even with LogLevel=debug.  apache2 -t and apache2ctl configtest did not report any errors.  Changing the LogRewrite to the correct value solved the startup failure, but substantial time was invested trying to find the problem.	odd... with 2.0.47 and a bogus directory for rewritelog, I get this in error_log:  [Tue Sep 30 05:25:30 2003] [error] (2)No such file or directory: mod_rewrite: could not open RewriteLog file /gobble/log  Was your RewriteLog directive in a VirtualHost container or at main scope?  The RewriteLog directive was inside a VirtualHost container. That'll be fixed in 2.0.48:  <http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/mappers/mod_rewrite.c.diff?r1=1.135.2.14&r2=1.135.2.15&diff_format=h>  I'm going to add a Changelog entry referring to this PR.  Thanks for the report and thanks for using Apache.			Andr?? Malo	Jeff Trawick	Richard Safran
23421	null	RESOLVED		Martin D??rst	1064520960000	1102749616000		Remove AddDefaultCharset from httpd.conf as shipped Apache 2.0 currently ships with 'AddDefaultCharset iso-8859-1' in httpd.conf. This should be fixed (by commenting out or removing it, or replacing it with AddDefaultCharset Off) and the comment in httpd.conf should be corrected, for the following reasons:  1) Charset information is important, but no charset information is much    preferable to wrong charset information (contrary to what the comment    in httpd.conf says).  2) Many document formats have their own internal way to specify character    encoding. It is often sufficient to rely on these. It is often easier,    for document authors and administrators, to make sure these are correct,    than to make sure that the served headers are correct.  3) In most parts of the world, including Europe and the Americas (because of    windows-1252), there is rarely any server that contains only iso-8859-1    documents, and there is rarely any server administrator who knows the    encodings of all the served documents (if s/he is even aware of character    encoding issues).  4) Upgraders from Apache 1.3 to Apache 2.0 often overlook this setting,    resulting in large numbers of files served wrongly with charset=iso-8859-1,    and an increasing number of complaints to ISPs and Web hosters. Fixing    this bug would make upgrading easier and more predictible, and would    reduce complaints to hosters that they have difficulties to address    because they are not familiar with character encoding issues.  5) In order to override the setting (and assuming users know how to do    this), users have to have FileInfo permissions for their .htaccess files.    httpd.conf as shipped contains an example of settings for UserDir    directories and similar cases where the users are allowed some    amount of configuration, but this is commented out. So the chance    is high users don't have a chance to fix the problem, even if they    know the correct encoding of their document and the correct way to    set the HTTP header.  6) The oft-cited default of iso-8859-1 for HTTP is something that exists    on only paper, but not at all in practice. If it were observed in    practice, 'AddCharsetDefault iso-8859-1' would be unnecessary.    Because the default is not observed, this setting is harmful.  7) The comment in httpd.conf claims that this setting is a good start for    internationalization. This ignores the fact that many hosts already    contain a lot of internationalized documents.  In connection with this, the documentation for AddDefaultCharset should be updated to clearly point out the potential dangers of using it (i.e. only use this if you know the character encoding of the majority of the documents on your server, and you know what the exceptions are and make sure they are set correctly).	see also bug 14513 http://nagoya.apache.org/bugzilla/show_bug.cgi?id=14513 The new default value causes corruption for people upgrading to the new  version. The mislabeling of Windows-1252 as iso8859-1 can cause the euro symbol  to be incorrect and result in erroneous financial transactions. The misleading Apache documentation and the change to apply the default charset  causes subtle differences which have significant impact. It can also cause non- subtle differences. The fact that web standard calls for http charset to  override the charset in the page, means that change will override even pages  with self-documenting charset (ie pages that use the meta tag). The old  behavior should be restored right away. I'm not enough of an expert in this area to make a decision about it, but the problem with simply removing this directive is that it creates problems with cross-site scripting.  See: http://httpd.apache.org/info/css-security/ and links from that page.  In fact, AddDefaultCharset was originally added to deal with these problems, so simply removing it without addressing the CSS issue would not be smart.  (See also bug 13986 that states that apache shouldn't set a default content-type by default. This issue should probably be addressed along side that one.) OK, I think we need a clarification. We are not requesting the command AddDefaultCharset be eliminated.  We are requesting that its use in the default configuration to set the charset to iso 8859-1 be eliminated.  As for the security risk, the significant piece of the referenced document seems to be: 'In addition, web pages should explicitly set a character set to an appropriate value in all dynamically generated pages. '  We can all agree with this. The problem is iso 8859-1 is not an appropriate value for the majority of configurations. The article references that this used to be the default for some of the web standards and is no longer the case.  It is because it is not the best choice in the majority of cases, even in English speaking markets these days, that it is no longer the default. Perhaps a better compromise solution is to at least ask the administrator what the value should be during the installation and  provide a list of the most common encodings for them to choose from. Or default to UTF-8 and let people know clearly that is what you use.  SuSE 9.0 shipped Apache 2.0 with AddDefaultCharset utf8  As a result any other encoding mentioned in the hmtl/xhtml/xml-source sent to the server was ignored.  That does not fit the behaviour of Apache talked about on the cross-site-scripting page; there it is told that option AddDefaultCharset is only activated if any page-specific encoding is missing.   A mistake in logic, of the behaviour of option AddDefaultCharset ? Apache has absolutely no interest in <meta> tags inside the html.  That comment is talking about AddCharset and similar methods of setting the HTTP headers. To Joshua Slive: Then the faulty behaviour is on the browser's side, insomuch a request is sent without an complete or appropriate header, i.e. including the encoding information. That was my first guess, at Mozilla.  Of course it's presumed that option AddDefaultCharset only is activated if no encoding information is available.Or, to extend the view, if no valid/accepted encoding is sent in the request, given a list of encodings accepted by the server.  Would that still help the CSS-problem?  Dietmar, I can't decipher what you are trying to say.  But this is not the best place to discuss it.  Please try the users@httpd or dev@httpd mailing list. Is this issue still not resolved?  I am Chinese and I am strongly on the side of the reporter.  The problem, I suppose, arises from a problematic standard.  AFAIK, the header sent from the server overrides that contained in a meta tag.  Browsers I use all conform to this behaviour, and sorrows of non-Western Web developers grow.  For Chinese, we routinely use  <meta http-equiv='Content-Type' content='text/html; charset=gb2312'>  to mark a page as Chinese.  And this method allows us to place an ISO-8859-1 page on the same server/directory without worrying about server configurations.  I even do not know now how to achieve this effect if 'AddDefaultCharset' is ever used.  Security is important, but I do not think setting the default charset by the SERVER is the right way to go.  Indeed, I think the suggestion to use a default charset has caused more problems than solved (see stories below).  It is the server-side SCRIPT that should take care of this.  And I do not think the comment in the conf file is correct: it really does harm, because setting it will PREVENT Web developer from specifying the charset in their pages, who should really be responsible for such issues.  By the way, some stories.  Several times I have been called by colleagues because they cannot make Apache display Chinese characters correctly on a newly installed box.  I once translated the mission page for webstandards.org, and after a site migration it no longer displayed Chinese.  After several emails the non-Western pages are moved to a special server or directory and it was OK.  Now the page is archived at   http://archive.webstandards.org/mission_gb2312.html  And it is wrong AGAIN, along with other translations like Japanese!  What is the use of security, if it makes things inaccessible?  (Not to mention that it is a wrong response for a security issue.  Even the page http://www.cert.org/tech_tips/malicious_code_mitigation.html#3 mentions only the use of a meta tag like the gb2312 example above.)  To Dietmar:  Your opinions about Accept-Charset are correct only if  1) A Chinese user can set his browser to accept only GB2312; 2) A Chinese user never need to view ISO-8859-1 pages, or the browser supports per-page configuration of Accept-Charset; and 3) If 'Accept-Charset: gb2312' is sent to the server, the server will not send the default 'charset=ISO-8859-1'.  I do not see any of them holds. I agree that shipping with an AddDefaultCharset preset is unsatisfactory, and screws up users of servers with unresponsive admins.  Can we simply remove it from the default config to deal with the case of authors having more clue than their sysops?  I'd be happy with that, but I'm going to ask for review in other fora where folks have relevant expertise.  Actually the solution is already available to users.  There's a bunch of AddCharset directives in the default httpd.conf that serve precisely this purpose: AddCharset ISO-8859-1  .iso8859-1  .latin1 AddCharset ISO-8859-2  .iso8859-2  .latin2 .cen AddCharset ISO-8859-3  .iso8859-3  .latin3 etc.  So a fix would be to correct errors and omissions in that list, and leave it to authors to control their charset using a suffix on the document name. Of course that's ugly, but at least it works.  Also worth noting: mod_proxy_html 2.x will parse META elements in HTML and XHTML documents and convert them to real HTTP headers. See http://apache.webthing.com/mod_proxy_html/  I just wrote:  > So a fix would be to correct errors and omissions in that list, and leave it > to authors to control their charset using a suffix on the document name. > Of course that's ugly, but at least it works.  Hmmm, I neglected to add that the ugliness goes away if that's used with  mod_negotiation: perhaps we shold ship with multivies on by default? The other crucial issue is of course to document it! *** Bug 30860 has been marked as a duplicate of this bug. *** In addition to the principal reasons given earlier there is also a pragmatic reason not to use AddDefaultCharset in the default httpd.conf. Sending the charset declaration triggers an obscure bug in MSIE with multipart forms, as documented at http://www.interactivetools.com/forum/gforum.cgi?post=34345;sb=post_latest_reply;so=ASC;forum_view=forum_view_collapsed (at the bottom).  I know that Microsoft should fix their browser but I spend a lot of time today debugging an old script that didn't work after upgrading to Apache 2 because of this. I think the right thing is not to trigger bugs in a product that is still used by so many users by shipping a httpd.conf that contains this as a default. I'm surprised that this bug is still around. The only justification for that that I was able to find in the record is the pointer to the Client Side Scripting (CSS) issue. However, this is based on a shallow understanding of CSS. In order to avoid CSS, just setting whatever character encoding is not good enough. A solution requires that the client side gets the right character encoding. Of course, declaring iso-8859-1 as a default doesn't work for a huge amount of Web pages. So this default should be removed as quickly as possible, and the documentation for CSS should be updated to make more clear that it's not 'declare an encoding' but 'declare the right encoding' that is important (also for other reasons than just security).  I can easily provide more information (e.g. a page that shows how use of the wrong encoding, such as declaring a page as iso-8859-1 that isn't iso-8859-1 can lead to attacks) if contacted directly. This was supposed to be fixed a long time ago.  It was for 1.3. I am verifying with the group and will remove it from the default config if there are no objections. Fixed in HEAD (2.1.x), may be backported later to 2.0.x.  svn rev 111582 *** Bug 33028 has been marked as a duplicate of this bug. ***			Dietmar Temme	Joe Orton	Joshua Slive	Martin D??rst	Nick Kew	Roy T. Fielding	Sebastiaan Hoogeveen	Tex Texin	Wu Yongwei
23501	null	RESOLVED		Dave Boynton	1064863860000	1185965602000		[mod_rewrite] incorrect load balancing solution The rewrite guide incorrect gives an example using BIND syntax that's been deprecated for awhile now. Both 2.0 and 1.3 documentation has the same problem.  The example is for:  Load Balancing Description:     Suppose we want to load balance the traffic to www.foo.com over www[0-5].foo.com (a total of 6 servers). How can this be done?  The solution goes on to list multiple cnames for the same label: www    IN  CNAME   www0.foo.com.        IN  CNAME   www1.foo.com.        IN  CNAME   www2.foo.com.        IN  CNAME   www3.foo.com.        IN  CNAME   www4.foo.com.        IN  CNAME   www5.foo.com.        IN  CNAME   www6.foo.com.  This is incorrect, according to RFC 2181 (and other DNS RFCs): 'There may be only one such canonical name for any one alias.' BIND 8 (and prior versions) could be made to work with multiple cnames, but BIND 9 no longer supports it at all.  The correct implementation uses multiple A records for the label, like so: www   IN  A       1.2.3.1       IN  A       1.2.3.2       IN  A       1.2.3.3       IN  A       1.2.3.4       IN  A       1.2.3.5       IN  A       1.2.3.6	I'm going through the bug db to make sure patches are findable.  Please see  http://httpd.apache.org/dev/patches.html  *** Bug 42349 has been marked as a duplicate of this bug. *** Created an attachment (id=20448) for trunk  Thanks. Fixed on trunk and 2.2.			Jeff Trawick	Joshua Slive	Takashi Sato
23606	null	CLOSED		giovanni tummarello	1065285060000	1065827659000		mode SSL config problem in the virtual host domain section could someone please put a small warning box here http://httpd.apache.org/docs-2.0/vhosts/name-based.html  saying that putting   NameVirtualHost *  <VirtualHost *>  is really not a good idea with all the current distributions (redhat for  example) that put mod_ssl together.. you get some strange error talking about  port 443 which it is not trivial to fix if not digging on google sometime (not  10 seconds.. it was more like 2 minutes) .. the solution is   namevirtualhost *:80 in most situations  I understand the semantic now but i see no reasons why there shouldnt be a  small warning box or a little change in the first example (which is usually  what one decides to copy paste)  thanks for listening :-) !	I agree.  In fact, all examples with '*' should be replaced with '*:80'. done.			Andr?? Malo	Joshua Slive
23618	null	CLOSED		freakin	1065449400000	1065824297000		Docs bug I dont know if this bug report is annoying or not, I dont intent to annoy  anyone.  The Apache 2.0 docs says:  'If the current Apache API had a filename-to-filename hook additionally to the  URI-to-filename hook then we wouldn't need this flag! But without such a hook  this flag is the only solution. The Apache Group has discussed this problem and  will add such a hook in Apache version 2.0.'  in the section on mod_rewrite.  I've mirrored it here:  http://209.51.149.4/manual/mod/mod_rewrite.html#rewriterule	It's totally fine ;-)  Thanks for the report, it's fixed now in CVS. *** Bug 43773 has been marked as a duplicate of this bug. ***			Andr?? Malo	Takashi Sato
23642	null	CLOSED		Hong-Gunn Chew	1065504420000	1069439776000		Incorrect timezone for XX:30 in logs When the timezone is +/- ?.5, the timezone would be logged as +/-XX1800, instead of +/-XX30.  For example, Adelaide is +9.5, but it is logged as +091800 instead of +0930.  This can be corrected by correcting modules/loggers/mod_log_config.c (2.0.47): 573c573 <                          sign, timz / (60*60), timz % (60*60)); --- >                          sign, timz / (60*60), (timz % (60*60))/60);  Thanks, HG	I'm going through the bug db to make sure patches are findable.  Please see  http://httpd.apache.org/dev/patches.html  patch is already committed to 2.1-dev and will likely be in the next 2.0.x release  thanks! 			Jeff Trawick
23713	null	CLOSED		P.M.	1065744600000	1065758056000		typo in description of bomb.gif in README in icons directory The file README, found on my system in /usr/share/apache2/icons/, contains a typo in the line which describes bomb.gif. The line reads as follows:           This can be used to repreesnt core files. It should read:                   |||           This can be used to represent core files.	Created an attachment (id=8519) Patch of the typo corrected  fixed, thanks!			Cliff Woolley	P.M.
23724	null	CLOSED		Olaf van der Spek	1065789840000	1066091804000		t be supressed I installed Apache 2.0.47 on Windows 98. The conf includes: LogLevel warn The error log includes: [Fri Oct 10 13:02:17 2003] [notice] Parent: Created child process -327251  But according to http://httpd.apache.org/docs-2.0/mod/core.html#loglevel only warn, error, crit, alert and emerg level messages should be present in the  log file.	doc problem This is now fixed in all three doc trees. Thanks.			Erik Abele	Jeff Trawick
23747	null	CLOSED		Liam Quinn	1065902340000	1067805613000		Directory listings use XHTML syntax in HTML document Directory listings with FancyIndexing use XHTML syntax in an HTML document:  <!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 3.2 Final//EN'> ... <img src='/icons/text.gif' alt='[TXT]' /> ... <hr />  In HTML, '<hr />' is actually equivalent to '<hr>>' (note the extra '>'). It's only in XHTML where the slash is used with empty elements. For details on empty elements in HTML vs. XHTML, see  http://www.cs.tut.fi/~jkorpela/html/empty.html  To fix the problem, don't use the slash in empty elements in HTML:  <!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 3.2 Final//EN'> ... <img src='/icons/text.gif' alt='[TXT]'> ... <hr>	Created an attachment (id=8539) Patch to use HTML syntax for empty elements  Quick note until someone picks it up. We need an option for switching  behaviour, because people may use (and do use) their own declaration.  Thanks for your report! Fixed the issue in 2.1 and proposed for backport into the 2.0 branch.  Thanks!			Andr?? Malo	Liam Quinn
23748	null	CLOSED		Liam Quinn	1065903540000	1069458368000		t met I had been using the following directives with Apache 1.3.27:  ExpiresActive On ExpiresByType image/gif A5184000 ExpiresByType image/jpeg A5184000  When I upgraded to Apache 2.0.47, I began getting entries such as these in my error_log:  [Sat Oct 11 16:02:54 2003] [error] [client w.x.y.z] internal error: bad expires code: /foo/bar/index.html [Sat Oct 11 16:10:44 2003] [error] [client w.x.y.z] internal error: bad expires code: /foo/bar/all.txt  These errors occur whenever there should be no Expires header (since no ExpiresByType matches and no ExpiresDefault is specified). With Apache 1.3.27, no such errors occurred.  In case it's relevant, I'm using Linux x86, kernel 2.2.19.	Created an attachment (id=8538) Patch to eliminate the error  Hmm. I think, the right fix would be to set new->expiresdefault = NULL in create_dir_expires_config and to change the merger accordingly. Your fix  seems to be just a work around.  Thanks for the report and thanks for using Apache! Created an attachment (id=8544) Alternate patch that uses NULL for expiresdefault  enabling the PatchAvailable keyword updated doc on submitting patches is at http://httpd.apache.org/dev/patches.html  *** Bug 24459 has been marked as a duplicate of this bug. *** I have tested and committed this patch to the 2.1-dev branch of Apache and submitted it for a vote for backporting into the 2.0 stable branch.  Thank you for using Apache and for taking the time to track down a fix and submit a patch. I have tested and committed this patch to the 2.1-dev branch of Apache and submitted it for a vote for backporting into the 2.0 stable branch.  Thank you for using Apache and for taking the time to track down a fix and submit a patch. *** Bug 21907 has been marked as a duplicate of this bug. ***			Allan Edwards	Andr?? Malo	Jeff Trawick	Liam Quinn	Paul J. Reder
23795	null	CLOSED		David Rees	1066087920000	1067461306000		mod_status reports too much CPU when using worker mpm When looking at /server-status, it is reporting about 10 times too much CPU time when compared to the prefork MPM.  This is on SGI IRIX 6.5.20m compiled with the following flags and the SGI MIPsPro compiler:  ./configure --enable-ssl=static --enable-deflate --enable-mods-shared=most --with-ssl=/usr/local/ssl --with-devrandom --with-mpm=worker  Here's the relevant output from mod_status when compiled without --with-mpm=worker:  Total accesses: 41 - Total Traffic: 1.9 MB CPU Usage: u6 s.26 cu0 cs0 - 29.8% CPU load 1.95 requests/sec - 94.1 kB/second - 48.2 kB/request 1 requests currently being processed, 7 idle workers  And with it:  Total accesses: 41 - Total Traffic: 1.9 MB CPU Usage: u67.21 s3.64 cu0 cs0 - 221% CPU load 1.28 requests/sec - 61.8 kB/second - 48.2 kB/request 1 requests currently being processed, 49 idle workers  With a bit of stress testing with multiple clients, I can get the CPU load reported to be on the order of 2-4000%, the machine only has 2 CPUs.  The requests on each run was generated from a fresh start over SSL and using the requests.  mod_jk 1.2.5 is also loaded into the server.	The problem is apparently that each thread is using times() syscall to retrieve info on CPU usage for entire process, and mod_status is joyfully adding up all the values :)  What we really need is to pick the times() info that was retrieved most recently by some thread in the process.  I'll attach a patch in a sec that seems to resolve the problem for me.  It would be helpful if you could try it out.  Note that in the extended status table the same CPU seconds will be reported for each thread.  I haven't done anything about that.  Perhaps '=' or some other symbol should be printed for threads other than the first one.  Created an attachment (id=8758) proposed patch for bogus CPU% with threaded MPM  I tried out the patch, it does appear to generate correct overall CPU usage statistics.  Interestingly, I don't get the same CPU times for each thread in a worker as you suggested, it looks like each thread reports the CPU usage at the time of the last request for the worker thread group.  I agree that it would be a good idea to only display the CPU time once for each thread group, it would be less confusing. >Interestingly, I don't get the same CPU times for each thread in a worker as you >suggested, it looks like each thread reports the CPU usage at the time of the >last request for the worker thread group.  Yeah, I realized later that was an erroneous claim, caused by a lack of common sense and not enough data points :)  I need to do a little more testing, such as create a looper module and see if CPU% is still sane, then commit to 2.1 and request merge to stable.  fixed in 2.1-dev; I'll propose it for merging to 2.0.x once folks have had a chance to compla^H^H^H^H^H^Hlook over it  btw, more code was needed to keep working on linuxthreads (old Linux pthreads implementation); also, I chose to keep displaying CPU time per thread in extended status table...  it provides additional hints with normal thread libraries and it is unique information with linuxthreads  fix committed to stable branch for 2.0.next 			David Rees	Jeff Trawick
23798	null	CLOSED		Robert Andersson	1066114260000	1067647674000		Mention force-no-vary workaround in Content Negotiation docs Some or all versions of Internet Explorer seems to not cache a resources with *any* Vary header. See discussion: http://marc.theaimsgroup.com/?l=apache-httpd-users&m=106579308905249&w=2  The environment variable 'forve-no-vary' can be used as a workaround, and this is mentioned in the document Environment Variables. This should be pointed out in the Content Negotiation document, under the section 'Note on Caching', as well, with a pointer to the env doc.  I'm no good with authoring ;), but something like this could be added to http://httpd.apache.org/docs-2.0/content-negotiation.html#caching :  'Some clients don't interpret the Vary header, set in negotiated responses, correctly (see the known client problems page <./misc/known_client_problems.html>). This can result in that resources are not properly cached. Setting the special force-no-vary environment variable may help (see Special Purpose Environment Variables <./env.html#special>). Example:       BrowserMatch MSIE force-no-vary=1 '  This is, of course, also relevant to Apache 1.3.	Thanks for the note.  I've updated the content-negotiation docs.  I didn't specifically blame MSIE because, although its behavior is annoying, it probably is technically 'correct'.  It will appear in the next round of doc updates.			Joshua Slive
23836	null	CLOSED		M. Brian Akins	1066223400000	1066932317000		Malformed host headers causes mod_include to seg fault Config:  AddOutputFilterByType INCLUDES text/html text/plain  Send '/' in host header.  Seg fault...  In function add_include_vars()  Quick fix:   --- mod_include.c.orig\tTue Oct 14 13:54:43 2003 +++ mod_include.c\tTue Oct 14 13:44:23 2003 @@ -3353,7 +3353,7 @@      include_server_config *sconf= ap_get_module_config(r->server->module_config,                                                                &include_module);   -    if (!(ap_allow_options(r) & OPT_INCLUDES)) { +    if (!(ap_allow_options(r) & OPT_INCLUDES) || (r->status == HTTP_BAD_REQUEST)) {          return ap_pass_brigade(f->next, b);      }     Here's the backtrace: #0  0x402558f3 in strrchr () from /lib/i686/libc.so.6 #1  0x08180000 in ?? () #2  0x4031595b in add_include_vars (r=0x817edf0, timefmt=0x4031d614 '%A,%d-%b-%Y %H:%M:%S %Z') at mod_include.c:158 #3  0x4031c4fd in includes_filter (f=0x8180000, b=0x8180050) atmod_include.c:3399 #4  0x0807ebe3 in ap_pass_brigade (next=0x8180000, bb=0x8180050) atutil_filter.c:550 #5  0x08081dce in ap_old_write_filter (f=0x8180038, bb=0x8180050) atprotocol.c:1321 #6  0x0807ebe3 in ap_pass_brigade (next=0x8180038, bb=0x8180190) atutil_filter.c:550 #7  0x080814ae in end_output_stream (r=0x817edf0) at protocol.c:1039 #8  0x0808151b in ap_finalize_request_protocol (r=0x817edf0) atprotocol.c:1061 #9  0x080697e5 in ap_send_error_response (r=0x817edf0,recursive_error=0) at http_protocol.c:2423 #10 0x08081050 in ap_read_request (conn=0x817ae50) at protocol.c:904 #11 0x080650eb in ap_process_http_connection (c=0x817ae50) athttp_core.c:286 #12 0x0807c1ef in ap_run_process_connection (c=0x817ae50) atconnection.c:85 #13 0x0807c5e6 in ap_process_connection (c=0x817ae50, csd=0x817ad70) atconnection.c:211 #14 0x0806c819 in process_socket (p=0x817ad38, sock=0x817ad70,my_child_num=0, my_thread_num=0,    bucket_alloc=0x8132128) at worker.c:632 #15 0x0806d047 in worker_thread (thd=0x81082c0, dummy=0x80e1af0) atworker.c:947 #16 0x40111d60 in dummy_worker (opaque=0x81082c0) at thread.c:127 #17 0x40125c6f in pthread_start_thread (arg=0x407c7be0) at manager.c:279	A different patch was committed to 2.1-dev and has been approved for stable branch.			Jeff Trawick
23850	null	CLOSED		TTSG Internet Services, Inc.	1066252260000	1078697464000		Allow from at times need /32 1) Create directory off root of server 2) Put in following .htaccess  AuthType Basic  AuthName Restricted Satisfy Any  AuthDBMUserFile /local/server/.htpasswd  <Limit GET POST> order deny,allow deny from all allow from 216.231.111.17 allow from 64.21.99.146  require valid-user  </Limit>  3) Access from 216.231.111.17, requests a password 4) Access from 64.21.99.146, doesn't request a password 5) Put change statement to 'allow from 216.231.111.17/32' 6) Access from 216.231.111.17 no longer asks for password 7) Add 'Allow from 204.107.90.128' (Out of the /19 that the server and 216.231.111.17 are in, but still advertised via BGP locally) and can't access. Use 'Allow from 204.107.90.128/32', can.  Why does it seem like if the IP is in a network local we have to put /32 on it, and if its remote it works ok?	I'm very skeptical you've identified a bug here for several reasons:  1. I've never heard of any problem remotely like this before, and these features are used frequently.  2. The fact that you are using <Limit GET POST> shows that you are not following recommended practices for apache configuration, and therefore there could be many other things wrong with your config.  I suggest you start with an absolutely default install of apache with no extra modules and no config modifications except the ones you suggest below.  If it still doesn't work, you can reopen this bug, but be sure to provide more details about what is in your logs, the exact OS version, etc.  Thanks for using Apache! Hi,  Ok, we did some investigation.   1) Download/uncompress/untar source 2) Compile with gcc 3.2.3 with just ./configure;make;make install 3) Create a directory under htdocs called testing, put in an .htaccess of :  AuthDBMUserFile /local/wwwcust/passes/sample AuthDBMGroupFile /dev/null AuthName Members_Only AuthType Basic  Satisfy Any  order deny,allow  deny from all  allow from 24.193.48.116  allow from 202.139.152  allow from 210.80.149  allow from 216.183.31.224/27  allow from 209.88.233.224/27  allow from 209.88.69.192/27  allow from 209.135.126  allow from 64.8.218  allow from 63.201.23  allow from 217.145.67.0/25  allow from 62.39.85  allow from 216.231.111.14 require valid-user  4) Edit the stock httpd.conf where it depicts the default document root like <Directory /usr/local/etc/httpd/htdocs> and change the 'AllowOverride None' to 'AllowOverride All'. Start server 5) From 216.231.111.14 attempt to access the directory, it will ask for an id/pass 6) Change it to 216.231.111.14/32, it works.  Delete all directories and configs.   Start the instructions again, except in step 2 , change it to 'CC=gcc -m32' infront of the ./configure;make;make install At step 5, it will let you in immediately.   So, it seems, in 64 bit mode it has issues, but not 32 bit.  We can reproduce this on mutiple machine that we own, and others own. Interesting.  I assume that it doesn't matter if you remove the Auth*/Require/Satisfy directives and just test mod_access?  I don't have a solaris system handy to test on, but if someone does, I'm sure they'd be interested in your exact OS/patch level. With only the following in .htaccess:   order deny,allow deny from all allow from 216.231.113.11 allow from 24.193.48.116   I see the same symptoms, coming from the 24.* address I get in (Outside our network) , from 216.* (local subnet) I get forbidden, if I add the /32 it works fine.  This server is running Solaris 9, kernel patch level 112233-07, apache 1.3.28 compiled with 64-bit gcc3.2.3 with a standard build , using gnu make 3.80 (also built 64-bit). What's the result of running:  $ cd srclib/apr/test $ make testall $ ./testall -v testipsub  from the 64-bit build tree?  Hi,  I find no 'apr' directory anywhere in the Apache 1.3.X tree when I untar it.  Thanks, Tuc/TTSG Internet Services, Inc. This was found and fixed independently by Henning Brauer from the OpenBSD team; the fix is checked in here for the next 1.3 release; thanks for the report.  http://cvs.apache.org/viewcvs.cgi/apache-1.3/src/modules/standard/mod_access.c?r1=1.46&r2=1.47  			Joe Orton	Joshua Slive	TTSG Internet Services, Inc.
23902	null	CLOSED		Andrew Thompson	1066448640000	1073775731000		Add .dmg to application/octet-stream in mime.types Please consider altering the application/octet-stream configuration in mime.types to:  application/octet-stream\tbin dms lha lzh exe class so dll dmg  'dmg' files are Apple Disk Images. This is the prefered application packaging format for all Mac OS X application distributions. Presently Apache defaults to serving these files with the mime type text/plain, which causes browsers to display these binary files in the browser window instead of prompting to save to disk. Server administrators that need to serve these files have to manualy add dmg to their configurations, and those whose sites are hosted by third parties have all the hassle of trying to change the config of a server they don't control (though I appreciate an AddType directive in .htaccess is a partial solution).  This issue annoys millions of Mac users, it would be great to see dmg added to the default Apache setup.  Should I open a seperate bug against httpd 2.0 or is this enough to get the issue looked at for both? I can make patches if it would help, but it seems like overkill for such a trivial issue - just let me know.	Makes sense to me too, so I've added this to the mime.types file of all three versions currently in  development. Thanks for using Apache.			Erik Abele
23956	null	CLOSED		Eric Seidel	1066682880000	1069794811000		mod_ssl should report actual OpenSSL version mod_ssl (both 1.3.x and 2.x) currently uses the SSL_LIBRARY_TEXT define instead of the  SSLeay_version() function to determine the version number of OpenSSL which it is using.  This is bad because here the mod_ssl binary is carrying the OpenSSL version number instead of  querying the version of OpenSSL it's using.  This can lead to confusion (especailly security related), if  for example an administrator patches OpenSSL to be 3.4.d instead of 3.4.a, to work around known  mod_ssl related vulnerabilities in OpenSSL.  Even though the system has been properly patched, it will still report the old (mod_ssl compiled in)  version number to Scanning software etc.  Our customers complained, and we have fixed the following in our version of Apache... however I feel  this change would make sense up-stream as well.  I've attached a diff against 1.3.28:  The 2.1.x diff is nearly identical, only different line numbers.  Simply replace the one instance of  'SSL_LIBRARY_TEXT' in ssl_engine_vars.c  with 'SSLeay_version(SSLEAY_VERSION)'.  Thanks for your time.  RCS file: /cvs/root/apache_mod_ssl/mod_ssl/pkg.sslmod/ssl_engine_vars.c,v retrieving revision 1.1.1.8 diff -u -r1.1.1.8 ssl_engine_vars.c --- ssl_engine_vars.c   2003/07/25 02:32:10     1.1.1.8 +++ ssl_engine_vars.c   2003/10/20 20:36:34 @@ -617,7 +617,7 @@          result = ap_psprintf(p, 'mod_ssl/%s', MOD_SSL_VERSION);      }      else if (strEQ(var, 'LIBRARY')) { -        result = ap_pstrdup(p, SSL_LIBRARY_TEXT); +        result = ap_pstrdup(p, SSLeay_version(SSLEAY_VERSION));          if ((cp = strchr(result, ' ')) != NULL) {              *cp = '/';              if ((cp2 = strchr(cp, ' ')) != NULL) cvs server: Diffing mod_ssl/pkg.sslsup	Thanks for the patch.  Note that to get a change in the independent mod_ssl that works with Apache 1.3, talk to the folks that maintain it (www.modssl.org).  It seems clear from your description what we need to do with 2.1 and 2.0.  Committed to HEAD, will propose for backport to 2.0.  Thanks for the patch.  http://cvs.apache.org/viewcvs/httpd-2.0/modules/ssl/ssl_engine_vars.c.diff?r1=1.27&r2=1.28			Jeff Trawick	Joe Orton
23998	null	CLOSED		Marco Muishout	1066821300000	1070077418000		mod_proxy truncates status line header causing warning in log files Situation: Client requests JSP page to local apache server (2.0.47). Local apache server  forwards mod_proxy) this request to a central apache server (2.0.47) which is  connected by mod_jk2 (2.0.2) to tomcat 4.1.24. When the local apache server receives its response, the request-response status  line is malformed and a warning is generated in the apache error log file.   The JSP application works fine, but our log files are clogged with these  warnings as every JSP request generates one. We are talking about a major  enterprise-wide global system.  Examining this problem showed that the error is caused by the fact that  mod_proxy is cleaning up/ignoring the trailing space in the status  line:'HTTP/1.1 200 '. It only seems to see or evaluate 'HTTP/1.1 200'.   I read that mod_jk omits the reponse-phrase ('OK' in this case) but this should  (according to standards) not be a problem when at least a trailing space is  added. By tracing the connactions I can see the 'space' in the response status  line before it enters apache.  Either mod_proxy filters out the space or the incoming status line is  incorrectly evaluated.  The error message is generated in  httpd-2.0.47/modules/proxy/proxy_http.c   line 761  For more information, please check  http://article.gmane.org/gmane.comp.apache.mod-proxy/561	Thanks for the report.  Yes, ap_rgetline is stripping any trailing spaces.  The proxy should just fix it and not be so noisy - I'll attach a patch. Created an attachment (id=8666) fix for trailing space handling  I tested the fix that was supplied and everything works OK. I attached two  error log files - one showing the warning, and one which shows the warning is  gone.  Both error log files were recorded while requesting the default application jsp  in out environment, with the apache mod_proxy instance running in debug mode. Created an attachment (id=8690) Apache error log file, including 'warning' bug  Created an attachment (id=8691) Apache error log file, bug fixed using supplied patch (no more warning)  fyi... fix already in 2.1-dev, recently approved for merge into stable branch for 2.0.next  As Jeff already noted, this is fixed.			Erik Abele	Jeff Trawick	Joe Orton	Marco Muishout
24165	null	CLOSED		Matthew Wilcox	1067293200000	1067729740000		mod_access docs SetEnvIf uses regex The mod_access documentation has a trivially easy to fix bug. SetEnvIf takes a regex, so the '.' needs to be quoted in the example:  <pre> SetEnvIf User-Agent ^KnockKnock/2.0 let_me_in &lt;Directory /docroot&gt;     Order Deny,Allow     Deny from all     Allow from env=let_me_in &lt;/Directory&gt; </pre>  Don't forget to update the Japanese translation at the same time. Thanks!	Fixed in CVS, thanks.			Andr?? Malo
24219	null	CLOSED		Andreas Goetz	1067439180000	1067733600000		t compress for IE with documented settings The apache2 docs suggest the following settings for mod_deflate:   Insert filter SetOutputFilter DEFLATE  # Netscape 4.x has some problems... BrowserMatch ^Mozilla/4 gzip-only-text/html  # Netscape 4.06-4.08 have some more problems BrowserMatch ^Mozilla/4/.0[678] no-gzip  # MSIE masquerades as Netscape, but it is fine BrowserMatch /bMSIE !no-gzip !gzip-only-text/html  However, I've found that this leads to NO compression for IE(6). Changing the  last line to  BrowserMatch MSIE !no-gzip !gzip-only-text/html works.   I'd suspect /b is not treated correctly in the regex?  Best regards, Andreas	The docs are correct. It's a bug in mod_setenvif's optimizer ... I'm investigating. Fixed in 2.1 and proposed for backport into the 2.0 stable branch. (<http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/metadata/mod_setenvif.c.diff?r1=1.43&r2=1.44>)  Thanks for the report and thanks for using Apache!			Andr?? Malo
24228	null	CLOSED		David Rees	1067456820000	1069816159000		Perf Tuning doc references USE_USLOCK_SERIALIZED_ACCEPT As far as I can tell, the USE_USLOCK_SERIALIZED_ACCEPT define isn't referenced anywhere in the Apache2 source except in the documentation.  It is referred to in the following places and should probbably be removed:  docs/manual/misc/perf-tuning.xml docs/manual/misc/perf-tuning.html.en	USLOCK stuff axes from 2.* documentation other minor cleanups applied to that section  Thanks for your report and thanks for using Apache!			Jeff Trawick
24232	null	CLOSED		Jens Weibler	1067466840000	1067538002000		t handle html-code in config Current Configuration of sapi_apache2.c shows php_admin_value error_prepend_string '' php_admin_value error_append_string ''  but real settings are:  php_admin_value     error_prepend_string    '<font color=ff0000>' php_admin_value     error_append_string     '</font>'  ' php_admin_value error_append_string '  is red ;)	I'm just testing a patch for this problem. This patch has been committed to httpd-2.1 and will shortly be proposed as a backport to 2.0 fix merged into stable branch for 2.0.49			Jeff Trawick	Thom May
24417	null	CLOSED		Uli Zappe	1067991840000	1087778978000		[PATCH] rotatelogs with local time (including DST) functionality While rotatelogs allows to specify an offset to UTC, it doesn't take DST into account. This sucks if  you want to process your (e.g. daily) log file with a cron job immediately afterwards, since cron will  take DST into account.  The following patch allows to specify the keyword 'local' instead of a numerical offset. In this case,  rotatelogs will rotate according to the local time, including DST.  Example:  | rotatelogs /path/to/access_log.%Y%m%d 86400 local  I have not yet updated the manpage accordingly; please tell me if I should do so (I'm no native  English speaker, though).   Here's the patch:   --- rotatelogs.c.ORIG   2003-02-03 18:32:09.000000000 +0100 +++ rotatelogs.c        2003-11-04 19:06:30.000000000 +0100 @@ -62,6 +62,10 @@   * Ported to APR by Mladen Turk <mturk@mappingsoft.com>   *   * 23 Sep 2001 + * + * Modified to work with local time (including DST) by Uli Zappe <uli@ritual.org> + *  + * 04 Nov 2003   */     @@ -100,6 +104,7 @@      apr_size_t nRead, nWrite;      int use_strftime = 0;      int now = 0; +    int local = 0;      const char *szLogRoot;      apr_file_t *f_stdin, *nLogFD = NULL, *nLogFDprev = NULL;      apr_pool_t *pool; @@ -149,7 +154,8 @@      }      else {          if (argc >= 4) { -            utc_offset = atoi(argv[3]) * 60; +            if (strcmp (argv[3], 'local') == 0) local = 1; +            else utc_offset = atoi(argv[3]) * 60;          }          tRotation = atoi(argv[2]);          if (tRotation <= 0) { @@ -169,7 +175,15 @@          if (apr_file_read(f_stdin, buf, &nRead) != APR_SUCCESS)              exit(3);          if (tRotation) { -            now = (int)(apr_time_now() / APR_USEC_PER_SEC) + utc_offset; +            int offset; +            apr_time_t _now = apr_time_now(); +            if (local) { +                apr_time_exp_t exptime; +                apr_time_exp_lt (&exptime, _now); +                offset = exptime.tm_gmtoff; +            } +            else offset = utc_offset; +            now = (int)(_now / APR_USEC_PER_SEC) + offset;              if (nLogFD != NULL && now >= tLogEnd) {                  nLogFDprev = nLogFD;                  nLogFD = NULL;	Created an attachment (id=9232) Patch for 2.0.48 to use localtime (including updated documentation)  Chris,  I'm not sure why you moved the modification in the code of rotatelogs to the place you did. Are  you sure this will work, especially on days when DST is switched on or off? I don't have the  opportunity to test this right now, but it's obviously important that the behavior is right on these  days.  Anyway, the following is obviously wrong in your version of the patch:  +            if (strcmp(argv[3], 'loc') == 0) { +                use_local = 0;  should be  +            if (strcmp(argv[3], 'loc') == 0) { +                use_local = 1;  or is there something I just didn't get? Yes, you got the obvious typo.  I did fix this, but I didn't upload the right version (and didn't catch it right away).  I also updated the documentation in my patch to note that it does not affect the log rotation time math (i.e. if you say '86400', it will still be rotated at 00:00:00 UTC); it just affects the time formatting done with strftime(3) to use the local time zone.  What I do is set my log rotation time to be 3600, and then use a filename like 'access_log.%Y-%m-%d' (so it re-determines the filename every hour, but it only changes at 00:00:00 local time).  I did it this way because the patch is much simpler (more likely to be acceptable), but I see how this could just make things more confusing, as it changes the behavior of the option.  Sorry about that.  Chris wrote: > I also updated the documentation in my patch to note that it does not affect > the log rotation time math (i.e. if you say '86400', it will still be rotated at > 00:00:00 UTC);  But that's exactly the behavior I wanted to avoid because it makes syncing with cron jobs so  difficult.  > What I do is set my log rotation time to be 3600, and then > use a filename like 'access_log.%Y-%m-%d' (so it re-determines the filename > every hour, but it only changes at 00:00:00 local time).  Which is kind of confusing. If you plan to rotate once a day, 86400 should work for you, even if you  use the 'local' option.  > I did it this way because the patch is much simpler (more likely to be > acceptable)  Well, my patch isn't *that* complicated, is it? And it does exactly what it should, in an intuitive way.  I think the foremost consideration should be what is simple for the *user*.  Ken Coar recently committed an equivalent feature to 2.1-dev, which I presume will be backported to stable branch for a future 2.0.x release.  Please have a look:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/rotatelogs.c?r1=1.32&r2=1.34  > Ken Coar recently committed an equivalent feature to 2.1-dev, which I presume > will be backported to stable branch for a future 2.0.x release.  Please have a look:  Ken's patch won't work correctly on the days when DST is switched on or off, because he puts the  test for the local time offset (utc_offset = lt.tm_gmtoff;) outside of the 'for (;;)' loop. Therefore, the  time offset will only be set once after the start of the rotatelogs process, and will not be updated  after a switch of DST occurs.  Ken himself writes in his comment: 'NB: Using -l in an environment which changes the GMT offset  (such as for BST or DST) can lead to unpredictable results!', suggesting he has indeed not tested his  patch on days when the switch occurs. However, unless you intend to use DST there's no point at all  in using local time instead of a fixed offset from GMT.  <Sigh> Why don't you just use the patch I committed? It's thoroughly tested, especially on days  when the DST switch occurs, and proven to work in a production environment for almost two years  now. I don't know why the patch here wasn't used.  When Ken's patch was posted to the developer's mailing list I pointed out this patch/PR.  Regardless, I pointed out your recent comments here to Ken and he integrated your comment.  See   http://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/rotatelogs.c  (I'm just the middleman here ;) )  Jeff, thanks! As far as I can see, the new code by Ken should work. Therefore I close this report. :-) Thanks for your review, and I'm sorry about the confused path to a solution for this issue! 			Chris Adams	Jeff Trawick	Uli Zappe
24437	null	RESOLVED		Jess Holle	1068051480000	1106347720000		mod_auth_ldap doubly-escapes backslash (/) characters in uids In order to authenticate against ActiveDirectory-style uids with backslashes in  them the authentication user name contains this character.  Unfortunately the LDAP logs are showing that Apache is over-escaping the  backslash -- at least on Windows (2000 SP4, all security updates applied).  I  suspect this above the LDAP SDK layer and thus applies to all platforms, but I  could be proven wrong, of course.  This is a serious issue to anyone needing to support use of such (existing)  directories.  Both workarounds and pointers to code areas to investigate (other  than 'look at the mod_auth_ldap and/or util_ldap sources' -- I know that much)  would be greatly appreciated!	It turns out that the Microsoft LDAP SDK escapes these characters on its own!  I found the filter escape code in mod_auth_ldap_build_filter in mod_auth_ldap.c and observed that its input and output was exactly what I'd expect.  I also note that it's output is what is passed to the LDAP SDK.  I commented out the escape code (in the simplest fashion, i.e. yes, I could use strncpy at this point) and then (and only then) am able to authenticate with /, ), (, and * in my user name.  I assume this is a Microsoft LDAP SDK feature as my other LDAP SDK experience suggests the escaping done by mod_auth_ldap is required.  All the same, I believe we should #if out this filter code when using the Microsoft LDAP SDK -- as it only currently serves to prevent that which it is intended to allow.  My change is to add the comments in the code excerpt below taken from mod_auth_ldap.c (sorry, I'm not creating a patch as strncpy would be better, etc, etc):      filtbuf_end = filtbuf + FILTER_LENGTH - 1;     for (p = user, q=filtbuf + strlen(filtbuf);          *p && q < filtbuf_end; *q++ = *p++) { /* Microsoft LDAP SDK does this automatically (!); doing this here causes double-escaping!!!    The following code block must therefore be removed when using Microsoft's LDAP SDK. */ /*         if (strchr('*()//', *p) != NULL) {             *q++ = '//';             if (q >= filtbuf_end) { \t        break; \t    }         } */     }     I believe your patch is correct, however we need to use a #ifdef to make   this determination, to prevent clashes with folks building under OpenLDAP   or the Netscape LDAP sdk.  Yes, that's a big reason why I did not provide a patch -- I had not taken the time to investigate the proper #ifdef's, etc, to use. Patch committed to v2.1.0-dev  Please test if this solves this problem.  Doh!  I'm sure that will work as it is identical to my fix apart from a proper #if block.  I should have taken the 2 extra minutes when I patched this on my own copy to look in apr_ldap.h and see   #define APR_HAS_MICROSOFT_LDAPSDK   1 on Windows and done a proper #if block around this.  Thanks for rounding out this fix and getting it in.  A merge back to 2.0 would be good too :-) Fixed in v2.0.50-dev.  As the person who provided the patch, I must regretfully re-open this SPR.  The patch works great *except* when the character immediately following the / is a valid hexidecimal character.  I'm not sure how to handle this case with the Microsoft LDAP SDK.  Hopefully we're missing some simple 'behave correctly' flag on the Microsoft LDAP SDK... Created an attachment (id=12919) Patch to address remaining issues (/[0-9,a-f], e.g. /a, etc)  I discovered Microsoft documentation at http://msdn.microsoft.com/library/default.asp?url=/library/en-us/adsi/adsi/search_filter_syntax.asp that essentially states 'RFC 1960 says...', followed by an accurate quote of this IETF RFC, followed by section titled 'Special characters' where they state a completely different means by which they require you to handle all the special characters from the IETF RFC -- without actually stating that they're requiring other syntax than that indicated by the RFC much less why they require this!  I produced a patch wherein the Microsoft documentation is obeyed when using their LDAP SDK.  This seems to fix the remaining issues, so I've attached the patch (see above). Is it possible to create a patch for v2.1 also? The patch does not apply cleanly to mod_authnz_ldap.c, not sure why.  Created an attachment (id=12930) Patch against HEAD rather than against 2.0.52  I've attached a patch against mod_authnz_ldap.c as requested.  Note that I've only tested this on Windows against Microsoft's LDAP at this point (the problematic case).  After pre-processing, there should be no differences in the code for any other platform resulting from my changes. Committed to HEAD, backport proposed to v2.0 The LDAP code in v2.0 is effectively abandoned, as it's too difficult to fix at this point (most of the fixes have involved major rewrites and have gone in httpd v2.1 and apr v1.1).  If this is broken in httpd v2.1, please reopen this bug.  I guess I'll check again in 2.2 whenever it is 'stable'.  I have to support a redistribution of a stable 2.x release, so at this time that would be 2.0.52.  Thus I'll keep applying my patch to 2.0.x.			Graham Leggett	Jess Holle	Will Rowe
24450	null	CLOSED		Chris Knight	1068082200000	1068212790000		GprofDir directive generates random directories (Note that this is with release 2.0.48 which is not listed in the Version box.)  If you define GprofDir in the Apache configuration, directories with random characters are generated.  It turns out that it's a problem with chdir_for_gprof in server/mpm/mpm_prefork/prefork.c where 'buf' is tested/used without initialization. Here's the patch:  202a203 >       *buf = '/0';  Documentation for the GprofDir and profiling in general would be greatly appreciated. I've been unable to get Apache to generate gmon.out, even with the '-pg -DGPROF' CFLAGS.	thanks for the patch! fix for random dirname problem now committed to 2.1-dev  somebody has fixed the missing 2.0.48 choice in the meantime  re instructions for gprof:  My guess is that [almost] nobody has done this since 1.3 days and there may not be skills right now to document it properly...  also, I don't know if there may be limitations of gprof that can break it with Apache 2 on some platforms (e.g., if libpthread is referenced due to thread-capable libapr).  You'll probably need to investigate further to get this resolved, though it would be worth posting a query to dev@httpd to see if anybody has gotten it working recently.  Perhaps see if gprof works with Apache 1.3 on your box first.  If not, then that simpler, better understood case should be resolved first.  At least one small issue is fixed. I'm closing this bug now but feel free to re-open it if you encounter further issues. Thanks for  using Apache.			Erik Abele	Jeff Trawick
24483	null	RESOLVED		Yutan	1068166140000	1168319523000		mod_usertrack dumps core...on apache 2.0.48 Core will be vomited if the Web page to which Apache2.0.48 is working is  perused by IE or Netscape.  However, if it is performed as follows, a Web page can be seen for the time  being.  $ telnet server 80 Trying 123.456.789.012 Connected to server. Escape character is '^]'. GET / <!doctype html public '-//W3C//DTD HTML 4.0 Transitional//EN'  'http://www.w3.org/TR/REC-html40/loose.dtd'> <html>  <head>   <meta http-equiv='Content-Type' content='text/html; charset=ISO-2022-JP'>   <title>Apache install-ji no test page</title>   ^^ in japanese title ...more  The test page of Apache also vomits core. In a httpd-2.0.47, it did not this problem.  [Fri Nov 07 09:34:19 2003] [notice] Apache/2.0.48 (Unix) configured -- resuming normal operations [Fri Nov 07 09:34:19 2003] [info] Server built: Nov  7 2003 09:13:42 [Fri Nov 07 09:34:19 2003] [debug] prefork.c(1037): AcceptMutex: flock (default:  flock) [Fri Nov 07 09:34:30 2003] [notice] child pid 13178 exit signal Segmentation fau lt (11) [Fri Nov 07 09:34:30 2003] [notice] child pid 13177 exit signal Segmentation fau lt (11)  The environment here is as follows.  The kernel and library of FreeBSD 4.9-RELEASE are using custom-made. (Compile option : -O3 -mcpu=k6 -march=k6 -malign-functions=4 -malign-jumps=4 - malign-loops=4)  httpd.conf is adjusted so that Japanese may be indicated by priority. The virtual host of IP base and the virtual host of a NOIP base are  intermingled.  The build script of Apache is as follows.  #!/bin/sh OPTIM='-D_REENTRANT -D_THREAD_SAFE -O9 -mcpu=k6 -march=k6 -malign-loops=4 -malig n-jumps=4 -malign-functions=4'  COPTFLAGS='$OPTIM' / CFLAGS='$OPTIM' / CC='cc $CFLAGS' / ./configure  --with-port=80 / --enable-mods-shared=info --enable-info / --enable-mods-shared=status --enable-status / --enable-mods-shared=imap --enable-imap / --enable-so / --enable-rewrite / --enable-deflate / --enable-expires / --enable-headers / --enable-usertrack  CC='cc' / OPTIM='$OPTIM' / CFLAGS='$CFLAGS' / COPTFLAGS='$COPTFLAGS' / make #make install	This problem is mod_usertrack. Enable this option is dump core!!  CookieTracking on  Well, we did change mod_usertrack in this version... but in all our testing it  worked for us.  Can you please give us a backtrace so that we can try to figure  out what's going on?  See http://httpd.apache.org/dev/debugging.html .  Thanks, Cliff backtrace report on spot_cookie(mod_usertrack.c)  Breakpoint 3, spot_cookie (r=0x8188050) at mod_usertrack.c:204 204         cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config, (gdb) n 210         if (!dcfg->enabled || r->main) { (gdb) 214         if ((cookie_header = apr_table_get(r->headers_in, (gdb) 218             if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm, 0))  { (gdb)  Program received signal SIGSEGV, Segmentation fault. 0x080a495b in regexec (preg=0x0,     string=0x8189040 'Apache=hostname.or.jp.1067634189379628; sheet=%u901A% u5E38%u30D5%u30A9%u30F3%u30C8; abcdefgh.html=11', nmatch=3,     pmatch=0xbfbff940, eflags=0) at pcreposix.c:269 269     rc = pcre_exec(preg->re_pcre, NULL, string, (int)strlen(string), 0,  options,  ------- Breakpoint 3, spot_cookie (r=0x8188050) at mod_usertrack.c:204 204         cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config, (gdb) s 210         if (!dcfg->enabled || r->main) { (gdb) s 214         if ((cookie_header = apr_table_get(r->headers_in, (gdb) s apr_table_get (t=0x8188218, key=0x80d051c 'Cookie') at apr_tables.c:481 481         if (key == NULL) { (gdb) s 485         hash = TABLE_HASH(key); (gdb) s 486         if (!TABLE_INDEX_IS_INITIALIZED(t, hash)) { (gdb) s 489         COMPUTE_KEY_CHECKSUM(key, checksum); (gdb) s 490         next_elt = ((apr_table_entry_t *) t->a.elts) + t->index_first[hash]; ; (gdb) s 491         end_elt = ((apr_table_entry_t *) t->a.elts) + t->index_last[hash]; (gdb) s 493         for (; next_elt <= end_elt; next_elt++) { (gdb) s 494             if ((checksum == next_elt->key_checksum) && (gdb) s 493         for (; next_elt <= end_elt; next_elt++) { (gdb) s 494             if ((checksum == next_elt->key_checksum) && (gdb) s 496                 return next_elt->val; (gdb) s 501     } (gdb) s spot_cookie (r=0x8188050) at mod_usertrack.c:218 218             if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm, 0))  { (gdb) s ap_regexec (preg=0x0,     string=0x8189040 'Apache=hostname.or.jp.1067634189379628; sheet=% u901A%u5E38%u30D5%u30A9%u30F3%u30C8; abcdefgh.html=11', nmatch=3,     pmatch=0xbfbff940, eflags=0) at util.c:398 398         return regexec(preg, string, nmatch, pmatch, eflags); (gdb) s regexec (preg=0x0,     string=0x8189040 'Apache=hostname.or.jp.1067634189379628; sheet=% u901A%u5E38%u30D5%u30A9%u30F3%u30C8; abcdefgh.html=11', nmatch=3,     pmatch=0xbfbff940, eflags=0) at pcreposix.c:233 233     int options = 0; (gdb) s 242     int *ovector = NULL; (gdb) s 243     int allocated_ovector = 0; (gdb) s 245     if ((eflags & REG_NOTBOL) != 0) options |= PCRE_NOTBOL; (gdb) s 246     if ((eflags & REG_NOTEOL) != 0) options |= PCRE_NOTEOL; (gdb) s 255     if (nmatch > 0) (gdb) s 257         if (nmatch <= SMALL_NMATCH) (gdb) s 259           ovector = &(small_ovector[0]); (gdb) s 269     rc = pcre_exec(preg->re_pcre, NULL, string, (int)strlen(string), 0, opti ons, (gdb) s  Program received signal SIGSEGV, Segmentation fault. 0x080a495b in regexec (preg=0x0,     string=0x8189040 'Apache=hostname.or.jp.1067634189379628; sheet=% u901A%u5E38%u30D5%u30A9%u30F3%u30C8; abcdefgh.html=11', nmatch=3,     pmatch=0xbfbff940, eflags=0) at pcreposix.c:269 269     rc = pcre_exec(preg->re_pcre, NULL, string, (int)strlen(string), 0, opti ons, (gdb) s  Program terminated with signal SIGSEGV, Segmentation fault. The program no longer exists.   value of called to pcre_exec (from spot_cookie)  269     rc = pcre_exec(preg->re_pcre, NULL, string, (int)strlen(string), 0,  options,  (gdb) printf '%d/n',preg 0 (gdb) printf '%d/n', preg->re_pcre Error accessing memory address 0x0: Bad address. (gdb) printf '%s/n', string Apache=hostname.or.jp.1067634189379628; sheet=%u901A%u5E38%u30D5%u30A9%u30F3% u30C8; abcdefgh.html=11 (gdb) printf '%d/n', strlen(string) 113 (gdb) printf '%s/n',options Error accessing memory address 0x0: Bad address.   On httpd-2.0.47 will running...  Breakpoint 1, spot_cookie (r=0x8186050) at mod_usertrack.c:198 198         cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config, (gdb) s 204         if (!dcfg->enabled || r->main) { (gdb) 208         if ((cookie = apr_table_get(r->headers_in, (gdb) apr_table_get (t=0x8186218, key=0x80cf7dc 'Cookie') at apr_tables.c:481 481         if (key == NULL) { (gdb) 485         hash = TABLE_HASH(key); (gdb) 486         if (!TABLE_INDEX_IS_INITIALIZED(t, hash)) { (gdb) 489         COMPUTE_KEY_CHECKSUM(key, checksum); (gdb) 490         next_elt = ((apr_table_entry_t *) t->a.elts) + t->index_first[hash]; ; (gdb) 491         end_elt = ((apr_table_entry_t *) t->a.elts) + t->index_last[hash]; (gdb) 493         for (; next_elt <= end_elt; next_elt++) { (gdb) 494             if ((checksum == next_elt->key_checksum) && (gdb) 493         for (; next_elt <= end_elt; next_elt++) { (gdb) 494             if ((checksum == next_elt->key_checksum) && (gdb) 496                 return next_elt->val; (gdb) 501     } (gdb) spot_cookie (r=0x8186050) at mod_usertrack.c:212 212             if ((value = ap_strstr_c(cookie, dcfg->cookie_name))) { (gdb) 215                 value += strlen(dcfg->cookie_name) + 1;  /* Skip over the '= ' */ (gdb) 216                 cookiebuf = apr_pstrdup(r->pool, value); (gdb) apr_pstrdup (a=0x8186018,     s=0x81873b7 'hostname.or.jp.1067634189379628; sheet=%u901A%u5E38% u30D5%u30A9%u30F3%u30C8; abcdefgh.html=11') at apr_strings.c:111 111         if (s == NULL) { (gdb) 114         len = strlen(s) + 1; (gdb) 115         res = apr_palloc(a, len); (gdb) apr_palloc (pool=0x8186018, size=107) at apr_pools.c:620 620         size = APR_ALIGN_DEFAULT(size); (gdb) 621         active = pool->active; (gdb) 624         if (size < (apr_size_t)(active->endp - active->first_avail)) { (gdb) 625             mem = active->first_avail; (gdb) 626             active->first_avail += size; (gdb) 628             return mem; (gdb) 679     } (gdb) apr_pstrdup (a=0x8186018,     s=0x81873b7 'hostname.or.jp.1067634189379628; sheet=%u901A%u5E38% u30D5%u30A9%u30F3%u30C8; line-index.html=11') at apr_strings.c:116 116         memcpy(res, s, len); (gdb) 117         return res; (gdb) 118     } (gdb) spot_cookie (r=0x8186050) at mod_usertrack.c:217 217                 cookieend = strchr(cookiebuf, ';'); (gdb) 218                 if (cookieend) (gdb) 219                     *cookieend = '/0';      /* Ignore anything after a ; */ (gdb) 222                 apr_table_setn(r->notes, 'cookie', cookiebuf); (gdb) apr_table_setn (t=0x81869a8, key=0x80cf7cd 'cookie',     val=0x8187980 'hostname.or.jp.1067634189379628')     at apr_tables.c:584 584         COMPUTE_KEY_CHECKSUM(key, checksum); (gdb) 585         hash = TABLE_HASH(key); (gdb) 586         if (!TABLE_INDEX_IS_INITIALIZED(t, hash)) { (gdb) 587             t->index_first[hash] = t->a.nelts; (gdb) 588             TABLE_SET_INDEX_INITIALIZED(t, hash); (gdb) 589             goto add_new_elt; (gdb) 640         t->index_last[hash] = t->a.nelts; (gdb) 641         next_elt = (apr_table_entry_t *) table_push(t); (gdb) apr_array_push_noclear (arr=0x81869a8) at apr_tables.c:158 158         if (arr->nelts == arr->nalloc) { (gdb) 169         ++arr->nelts; (gdb) 170         return arr->elts + (arr->elt_size * (arr->nelts - 1)); (gdb) 171     } (gdb) apr_table_setn (t=0x81869a8, key=0x80cf7cd 'cookie',     val=0x8187980 'hostname.or.jp.1067634189379628')     at apr_tables.c:642 642         next_elt->key = (char *)key; (gdb) 643         next_elt->val = (char *)val; (gdb) 644         next_elt->key_checksum = checksum; (gdb) 645     } (gdb) spot_cookie (r=0x8186050) at mod_usertrack.c:224 224                 return DECLINED;    /* There's already a cookie, no new one */ (gdb) 228     } (gdb) 0x0809f5f5 in ap_run_fixups (r=0x8186050) at request.c:114 114                               (request_rec *r), (r), OK, DECLINED) (gdb) fix_encoding (r=0x8186050) at mod_negotiation.c:3077 3077        const char *enc = r->content_encoding; (gdb) 3078        char *x_enc = NULL; (gdb) 3083        if (!enc || !*enc) { (gdb) 3084            return DECLINED; (gdb) 3117    }  ...etc...  Looks like there is a bug in the cookie finding part of mod_usertrack introduced by my changes to the most recent mod_usertrack: If 'CookieTracking on' is in httpd.conf, 'CookieName Apache' also has to be in there. (Or, you can have the value of CookieName be whatever you like; but CookieName *has* to be set to circumvent the bug I introduced.) I'll be working on a fix for this in the next few days, but for now the workaround should work. --Manni Wood Is it a light initialization mistake? Dump core was avoidable. Thanks.  ---- An easy patch... (not test...It moves for the time being.)  mod_usertrack.c : line 254:  static void *make_cookie_dir(apr_pool_t *p, char *d) {     cookie_dir_rec *dcfg;     dcfg = (cookie_dir_rec *) apr_pcalloc(p, sizeof(cookie_dir_rec));     dcfg->cookie_name = COOKIE_NAME;     dcfg->cookie_domain = NULL;     dcfg->style = CT_UNSET;     dcfg->enabled = 0; +    dcfg->regexp_string = (char *)apr_palloc(p, 25 + strlen(COOKIE_NAME) * 2); +    apr_snprintf(dcfg->regexp_string, 25 + strlen(COOKIE_NAME) * 2 +        , '^%s([^;]+)|;[ /t]+%s=([^;]+)', COOKIE_NAME, COOKIE_NAME); +    dcfg->regexp=ap_pregcomp(p, dcfg->regexp_string, REG_EXTENDED);     return dcfg; }  Since it was thought that abnormalities occurred in all OS's as long as the  source code was seen, Plathome was changed into All.  The following is my first cut at a patch. It solves all of the problems, but it has not yet been assessed by anyone on the apache developer's list.  Take the patch that follows, copy it to a file called mod_usertrack_2.0.48.patch, copy mod_usertrack_2.0.48.patch to httpd-2.0.48/modules/metadata, then run patch -p0 < mod_usertrack_2.0.48.patch and recompile.  -Manni  --- mod_usertrack-old.c 2003-11-08 01:42:11.000000000 -0500 +++ mod_usertrack.c     2003-11-08 23:02:28.000000000 -0500 @@ -104,7 +104,7 @@  #include 'http_config.h'  #include 'http_core.h'  #include 'http_request.h' - +#include 'http_log.h'     module AP_MODULE_DECLARE_DATA usertrack_module;    @@ -211,6 +211,14 @@          return DECLINED;      }    +    /* Check to be sure there is a regexp available; it may not have +       compiled, leaving dcfg->regexp null. */ +    if (dcfg->regexp == NULL) { +        ap_log_error(APLOG_MARK, APLOG_ERR, APR_SUCCESS, r->server, 'The regular expression that will be used to find the usertrack cookie in the cookie header could not be compiled. Disabling mod_usertrack.'); +        dcfg->enabled = 0; +        return DECLINED; +    } +      if ((cookie_header = apr_table_get(r->headers_in,                                         (dcfg->style == CT_COOKIE2                                          ? 'Cookie2' @@ -260,6 +268,21 @@      dcfg->cookie_domain = NULL;      dcfg->style = CT_UNSET;      dcfg->enabled = 0; + +    /* The goal is to end up with this regexp, +     * ^COOKIE_NAME=([^;]+)|;[ /t]+COOKIE_NAME=([^;]+) +     * with COOKIE_NAME +     * obviously substituted with the real cookie name defined +     * by the COOKIE_NAME macro. This regexp will get replaced +     * by the regexp in set_cookie_name() if the CookieName is +     * used in httpd.conf. */ +    dcfg->regexp_string = apr_pstrcat(p, '^', COOKIE_NAME, +                                      '=([^;]+)|;[ /t]+', COOKIE_NAME, +                                      '=([^;]+)', NULL); + +    /* Remember that ap_pregcomp could return null, so +       we will have to deal with this later in spot_cookie(). */ +    dcfg->regexp = ap_pregcomp(p, dcfg->regexp_string, REG_EXTENDED);      return dcfg;  }    BTW, the segfault happens for me when Netscape and RFC2109 cookies are set. Setting CookieName to Apache gets rid of the problem.  If RFC2965 cookies are set, the problem is not the segfault, but rather the fact that cookie simply isn't found. Therefore, every new connection generates yet another cookie (as visible in the log). libapreq2 also sees the cookie as a different one every time. Therefore, the session upkeeping cannot be done at all.  In any event, setting CookieName to Apache does not work around the above problem for RFC2965 cookies. Not sure if the patch does... Bojan Smojver, I recommend you use CookieStyle Netscape or CookieStyle Cookie (or the synonymous CookieStyle 2109) in httpd.conf, not CookieStyle Cookie2 (or the synonymous CookieStyle RFC2965).  I watched HTTP network traffic through Ethereal, and noted that while Apache correctly sends 'Cookie2:' headers, Mozilla does not accept them. This is why you see a new cookie each time in your logs: Apache is not finding the cookie because your browser is not accepting 'Cookie2:' headers.  The following is my second try at a patch. It's more elegant than my first patch. It solves all of the problems (I tested it with or without the CookieName directive, and with CookieStyle set to Apache, Cookie, and Cookie2 -- though Mozilla doesn't yet accept Cookie2 headers, so I couldn't test cookie detection). Like my previous patch, this patch has not yet been assessed by anyone on the Apache developer's list.  Take the patch that follows, copy it to a file called mod_usertrack_2.0.48.patch, copy mod_usertrack_2.0.48.patch to httpd-2.0.48/modules/metadata, then run patch -p0 < mod_usertrack_2.0.48.patch and recompile.  -Manni  Bojan Smojver, I recommend you use CookieStyle Netscape or CookieStyle Cookie (or the synonymous CookieStyle 2109) in httpd.conf, not CookieStyle Cookie2 (or the synonymous CookieStyle RFC2965).  I watched HTTP network traffic through Ethereal, and noted that while Apache correctly sends 'Cookie2:' headers, Mozilla does not accept them. This is why you see a new cookie each time in your logs: Apache is not finding the cookie because your browser is not accepting 'Cookie2:' headers.  The following is my second try at a patch. It's more elegant than my first patch. It solves all of the problems (I tested it with or without the CookieName directive, and with CookieStyle set to Apache, Cookie, and Cookie2 -- though Mozilla doesn't yet accept Cookie2 headers, so I couldn't test cookie detection). Like my previous patch, this patch has not yet been assessed by anyone on the Apache developer's list.  Take the patch that follows, copy it to a file called mod_usertrack_2.0.48.patch, copy mod_usertrack_2.0.48.patch to httpd-2.0.48/modules/metadata, then run patch -p0 < mod_usertrack_2.0.48.patch and recompile.  -Manni  --- mod_usertrack-old.c\t2003-11-10 23:28:19.000000000 -0500 +++ mod_usertrack.c\t2003-11-11 00:16:15.000000000 -0500 @@ -199,6 +199,20 @@   * which has three subexpressions, $0..$2 */  #define NUM_SUBS 3   +static void set_and_comp_regexp(cookie_dir_rec *dcfg,  +                                apr_pool_t *p, +                                const char *cookie_name)  +{ +    /* The goal is to end up with this regexp,  +     * ^cookie_name=([^;]+)|;[/t]+cookie_name=([^;]+)  +     * with cookie_name obviously substituted either +     * with the real cookie name set by the user in httpd.conf, or with the +     * default COOKIE_NAME. */ +    dcfg->regexp_string = apr_pstrcat(p, '^', cookie_name, '=([^;]+)|;[ /t]+', cookie_name, '=([^;]+)', NULL); + +    dcfg->regexp = ap_pregcomp(p, dcfg->regexp_string, REG_EXTENDED); +} +  static int spot_cookie(request_rec *r)  {      cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config, @@ -260,6 +274,11 @@      dcfg->cookie_domain = NULL;      dcfg->style = CT_UNSET;      dcfg->enabled = 0; + +    /* In case the user does not use the CookieName directive, +     * we need to compile the regexp for the default cookie name. */ +    set_and_comp_regexp(dcfg, p, COOKIE_NAME); +      return dcfg;  }   @@ -345,18 +364,10 @@  {      cookie_dir_rec *dcfg = (cookie_dir_rec *) mconfig;   -    /* The goal is to end up with this regexp, -     * ^cookie_name=([^;]+)|;[ /t]+cookie_name=([^;]+) -     * with cookie_name -     * obviously substituted with the real cookie name set by the -     * user in httpd.conf. */ -    dcfg->regexp_string = apr_pstrcat(cmd->pool, '^', name, -                                      '=([^;]+)|;[ /t]+', name, -                                      '=([^;]+)', NULL); -      dcfg->cookie_name = apr_pstrdup(cmd->pool, name);   -    dcfg->regexp = ap_pregcomp(cmd->pool, dcfg->regexp_string, REG_EXTENDED); +    set_and_comp_regexp(dcfg, cmd->pool, name); +      if (dcfg->regexp == NULL) {          return 'Regular expression could not be compiled.';      }  Similar behavior exists in version 1.3.29 (Solaris 7); 'CookieTracking On' with  no 'CookieName' results in a SIGSEGV.  Explicitly setting CookieName as  suggested in 'Additional Comments From Manni Wood 2003-11-07 16:55' appears to  be a successful workaround for 1.3.29 as well.  # # Debugger trace of mod_usertrack segfault on apache 1.3.29, Solaris 7 # ('CookieTracking on', no CookieName set in httpd.conf # Breakpoint 1, spot_cookie (r=0xe7950) at mod_usertrack.c:295 295         cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config, # # # show cookie_dir_rec # # (gdb) print *dcfg $8 = {enabled = 1, style = CT_NETSCAPE, format = CF_NORMAL,    cookie_name = 0x1 <Address 0x1 out of bounds>,    cookie_domain = 0x1 <Address 0x1 out of bounds>,    prefix_string = 0x190 <Address 0x190 out of bounds>, regexp_string = 0x0,  regexp = 0x0} # # # Step further ... # # (gdb) s 301         if (!dcfg->enabled) { (gdb) s 305         if ((cookie_header = ap_table_get(r->headers_in, (gdb) s 309             if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm,  0)) { # # # Show parameters passed to ap_regexec.  cookie_header appears # to hold data; dcfg->regexp is a null pointer # # (gdb) print cookie_header $9 = 0xe7360 'Apache=172.19.30.174.114851068582299525' (gdb) print dcfg->regexp $11 = (regex_t *) 0x0 # # # Stepping into ap_regexec ... # # (gdb) s  Program received signal SIGSEGV, Segmentation fault. 0xff1e88e0 in __regexec_C () from /usr/lib/libc.so.1 # # # show backtrace # # # (gdb) bt #0  0xff1e88e0 in __regexec_C () from /usr/lib/libc.so.1 #1  0x4412c in ap_regexec () #2  0xfe591090 in spot_cookie (r=0xe7950) at mod_usertrack.c:309 #3  0x20130 in run_method () #4  0x20290 in ap_run_fixups () #5  0x409e4 in process_request_internal () #6  0x40f90 in ap_internal_redirect () #7  0x401e4 in ap_die () #8  0x402b8 in decl_die () #9  0x4069c in process_request_internal () #10 0x40aa0 in ap_process_request () #11 0x33380 in child_main () #12 0x3363c in make_child () #13 0x33858 in startup_children () #14 0x3431c in standalone_main () #15 0x34f90 in main ()   $ httpd -V  $ /d/apache/bin/httpd -V Server version: Apache/1.3.29 (Unix) Server built:   Nov 11 2003 10:26:38 Server's Module Magic Number: 19990320:15 Server compiled with....  -D EAPI  -D EAPI_MM  -D EAPI_MM_CORE_PATH='logs/httpd.mm'  -D HAVE_MMAP  -D USE_MMAP_SCOREBOARD  -D USE_MMAP_FILES  -D HAVE_FCNTL_SERIALIZED_ACCEPT  -D HAVE_SYSVSEM_SERIALIZED_ACCEPT  -D HAVE_PTHREAD_SERIALIZED_ACCEPT  -D DYNAMIC_MODULE_LIMIT=64  -D HARD_SERVER_LIMIT=2048  -D HTTPD_ROOT='/d/apache-1.3.29-20031117'  -D SUEXEC_BIN='/d/apache-1.3.29-20031117/bin/suexec'  -D DEFAULT_PIDLOG='logs/httpd.pid'  -D DEFAULT_SCOREBOARD='logs/httpd.scoreboard'  -D DEFAULT_LOCKFILE='logs/httpd.lock'  -D DEFAULT_ERRORLOG='logs/error_log'  -D TYPES_CONFIG_FILE='conf/mime.types'  -D SERVER_CONFIG_FILE='conf/httpd.conf'  -D ACCESS_CONFIG_FILE='conf/access.conf'  -D RESOURCE_CONFIG_FILE='conf/srm.conf'    That's right, Steve. When I introduced my mod_usertrack patch (and, sadly, bug) to mod_usertrack for the latest 2.0.x release, I also back-ported it to the latest 1.3.x release, so the bug will be the same for 1.3.x as for 2.0.x, and the workaround will be the same, as you have already discovered.  I'm waiting for advice on the 2.0.x patch you see below from a developer who's closer to the ASF than I am. Once I get an all clear, I'll submit the fix to the Apache developer's mailing list as a 2.0.x patch as well as a back-ported 1.3.x patch.  -Manni  *** Bug 24384 has been marked as a duplicate of this bug. *** manni: latest patch is looking good so far.  i'll give it a closer look  tomorrow.  sorry i couldn't get it taken care of at apachecon last week... my  notebook's hard drive crashed!  doh!!  =)  fyi, i put a notice on http://httpd.apache.org/ about this problem since lots  of people seem to be hitting it.    Please tag such reports with the FAQ keyword as well :)  I'm somewhat busy, and did'nt see and become precocious. Checked with Mr. Manni Wood's patch. Since the same bug was checked also by the old Sun machine, Plathome was  changed into All.  Patch backported for 1.3, passes tests and posted to list. *** Bug 26203 has been marked as a duplicate of this bug. *** Fix committed to 2.1, 2.0 and 1.3:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/metadata/mod_usertrack.c#rev1.42 http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/metadata/mod_usertrack.c#rev1.39.2.3 http://cvs.apache.org/viewcvs.cgi/apache-1.3/src/modules/standard/mod_usertrack.c#rev1.60  Um, it looks like Jim committed the fix for this bug to 1.3, but it hasn't  gotten committed yet to 2.0 or 2.1 (for no particular reason than I never got  around to it).  Reopening until that happens. Oh yeah, thanks Cliff, you're right. I was blindly looking at the places where the problem was  introduced :(  Thanks, guys, for helping patch this. --Manni Fixed in 2.0.49. Please upgrade. *** Bug 28000 has been marked as a duplicate of this bug. *** Changes on a closed fixed bug are not that clever. Please give more details if you want to reopen it. Thanks. mod_usertrack is segfaulting for me on Apache 1.3.33 (Debian package 1.3.33-6 on AMD64).  CookieTracking on --> child processes segfault  Setting CookieName makes no difference.  The same Debian package recompiled for i386 works.  It only fails on AMD64.  strace is not very informative.  The stack trace from the segfault is:  #0  0x00000000004317da in regcomp () #1  0x000000000043133d in regcomp () #2  0x0000000000430954 in regcomp () #3  0x00000000004305f1 in regcomp () #4  0x00002aaaac522a70 in ?? () from /usr/lib/apache/1.3/mod_usertrack.so #5  0x000000000040ecc1 in ap_cleanup_method_ptrs () #6  0x00000000004203ca in ap_some_auth_required () #7  0x0000000000420555 in ap_process_request () #8  0x00000000004196ce in ap_child_terminate () #9  0x000000000041991d in ap_child_terminate () #10 0x0000000000419996 in ap_child_terminate () #11 0x000000000041a329 in ap_child_terminate () #12 0x000000000041a805 in main ()  (Sorry, no symbols in Debian packages - I will try to get those next).  Rich. This is the full stack trace.  It's different from the one above ...  I think because I've now got the cookie and it's trying to parse it.  #0  0x00000000004317da in sstep (g=0x66b9b0, start=-2039141192980765773,     stop=34, bef=8, ch=132, aft=8) at engine.c:909 #1  0x000000000043133d in sslow (m=0x7fffffbc6410,     start=0xe3b383e38983e3b3 <Address 0xe3b383e38983e3b3 out of bounds>,     stop=0x83edf0 'Apache=10.0.1.138.132001143290662991; __utma=170107067.1695268367.1143290799.1143290799.1143290799.1; __utmb=170107067; __utmc=170107067; __utmz=170107067.1143290799.1.1.utmccn=(direct)|utmcsr=(direct'..., startst=35,     stopst=34) at engine.c:738 #2  0x0000000000430954 in sdissect (m=0x7fffffbc6410,     start=0xe3b383e38983e3b3 <Address 0xe3b383e38983e3b3 out of bounds>,     stop=0x83edf0 'Apache=10.0.1.138.132001143290662991; __utma=170107067.1695268367.1143290799.1143290799.1143290799.1; __utmb=170107067; __utmc=170107067; __utmz=170107067.1143290799.1.1.utmccn=(direct)|utmcsr=(direct'...,     startst=120993912, stopst=34) at engine.c:371 #3  0x00000000004305f1 in smatcher (g=0x66b9b0,     string=0x8 <Address 0x8 out of bounds>, nmatch=3, pmatch=0x7fffffbc64c0,     eflags=0) at engine.c:157 #4  0x00002aaaac522a70 in spot_cookie (r=0x83a8d0) at mod_usertrack.c:310 #5  0x000000000040ecc1 in run_method (r=0x83a8d0, offset=-1987845197,     run_all=1) at http_config.c:327 #6  0x00000000004203ca in process_request_internal (r=0x83a8d0)     at http_request.c:1293 #7  0x0000000000420555 in ap_process_request (r=0x83a8d0)     at http_request.c:1314 #8  0x00000000004196ce in child_main (child_num_arg=8628432)     at http_main.c:4873 #9  0x000000000041991d in make_child (s=0x5540b0, slot=0, now=1143290662)     at http_main.c:4997 #10 0x0000000000419996 in startup_children (number_to_start=5)     at http_main.c:5079 #11 0x000000000041a329 in standalone_main (argc=8552640,     argv=0xe3b383e38983e3b3) at http_main.c:5411 #12 0x000000000041a805 in main (argc=2, argv=0x7fffffbc67c8)     at http_main.c:5768  mod_usertrack.c line 310 is the second line here (the one containing ap_regexec ...)      if ((cookie_header = ap_table_get(r->headers_in, 'Cookie'))) {         if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm, 0)) {             char *cookieval = NULL;             /* Our regexp,              * ^cookie_name=([^;]+)|;[ /t]+cookie_name=([^;]+)              * only allows for $1 or $2 to be available. ($0 is always              * filled with the entire matched expression, not just              * the part in parentheses.) So just check for either one              * and assign to cookieval if present. */             if (regm[1].rm_so != -1) {                 cookieval = ap_pregsub(r->pool, '$1', cookie_header,                                        NUM_SUBS, regm);             }             if (regm[2].rm_so != -1) {                 cookieval = ap_pregsub(r->pool, '$2', cookie_header,                                        NUM_SUBS, regm);             }             /* Set the cookie in a note, for logging */             ap_table_setn(r->notes, 'cookie', cookieval);              return DECLINED;    /* There's already a cookie, no new one */         }     }     make_cookie(r);     return OK;                  /* We set our cookie */  (gdb) frame 4 #4  0x00002aaaac522a70 in spot_cookie (r=0x83a8d0) at mod_usertrack.c:310 310             if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm, 0)) { (gdb) print cookie_header $1 = 0x83edd8 'Apache=10.0.1.138.132001143290662991; __utma=170107067.1695268367.1143290799.1143290799.1143290799.1; __utmb=170107067; __utmc=170107067; __utmz=170107067.1143290799.1.1.utmccn=(direct)|utmcsr=(direct'... (gdb) print regm $2 = {{rm_so = -1, rm_eo = 0}, {rm_so = 0, rm_eo = 0}, {rm_so = 0, rm_eo = 0}} (gdb) print NUM_SUBS $3 = 3 (gdb) print dcfg->regexp $4 = (regex_t *) 0x73bf20 (gdb) print *dcfg->regexp $5 = {re_magic = 62053, re_nsub = 2, re_endp = 0x0, re_g = 0x66b9b0}  The issue for which this bug was re-opened is AFAICT only the crash in regcomp() et al on x86_64 - which is a different bug, bug 31858.  Marking CLOSED again.			Andr?? Malo	Bojan Smojver	Cliff Woolley	Erik Abele	Jim Jagielski	Joe Orton	Manni Wood	Richard W.M. Jones	Steve Revilak	Will Rowe	Yutan
24643	null	CLOSED		Sviatoslav Sviridov	1068640860000	1073917910000		' On SMP systems build can fail because of not full dependencies in Makefile with next error:  gawk -f /home/svd/RPM/BUILD/httpd-2.0.48/build/make_var_export.awk "cat export_files" > export_vars.h make[2]: *** No rule to make target "exports.c', needed by "httpd.exp'.  Stop.  To fix it I'm using this patch:  --- httpd-2.0.48/server/Makefile.in~    2003-03-11 17:41:55 +0200 +++ httpd-2.0.48/server/Makefile.in     2003-11-12 13:57:18 +0200 @@ -64,6 +64,8 @@  $(top_builddir)/server/exports.c: export_files         $(AWK) -f $(top_srcdir)/build/make_exports.awk "cat $?" > $@   +exports.c: $(top_builddir)/server/exports.c +  export_vars.h: export_files         $(AWK) -f $(top_srcdir)/build/make_var_export.awk "cat $?" > $@	What's the issue with SMP systems?  Do you mean that the box where it failed is SMP?  What commands are you using to build Apache?  What Linux is it?  It fails with a parallel make i.e. make -j2 with GNU make... HEAD has this change:  # Needed to allow exports.c to be generated in a parallel build successfully .NOTPARALLEL: $(top_builddir)/server/exports.c  I'm not sure whether this is really needed or whether the paths to exports.c just need to be fixed to be either absolute or not all through that Makefile, it seems confused. Sorry for not very accurate report, yes, it fails when make satrted as 'make -j2'.  And it seems that adding  .NOTPARALLEL: $(top_builddir)/server/exports.c  also helps. I hope, it's better solution. I'm not so experienced in Makefiles, so I think you'll do it better than me. Thanks. Created an attachment (id=9357) unfixes for server/Makefile.in  Attached what looks like the right fix to me (for HEAD); awaiting review before committing. Fixed for 2.0.49 - thanks for the report.			Jeff Trawick	Joe Orton	Sviatoslav Sviridov
24734	null	CLOSED		Markus Julen	1068941880000	1069386750000		Unable to use empty vars assigned in .htaccess It's no longer possible to set empty variables in the .htaccess files. mod_env sets them, but #printenv (mod_include) crashes and #echo (mod_include) treats them as  not defined - prints '(none)'  possible solution:  diff -rc org/modules/metadata/mod_env.c patched/modules/metadata/mod_env.c *** org/modules/metadata/mod_env.c      Sun Nov 16 00:16:45 2003 --- patched/modules/metadata/mod_env.c  Sun Nov 16 00:17:30 2003 *************** *** 158,164 ****       /* name is mandatory, value is optional.  no value means        * set the variable to an empty string        */ !     apr_table_setn(sconf->vars, name, value);          return NULL;   } --- 158,168 ----       /* name is mandatory, value is optional.  no value means        * set the variable to an empty string        */ !     if (value != NULL) { !         apr_table_setn(sconf->vars, name, value); !     } else { !         apr_table_setn(sconf->vars, name, ''); !     }          return NULL;   }	just curious: when you say 'It's no longer possible' you're comparing 1.3 with 2.0.48, right?  Yes, it works with 1.3 (1.3.26 was the latest I checked it on).  It doesn't work with 2.0.47 and .48 in .htaccess files (mod_env), but setting it in an html file works  (mod_include). Thanks for the response.  I expect to commit the fix in next 24h or so. Thanks for your efforts!  The fix is now in Apache 2.1-dev and has been proposed for merging into the stable branch (2.0.next).  now merged into stable branch for 2.0.49			Jeff Trawick	Markus Julen
24801	null	CLOSED		Jess Holle	1069194960000	1096480360000		Apache crashes when distinct users exceeds LDAPCacheEntries The following *is* true with Apache 2.0.47 on Windows.  It *may* well be true  on other platforms as well -- I've not done sufficient testing to say for  certain.  Apache crashes when the number of distinct users authenticating against LDAP  exceeds the setting used for LDAPCacheEntries.  This does not always occur on  first exceeding this cache size, but in my experience it will invariably occur  after a few occurences of exceeding the cache size.  A little debugging strongly suggests that there is an issue with the code which  removes old entries from the cache in this case.  The workaround is either to use a value of 0 for LDAPCacheEntries, i.e. disable  the cache, or use a value that is larger than your user population plus some  safety factor.  The safety factor is necessary in that it appears to be  possible to have more than one entry for a given user in the cache.  This  appears to occur when one request is using the user entry when another request  for authenticating the same user comes in.  This issue is masked by bug #24800 and cannot be reached until you work around  it.	P.S.  I believe this issue might may still be masked by an undersized shared memory block even though bug #24800 appears to be fixed in 2.0.49.  For instance with:    LDAPCacheEntries 2150   # Next line was necessary last I checked as 0 caused issues with active cache   LDAPOpCacheEntries  1   LDAPSharedCacheSize 865000   LDAPSharedCacheFile logs/mod_ldap_cache  I get a child process crash one I get to somewhere between 2151 and 2155 distinct users.  Finally, I'm pretty sure I verified that this issue exists on Solaris and AIX as well -- but I clearly forgot to note it here. Trying to look at this now, although I'm not that familiar with the cache code. Do you have an example of a stacktrace where the crash is occuring?  I'm trying to work out why the problem would be in cache cleanup rather than in adding to the cache - maybe it's an edge case somewhere in the cleanup?  It's a long-standing bug that the shared memory caching code does not check for the apr_rmm_*alloc functions returning NULL, so it will of course die horribly if the rmm segment fills up and the code tries to allocate more:  return (void *)apr_rmm_addr_get(cache->rmm_addr, apr_rmm_calloc(cache->rmm_addr, size));  That is a separate bug -- which I believe has been fixed in/by 2.0.49 -- at least my test case for it no longer failed there.  This bug is about the case where the physical shared memory bytes are sufficient but the specified logical cache size (i.e. # of entries) is not.  In this case, the cache should simply purge older entries.  Instead it crashes (attempting to do this).  I've been meaning to generate a stack trace, but have not managed yet. Created an attachment (id=11633) Add checking for NULL in *_rmm_* functions  Does this patch make any difference for you?  In util_ald_cache_insert(), it attempts to add an item to the cache. There is no check for whether the cache is full, because it is assumed that on the edge case (of the very last cache entry being allocated) util_ald_cache_purge() will run, which again is assumed to bring down the cache size.  So in this case, it looks like util_ald_cache_purge() is not bringing down the cache size, so on the next entry we overflow.  Try this patch and see if it makes a difference - it checks for overflow before we add, not after. The purge code is probably still broken, but at least we won't segfault. Created an attachment (id=11634) Add sanity check so that we don't overflow if purge fails for any reason  Just committed the above patches to the v2.1.0-dev tree, as they stomp on the segfaults.  The cache problem remains however, if the cache sizes at set to 1, mod_auth_ldap starts returning auth failures.  I applied the patch provided to 2.0.49 sources (the latest I had readily available) and get a crash with the following traceback (on Windows).  Note this was for user 2161 with a cache size of 2150.  Also note that this executable also includes the latest patches for util_ldap.c [for authenticated LDAP server access] and mod_auth_ldap.c [for avoiding double-escaping with Microsoft's LDAP SDK].  util_ldap_dn_compare_node_compare(void * 0x00815b98, void * 0x04d4de80) line 91 + 12 bytes util_ald_cache_fetch(util_ald_cache * 0x00d8008c, void * 0x04d4de80) line 351 + 17 bytes util_ldap_cache_checkuserid(request_rec * 0x6fb51341, util_ldap_connection_t * 0x007dd1e8, const char * 0x0078ced0, const char * 0x007799c8, int 7991832, char * * 0x00000002, const char * 0x00000000, const char * 0x04d4def0, const char * * 0x007dee59, const char * * * 0x04d4dee4) line 766 + 22 bytes mod_auth_ldap_check_user_id(request_rec * 0x6ff10e5f) line 334 ap_run_check_user_id(request_rec * 0x007dd1e8) line 69 + 31 bytes ap_process_request_internal(request_rec * 0x6ff0d6f8) line 193 + 6 bytes ap_process_request(request_rec * 0x007dd1e8) line 245 ap_process_http_connection(conn_rec * 0x6ff0423f) line 250 + 6 bytes ap_run_process_connection(conn_rec * 0x007c8ab8) line 42 + 31 bytes ap_process_connection(conn_rec * 0x007c8ab8, void * 0x007c89e8) line 175 + 6 bytes worker_main(long 2013300156) line 718 MSVCRT! 780085bc() KERNEL32! 7c581af6()  Once I let this process die a new child process is created and the test set (of 2500 users) works fine.  For testing this sort of thing, I recommend just exporting a single user (with password) from LDAP and using this export as a template to programmatically create many users all the same attributes except for the user name.  You can then use a simple program, script, or even Ant to attempt to fetch an authenticated resource on behalf of each user in turn. Patches to fix segfaults in the cache code were applied to v2.1.0-dev and v2.0.50-dev. Testing this by reducing the cache sizes to a size of 1 show that the segfaults are gone, but the mod_auth_ldap module is returning an auth fail when it shouldn't, and the cache gets full and stays full.  I have created a new bug report for this: 29207.   *** This bug has been marked as a duplicate of 29207 *** > Note that the last time I tested the cache entry overflow it still > crashed when I through 2500 unique user login attempts at a 2150 > entry cache.  This is more representative of our real use cases > than 5 unique users against a single user entry cache or the like > and I've not had a chance to (or much interest in) testing this > particular case.  I've built an Apache 2.0.50 from sources for Windows (to get HTTPS support, of course, plus tiny extensions to mod_deflate and sockopt -- which is missing send-buffer-size configurability on Windows) and re-ran the test noted above.  I get a 100% repeatable crash at around user 2160, i.e. the buffer overflow is *not* fixed, at least not on Windows.  [I can test Solaris and AIX when I get those binaries built.]  In short, this bug is *not* fixed in 2.0.50. Created an attachment (id=12817) Fix to util_ald_cache_purge() to relink lists properly  As per the last comment, I have found the problem behind this bug: util_ald_cache_purge() simply never relinked the linked list entries during cache purge.  Instead it freed various elements in the linked list without updating any linked list pointers, thus begging for trouble as the memory is reused, etc...  Also, I know this has been resolved as 'duplicate', but the fix I have found proves that the problem was not limited to 'duplicate'' bug 29207.  I am thus reopening this until someone commits my patch. The final patch for this bug that fixes the util_ald_cache_purge()relink  problem has been backported and posted.  See  dist/httpd/patches/apply_to_2.0.52. *** Bug 29207 has been marked as a duplicate of this bug. ***			Brad Nicholes	Graham Leggett	Jess Holle	Joe Orton
24805	null	CLOSED		Herbert G. Fischer	1069197780000	1071354123000		piped log programs respawning again after Apache is stopped Hi,  After digging the internet for something usefull on this problem I solved posting this bug report with all I discovered about this 'bug' (probably).  When Apache starts, it starts all piped log programs 'instances' correctly, but, when I stop Apache, all piped log programs instances remain running 'sleepy' (not zombie). Starting Apache again, it forks another set of instances of these piped log programs leaving a lot of them running on the system.  Initialy I tested with rotatelogs and cronologs, but also this problem can happen with any piped program, dealing or not with the logs (even a simple grep as piped log program).  I started debugging Apache by attaching strace to the main root Apache process and stoping Apache to see the error messages. I discovered that Apache logs on error_log these messages:  piped log program '/usr/local/sbin/cronolog /usr/local/sites/default/logs/access.%Y-%m-%d.log' failed unexpectedly piped log program '/usr/local/sbin/cronolog /usr/local/sites/portal/logs/access.%Y-%m-%d.log' failed unexpectedly  The interesting thing is that when I use strace this way and stops Apache, all instances of the piped log programs stops as nothing had happened wrong.  Here are some of the lines strace shows me:  ============================================================================== wait4(-1, 0xbffff900, WNOHANG|WUNTRACED, NULL) = 0 select(0, NULL, NULL, NULL, {1, 0})     = 0 (Timeout) wait4(-1, 0xbffff900, WNOHANG|WUNTRACED, NULL) = 0 select(0, NULL, NULL, NULL, {1, 0})     = ? ERESTARTNOHAND (To be restarted) --- SIGTERM (Terminated) @ 0 (0) --- sigreturn()                             = ? (mask now [RTMIN]) getpgrp()                               = 28370 kill(-28370, SIGTERM)                   = 0 --- SIGTERM (Terminated) @ 0 (0) --- sigreturn()                             = ? (mask now [RTMIN]) --- SIGCHLD (Child exited) @ 0 (0) --- select(0, NULL, NULL, NULL, {0, 16384}) = 0 (Timeout) wait4(28373, [WIFEXITED(s) && WEXITSTATUS(s) == 0], WNOHANG|WUNTRACED, NULL) = 28373 wait4(28374, [WIFEXITED(s) && WEXITSTATUS(s) == 0], WNOHANG|WUNTRACED, NULL) = 28374 wait4(28375, [WIFEXITED(s) && WEXITSTATUS(s) == 0], WNOHANG|WUNTRACED, NULL) = 28375 wait4(28376, [WIFEXITED(s) && WEXITSTATUS(s) == 0], WNOHANG|WUNTRACED, NULL) = 28376 wait4(28377, [WIFEXITED(s) && WEXITSTATUS(s) == 0], WNOHANG|WUNTRACED, NULL) = 28377 wait4(28372, [WIFSIGNALED(s) && WTERMSIG(s) == SIGTERM], WNOHANG, NULL) = 28372 write(2, 'piped log program /'/usr/local/sb'..., 115) = 115 pipe([17, 18])                          = 0 dup2(7, 17)                             = 17 dup2(11, 18)                            = 18 access('/usr/local/sbin/cronolog', R_OK|X_OK) = 0 fork()                                  = 28428 close(17)                               = 0 wait4(28371, [WIFSIGNALED(s) && WTERMSIG(s) == SIGTERM], WNOHANG, NULL) = 28371 write(2, 'piped log program /'/usr/local/sb'..., 114) = 114 pipe([17, 19])                          = 0 dup2(5, 17)                             = 17 dup2(8, 19)                             = 19 access('/usr/local/sbin/cronolog', R_OK|X_OK) = 0 fork()                                  = 28429 close(17)                               = 0 unlink('/usr/local/httpd-2.0.48/logs/httpd.pid') = 0 getpid()                                = 28370 gettimeofday({1069192645, 791003}, NULL) = 0 write(13, '[Tue Nov 18 19:57:25 2003] [noti'..., 66) = 66 ==============================================================================  Then I started digging Apaches source code (without understanding too much) and I built apache with -DNEED_WAITPID but this did not worked. I thought on some patch for the part that Apache kills all piped logs with apr funcions but that seams too much complicated for me.  Here are some details of boot systems that I'm having this problem:  OS.: Slackware 9.1 (gcc 3.2.3, glibc 2.3.2, kernel 2.4.22)  ldd output from httpd: libssl.so.0 => /usr/lib/libssl.so.0 (0x4001f000) libcrypto.so.0 => /usr/lib/libcrypto.so.0 (0x40051000) libaprutil-0.so.0 => /usr/local/httpd-2.0.48/lib/libaprutil-0.so.0 (0x4014f000) libgdbm.so.2 => /usr/lib/libgdbm.so.2 (0x40167000) libdb-3.3.so => /lib/libdb-3.3.so (0x4016d000) libexpat.so.0 => /usr/lib/libexpat.so.0 (0x401f6000) libapr-0.so.0 => /usr/local/httpd-2.0.48/lib/libapr-0.so.0 (0x40215000) librt.so.1 => /lib/librt.so.1 (0x40239000) libm.so.6 => /lib/libm.so.6 (0x4024b000) libcrypt.so.1 => /lib/libcrypt.so.1 (0x4026e000) libnsl.so.1 => /lib/libnsl.so.1 (0x4029b000) libdl.so.2 => /lib/libdl.so.2 (0x402b0000) libpthread.so.0 => /lib/libpthread.so.0 (0x402b3000) libc.so.6 => /lib/libc.so.6 (0x40305000) /lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)  and the configure command I used to build apache (without -DNEED_WAITPID): ./configure /         --prefix=/usr/local/httpd-2.0.48 /         --enable-module=ALL /         --enable-mime-magic /         --enable-headers /         --enable-expires /         --enable-cgi /         --enable-info /         --enable-rewrite /         --enable-ssl /         --enable-so  Anything else ???	Correction:  After stoping Apache, the pipe log programs stops too, but Apache forks another set of them before stoping itself.  # apachectl start # ps axuww  USER       PID %CPU %MEM   VSZ  RSS TTY      STAT START   TIME COMMAND root     18785  1.0  0.7 22832 7732 ?        S    21:52   0:00 /usr/local/httpd-2.0.48/bin/httpd -k start apache   18788  0.0  0.7 22856 7772 ?        S    21:52   0:00 /usr/local/httpd-2.0.48/bin/httpd -k start apache   18789  0.0  0.7 22856 7772 ?        S    21:52   0:00 /usr/local/httpd-2.0.48/bin/httpd -k start apache   18790  0.0  0.7 22856 7772 ?        S    21:52   0:00 /usr/local/httpd-2.0.48/bin/httpd -k start apache   18791  0.0  0.7 22856 7772 ?        S    21:52   0:00 /usr/local/httpd-2.0.48/bin/httpd -k start apache   18792  0.0  0.7 22856 7772 ?        S    21:52   0:00 /usr/local/httpd-2.0.48/bin/httpd -k start root     18786  0.0  0.0  1480  268 ?        S    21:52   0:00 /usr/local/sbin/cronolog /usr/local/sites/portal/logs/access.%Y-%m-%d.log root     18787  0.0  0.0  1480  268 ?        S    21:52   0:00 /usr/local/sbin/cronolog /usr/local/sites/default/logs/access.%Y-%m-%d.log  # apachectl stop # ps axuww  root     18819  0.0  0.0  1480  268 ?        S    21:54   0:00 /usr/local/sbin/cronolog /usr/local/sites/default/logs/access.%Y-%m-%d.log root     18820  0.0  0.0  1480  268 ?        S    21:54   0:00 /usr/local/sbin/cronolog /usr/local/sites/portal/logs/access.%Y-%m-%d.log I created a small C program that captures all signals and logs to a file which signal it received. This program only stops with SIGKILL.  I put it as a piped log program on httpd.conf to test what apache is doing with them.  After running apachectl start, apache runs twice each piped log. I've put two custom logs with piped logs on httpd.conf and apache started 4 piped log instances.  here are the logs after apache starts:  pid 9146 started at Thu Nov 20 11:58:51 2003 pid 9146 received signal 15 pid 9147 started at Thu Nov 20 11:58:51 2003 pid 9147 received signal 15 pid 9149 started at Thu Nov 20 11:58:52 2003 pid 9150 started at Thu Nov 20 11:58:52 2003  Apache starts a set of these piped log programs and send SIGTERM to them. After, apache starts them again.  After calling apachectl stop, here are the logs:  pid 9146 started at Thu Nov 20 11:58:51 2003 pid 9146 received signal 15 pid 9147 started at Thu Nov 20 11:58:51 2003 pid 9147 received signal 15 pid 9149 started at Thu Nov 20 11:58:52 2003 pid 9149 received signal 15 pid 9150 started at Thu Nov 20 11:58:52 2003 pid 9150 received signal 15  Apache sent SIGTERM to the last two instances of my piped log programs.  I think that the bug is related to how Apache treats piped log programs crashes.  When calling apachectl stop, apache kills all piped log programs with SIGTERM but the crash-safe code of piped log programs starts all piped log programs again, leaving them running before apache really stops.  Please! I need help here! Nobody is helping! I'm starting to consider not testing Apache 2 anymore if nobody helps me on this problem. I am sorry you are frustrated, and I am very empathetic.  Please note that something is happening with this PR, but it is not at all obvious to the casual observer.  The piped log program respawning issue appears to be related to a mod_cgid daemon respawning issue that has prevented the cgid daemon respawning logic to be merged into stable.  What we're working on is a way for other child logic such as piped log management and cgid daemon management to be able to query whether or not the server is terminating.  That info is needed to avoid re-spawning the child at termination.  See the thread 'ap_get_server_state()' on dev@httpd.  Respawning logic is just one use for ap_get_server_state(), so there probably isn't any explicit text describing the relationship in that thread. another note in case certain developers see this and think I am ignoring their comments :)  replace 'ap_get_server_state()' references in my previous update to this PR with 'new flavor of ap_mpm_query(), or something else that gives the state of the server'  you didn't mention what MPM you're using...  I added some general support to prefork thus far to fix this type of problem, and also changed the piped log support to use this logic...  changes for worker and other MPMs will come later  I'll attach a patch for 2.0.48 and prefork MPM in a moment...  if you're using prefork, please try it out...  the symptoms I get seem to vary from platform to platform (sometimes I can't see any symptom, sometimes Apache tries to start the piped log program but something has been corrupted and prevents it from starting, etc.) Created an attachment (id=9220) keep apache from trying to restart piped loggers at termination  I don't know what MPM is. Can you tell me, so I can tell you what MPM I'm using.  I found that all this problem doesn't happen on a IBM PPC 7046-B50 PowerPC 604r with SuSE 7.3 PPC. If you don't know which MPM, that probably means you're using the default (prefork).  You can display the MPM via 'apachectl -V'.  Here is how prefork looks:  $ /usr/local/apache2047/bin/apachectl -V | grep MPM  -D APACHE_MPM_DIR='server/mpm/prefork'  Here is how worker looks:  $ ph/2.0.47/built/bin/apachectl -V | grep MPM  -D APACHE_MPM_DIR='server/mpm/worker'  Incidentally, I too had a system that had no apparent ill symptom (RedHat 6.1 on a Pentium III 500MHz).  I suspect that many (most?) people aren't noticing any such problem with piped loggers, at least on a regular basis.  Yes... It's prefork. If I can switch this to another thing, what do you recommend ? I pretend to try to see if this problem is solved for now.  here is my apachectl -V output:  Server version: Apache/2.0.48 Server built:   Nov 18 2003 21:28:26 Server's Module Magic Number: 20020903:4 Architecture:   32-bit Server compiled with....  -D APACHE_MPM_DIR='server/mpm/prefork'  -D APR_HAS_SENDFILE  -D APR_HAS_MMAP  -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)  -D APR_USE_SYSVSEM_SERIALIZE  -D APR_USE_PTHREAD_SERIALIZE  -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT  -D APR_HAS_OTHER_CHILD  -D AP_HAVE_RELIABLE_PIPED_LOGS  -D HTTPD_ROOT='/usr/local/httpd-2.0.48'  -D SUEXEC_BIN='/usr/local/httpd-2.0.48/bin/suexec'  -D DEFAULT_PIDLOG='logs/httpd.pid'  -D DEFAULT_SCOREBOARD='logs/apache_runtime_status'  -D DEFAULT_LOCKFILE='logs/accept.lock'  -D DEFAULT_ERRORLOG='logs/error_log'  -D AP_TYPES_CONFIG_FILE='conf/mime.types'  -D SERVER_CONFIG_FILE='conf/httpd.conf'   This are the hardware configuration of both machines I've experienced problems:  Intel P4 Xeon 2.2 Ghz - 2GB RAM Intel P4 1.6 - 512MB RAM  Both are running optimized kernels for P4.  I was thinking on something... but I cannot see if it's absurd...  Both machines are very fast, and both are using Slack 9.1 As Apache 2 have multithread support, can the speed affect Apache ou some system lib for multithread ??  Tks! Also:  I need to use PHP within these servers. So, I going to have problems on changing the MPM to worker or another else ?? I'm not suggesting you switch to worker MPM ;)  I originally didn't know which MPM you were using and wanted to point out that the patch doesn't fix the worker scenario, only the prefork scenario.  Now we know you're using prefork, so keep your configuration, apply the patch, and do make && make install and hopefully this problem will be resolved for you.   I see.  I tested with MPM worker and PHP+ZTS and It worked correctly. No respawning piped log programs.  This setup it stable ?? Can I leave that ? The PHP folks recommend to NOT use PHP with a threaded Apache 2 MPM such as worker, because they offer interfaces to a lot of 3rd party libraries and cannot ensure that such calls are thread-safe.  I don't know how to evaluate whether or not your PHP usage is subject to such problems.  Unless the PHP folks can help you evaluate your situation, I'd recommend using the prefork MPM.  Thanks for you help. I'm getting back to prefork with your patch applied. But I'm not giving up.  If you need anything to help debug this problem, as I have it, please, tell me.  And thanks for the patch! *** Bug 19035 has been marked as a duplicate of this bug. *** *** Bug 19981 has been marked as a duplicate of this bug. *** *** Bug 23109 has been marked as a duplicate of this bug. *** Fix committed to 2.1-dev.  Hopefully it can be committed to stable branch before too terribly long.  *** Bug 19846 has been marked as a duplicate of this bug. *** Just want to confirm that this patch does appear to fix the bug for me, I no longer have stale cronolog processes sitting around after stopping or restarting Apache. My problem was the same David Rees wrote about, I can also confirm that it is solved now.  Please push it into 2.0.49 The patch solved my problem too. Thanks! I recommend this onto the next Apache release. Thanks for the reports, folks!  I have indicated with the merge request that it was tested successfully by our users. 			David Rees	Herbert G. Fischer	Jeff Trawick	Peter Bieringer
24884	null	CLOSED		yuk	1069412100000	1071250431000		t include cache headers I made a lot of test with apache 2.0.48 compiled on HP-UX 11.00 and with the Apache included in MandrakeLinux 9.1.  When I do a GET and obtain a 200 in the reply there are the cache headers, but when the reply is 304 there is no way have theese headers. So when the browser's cache expires, the expire-date is not updated more. For each page I obtain a 304 for each element for ever...  Example:  the request:  GET /test.html HTTP/1.1 Accept: */* Accept-Language: it Accept-Encoding: gzip, deflate If-modified-since: Thu, 20 Nov 2003 11:54:42 GMT If-None-Match: '12a-a0006480' User-Agent: Mozilla/4.0 (compatible; MSIE 6.0) Host: 10.254.3.20 Connection: Keep-Alive  the 304 (expire-date is not updated):  HTTP/1.1 304 Not Modified Date: Fri, 21 Nov 2003 09:40:43 GMT Server: Apache Connection: Keep-Alive Keep-Alive: timeout=10, max=8 ETag: '12a-a0006480'   the 200 (the cache is updated):  HTTP/1.1 200 OK Date: Fri, 21 Nov 2003 09:40:43 GMT Server: Apache Last-Modified: Thu, 20 Nov 2003 11:54:42 GMT ETag: '12a-a0006480' Accept-Ranges: bytes Content-Length: 298 Cache-Control: max-age=86400 Expires: Sat, 22 Nov 2003 09:40:33 GMT Keep-Alive: timeout=10, max=10 Connection: Keep-Alive Content-Type: text/html; charset=ISO-8859-1 Data (298 bytes)  I think there is a problem in mod_expires...  Thanks Fabio	I found an old issue (http://www.apacheweek.com/issues/96-08-30)... seems to be  an old problem:  <cut....>  Responses can also contain a definite time when the document will expire, in  the Expires HTTP header. There are some cases where the expiry time of a  document might change, even if the document itself has not changed. So a 304  status message can include an updated expires time, which the browser should  use to replace the expires time in it's cached copy of the file. Currently  Apache does not send out the expires header on 304 status, which is required by  HTTP/1.1. The problem with not sending out the expires header is that the  browser still keeps the old expiry time, so it thinks the document has expired  straight away. This will be fixed in the next release.   <cut....>  Is there a work-around?  Thanks, Fabio  I am currently working on this problem. There is not currently a workaround that I know of. I know what the problem is (only certain filters are run in the error path and expires is not one of them). I am currently working on a solution to the problem. Thank you for reporting this and for using Apache. *** Bug 25123 has been marked as a duplicate of this bug. *** The solution lies somewhere within the following:  mod_expires only register with 'ap_register_output_filter'...  and within 'modules/http/http_protocol.c', we do this (flushing the output filter):  AP_DECLARE(void) ap_send_error_response(request_rec *r, int recursive_error) {     int status = r->status;     int idx = ap_index_of_response(status);     char *custom_response;     const char *location = apr_table_get(r->headers_out, 'Location');      /* At this point, we are starting the response over, so we have to reset      * this value.      */     r->eos_sent = 0;      /* and we need to get rid of any RESOURCE filters that might be lurking      * around, thinking they are in the middle of the original request      */      r->output_filters = r->proto_output_filters;  This PR has been fixed in the 2.1-dev branch and has been suggested for backporting to the 2.0 stable branch. Thank you for using Apache and for submitting this report. I can't use '-dev' version... I'll wait for the 2.0.49 (I hope).  Thank you very much for your work!!  Bye			Joshua Slive	Marc Jauvin	Paul J. Reder	yuk
24922	null	CLOSED		Kirill K	1069542780000	1088859599000		ftp proxy connects to 0.0.0.0 Hello. I'm trying to forward requests to remote ftp-server with simple htaccess (located in /ftp/ dir): RewriteEngine on RewriteRule (.*)/.txt$ ftp://123.123.123.123/$1.txt [P]  But Apache (2.0.48) returns such error: Proxy Error The proxy server received an invalid response from an upstream server. The proxy server could not handle the request GET /ftp/file.txt.  Reason: Could not connect to remote machine: (null) port 80  I've tested same htaccess with http forward and it just works fine. In error.log (debug mode) i'm getting such messages:  proxy_ftp.c(824): proxy: FTP: serving URL ftp://123.123.123.123 proxy_ftp.c(917): proxy: FTP: connecting ftp://123.123.123.123 to (null):80 proxy_ftp.c(995): proxy: FTP: fam 2 socket created, trying to connect to 0.0.0.0:80 ((null))... (OS 10049)The requested address is not valid in its context.  : proxy: FTP: attempt to connect to 0.0.0.0:80 ((null)) failed  Some more info: i've tested it under FreeBSD and WinXP, got same result, also if there's local ftp-server running (listening to 0.0.0.0, not 127.0.0.1), then apache connects to it successfully. Also, i've tried different URI schemes, because i think that module just cant  parse it correctly, but no way.. ftp://123.123.123.123 ftp://123.123.123.123/ ftp://123.123.123.123:21 ftp://123.123.123.123:21/ ftp://anonymous:password@123.123.123.123 etc, all failed.  Also, i've tried to bind remote ftp with ProxyPass directive -- same result  (and again -- binding http server was successful) Please help, I don't like SQUID for some reasons and really would like to have  ftp-proxy with Apache running. Thanks a lot in advance.	Today i've added desired IP directly into proxy_ftp.c and though now Apache  tries to open desired IP, i'm getting segfault (11) just like in this bug: http://nagoya.apache.org/bugzilla/show_bug.cgi?id=14976  Seems like it still not fixed in 2.0.48.     Seriously doubt that this is an identical segfault, Kirill.  Why not attach   a backtrace of the crash dump?  And why would you complain about segfaults   in a modified module if you didn't post the patch you attempted to use???    Please, more details - we don't read minds and would love to look closer at   these issues :)  Sorry, never did things like that :) Here goes the backtrace:  (gdb) bt #0  0x283572c6 in memcpy () from /usr/lib/libc.so.5 #1  0x0000000c in ?? () #2  0x28349d3f in strchr () from /usr/lib/libc.so.5 #3  0x2834cad5 in __vfprintf () from /usr/lib/libc.so.5 #4  0x2833cd35 in sprintf () from /usr/lib/libc.so.5 #5  0x284ff596 in ap_proxy_ftp_handler ()  from /opt/apache/modules/mod_proxy_ftp.so #6  0x74662f2f in ?? () Cannot access memory at address 0x3a707466  I'll try to collect more info tomorrow, but need to re-compile apache for that. one more dump: (gdb) bt full #0  apr_palloc (pool=0x280d11d0, size=8) at apr_pools.c:640         active = (struct apr_memnode_t *) 0x280d2a80         node = (struct apr_memnode_t *) 0x2         mem = (void *) 0x0         free_index = 671945168 (gdb)  (after i've recompiled apache with -g option) Created an attachment (id=10892) A quick patch that made reverse ftp work fine for me  Patch applied to v2.1.0-dev, awaiting backport to v2.0 committed to 2.0.51-dev  thanks again for the patch!			Graham Leggett	Jeff Trawick	Kirill K	Pascal Terjan	Will Rowe
24991	null	CLOSED		Larry Toppi	1069795920000	1071086252000		mod_proxy_http leaks memory when using HTTP POST requests When reverse proxying a web page using the ProxyPass directive, Apache leaks  memory when running the JMeter stress test tool using HTTP POST requests.   This does not happen with HTTP GET requests.  Sample config:  <VirtualHost *:81> \tServerName <your-server-name> \t<Location /> \t\tProxyPass http://localhost/ \t</Location> </VirtualHost>	Created an attachment (id=9470) Fixed EOS bucket leak in proxy_http.c  the patch looks simple (and correct) enough...    any idea if the short-circuit test for EOS just above this leaks that bucket too?  I'm referring to this logic:  if (APR_BUCKET_IS_EOS(APR_BRIGADE_FIRST(bb))) {                 break;             }  It looks to me like that simple brigade will get leaked in that condition.  I'm re-opening the bug and adding the PatchAvailable keyword; until somebody commits your fix to 2.1-dev, it should be visible by everybody as something to work on.  > I'm referring to this logic: > if (APR_BUCKET_IS_EOS(APR_BRIGADE_FIRST(bb))) { >                 break; >             } > It looks to me like that simple brigade will get leaked in that condition.  Not necessarily completely leaked, though it might live longer than one could  hope for.  As long as the bucket remains in its brigade, the bucket and brigade  will get killed off when the pool associated with the brigade is cleaned up. Thanks for clarifying, Cliff!  I'm +1 for the patch.  That was my only dangling question.  thanks for the patch!  commited to 2.1-dev, proposed for merging to stable branch for 2.0.next  patch now committed to stable branch for 2.0.next 			Cliff Woolley	Jeff Trawick	Larry Toppi
25036	null	CLOSED		Jonathan Wakely	1069884960000	1077315251000		man pages for ab and apachectl say section number (1) not (8) The man pages for ab(8) and apachectl(8) incorrectly claim to be in section 1 of the manual.  'man -w apachectl' gives:     /usr/share/man/man8/apachectl.8.gz  but 'man apachectl' gives:  apachectl(1)                                         apachectl(1)  NAME        apachectl - Apache HTTP server control interface  I'll attach a patch to change this...	Created an attachment (id=9314) Change section number in ab and apachectl man pages  Thanks!			Andr?? Malo	Jonathan Wakely
25040	null	CLOSED		Karl Fogel	1069903980000	1075404166000		t play well with subrequests Digest auth doesn't cooperate well with subrequests, because it insists on using the URI from the Auth header instead of the URI in the subrequest.  I may be getting some of the subtleties wrong here; please see this mail from Justin Erenkrantz for a better description:  http://subversion.tigris.org/servlets/ReadMsg?list=dev&msgNo=50876  It's part of this thread  http://subversion.tigris.org/servlets/BrowseList?list=dev&by=thread&from=135712  ...which starts with Ben Collins-Sussman explaining why Subversion's recent switch to using subrequests for authorization broke digest auth, for users who had previously been using it successfully.  Oh: and later, in a private email exchange, Sander Striker tentatively confirmed Brian Fitzpatrick's outline of a solution:     B. W. Fitzpatrick wrote:    > So basically, mod_auth_digest needs to see if it's in    > a subreq, and if it is, then ignore the URI in the    > Auth header and use the uri from the subreq itself?    >    > Is that a correct understanding?        That sounds about right.        Sander	I think Fitz has it reversed.  mod_auth_digest needs to use the uri of r->main, not of the subreq because the hashed nonce will  be off of the original request's URI.  Right now, I think it's using the subreq's uri (i.e. r->uri), but  that isn't what the user sent.  Hence, it can't compute the 'same' hash. Actually, I think it shouldn't be doing anything other than checking if the subreq uri is in the same directory/location block (or, in the same auth domain), and if so, just copy what was done for the main request. My subversion server already had a modified mod_auth_digest, so I went digging. It looks like the subreq is already using fields of the main request to check the digest, with one exception -- digest_header_rec does not have a method field. When I get these authentication failures, the subreq method doesn't match the main req's method.  I added that field, set it to r->method in parse_hdr_and_update_nc(), and modified old_digest() and new_digest() to use resp->method instead of r->method, and that fixed the problem. Created an attachment (id=9946) The changes described above in patch form (and stripped of other local changes)  Just adding the PatchAvailable keyword... Committed to httpd-2.1 as r1.82 of modules/aaa/mod_auth_digest.c.  Proposed for backport to 2.0.  Will be included in the next release.  Thanks!			Erik Abele	Josh Dady	Justin Erenkrantz	Sander Striker
25090	null	RESOLVED		Steven Levine	1070160540000	1117768324000		htpasswd usage help output with unix line endings htpasswd invoked as:    htpasswd  outputs the help text with unix sstyle line endiings.	Fixed in r179689			Paul Querna
25101	null	CLOSED		Tomasz Kepczynski	1070271540000	1071761513000		Polish error messages I include patch file with Polish version of HTTP error messages.	Created an attachment (id=9338) Polish HTTP error messages  Thanks.  Given that members of the docs project don't speak Polish, we need to have someone review the accuracy of this translation before we can commit it.  If you could recruit another fluent Polish speaker to read your translation, assure that it matches the English original, and then post a message here to that effect, then we can commit your translation. Created an attachment (id=9355) Spelling and content corrections for Polish error messages  Translation looks fine & matches the original Your second patch has been committed to Apache httpd 2.1-dev, and I'll request that it be merged into the stable branch for the 2.0.next release.  Thanks for your contribution, and thanks for using Apache.			Jeff Trawick	Joshua Slive	Juliusz Czarnogorcew	Tomasz Kepczynski
25268	null	CLOSED		Heiko Recktenwald	1070792160000	1073775818000		video/vnd.mpegurl mxu m4u in mime.types and mime.types-dist Hi, the extension m4u, see http://www.iana.org/assignments/media-types/video/vnd-mpegurl, should be added to the line   video/vnd.mpegurl mxu in mime.types and mime.types-dist in Apache 1.3 and 2.0.  It should be  video/vnd.mpegurl mxu m4u  m4u was registered at IANA too, I had forgotten this when I asked to include audio/x-mpegurl m3u and video/vnd.mpegurl mxu some time ago, thanks! ;-), and now there is an important player now that supports at least m4u, it must be cleared now,  Thanks again!   Heiko	Sorry, wrong component,  H. Now finally committed to all three versions currently in development. Thanks.			Erik Abele	Heiko Recktenwald
25269	null	CLOSED		Heiko Recktenwald	1070792760000	1073775878000		video/vnd.mpegurl mxu m4u in mime.types and mime.types-dist Same as BUG 25268 for Apache 1.3  Thanks,  Heiko  uzs106@uni-bonn.de	Sorry, wrong OS,  H. Committed to the 1.3, 2.0 and 2.1 trees. See also #25268.			Erik Abele	Heiko Recktenwald
25414	null	CLOSED		Geoffrey Young	1071077460000	1071096066000		Limit directives <Limit> and <LimitExcept> do not require a closing '>' in the initial container.  that is  <Limit GET POST ... </Limit>  is currently accepted as valid.  PatchAvailable.  Index: server/core.c =================================================================== RCS file: /home/cvspublic/httpd-2.0/server/core.c,v retrieving revision 1.252 diff -u -r1.252 core.c --- server/core.c       21 Nov 2003 15:02:04 -0000      1.252 +++ server/core.c       10 Dec 2003 17:16:59 -0000 @@ -1552,11 +1552,21 @@      return NULL;  }    +/* + * Report a missing-'>' syntax error. + */ +static char *unclosed_directive(cmd_parms *cmd) +{ +    return apr_pstrcat(cmd->pool, cmd->cmd->name, +                       '> directive missing closing '>'', NULL); +} +  AP_CORE_DECLARE_NONSTD(const char *) ap_limit_section(cmd_parms *cmd,                                                        void *dummy,                                                        const char *arg)  { -    const char *limited_methods = ap_getword(cmd->pool, &arg, '>'); +    const char *endp = ap_strrchr_c(arg, '>'); +    const char *limited_methods;      void *tog = cmd->cmd->cmd_data;      apr_int64_t limited = 0;      const char *errmsg; @@ -1566,6 +1576,12 @@          return err;      }    +    if (endp == NULL) { +        return unclosed_directive(cmd); +    } + +    limited_methods = apr_pstrndup(cmd->pool, arg, endp - arg); +      while (limited_methods[0]) {          char *method = ap_getword_conf(cmd->pool, &limited_methods);          int methnum; @@ -1609,15 +1625,6 @@  #else  #define USE_ICASE 0  #endif - -/* - * Report a missing-'>' syntax error. - */ -static char *unclosed_directive(cmd_parms *cmd) -{ -    return apr_pstrcat(cmd->pool, cmd->cmd->name, -                       '> directive missing closing '>'', NULL); -}     static const char *dirsection(cmd_parms *cmd, void *mconfig, const char *arg)  {	Adding 'PatchAvailable' to the keywords field. patch trivia: when I cut and pasted from a Mozilla display of your patch in this PR, I ended up with an extra space on the three lines in your patch which were supposed to represent blank lines...  the patch wouldn't apply, of course...  moral of the story: use an attachment  fix committed to 2.1-dev 			Erik Abele	Jeff Trawick
25420	null	CLOSED		Viraj Alankar	1071084960000	1071110817000		Grammatical error in auth.html On this page:  http://httpd.apache.org/docs-2.0/howto/auth.html  Under the section 'Getting it working', the 3rd paragraph says:  To create the file, use the htpasswd utility that came with Apache. This be  located in the bin directory of wherever you installed Apache. ...  'This be' should be changed to 'This is'	Thanks, fixed. I changed it to 'This will be' to be consistent with the 1.3 docs ;)			Erik Abele
25460	null	CLOSED		Geoffrey Young	1071187860000	1101705346000		 are valid syntax this was first posted on httpd-dev  http://marc.theaimsgroup.com/?t=107089936600004&r=1&w=2  currently, all core container directives have an issue (albeit a minor one) - they require an argument in practice but are allowed to proceed without one during configuration.  for example  <IfModule >  does not currently throw an error.  instead, the config is allowed to proceed, soaking up the container.  more details are available within the thread.  there has been discussion on httpd-dev whether <IfDefine > should be allowed, equally split between the two people who voiced their opinion.  this patch attempts to bridge the gap, requiring that core containers specify arguments, while <IfDefine 0> is guaranteed to never be true (-D0 becomes invalid, similar to -D''), thus providing a migration path away from <IfDefine >.	Created an attachment (id=9526) disallow -D0, fail <IfDefine >, <IfModule >, etc.  added PatchAvailable keyword.  it would be nice it both the keyword and attachment fields were present on the initial bug entry form - this will be the third email in a 1 minute span for a new bug report. Committed to httpd trunk in svn revision 106879.			Geoffrey Young	Paul Querna
25477	null	CLOSED		Robert Heller	1071239820000	1080014009000		suexec dependencie on mod_userdir not documented For some reason, mod_suexec is not invoking suexec when accessing a CGI script in a user's directory (/~user/cgi-bin/foo.cgi -- ~user/public_html/cgi-bin/foo.cgi).  Here is the section of the httpd.conf file that relates to user dirs:  <IfModule mod_userdir.c>     #     # UserDir is disabled by default since it can confirm the presence     # of a username on the system (depending on home directory     # permissions).     #     #UserDir disable       #     # To enable requests to /~user/ to serve the user's public_html     # directory, remove the 'UserDir disable' line above, and uncomment     # the following line instead:     #     UserDir public_html      ScriptAliasMatch ~([a-z]+)/cgi-bin/(.*) /home/zathras/$1/public_html/cgi-bi$       <Directory ~ '/home/zathras/[a-z0-9]+/public_html/cgi-bin'>        AllowOverride None       Options +ExecCGI       </Directory>           </IfModule>	The ScriptAliasMatch could very well be the problem here.  Try removing it and adding a 'SetHandler cgi-script' into the <Directory> block.  OK, using SetHandler seems to fix it.  So the problem seems to be with ScriptAliasMatch (or at the very least there is a documentation bug).  No bug in ScriptAlias.  The problem is that mod_suexec is tied directly to mod_userdir.  You circumvented mod_userdir by using ScriptAlias.  This should probably be mentioned in the 'Using suexec' section of suexec.html.  *** Bug 27840 has been marked as a duplicate of this bug. *** I have updated the suexec docs to mention the requirement of going through mod_userdir.  Thanks for using Apache!			Joshua Slive	Robert Heller
25520	null	CLOSED		Adam Sussman	1071450600000	1074298674000		Corrupt log lines at high volumes mod_log_config with buffered logging turned on shows corrupted log lines when serving at very high volumes using the worker mpm.  This is very consistent behaviour with all recent versions of 2.0.  The problem appears to be that the per-child buffer management is not thread safe.  There is nothing to prevent the memcpy operations in ap_buffered_log_writer by different threads from overlapping.  Since this is a problem that happens at high volume, adding a mutex around this isn't necessarily the most attractive option.  Also, it is unclear whether or not a thread mutex is good enough.  mod_rewrite uses a global mutex for its logging.	A thread mutex should be good enough for handling the buffer and possibly flushing.  Each process would be atomically appending a set of complete trace records to the file, and that doesn't have to be handled explicitly by mod_log_config.  With buffered logs there will be a much higher incidence of out of order records, but that can happen already.  I wonder if the big picture is that for a threaded MPM config you're better off shoving everything to a piped logger to handle in its simple way rather than adding serious mutex contention to the web server.  Still, the code to make it functionally correct is relatively simple so it should be implemented and the user should get to decide which is more appropriate.  fix just committed to Apache 2.1-dev...  I'll propose it for backport once folks have had a chance to look at it  Thanks for your report, and thanks for using Apache! 			Jeff Trawick
25635	null	CLOSED		Mark Thias	1071775020000	1075046432000		RewriteMap script puts newline character in URL and not handled by mod_rewrite I'm trying to use a RewriteMap and a RewriteRule for load balancing. I use a  python script in the RewriteMap to modify the URL but I get a newline character  in the URL which causes a browser error.  HTTP ERROR: 404 /ctms/%0D Not Found   My environment is as follows:   1. Apache 2.0.48   2. Win2K 5.00.2195 Service Pack 3   3. Python23   My httpd.conf looks as follows:   RewriteEngine on  RewriteLogLevel 20  RewriteLog rewrite.log  RewriteMap servers 'prg:C:/Tools/Python23/python.exe c:/proxy.py'  RewriteRule ^/ctms/(.*) ${servers:$1}  [P,L]   My python script:   #!c:/Tools/Python23/python.exe   count=0   import sys  import string  import os   if __name__ == '__main__':      servers = ['http://server1:8080/ctms/','http://server2:8080/ctms/']      while 1:          data = sys.stdin.readline()          if not data:              break          count = (count+1) % 2          print servers[count]  ( remaps correctly but puts newline character in  URL )  #        sys.stdout.write('%s' % servers[count])  (tried this but causes hang)  #        sys.stdout.write('%s/n' % servers[count])  (tried this, same as print)          sys.stdout.flush()  ( if I don't have this, does not remap )     Rewrite.log:   (2) init rewrite engine with requested uri /ctms/  (3) applying pattern '^/ctms/(.*)' to uri '/ctms/'  (2) init rewrite engine with requested uri /ctms/  (3) applying pattern '^/ctms/(.*)' to uri '/ctms/'  (5) map lookup OK: map=servers key= -> val=http://server1:8080/ctms/  198.213.32.14 - - [17/Dec/2003:15:12:20 --0600] [server1/sid#23c590] [rid#47e9c0/initial] (2) rewrite /ctms/ -> http://server1:8080/ctms/  198.213.32.14 - - [17/Dec/2003:15:12:20 --0600] [server1/sid#23c590] [rid#47e9c0/initial] (2) forcing proxy-throughput with  http://server1:8080/ctms/ 198.213.32.14 - - [17/Dec/2003:15:12:20 --0600]  [server1/sid#23c590][rid#47e9c0/initial] (1) go-ahead with proxy request  proxy:http://server1:8080/ctms/<newline character here> [OK]	FYI: Fixed in 2.1  Thanks for the report and thanks for using Apache.			Andr?? Malo
25659	null	RESOLVED		David Blake	1071856020000	1127234577000		Memory leak in ssl_util_algotypeof(). The function ssl_util_algotypeof(X509 *pCert, EVP_PKEY *pKey) allows being  called with the parameter pKey == NULL.  The parameter pKey is allocated with  X509_get_pubkey() which needs a matching call to EVP_PKEY_free(pKey) somewhere.  Since the parameter for pKey was pass in as NULL the calling function doesn't  have a way of freeing it so a conditional check is needed for this case.  The  patch I have provided checks the pKey parameter for NULL and sets a boolean so  that before exiting the function we can conditionally free pKey.	Created an attachment (id=9646) Patch to fix memory leak in ssl_util_algotypeof().  PatchAvailable Thanks for your patch submission!  Aren't BOOL, TRUE, and FALSE Windows-only features?  I believe that this should use int, 1, and 0 for portability.  ugg, ignore last comment :)  I didn't realize until looking at your next patch that mod_ssl defines these odd types when the platform doesn't define it...  This patch does exactly what the OpenSSL applications code does: free the pubkey after use. The check on  the incoming parameter is necessary because the other time this function gets  called, it is fed a key that  is used after the function call.   +1 on this patch.  +1 on this patch too. I committed a slightly modified patch.			David Blake	Jeff Trawick	Martin Kraemer	Sander Temme
25714	null	CLOSED		P.M.	1072145640000	1072185868000		' 'happend' is a misspelling of 'happened'.  Here is a patch to correct this file, although I'm not sure the html is the source:  --- security_tips.html.en.old   2003-12-22 21:07:45.000000000 -0500 +++ security_tips.html.en       2003-12-22 21:08:10.000000000 -0500 @@ -299,7 +299,7 @@            <p>To keep up-to-date with what is actually going on against your server       you have to check the <a href='../logs.html'>Log Files</a>.  Even though  -    the log files only reports what has already happend, they will give you  +    the log files only reports what has already happened, they will give you       some understanding of what attacks is thrown against the server and       allows you to check if the necessary level of security is present.</p>       @@ -320,7 +320,7 @@        by server configuration: /usr/local/apache/htdocs/.htpasswd      </code></p></div>       -    <p>As you can see, the log files only report what already has happend, so  +    <p>As you can see, the log files only report what already has happened, so       if the client had been able to access the <code>.htpasswd</code> file you       would have seen something similar to:</p>       @@ -345,4 +345,4 @@  </div><div id='footer'>  <p class='apache'>Maintained by the <a href='http://httpd.apache.org/docs-project/'>Apache HTTP Server Documentation Project</a></p>  <p class='menu'><a href='../mod/'>Modules</a> | <a href='../mod/directives.html'>Directives</a> | <a href='../faq/'>FAQ</a> | <a href='../glossary.html'>Glossary</a> | <a href='../sitemap.html'>Sitemap</a></p></div> -</body></html> / No newline at end of file +</body></html>	Created an attachment (id=9676) Patch to correct typo  Thanks for the fix, now committed to 2.1-dev as well as stable branch for 2.0.next! 			Jeff Trawick	P.M.
25772	null	CLOSED		Greg Wilkins	1072519500000	1075319570000		REMOTE_PORT This is a feature request for REMOTE_PORT to be added to the server-variables available to mod_rewrite.    Other than for completeness, the reason this is needed is that Cisco has a class of router that identifies user specific routing sessions with signalling that is based on the source port of the TCP/IP connection.  Web based software dealing with these routers has had to use customized HTTP servers (normally based on Jetty).  Having this server variable available in mod_rewrite would allows a standard httpd to be used with these routers.  regards	I think enhancement request 18579 may also be related to this type of Cisco Router. I've added the variable in 2.1 (main development branch) and proposed it for backport into 2.0 and 1.3. Finally included into 2.0 and 1.3, so it will appear in the next releases.  Thanks for using Apache.			Andr?? Malo	Greg Wilkins
25867	null	CLOSED		Rob Meyer	1073071020000	1073229123000		[patch] SSL random number seeding errors on startup Installing httpd-2.0.48 on solaris, with SSL support (openSSL 0.9.7c) led me to the following error:  [Fri Jan 02 10:18:39 2004] [warn] Init: PRNG still contains insufficient entropy! [Fri Jan 02 10:18:39 2004] [error] Init: Failed to generate temporary 512 bit RSA private key Configuration Failed  The SSLRandomSeed directive was set to builtin though, which according to the docs should always be available. Trying values to point it at my egd socket also had no effect. A truss of the process showed it trying to open /dev/random, /dev/srandom, and /dev/urandom anyway. A pretty exhaustive search turned up lots of people with this problem, but no real definitive answers.  Finally, I figured it out, and I'm guessing the situation is similar for a lot of people. I had just installed the server, without generating any certificates yet, so I was using 'apachectl start' to make sure the server started up without SSL support. This of course doesn't define 'SSL' on the command line, and the entire ssl.conf is wrapped in an <IFdefined SSL>. So therefore, the SSLRandomSeed directive was never getting read, and apache was asking openssl for the default /dev/random.  So 'apachectl start' seems to be broken if the server is compiled with mod_ssl and the platform does not have a /dev/random. The most obvious fix is to move the SSLRandomSeed directives outside of the IFdefine SSL, making them execute regardless of the SSL setting (but still only included if mod_ssl is present). A patch to do just that for ssl-std.conf.in is included.   If this isn't an appropriate solution, or 'apachectl start' is not supported for ssl-enabled installations, then this should be at least mentioned in the docs or FAQ, probably where the mention of this exact error message occurs (in the 'About installation' section), as it seems to be pretty commonly encountered (sometimes with a different root cause, but I'd imagine this one is pretty common judging by the number of identical questions out there on the web with no definitive answer).	Created an attachment (id=9772) Patch for ssl-std.conf.in to make seeding configuration always valid  There is already some mention of this in the FAQ: http://httpd.apache.org/docs-2.0/ssl/ssl_faq.html#entropy  Maybe it is too early for me to read patches, but your patch appears to move the SSLRandomSeed outside <IfDefine SSL> which would generally be a bad thing since the loading of mod_ssl in a dso default config has: <IfDefine SSL> LoadModule ssl_module modules/mod_ssl.so </IfDefine> So you'd run into startup errors whenever starting without -DSSL Whoops. I've got a static mod_ssl, and the only place IFDefine appeared in the default config files was in ssl-std.conf wrapping the whole thing. Didn't realize it was used in shared mod_ssl configurations, and that is definitely going to cause a problem. Looks like this only applies to static mod_ssl compliations, and that a different fix is needed.  I'm not very familiar with the apache codebase, but it would seem that the real fix is to not initialize mod_ssl at all if SSL is not defined at runtime. That would solve the problem and would make the most sense. If you're not asking for ssl to be turned on, then it probably should not get initialized (which then requires the directives that get explicitly excluded when you run the server without -DSSL, leading to this little catch 22). Maybe I'll poke around and see if this possible (probably take me a while though).  As for the FAQ, right now, when someone asks this question, they get told to look at the FAQ, and even if they read and understand this item completely, there is still more to it. Currently in the affected configuration, you can change SSLRandomSeed all you like; it never gets read out of the config file. You either need to move it out of the IFdefine, or recompile the server with a different default random socket.  So the quickest interim solution would just be to tack this on in the FAQ right in the section you mention:  'When mod_ssl is compiled into your httpd statically, you must start it with the -DSSL flag (or use 'apachectl startssl'), otherwise the SSLRandomSeed directive will be ignored, and the compiled-in default will be used.'  I do think that just a plain start command without -DSSL should work to start httpd without SSL support, since starting with SSL support may not always be desireable (or possible if the person starting the server doesn't know the passphrase for the key). Using IfDefine SSL doesn't make sense in the same way  for a static module as it does for the dso version. My suggested fix would be to wrap everyting that is now wrapped in IfDefine SSL in an IfModule instead  (except the LoadModule and possibly the example https vhost). Everything is wrapped in an Ifmodule:  <IfModule mod_ssl.c>     conf/ssl.conf </IfModule>  But that's alaways included since mod_ssl is static. But then since SSL is not defined, everything in ssl.conf is ignored, leaving out the Seed config, causing it to revert to the compiled-in default. So what we need is for the SSLRandomSeed directives to always get loaded when mod_ssl is static, but not when it's dynamic...  ...Wait, shouldn't my first patch be okay then? Because in a dynamic situation if the mod_ssl module isn't loaded the bit I changed is already wrapped in an IFModule, so it should get loaded at all. If the modules not loaded, none of the ssl config gets run...   Well, that's what I get for relying on my memory ;) Your patch shouldn't do any harm in the dso case. I'm +1 on the change. Yep, this logic looks correct to me. I've committed a slightly changed version of your patch to the  2.1 tree and proposed it for backport to the 2.0 tree.  See http://cvs.apache.org/viewcvs.cgi/httpd-2.0/docs/conf/ssl-std.conf.in?r1=1.4&r2=1.5 Finally backported to 2.0 and thus in the next release. Thanks!			Erik Abele	Mads Toftum	Rob Meyer
25870	null	CLOSED		iCy-fLaME	1073073900000	1080003302000		IndexIgnore documentation is misleading i.r.t. the accepted expressions OS: Win2k3 Ent. Srv.  No matter where and how I put IndexIgnore, it simply wont show any effects when  gnerating the index page.  IndexIgnore m3u .m3u  I tried putting in global & dir specific way, but no luck.  However,  IndexOptions NameWidth=*  does work. So, aparently mod_autoindex is only partially not functioning.	This is not a bug with mod_autoindex but rather a bug in the documentation.  mod_autoindex uses ap_str(case)cmp_match which expects a shell-style wildcard expression (or a  full filename), in your case something like 'IndexIgnore *.m3u' and *not* partial filenames or  extensions as stated in the documentation. Fixed docs.  Thanks for using Apache.			Erik Abele	Joshua Slive
25875	null	CLOSED		Tom Verhoeff	1073120700000	1073137266000		!-- and # for SSI Under 'Basic Elements' in the mod_include doc, there is a clear explanation about whitespace before -->:       'Note that the comment terminator (-->) should be preceded by whitespace      to ensure that it isn't considered part of an SSI token.'  However, it took me several hours to discover that whitespace apparentely is NOT allowed between <!-- and #.  Please include a sentence in the documentation about this, or, alternatively, see to it that the parser ignores whitespace between <!-- and #.  This is also NOT covered in the 1.3 and 2.1 documentation, nor in the FAQ.	Added a sentence with regard to the issue.  Thanks for your report and thanks for using Apache.			Andr?? Malo
25917	null	RESOLVED		Joachim Selke	1073341800000	1185968227000		mod_rewrite should be capable of sending back a HTTP response of 404 (NOT FOUND) With mod_rewrite you can send back a whole series of HTTP responses: 302 (MOVED TEMPORARILY), 403 (FORBIDDEN), 410 (GONE), ...  But an important one is missing: 404 (NOT FOUND).  Why is this important? Let's assume the following situation: You create two new web resources that you want to be accessible via the URLs <http://foo.example/bar/> (first resource) and <http://foo.example/bar/something> (second resource), but no other URLs.  At the moment the first resource is also available via <http://foo.example/bar/index.html> (if your DirectoryIndex is set to index.html) and there is no (simple) way to completely remove (that means answering to a request with a HTTP response of 404) this unwanted URL. A simple enhancement of mod_rewrite would solve this problem.	Fixed in 2.1. Now any valid response code can be given via the R flag. It implies [L] and the substitution pattern will be dropped (except for redirects). (In reply to comment #1) > Fixed in 2.1. Now any valid response code can be given via the R flag.  I wonder why this is not mentioned in the documentation of mod_rewrite. <http://httpd.apache.org/docs/2.2/en/mod/mod_rewrite.html> tells about status codes 300-400 only. I think the new feature should be mentioned there. The documentation still does not mention this feature. Instead it tells that only status code in the range 300-400 are possible options for the 'R=....' flag.  I reopened this bug and changed the affected component to Documentation. Docs fixed. Thanks.			Andr?? Malo	Joachim Selke	Joshua Slive
26002	null	CLOSED		Scott Moore	1073602020000	1073953064000		mod_usertrack prohibits other modules from setting cookies mod_usertrack improperly makes a call to apr_table_setn to create the  'Set-Cookie' header.  If another module has run before mod_usertrack and added  it's own 'Set-Cookie' or 'Set-Cookie2' header, the data is lost.  This affects  both Apache 2.0 and Apache 1.3.   A call to apr_table_addn instead may be more appropriate (mod_usertrack.c, line  191).	Fixed in 2.1 and proposed for backport into 2.0 and 1.3 branches.  Thanks for the report and thanks for using Apache. *** Bug 26693 has been marked as a duplicate of this bug. ***			Andr?? Malo
26079	null	CLOSED		Allan Sandfeld	1073956020000	1075317318000		RealMedia files reported as RealAudio This is a transfer of a bug originally assigned to konqueror  <http://bugs.kde.org/show_bug.cgi?id=72323>. I've tracked the bug down to  conf/mime.types in both Apache 1.3 and Apache 2.0.    Basically these the three lines:  audio/x-pn-realaudio\t\tram rm  audio/x-pn-realaudio-plugin\trpm  audio/x-realaudio\t\tra    Should be replaced by:  audio/x-pn-realaudio\t\tram ra  audio/x-pn-realaudio-plugin\trpm  application/vnd.rn-realmedia    rm    Also completly unrelated I would suggest identifying rpms with  application/x-rpm, as in the linux package format, as it much more widely used  than plugins for realplayer.	Fixed in 2.1 and proposed for backport into the stable branches. (removed rpm completely).  Thanks for the report and thanks for using Apache.			Andr?? Malo
26390	null	CLOSED		giuliano carlini	1074905400000	1085504027000		LDAPTrustedCA inside VirtualHost LDAPTrustedCA inside of VirtualHost doesn't work. While it processed, as demonstrated by the debug log:      [Fri Jan 23 16:43:12 2004] [debug] util_ldap.c(1038): LDAP: SSL trusted certificate authority file - /usr/share/ssl/CA/certs/ca-bundle.cert.pem     [Fri Jan 23 16:43:12 2004] [debug] util_ldap.c(1054): LDAP: SSL trusted certificate authority file type - BASE64_FILE     ....     [Fri Jan 23 16:46:12 2004] [debug] mod_auth_ldap.c(829): LDAP: auth_ldap using SSL connections  It isn't used by the code in util_ldap_post_config()      [Fri Jan 23 16:46:12 2004] [notice] LDAP: Built with OpenLDAP LDAP SDK     [Fri Jan 23 16:46:12 2004] [notice] LDAP: SSL support unavailable  However, if the LDAPTrustedCA is moved outside of the VirtualHost to the global context, then it works.  My guess is that st->cert_auth_file is being copied from the global context rather than from the virtual host context.	At the moment, the LDAPTrustedCA directive is only valid in the global context.  OpenLDAP supports setting the CA certs per connection, but I am not sure whether the Netware, Microsoft or Netscape SDKs do. This won't be practical until more info can be found on the other SDKs.  Comment from dev@httpd.apache.org:  Brad Nicholes wrote: >    This is something that I have been wanting to do for sometime but > haven't given it much thought until now.  I talked to some of our Novell > LDAP engineers to get a better perspective on this.  According to them, > per-session certificates will not work in Novell LDAP and they also > believe that it doesn't work for Netscape or Microsoft either.  They > also had some concerns about OpenLDAP as well and although per-session > certificates appear to be supported, they weren't sure how well it > actually worked.   >   Just looking at the code in the util_ldap_post_config() routine and > how each of them set up the certificates, I wouldn't expect Netscape, > Novell or Microsoft SDK's to support per-session certificates.  The > Netscape SDK and the Novell SDK use the same function to initialize the > SSL libraries, but even though the current util_ldap code for Novell > isn't written this way, the Novell SDK allows the user to configure a > list of certificates rather than a single certificate by calling > ldapssl_add_trusted_cert().  The Netscape SDK probably allows for the > same thing through their CERT7 database file which is required.  The > Microsoft SDK appears to pull its certificate from the registry so I > have no idea if it even allows for multiple certificates.  All of these > methods appear to be global rather than per-session.   >   My feeling is that about the best we could do is to allow the > LDAPTrustedCA and LDAPTrustedCAType directives to be callable from > within a virtualhost configurtion and keep a list of certificates that > can then be passed to the LDAP libraries during the post_config.  But > this would really only make sense for OpenLDAP and Novell.  Since > Netscape requires a CERT7 database file, it wouldn't know how to handle > multiple files and these directives are NOOPs for Microsoft.  Then it > might lead the administrator to believe that certain virtual hosts are > using certain certificates when in fact that wouldn't be the case.  All > virtual hosts would use all specified certificates.  Resolved to keep these directives global in scope for now, commit a fix to v2.1.0-dev to throw an error if an attempt is made to place these directives inside virtualhosts.  Due to limitations in the LDAP libraries, CA cert settings are server wide. v2.1.0-dev and v2.0.50 will throw an error if an attempt is made to define these directives inside a virtualhost. 			Graham Leggett
26462	null	CLOSED		Jens Chr. Bachem	1075211340000	1093037073000		RewriteMap urlmap txt of same age get confused between vhosts I've got four vhosts using different txt RewriteMaps. All of them contain an entry with key '/' besides others which are unique. The maps are generated automatically. If the maps are of the same age (generation is very fast) the entries for '/' behave as configured round-robin. The effect disappears as soon as I slow down the map generation to get different timestamps for the map files.  Configfiles can be supplied if they are considered relevant.	Yep, your config would be of interest.  Thanks. (I've received the config via mail)  Sorry for the long delay.  However, the problem is, that you're using the same name for the maps, which confuses the rewritemap cache. The problem is fixed now in 2.1 and I'm going to propose it for backport into 2.0 and 1.3 branches.  I've uploaded a patch for 1.3 here: <http://www.apache.org/~nd/mod_rewrite-confusion-1.3.patch>.  Thanks for the report and thanks for using Apache. The fix will be in 1.3.32.			Andr?? Malo
26467	null	RESOLVED		Ben Collins-Sussman	1075222920000	1126863405000		, then hangs long-lived httpd children A graceful restart SIGTERMs the 'rotatelogs' child, but a long-lived httpd process may still be serving a connection via KeepAlive.  The httpd child continues to write logdata into the pipe, but there's no process reading from the pipe anymore.  Eventually the pipe fills up, and the httpd child just hangs.  This bug was discovered when doing a large Subversion commit with apache configured to use piped logging to 'rotatelogs'.  It's a pretty common setup, and it's likely to burn future Apache (and Subversion) users.  Joe Orton says, 'To fix this properly, I suppose piped loggers should not get SIGTERMedduring a graceful restart, they should read till EOF then exit(0): then when the last child attached to the piped logger for a particular generation quits, the pipe is closed and the piped logger terminates gracefully too, without losing log messages.'  Here's the complete mail thread:     http://www.mail-archive.com/dev%40httpd.apache.org/msg19247.html	I've been pouring over Google search results trying to figure out the cause of an extremely similar bug which seems to affect the 1.3.x branch of the Apache HTTP server also.  Has there been any movement on this issue.  Is it likely 1.3.x would also have this problem? Yes, this bug also affects 1.3. Created an attachment (id=15021) Kill hung child httpd procs  This little script (requires Proc::ProcessTable) is a hack to find child processes other than the root one that have been around since before the last rotatelogs process. Just in case it's useful to anyone else... can run from cron. > processes other than the root one that have been around since before the last > rotatelogs process.  Sorry... s/last/first/ FWIW, I'm playing with a patch to prevent the hang.  Hopefully I can commit to 2.1 this weekend.  Changing rotatelogs to snarf up all entries from these gracefully dying children would be nice, but first order of business is to prevent the hang occurring, since it can occur with any piped logger, and it shouldn't depend on how reliable the piped logger is.  I can't reproduce the hang when I take care to close the read side of the logger pipe in the MPM children (i.e., the processes which serve requests and which would write to the logger pipe).  I just posted a patch and further comments to dev@httpd.  [PATCH] PR 26467 child process can hang when piped logger goes away A fix to avoid the hang has been committed to 2.1-dev and hopefully will be in 2.0.next.  I stuck a patch for 1.3.x at http://people.apache.org/~trawick/pr26467_13.txt  This 1.3 patch appears to Do The Right Thing, but YYMV.  I haven't tested it in detail.  I have patched the version of Apache 1.3 I am running on two web servers that use piped loggers and I can already see that the symptoms of this problem are gone.  There are no hanging PIDs being leftover at all anymore.  I had a script that went through and killed the ones that were clearly hanging previously, and I've modified it to only tell me if any would be killed for hanging.  None have come up yet, which would certainly never happen in the past even for the short time I've been running with the patch.  This is certainly not proof that the 1.3 patch is perfect or that it doesn't cause any other problems, but it definitely does the right thing as best I can tell.  What's the chances something like this could land in 1.3.34? Regarding the 1.3 patch: Thanks for the feedback.  I need to make sure it does the right thing on non-Unix, then I'll add it to 1.3 STATUS file, asking for approval to commit for 1.3.next. On Unix, just looking at the processes with lsof it is easy to see that it is doing the right thing and there should be no worries.  The 2.x fix has now been merged into the stable 2.0.x branch for the upcoming 2.0.55 release.  The hang is now fixed for 2.0.55, so marking this fixed.  Avoiding the problem completely (i.e. not forcibly killing piped loggers at restart) is a slightly different issue. Can someone clarify this bug for me?  We'd been having a hang about every 2-14  days that started once we turned on the DisableWin32AcceptEx option.  We  noticed that the hang occurred after the child process restarted for whatever  reason.  Usually this was not triggered by a graceful restart, but  occasionally it was.  Meaning it would show up in the logs, but a person  didn't usually choose to do a restart, something else caused it.  We figured the build up of rotatelogs had something to do with the problem, as  there were a ton of rotatelogs.exe sitting in there.  I noticed this bug  mentioned in the 2.0.55 release and tried the upgrade.  We've been pretty  stable since.  It hung once during a graceful restart after 29 days, and has  been up for 26 days since.  I'm confident this bug was causing the hang, but still notice a tremendous  number of rotatelogs.exe.  After a fresh reboot, there are about 6  rotatelogs.exe is the process list.  After 26 days on Parent Server Generation  14, we have 40+ rotatelogs.exe sitting in the process list.  When we hang, there's no way to recover without rebooting Windows.  At least  not that I'm aware of.  Apache seems to hang, tying up the socket(s), and  stopping and starting apache fails.  My concern is the number of accumulating rotatelogs, and the fact that we  still hung after a month under similar circumstances during a graceful  restart.  Of course once a month is better than every couple of days.  I just  wanted to share what we have been experiencing with this bug, and it's  apparent patch, and see if anyone could clarify what we are experiencing, if  it is/was related to this bug, and why we still see so many rotatelogs. *** Bug 40041 has been marked as a duplicate of this bug. ***			Jeff Trawick	Joe Orton	Kevin Stange	Matthew Sullivan	Will Yardley
26552	null	CLOSED		Mathieu Fenniak	1075480440000	1075740001000		server/export_files is never deleted The file server/export_files is generated during the build process, but neither a 'make clean' nor a 'make distclean' will remove it.  export_files contains absolute path references, so if the httpd source files are moved the build process will give out warnings.	Try this patch.  The files which get created by 'make' will get removed by 'make clean', not some combination of 'make distclean' and 'make extraclean'.  Index: server/Makefile.in =================================================================== RCS file: /home/cvs/httpd-2.0/server/Makefile.in,v retrieving revision 1.88 diff -u -r1.88 Makefile.in --- server/Makefile.in\t9 Jan 2004 12:19:55 -0000\t1.88 +++ server/Makefile.in\t2 Feb 2004 14:10:10 -0000 @@ -1,8 +1,7 @@    CLEAN_TARGETS = gen_test_char test_char.h gen_uri_delims uri_delims.h / -\tApacheCoreOS2.def buildmarked.c -DISTCLEAN_TARGETS = httpd.exp -EXTRACLEAN_TARGETS = export_files exports.c export_vars.h +\tApacheCoreOS2.def buildmarked.c httpd.exp export_files / +\texports.c export_vars.h    SUBDIRS = mpm    The supplied patch fixes the problem. thanks for your quick test!   fix committed to 2.1-dev  once any review comments are resolved, I'll propose merging it into the stable branch for 2.0.next  *** Bug 29707 has been marked as a duplicate of this bug. ***			Jeff Trawick	Joe Orton	Mathieu Fenniak
26554	null	RESOLVED		Peter Watkins	1075480860000	1176119718000		ApacheBench: add ability to override User-Agent header I need to benchmark a site that sends different versions of content depending on the User-Agent presented by the HTTP client. In order to benchmark the site's performance for the different 'browser variations', I need the ability to send benchmark requests with different User-Agent request header values. I have put together a patch for ab.c that adds a '-U' command line argument for overrriding the default value. Also my patch modifies the '-h' behavior so that it not only explains the -U option, but shows the default User-Agent that is compiled into ab, e.g.      -U attribute    User-Agent value to send instead of 'ApacheBench/2.0.40-dev'  I hope this patch (to be attached after this ticket is created) will be considered for inclusion into the project.  Thank you.	Created an attachment (id=10162) patch for support/ab.c to provide requested capability  An alternate design: Don't build default User-Agent header field if User-Agent was specified via the existing command-line option -H.  Created an attachment (id=10188) Jeff Trawick's alternate logic (use -H)  Jeff, that certainly works (a quick read of RFC 1945 suggests that the User-Agent header can come later in the request message, so moving the User-Agent to after the Accept request header appears to be RFC-compliant), and I've attached another patch implementing this.   I think I prefer the -U plan though, as  * it's less fragile (strstr() is case-sensitive & the more users type, the greater chance of error)   * this general idea, whether implemented as -U or special handling of -H, requires the -h usage() information to be updated, and requires about the same amount of code changes (so there's not much 'economy' argument against -U)  * [weak argument] adding -U is backwards-compatible (doesn't alter the order of headers or change the behavior of -H in any situations)  But I'd be happy either way, as either approach gives users more flexibility.  Thanks.  comments/opinions from other developers would of course be appreciated ;)  I believe that my revised patch for  http://issues.apache.org/bugzilla/show_bug.cgi?id=31268 incorporates the fix this bug as well. Fixed in r526872. I went with Arvind's patch as a general fix for -H command-line switch behaviour.  Specify -H 'User-Agent: foobar/1.0' to ab to override the default User-Agent setting. 			Arvind Srinivasan	Jeff Trawick	Peter Watkins	Sander Temme
26562	null	CLOSED		Ken Avery	1075497540000	1083239401000		There appears to be a major memory leak in mod_ssl/OpenSSL I have been tracking this down for a couple of weeks and thought it was in the  code my company is developing and it appears that is not the case. In order to  eliminate our code from the mix and isolate the problem here is what I did:  This was done on Windows and Linux:  1. Download the latest Apache from www.apache.org.  2. Download the latest OpenSSL from www.openssl.org.  3. Build them both, with apache add the mod_ssl option and also for Linux use  the MPM worker module.  4. Install and modify the ssl.conf file ServerName value.  5. Run Apache (httpd)  6a. Run the Performance monitor on Windows and look at Private Bytes for the  second Apache process.  6b. On Linux run top -p pid(httpd1) -p pid(http2) ???.. -p pid(httpN) watching  the size of the processes  7. Set you browser to not cache requests and check for a new page every time.  8. Start fetching a page from https://localhost and keep refreshing the page.   So far 3 other engineers have reproduced this test because they did not believe  the problem could be in Apache mod_ssl/OpenSSL, they all verified that it leaks  like a sieve.  We were all trying to figure out why no one else has complained about such a  huge leak so we ran another test. We tried using the prefork MPM and it turns  out that worked fine. Based on the results it appears the OS is cleaning up  memory for the prefork module and the threaded model never gets its memory  freed. I have used a debugger on Windows and set break points on the  CRYPTO_malloc and CRYPTO_free functions and have seen gobs of memory  CRYPTO_malloc(ed) and not one time have I seen CRYPTO_free called. I was not  sure if having the OS cleanup memory was part of the design (if indeed that is  what is happening) or if there is potentially a problem in the OpenSSL memory  management code.  With all this said, I am by no means an expert on this code and could really  use some help understanding what is going on here? Any and all help is appreciated,  Ken	I posted two patches to fix memory leaks in issues 25659 and 25667.  I don't  know if they are directly related to what you are seeing but I haven't received  any feedback on whether anyone else has tried them out.  Let me knoe if you  think they may be related. David,  I tried both of the bug fixes you posted (25659, 25667) and they did not help,  I suspect the problem is related to the way threads handle memory verses  forked processes.  Ken FYI - I am seeing multiples of 8K chuncks of memroy disapear at a time. I  don't know if this helps? That would most likely be a heap bucket not being freed somewhere. I'm still unable to reproduce this on Linux.  Can you post the mod_ssl configuration you're using? Here is the ssl.conf file:  # # This is the Apache server configuration file providing SSL support. # It contains the configuration directives to instruct the server how to # serve pages over an https connection. For detailing information about these  # directives see <URL:http://httpd.apache.org/docs-2.0/mod/mod_ssl.html> # #   For the moment, see <URL:http://www.modssl.org/docs/> for this info.  #   The documents are still being prepared from material donated by the #   modssl project. #  # Do NOT simply read the instructions in here without understanding # what they do.  They're here only as hints or reminders.  If you are unsure # consult the online docs. You have been warned.   # <IfDefine SSL>  #   Until documentation is completed, please check http://www.modssl.org/ #   for additional config examples and module docmentation.  Directives #   and features of mod_ssl are largely unchanged from the mod_ssl project #   for Apache 1.3.  # # When we also provide SSL we have to listen to the  # standard HTTP port (see above) and to the HTTPS port # # Note: Configurations that use IPv6 but not IPv4-mapped addresses need two #       Listen directives: 'Listen [::]:443' and 'Listen 0.0.0.0:443' # Listen 443  ## ##  SSL Global Context ## ##  All SSL configuration in this context applies both to ##  the main server and all SSL-enabled virtual hosts. ##  # #   Some MIME-types for downloading Certificates and CRLs # AddType application/x-x509-ca-cert .crt AddType application/x-pkcs7-crl    .crl  #   Pass Phrase Dialog: #   Configure the pass phrase gathering process. #   The filtering dialog program ("builtin' is a internal #   terminal dialog) has to provide the pass phrase on stdout. SSLPassPhraseDialog  builtin  #   Inter-Process Session Cache: #   Configure the SSL Session Cache: First the mechanism  #   to use and second the expiring timeout (in seconds). #SSLSessionCache        none #SSLSessionCache        shmht:logs/ssl_scache(512000) #SSLSessionCache        shmcb:logs/ssl_scache(512000) SSLSessionCache         dbm:logs/ssl_scache SSLSessionCacheTimeout  300  #   Semaphore: #   Configure the path to the mutual exclusion semaphore the #   SSL engine uses internally for inter-process synchronization.  SSLMutex  file:logs/ssl_mutex  #   Pseudo Random Number Generator (PRNG): #   Configure one or more sources to seed the PRNG of the  #   SSL library. The seed data should be of good random quality. #   WARNING! On some platforms /dev/random blocks if not enough entropy #   is available. This means you then cannot use the /dev/random device #   because it would lead to very long connection times (as long as #   it requires to make more entropy available). But usually those #   platforms additionally provide a /dev/urandom device which doesn't #   block. So, if available, use this one instead. Read the mod_ssl User #   Manual for more details. SSLRandomSeed startup builtin SSLRandomSeed connect builtin #SSLRandomSeed startup file:/dev/random  512 #SSLRandomSeed startup file:/dev/urandom 512 #SSLRandomSeed connect file:/dev/random  512 #SSLRandomSeed connect file:/dev/urandom 512  ## ## SSL Virtual Host Context ##  <VirtualHost _default_:443>  #  General setup for the virtual host DocumentRoot '/Apache2/htdocs' ServerName new.host.name:443 ServerAdmin you@your.address ErrorLog logs/error_log TransferLog logs/access_log  #   SSL Engine Switch: #   Enable/Disable SSL for this virtual host. SSLEngine on  #   SSL Cipher Suite: #   List the ciphers that the client is permitted to negotiate. #   See the mod_ssl documentation for a complete list. SSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL  #   Server Certificate: #   Point SSLCertificateFile at a PEM encoded certificate.  If #   the certificate is encrypted, then you will be prompted for a #   pass phrase.  Note that a kill -HUP will prompt again.  Keep #   in mind that if you have both an RSA and a DSA certificate you #   can configure both in parallel (to also allow the use of DSA #   ciphers, etc.) SSLCertificateFile /Apache2/conf/ssl.crt/server.crt #SSLCertificateFile /Apache2/conf/ssl.crt/server-dsa.crt  #   Server Private Key: #   If the key is not combined with the certificate, use this #   directive to point at the key file.  Keep in mind that if #   you've both a RSA and a DSA private key you can configure #   both in parallel (to also allow the use of DSA ciphers, etc.) SSLCertificateKeyFile /Apache2/conf/ssl.key/server.key #SSLCertificateKeyFile /Apache2/conf/ssl.key/server-dsa.key  #   Server Certificate Chain: #   Point SSLCertificateChainFile at a file containing the #   concatenation of PEM encoded CA certificates which form the #   certificate chain for the server certificate. Alternatively #   the referenced file can be the same as SSLCertificateFile #   when the CA certificates are directly appended to the server #   certificate for convinience. #SSLCertificateChainFile /Apache2/conf/ssl.crt/ca.crt  #   Certificate Authority (CA): #   Set the CA certificate verification path where to find CA #   certificates for client authentication or alternatively one #   huge file containing all of them (file must be PEM encoded) #   Note: Inside SSLCACertificatePath you need hash symlinks #         to point to the certificate files. Use the provided #         Makefile to update the hash symlinks after changes. #SSLCACertificatePath /Apache2/conf/ssl.crt #SSLCACertificateFile /Apache2/conf/ssl.crt/ca-bundle.crt  #   Certificate Revocation Lists (CRL): #   Set the CA revocation path where to find CA CRLs for client #   authentication or alternatively one huge file containing all #   of them (file must be PEM encoded) #   Note: Inside SSLCARevocationPath you need hash symlinks #         to point to the certificate files. Use the provided #         Makefile to update the hash symlinks after changes. #SSLCARevocationPath /Apache2/conf/ssl.crl #SSLCARevocationFile /Apache2/conf/ssl.crl/ca-bundle.crl  #   Client Authentication (Type): #   Client certificate verification type and depth.  Types are #   none, optional, require and optional_no_ca.  Depth is a #   number which specifies how deeply to verify the certificate #   issuer chain before deciding the certificate is not valid. #SSLVerifyClient require #SSLVerifyDepth  10  #   Access Control: #   With SSLRequire you can do per-directory access control based #   on arbitrary complex boolean expressions containing server #   variable checks and other lookup directives.  The syntax is a #   mixture between C and Perl.  See the mod_ssl documentation #   for more details. #<Location /> #SSLRequire (    %{SSL_CIPHER} !~ m/^(EXP|NULL)/ / #            and %{SSL_CLIENT_S_DN_O} eq 'Snake Oil, Ltd.' / #            and %{SSL_CLIENT_S_DN_OU} in {'Staff', 'CA', 'Dev'} / #            and %{TIME_WDAY} >= 1 and %{TIME_WDAY} <= 5 / #            and %{TIME_HOUR} >= 8 and %{TIME_HOUR} <= 20       ) / #           or %{REMOTE_ADDR} =~ m/^192/.76/.162/.[0-9]+$/ #</Location>  #   SSL Engine Options: #   Set various options for the SSL engine. #   o FakeBasicAuth: #     Translate the client X.509 into a Basic Authorisation.  This means that #     the standard Auth/DBMAuth methods can be used for access control.  The #     user name is the "one line' version of the client's X.509 certificate. #     Note that no password is obtained from the user. Every entry in the user #     file needs this password: "xxj31ZMTZzkVA'. #   o ExportCertData: #     This exports two additional environment variables: SSL_CLIENT_CERT and #     SSL_SERVER_CERT. These contain the PEM-encoded certificates of the #     server (always existing) and the client (only existing when client #     authentication is used). This can be used to import the certificates #     into CGI scripts. #   o StdEnvVars: #     This exports the standard SSL/TLS related "SSL_*' environment variables. #     Per default this exportation is switched off for performance reasons, #     because the extraction step is an expensive operation and is usually #     useless for serving static content. So one usually enables the #     exportation for CGI and SSI requests only. #   o CompatEnvVars: #     This exports obsolete environment variables for backward compatibility #     to Apache-SSL 1.x, mod_ssl 2.0.x, Sioux 1.0 and Stronghold 2.x. Use this #     to provide compatibility to existing CGI scripts. #   o StrictRequire: #     This denies access when 'SSLRequireSSL' or 'SSLRequire' applied even #     under a 'Satisfy any' situation, i.e. when it applies access is denied #     and no other module can change it. #   o OptRenegotiate: #     This enables optimized SSL connection renegotiation handling when SSL #     directives are used in per-directory context.  #SSLOptions +FakeBasicAuth +ExportCertData +CompatEnvVars +StrictRequire <Files ~ '/.(cgi|shtml|phtml|php3?)$'>     SSLOptions +StdEnvVars </Files> <Directory '/Apache2/cgi-bin'>     SSLOptions +StdEnvVars </Directory>  #   SSL Protocol Adjustments: #   The safe and default but still SSL/TLS standard compliant shutdown #   approach is that mod_ssl sends the close notify alert but doesn't wait for #   the close notify alert from client. When you need a different shutdown #   approach you can use one of the following variables: #   o ssl-unclean-shutdown: #     This forces an unclean shutdown when the connection is closed, i.e. no #     SSL close notify alert is send or allowed to received.  This violates #     the SSL/TLS standard but is needed for some brain-dead browsers. Use #     this when you receive I/O errors because of the standard approach where #     mod_ssl sends the close notify alert. #   o ssl-accurate-shutdown: #     This forces an accurate shutdown when the connection is closed, i.e. a #     SSL close notify alert is send and mod_ssl waits for the close notify #     alert of the client. This is 100% SSL/TLS standard compliant, but in #     practice often causes hanging connections with brain-dead browsers. Use #     this only for browsers where you know that their SSL implementation #     works correctly.  #   Notice: Most problems of broken clients are also related to the HTTP #   keep-alive facility, so you usually additionally want to disable #   keep-alive for those clients, too. Use variable 'nokeepalive' for this. #   Similarly, one has to force some clients to use HTTP/1.0 to workaround #   their broken HTTP/1.1 implementation. Use variables 'downgrade-1.0' and #   'force-response-1.0' for this. SetEnvIf User-Agent '.*MSIE.*' /          nokeepalive ssl-unclean-shutdown /          downgrade-1.0 force-response-1.0  #   Per-Server Logging: #   The home of a custom SSL log file. Use this when you want a #   compact non-error SSL logfile on a virtual host basis. CustomLog logs/ssl_request_log /           '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b'  </VirtualHost>                                    </IfDefine>   BTW - Check your log file to see if there is a SIGNAL 11 SEGFAULT that will  cause Apache to restart the threads and make it appear that everything is OK. Here is some more info from on our Linux Heads:  While attempting to locate the cause for what appears to be a memory  consumption problem in the SSL code, the server segmentation faults. The first  worker child & all of its child threads continue to consume memory while the  parent stays the same or gets a little smaller.  The child threads never give  the memory back unless restarted.  Please advise if this is an expected  behavior.  Running with 'SSLSessionCache none' doesn't consume memory (and doesn't seg  fault), but it performs poorly when using 2048 bit keys.  I observed the segmentation fault issue in mod_ssl while running the small  script listed below.  Based on the stack information the issue appears to be  in shmcb_cton_memcpy() during an attempt to remove a session id.  The server  keeps on reponding, but all the child threads die and are restarted. I am not  sure what is happening, but the following variables seem to get corrupted:  The stack trace shows these are supposed to be:  src_offset=6402  src_len=10240  Inside the frame they have these values:  (gdb) print src_offset (in edi register) $55 = 3183473748   (gdb) print src_len    (in edx register)  $56 = 3183464512  The configuration file, and my initial debug session are attached.  Apache error_log ... [Mon Mar 15 11:21:33 2004] [notice] Apache/2.0.48 configured -- resuming  normal operations [Mon Mar 15 11:25:28 2004] [error] server reached MaxClients  setting, consider raising the MaxClients setting [Mon Mar 15 11:38:29 2004]  [notice] child pid 1065 exit signal Segmentation fault (11) [Mon Mar 15  12:06:28 2004] [notice] child pid 1154 exit signal Segmentation fault (11)  [Mon Mar 15 12:44:49 2004] [notice] child pid 1258 exit signal Segmentation  fault (11) [Mon Mar 15 13:04:40 2004] [notice] child pid 1315 exit signal  Segmentation fault (11) [Mon Mar 15 13:17:29 2004] [notice] child pid 1363  exit signal Segmentation fault (11) [Mon Mar 15 13:45:12 2004] [notice] child  pid 1401 exit signal Segmentation fault (11) ...  OS RedHat 7.3   gcc-2.96-113 glibc-2.2.5-43 openssl-0.9.6b-35.7  Apache 2.0.48 Build Script:  ./configure  --with-program-name=leakd --with-port=9200 --with-mpm=worker -- enable-ssl=shared --enable-maintainer-mode / --enable-proxy=shared --enable- cgi=shared --enable-setenvif=shared --enable-cgi=shared --enable-access=shared  / --enable-rewrite=shared --enable-dir=shared --enable-actions=shared --enable- mime=shared --enable-proxy_connect=shared / --enable-proxy_http=shared -- enable-negotiation=shared --enable-alias=shared --enable-env=shared --enable- dir=shared / --enable-mod-actions=shared --enable-log-config=shared --enable- imap=shared --enable-headers=shared / --enable-layout=webserver --disable- autoindex --disable-userdir --disable-usertrack --disable-cgid / --disable- asis --disable-auth --disable-auth_digest --disable-auth_dbm --disable- auth_anon --disable-dav / --disable-dav_fs --disable-vhost_alias --disable- unique_id --disable-speling --disable-cern_meta --disable-include / --disable- expires --enable-status=shared --enable-info=shared  ldd leakd:          libssl.so.2 => /lib/libssl.so.2 (0x40024000)         libcrypto.so.2 => /lib/libcrypto.so.2 (0x40052000)         libaprutil-0.so.0 => /usr/webserver/lib/libaprutil-0.so.0 (0x40119000)         libgdbm.so.2 => /usr/lib/libgdbm.so.2 (0x4012d000)         libdb-3.3.so => /lib/libdb-3.3.so (0x40133000)         libexpat.so.0 => /usr/lib/libexpat.so.0 (0x401c2000)         libapr-0.so.0 => /usr/webserver/lib/libapr-0.so.0 (0x401e1000)         libpthread.so.0 => /lib/libpthread.so.0 (0x40200000)         librt.so.1 => /lib/librt.so.1 (0x40215000)         libm.so.6 => /lib/libm.so.6 (0x40226000)         libcrypt.so.1 => /lib/libcrypt.so.1 (0x40247000)         libnsl.so.1 => /lib/libnsl.so.1 (0x40274000)         libdl.so.2 => /lib/libdl.so.2 (0x40288000)         libc.so.6 => /lib/libc.so.6 (0x4028c000)         /lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)   Simple script on external machine downloads copies of the stock Apache  index.html.en page under both unsecure & secure sites:  #!/bin/sh counter=0 limit=32000 while [ '$counter' -lt '$limit' ] do   wget -O - http://myboxaddr:9200   wget -O - https://myboxaddr:9201   counter="expr $counter + 1"   echo 'Count=> $counter' done  Hmmm, haven't seen shmcb segfaults in a while.  Tried any different SSLMutex settings, e.g. 'SSLMutex default'?  Can you file a separate bug on that, and include the backtrace for the shmcb segfaults.  After tagging memory and running tests over the weekend it appears that calls  to OPENSSL_malloc in the following files failed to release memory by calling  the corresponding OPENSSL_free:  bn_bind.c - 494,788 outstanding OPENSSL_malloc bn_lib.c  - 123,673 outstanding OPENSSL_malloc  I am not sure how this relates to the Apache/mod_ssl threaded MPMs; though, it  does appear to be a problem.  Any ideas? I have narrowed it down to the function BN_BLINDING_new in the file  crypto/bn/bn_blind.c, the memory allocated for the BN_BLINDING structure never  gets freed. I am assuming that the BIGNUM structures allocated with BN_new  inside of BN_BLINDING never gets freed also.  Here are my test results after running 24 hours monitoring the OPENSSL_malloc  and OPENSSL_free calls:  1. BN_BLINDING ??? allocations 53,615, frees 0, outstanding 53,615  2. BN_new ??? allocations 8,347,200, frees 8,127,872 outstanding 219,328  3. I also track the heap and it grows proportional to the lack of BN frees The patches released to enable RSA blinding in OpenSSL initially had thread-safety issues; the fixes for those issues may well have introduced leaks...  Try reproducing using a vanilla OpenSSL 0.9.6m release: if it's still a problem, report the bug back at openssl.org.  It seems unlikely this is a mod_ssl issue now, agreed?    The blinging leak is fixed in OpenSSL 0.9.7d - mod_ssl still has a huge leak in  the threaded MPMs using session caching Can you try the following patch ? It seems to fix the mem leak on HP-UX atleast :)  RCS file: /home/cvs/httpd-2.0/modules/ssl/ssl_engine_init.c,v retrieving revision 1.126 diff -u -r1.126 ssl_engine_init.c --- ssl_engine_init.c   5 Mar 2004 02:44:40 -0000       1.126 +++ ssl_engine_init.c   25 Mar 2004 23:27:02 -0000 @@ -450,7 +450,7 @@           * to ignore process local-caching and           * to always get/set/delete sessions using mod_ssl's callbacks.           */ -        cache_mode = SSL_SESS_CACHE_SERVER|SSL_SESS_CACHE_NO_INTERNAL_LOOKUP; +        cache_mode = SSL_SESS_CACHE_SERVER|SSL_SESS_CACHE_NO_INTERNAL;      }        SSL_CTX_set_session_cache_mode(ctx, cache_mode);  Is this fixed in CVS or not? If not, it's not fixed. Yes, this is fixed in HEAD and for 2.0.50. Thanks.			Andr?? Malo	Cliff Woolley	David Blake	Joe Orton	Ken Avery	Madhusudan Mathihalli
26602	null	CLOSED		Martin Horak	1075731420000	1093040785000		t allow relative path in LDAPTrustedCA directive util_ldap doesn't allow path relative to ServerRoot in LDAPTrustedCA directive	At the moment, the path is passed as is to the SDK functions directly, without being modified at all. For this to work, util_ldap would have to resolve the relative link against ServerRoot before passing the filename.  I have replace the call to apr_pstrdup() with ap_server_root_relative() which  should allow relative paths to be resolved against ServerRoot.  It has also  been proposed for backport. Patch has been backported to the 2.0 branch This does not appear to be fixed as of 2.0.49. When using a relative path to ServerRoot in the httpd.conf file it did not throw any errors or give any indication in the logs that it was not parsing the file. On the contrary it seemed to indicate all was well. I have posted the out put in another bug (possible dup?) #22711 This was broken in 2.0.49.  The fix wasn't back ported until 2.0.50 *** Bug 22711 has been marked as a duplicate of this bug. ***			Brad Nicholes	Graham Leggett	gregaryh@juno.com
26767	null	CLOSED		Thomas Carrie	1076243700000	1077389915000		Broken internal link in CGi tutorial View source from the URL above, look for 'configuringapachetopermitcgi', this anchor is undefined	Fixed.  Thanks for your care and thanks for using Apache.			Andr?? Malo
27106	null	CLOSED		Mick Wall	1077276120000	1077706541000		Possible memory leak when accessing SSL port with plain HTTP I was running some tests with apachebench to get some performance timings, I  inadvertantly gave a URL that was SSL enabled but with a http:// prefix.  If I  do this from a browser I get the message   Your browser sent a request that this server could not understand. Reason: You're speaking plain HTTP to an SSL-enabled server port. Instead use the HTTPS scheme to access this URL, please.   I was watching the memory footprint of httpd while doing this, and it grows  RAPIDLY!,  here is a trace, dumped every 5 seconds     40001 A   nsuser  48354  17728 104  60 20 3d144  6556        *  11:10:29      -  0:01 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  79  60 20 3d144 171528        *  11:10:29      -  0:06 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  76  60 20 3d144 418664        *  11:10:29      -  0:10 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728   2  60 20 3d144 630156        *  11:10:29      -  0:14 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728   0  60 20 3d144 630156        *  11:10:29      -  0:14 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728   0  60 20 3d144 630156        *  11:10:29      -  0:14 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728   0  60 20 3d144 630156        *  11:10:29      -  0:14 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  23  60 20 3d144 631532        *  11:10:29      -  0:14 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728 118  60 20 3d144 643608        *  11:10:29      -  0:21 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  13  60 20 3d144 649964        *  11:10:29      -  0:28 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  32  60 20 3d144 656148        *  11:10:29      -  0:34 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  52  60 20 3d144 662140        *  11:10:29      -  0:41 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  75  60 20 3d144 668276        *  11:10:29      -  0:48 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728 109  60 20 3d144 674340        *  11:10:29      -  0:54 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728 131  60 20 3d144 680632        *  11:10:29      -  1:01 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  18  60 20 3d144 686904        *  11:10:29      -  1:08 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  43  60 20 3d144 693064        *  11:10:29      -  1:14 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  73  60 20 3d144 699364        *  11:10:29      -  1:21 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  92  60 20 3d144 705672        *  11:10:29      -  1:28 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728 110  60 20 3d144 711836        *  11:10:29      -  1:34 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  12  60 20 3d144 718044        *  11:10:29      -  1:41 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  36  60 20 3d144 724340        *  11:10:29      -  1:48 lt-httpd -k start -DSSL    40001 A   nsuser  48354  17728  57  60 20 3d144 730148        *    Shortly after this the process crashed.  Regards  Mick	Ouch! Thanks for the report, the fix is here:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.117&r2=1.118  this change will be proposed for inclusion in the next 2.0 release. The Common Vulnerabilities and Exposures project (cve.mitre.org) has assigned the name CAN-2004-0113 to this issue. There was a minor bug in the patch posted previously; the better fix is below:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.100.2.11&r2=1.100.2.12 adfgsdfg			Joe Orton	Mark Cox	zedis
27189	null	CLOSED		Steve Reppucci	1077635040000	1095860334000		Specifying ScoreBoardFile causes exit in 2.0.48 Specifying a ScoreBoardFile causes apache to exit with the following in the error_log:  [Tue Feb 24 09:09:01 2004] [crit] (17)File exists: unable to create scoreboard '/usr/local/apache2/logs/apache_runtime_status' (name-based shared memory failure)  The relevant section from my httpd.conf:   <IfModule !perchild.c>     ScoreBoardFile logs/apache_runtime_status   </IfModule>   Looking at server/scoreboard.c, there's a comment:     /* The shared memory file must not exist before we create the      * segment. */  The scoreboard file has definitely been created at this point though -- I tried deleting it just before starting the server, and the crash still occurs, with a new scoreboard in logs/apache_runtime_status.  If I comment out the 'ScoreBoardFile' directive, the server starts fine, and no scoreboard file is created (as expected).   Info from my build:  # cd /usr/local/apache2 # ./bin/httpd -V Server version: Apache/2.0.48 Server built:   Feb 19 2004 11:07:53 Server's Module Magic Number: 20020903:4 Architecture:   32-bit Server compiled with....  -D APACHE_MPM_DIR='server/mpm/prefork'  -D APR_HAS_SENDFILE  -D APR_HAS_MMAP  -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)  -D APR_USE_SYSVSEM_SERIALIZE  -D APR_USE_PTHREAD_SERIALIZE  -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT  -D APR_HAS_OTHER_CHILD  -D AP_HAVE_RELIABLE_PIPED_LOGS  -D HTTPD_ROOT='/usr/local/apache2'  -D SUEXEC_BIN='/usr/local/apache2/bin/suexec'  -D DEFAULT_PIDLOG='logs/httpd.pid'  -D DEFAULT_SCOREBOARD='logs/apache_runtime_status'  -D DEFAULT_LOCKFILE='logs/accept.lock'  -D DEFAULT_ERRORLOG='logs/error_log'  -D AP_TYPES_CONFIG_FILE='conf/mime.types'  -D SERVER_CONFIG_FILE='conf/httpd.conf' # ./bin/httpd -l Compiled in modules:   core.c   mod_access.c   mod_auth.c   mod_auth_digest.c   mod_include.c   mod_log_config.c   mod_env.c   mod_setenvif.c   mod_ssl.c   prefork.c   http_core.c   mod_mime.c   mod_dav.c   mod_status.c   mod_autoindex.c   mod_asis.c   mod_cgi.c   mod_dav_fs.c   mod_dir.c   mod_actions.c   mod_userdir.c   mod_alias.c   mod_rewrite.c   mod_so.c	Thanks for the report.  The simple solution is 'don't use ScoreBoardFile, it is completely unnecessary'.   A fix for this is in HEAD, nonetheless.			Joe Orton
27271	null	CLOSED		Michael Grossniklaus	1077831300000	1098712207000		mod_auth_ldap on active directory fail after entering false credentials I'm running Apache/2.0.48 (Win32) with mod_ssl/2.0.48 and OpenSSL/0.9.7c on a  Windows 2000 Advanced Server SP4. I've configured the mod_auth_ldap that came  with the Apache distribution to validate user accounts against my ADS.  Therefore I've included the following lines into my httpd.conf:  LoadModule auth_ldap_module modules/mod_auth_ldap.so LoadModule ldap_module  modules/util_ldap.so  and  <Directory 'C:/Program Files/Apache Group/Apache2/htdocs'> Options Indexes  FollowSymLinks AllowOverride None Order allow,deny Allow from all  AuthName 'Global Information Systems Domain' AuthType Basic AuthLDAPUrl 'ldap://localhost/dc=globis,dc=infk,dc=d,dc=ethz,dc=ch? sAMAccountName?sub?(objectCategory=Person)(objectClass=User)' AuthLDAPBindDN 'cn=LDAPUser,cn=Users,dc=globis,dc=infk,dc=d,dc=ethz,dc=ch' AuthLDAPBindPassword '*********' require valid-user </Directory>  Now, the problem is REALLY strange! As long as the users enter their  credentials correctly, everything works perfectly... But (and it's a big BUT)  as soon someone enters a wrong user/password, the validation always fails from  any machine and browser until the Apache service is restarted...  The following warning is logged in the 'error_log' file once: [Thu Feb 26 21:37:13 2004] [warn] [client 129.132.13.8] [6884] auth_ldap  authenticate: user abc authentication failed; URI / [ldap_simple_bind_s() to check user credentials failed][Invalid Credentials]  Every subsequent attempt to log in produces the following error: [Thu Feb 26 21:37:37 2004] [warn] [client 129.132.13.8] [6884] auth_ldap  authenticate: user abc authentication failed; URI / [User not found][No Such  Object] [Thu Feb 26 21:38:39 2004] [warn] [client 129.132.13.28] [6884]  auth_ldap authenticate: user xyz authentication failed; URI / [User not found] [No Such Object]	Created an attachment (id=10575) Apache Configuration File  Could it be a caching problem of mod_ldap? You have answered the question yourself. When a user enter wrong credentials, the cached connection is seen by the ldap server as an anonymous connection and by the  cache of ldap_util as a bind connection to 'cn=LDAPUser...', so it is reused for other authentication connection without success since anonymous connection has no access to an Active Directory users list. See bug 27134 for details and a patch to try. Let us known if you succeed with that patch. Please try the patch at http://nagoya.apache.org/bugzilla/show_bug.cgi?id=27748 and tell me if it fixes this problem. This patch has been applied to v2.1.0-dev, and awaits backporting to v2.0.50-dev.  Is this bug still present, or can I close it?  Graham,  I think this was fixed in 2.0.50. I just tested with 2.0.52 and password prompting works like it should. Will close - thanks for confirming this for me! 			Denis Gervalle	Graham Leggett	Jari Ahonen	Michael Grossniklaus
27313	null	CLOSED		Alexis Huxley	1077987120000	1078584874000		 on non-IPv6 system This complete report, without the line breaks inserted by the bugzilla  interface, together with the httpd.conf can be found at the following URL until mid-march; then I'll remove it. Hopefully that gives enough time for someone with the capability to download it and replace this report text with it. http://dione.no-ip.org/~alexis/ticking.txt  This is a summary of a bug reported on the dev mailing list this month.  See http://www.mail-archive.com/dev@httpd.apache.org/msg19720.html for the full thread.  Ok, first, what I'm running:  \tApache/2.1.0-dev (Unix) DAV/2 SVN/0.36.0+  More specifically, I got and compiled Apache2 from CVS on:  \tdione:/usr/server/opt/apache2/bin# ls -l httpd \t-rwxr-xr-x    1 root     root      3221030 Jan 15 18:01 httpd \tdione:/usr/server/opt/apache2/bin#   The OS is:  \tLinux dione 2.4.16 #1 Sat Mar 9 19:04:14 CET 2002 i686 GNU/Linux  Now the problem description:  The problem I am reporting here seems to have been in since Apache 2.0.47 or 2.0.48.   About once every three weeks it happens that the hard disk of the machine where I run apache2 starts audibly 'ticking' - i.e. it starts making some sort of non-cached access (maybe the log writing below?) at a rate of once per second.  Actually, recently it seems to be happening every couple of days.  The server could still serve other pages without problem, so there was no DoS.  Now what I investigated:  The first few times it happened I rebooted, assuming the disk or controller had got its knickers in a twist. The next times I shutdown all of the locally added init.d scripts which fixed it. The next time I shut down half of those init.d scripts which worked. Next time half of that half, and so on until eventually I traced it down to the httpd daemon, which was yesterday!   I checked the apache logs and I see this in error_log:          [Mon Feb 16 23:35:33 2004] [warn] (97)Address family not supported by protocol: get socket to connect to listener         [Mon Feb 16 23:35:34 2004] [warn] (97)Address family not supported by protocol: get socket to connect to listener         [Mon Feb 16 23:35:35 2004] [warn] (97)Address family not supported by protocol: get socket to connect to listener         [Mon Feb 16 23:35:36 2004] [warn] (97)Address family not supported by protocol: get socket to connect to listener         [Mon Feb 16 23:35:37 2004] [warn] (97)Address family not supported by protocol: get socket to connect to listener \t....   It goes on until I restart httpd.  I wondered if some access had triggered it so I checked the access_log and immediately before 23:35:33 I have the following (sorry for very long lines!):          cache-mtc-aa06.proxy.aol.com - - [16/Feb/2004:23:35:16 +0100] 'GET /~alexis/STABLE/hiking/tegernschlier/ HTTP/1.0' 200 8755 'http://www.google.com/search?q=Schliersee&hl=en&lr=&ie=UTF-8&start=310&sa=N'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ak04.proxy.aol.com - - [16/Feb/2004:23:35:18 +0100] 'GET /~alexis/STABLE/css/standard.css HTTP/1.0' 200 5017 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ab10.proxy.aol.com - - [16/Feb/2004:23:35:21 +0100] 'GET /~alexis/STABLE/images/d_arrow_7rows.gif HTTP/1.0' 200 242 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ab10.proxy.aol.com - - [16/Feb/2004:23:35:21 +0100] 'GET /~alexis/STABLE/images/d_arrow_2rows.gif HTTP/1.1' 200 111 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-aa08.proxy.aol.com - - [16/Feb/2004:23:35:21 +0100] 'GET /~alexis/STABLE/hiking/tegernschlier/images/tn-map.jpg HTTP/1.0' 200 3005 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ad09.proxy.aol.com - - [16/Feb/2004:23:35:21 +0100] 'GET /~alexis/STABLE/hiking/tegernschlier/images/tn-5_20021110-0981_de-gindelalmschneid-tegernsee_michael-light-snow.jpg HTTP/1.0' 200 2279 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ad14.proxy.aol.com - - [16/Feb/2004:23:35:22 +0100] 'GET /~alexis/STABLE/hiking/tegernschlier/images/tn-5_20021110-0982_de-gindelalmschneid-tegernsee_michael-medium-snow.jpg HTTP/1.0' 200 1478 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ad08.proxy.aol.com - - [16/Feb/2004:23:35:22 +0100] 'GET /~alexis/STABLE/hiking/tegernschlier/images/tn-5_20021110-0985_de-gindelalmschneid-gindelalm_michael-heavy-snow.jpg HTTP/1.0' 200 1487 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ad13.proxy.aol.com - - [16/Feb/2004:23:35:23 +0100] 'GET /~alexis/STABLE/hiking/tegernschlier/images/tn-5_20021110-0987_de-gindelalmschneid-au_sunny-lake.jpg HTTP/1.0' 200 2571 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ac08.proxy.aol.com - - [16/Feb/2004:23:35:25 +0100] 'GET /~alexis/STABLE/hiking/tegernschlier/images/tn-5_20021110-0989_de-gindelalmschneid-schwaig_view-of-schliersee.jpg HTTP/1.0' 200 2011 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ab01.proxy.aol.com - - [16/Feb/2004:23:35:27 +0100] 'GET /~alexis/STABLE/images/valid-html401.png HTTP/1.0' 200 2948 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ah02.proxy.aol.com - - [16/Feb/2004:23:35:27 +0100] 'GET /~alexis/STABLE/images/vcss.png HTTP/1.0' 200 1134 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'         cache-mtc-ac02.proxy.aol.com - - [16/Feb/2004:23:35:27 +0100] 'GET /~alexis/STABLE/hiking/tegernschlier/images/tn-5_20021110-0991_de-gindelalmschneid-schliersee_lake-view-east.jpg HTTP/1.0' 200 2084 'http://dione.no-ip.org/~alexis/STABLE/hiking/tegernschlier/'; 'Mozilla/4.0 (compatible; MSIE 6.0; AOL 8.0; Windows 98)'  The pages on this host get hit only a dozen times per hour, so two accesses with only ten seconds between them (I mean the last thing in access_log and the first in error_log) probably are caused by the same client.  A few days later the same thing. Here is what preceded it:          cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:26 +0100] 'GET /~alexis/STABLE/hiking/wank/images/tn-5_20030525-1261_de-wank-panorama_logging-and-lift.jpg HTTP/1.1' 200 3345 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:27 +0100] 'GET /~alexis/STABLE/hiking/wank/images/tn-5_20030525-1268_de-wank-eckenberg_cloud-lars-paola.jpg HTTP/1.1' 200 1608 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:27 +0100] 'GET /~alexis/STABLE/hiking/wank/images/tn-5_20030525-1265_de-wank-eckenberg_steps-lars-paola-karin.jpg HTTP/1.1' 200 2787 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:26 +0100] 'GET /~alexis/STABLE/hiking/wank/images/tn-map.jpg HTTP/1.1' 200 2714 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:26 +0100] 'GET /~alexis/STABLE/hiking/wank/images/tn-5_20030525-1264_de-wank_karin-paola-lars.jpg HTTP/1.1' 200 2220 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:26 +0100] 'GET /~alexis/STABLE/images/d_arrow_7rows.gif HTTP/1.1' 200 242 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:26 +0100] 'GET /~alexis/STABLE/images/d_arrow_2rows.gif HTTP/1.1' 200 111 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:27 +0100] 'GET /~alexis/STABLE/hiking/wank/images/tn-5_20030525-1272_de-wank-eckenberg_view-of-hoher-fricken-bischof-krottenkopf.jpg HTTP/1.1' 200 2470 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:27 +0100] 'GET /~alexis/STABLE/hiking/wank/images/tn-5_20030525-1270_de-wank-eckenberg_view-of-esterberg-alm.jpg HTTP/1.1' 200 2171 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:27 +0100] 'GET /~alexis/STABLE/hiking/wank/images/tn-5_20030525-1274_de-wank-saddle_eckenberg.jpg HTTP/1.1' 200 1756 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:27 +0100] 'GET /~alexis/STABLE/hiking/wank/images/tn-5_20030525-1277_de-wank-saddle_ameisberg.jpg HTTP/1.1' 200 2931 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:27 +0100] 'GET /~alexis/STABLE/images/valid-html401.png HTTP/1.1' 200 2948 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:27 +0100] 'GET /~alexis/STABLE/images/vcss.png HTTP/1.1' 200 1134 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:25 +0100] 'GET /~alexis/STABLE/hiking/wank/ HTTP/1.0' 200 9304 'XXXX:++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'         cache6-midd.server.ntli.net - - [20/Feb/2004:21:27:30 +0100] 'GET /~alexis/STABLE/css/standard.css HTTP/1.1' 200 5017 'http://dione.no-ip.org/~alexis/STABLE/hiking/wank/'; 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; Hotbar 4.3.5.0; .NET CLR 1.0.3705)'  Now, what I got asked on the mailing list:  > OK, what platform are you on, what Listen directives are you using, and > are you using IPv6 on the box at all?  It would be useful to run 'strace > -p' on the pid of the parent once the server gets into this state.  I checked for IPv6 as follows:  > > \tdione$ telnet ::1  > > \tTrying ::1... > > \ttelnet: Unable to connect to remote host: Address family not supported by protocol  Ther is only one 'Listen' directive:  \tdione:/usr/server/opt/apache2/bin# grep ^[^#]*Listen ../conf/httpd.conf \tListen 80 \tdione:/usr/server/opt/apache2/bin#   'strace -p' on the parent httpd, when it gets in this state, reports:          Script started on Wed Feb 25 22:17:44 2004         dione:/tmp# ps fax | grep httpd          2141 pts/7    S      0:00                      /_ grep httpd          1008 ?        S      0:00 /usr/server/opt/apache2/bin/httpd -k start          1009 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1010 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1011 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1012 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1013 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1059 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1060 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1080 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1081 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1082 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start          1332 ?        S      0:00  /_ /usr/server/opt/apache2/bin/httpd -k start         dione:/tmp# strace -p 1008         Process 1008 attached - interrupt to quit         select(0, NULL, NULL, NULL, {0, 620000}) = 0 (Timeout)         write(6, '!', 1)                        = 1         socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 ENOSYS (Function not implemented)         socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 ENOSYS (Function not implemented)         socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 EAFNOSUPPORT (Address family not supported by protocol)         gettimeofday({1077743877, 15040}, NULL) = 0         write(7, '[Wed Feb 25 22:17:57 2004] [warn'..., 114) = 114         waitpid(-1, 0xbffffa00, WNOHANG|WUNTRACED) = 0         select(0, NULL, NULL, NULL, {1, 0})     = 0 (Timeout)         write(6, '!', 1)                        = 1         socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 ENOSYS (Function not implemented)         socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 ENOSYS (Function not implemented)         socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 EAFNOSUPPORT (Address family not supported by protocol)         gettimeofday({1077743878, 64645}, NULL) = 0         write(7, '[Wed Feb 25 22:17:58 2004] [warn'..., 114) = 114         waitpid(-1, 0xbffffa00, WNOHANG|WUNTRACED) = 0         select(0, NULL, NULL, NULL, {1, 0})     = 0 (Timeout)         write(6, '!', 1)                        = 1         socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 ENOSYS (Function not implemented)         socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 ENOSYS (Function not implemented)         socket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 EAFNOSUPPORT (Address family not supported by protocol)         gettimeofday({1077743879, 118433}, NULL) = 0         write(7, '[Wed Feb 25 22:17:59 2004] [warn'..., 114) = 114         waitpid(-1, 0xbffffa00, WNOHANG|WUNTRACED) = 0         select(0, NULL, NULL, NULL, {1, 0})     = 0 (Timeout)         .....  > OK, interesting, what does: >  > strace telnet ::1  And here is what it gave:  \tScript started on Mon Feb 23 17:27:11 2004 \tdione$ strace telnet ::1 \texecve('/usr/bin/telnet', ['telnet', '::1'], [/* 49 vars */]) = 0 \tuname({sys='Linux', node='dione', ...}) = 0 \tbrk(0)                                  = 0x805ba88 \told_mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x40017000 \taccess('/etc/ld.so.nohwcap', F_OK)      = -1 ENOENT (No such file or directory) \topen('/etc/ld.so.preload', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/tls/i686/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/tls/i686/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/tls/i686/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/tls/i686/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/tls/i686/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/tls/i686/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/tls/i686/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/tls/i686', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/tls/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/tls/mmx/cmov', /0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/tls/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/tls/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/tls/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/tls/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/tls/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/tls', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/i686/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/i686/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/i686/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/i686/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/i686/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/i686/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/i686/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/i686', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/home/alexis/lib/dione/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/home/alexis/lib/dione', {st_mode=S_IFDIR|0700, st_size=4096, ...}) = 0 \topen('tls/i686/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/libncurses.so.5', O_RDONLY)   = -1 ENOENT (No such file or directory) \topen('i686/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/libncurses.so.5', O_RDONLY)  = -1 ENOENT (No such file or directory) \topen('mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('mmx/libncurses.so.5', O_RDONLY)   = -1 ENOENT (No such file or directory) \topen('cmov/libncurses.so.5', O_RDONLY)  = -1 ENOENT (No such file or directory) \topen('libncurses.so.5', O_RDONLY)       = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/tls/i686/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/tls/i686/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/tls/i686/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/tls/i686/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/tls/i686/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/tls/i686/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/tls/i686/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/tls/i686', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/tls/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/tls/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/tls/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/tls/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/tls/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/tls/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/tls/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/tls', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/i686/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/i686/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/i686/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/i686/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/i686/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/i686/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/i686/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/i686', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/local/lib', {st_mode=S_IFDIR|S_ISGID|0775, st_size=4096, ...}) = 0 \topen('/usr/server/lib/tls/i686/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/tls/i686/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/tls/i686/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/tls/i686/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/tls/i686/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/tls/i686/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/tls/i686/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/tls/i686', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/tls/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/tls/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/tls/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/tls/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/tls/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/tls/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/tls/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/tls', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/i686/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/i686/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/i686/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/i686/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/i686/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/i686/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/i686/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/i686', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/mmx/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/mmx/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/mmx/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/mmx', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/cmov/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib/cmov', 0xbffff098) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/libncurses.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/server/lib', {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 \topen('/etc/ld.so.cache', O_RDONLY)      = 3 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=42165, ...}) = 0 \told_mmap(NULL, 42165, PROT_READ, MAP_PRIVATE, 3, 0) = 0x40018000 \tclose(3)                                = 0 \taccess('/etc/ld.so.nohwcap', F_OK)      = -1 ENOENT (No such file or directory) \topen('/lib/libncurses.so.5', O_RDONLY)  = 3 \tread(3, '/177ELF/1/1/1/0/0/0/0/0/0/0/0/0/3/0/3/0/1/0/0/0/260/342'..., 512) = 512 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=254544, ...}) = 0 \told_mmap(NULL, 255884, PROT_READ|PROT_EXEC, MAP_PRIVATE, 3, 0) = 0x40023000 \told_mmap(0x40059000, 32768, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED, 3, 0x36000) = 0x40059000 \told_mmap(0x40061000, 1932, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x40061000 \tclose(3)                                = 0 \topen('/home/alexis/lib/dione/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/cmov/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/cmov/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/cmov/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/cmov/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/libstdc++.so.5', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('i686/mmx/cmov/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/mmx/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/cmov/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/libstdc++.so.5', O_RDONLY)   = -1 ENOENT (No such file or directory) \topen('mmx/cmov/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('mmx/libstdc++.so.5', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('cmov/libstdc++.so.5', O_RDONLY)   = -1 ENOENT (No such file or directory) \topen('libstdc++.so.5', O_RDONLY)        = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/libstdc++.so.5', O_RDONLY) = -1 ENOENT (No such file or directory) \taccess('/etc/ld.so.nohwcap', F_OK)      = -1 ENOENT (No such file or directory) \topen('/usr/lib/libstdc++.so.5', O_RDONLY) = 3 \tread(3, '/177ELF/1/1/1/0/0/0/0/0/0/0/0/0/3/0/3/0/1/0/0/0/20/262'..., 512) = 512 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=729688, ...}) = 0 \told_mmap(NULL, 749312, PROT_READ|PROT_EXEC, MAP_PRIVATE, 3, 0) = 0x40062000 \told_mmap(0x400ff000, 86016, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED, 3, 0x9d000) = 0x400ff000 \told_mmap(0x40114000, 20224, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x40114000 \tclose(3)                                = 0 \topen('/home/alexis/lib/dione/libm.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/cmov/libm.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/libm.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/cmov/libm.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/libm.so.6', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('tls/mmx/cmov/libm.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/libm.so.6', O_RDONLY)     = -1 ENOENT (No such file or directory) \topen('tls/cmov/libm.so.6', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('tls/libm.so.6', O_RDONLY)         = -1 ENOENT (No such file or directory) \topen('i686/mmx/cmov/libm.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/mmx/libm.so.6', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('i686/cmov/libm.so.6', O_RDONLY)   = -1 ENOENT (No such file or directory) \topen('i686/libm.so.6', O_RDONLY)        = -1 ENOENT (No such file or directory) \topen('mmx/cmov/libm.so.6', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('mmx/libm.so.6', O_RDONLY)         = -1 ENOENT (No such file or directory) \topen('cmov/libm.so.6', O_RDONLY)        = -1 ENOENT (No such file or directory) \topen('libm.so.6', O_RDONLY)             = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/libm.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/libm.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \taccess('/etc/ld.so.nohwcap', F_OK)      = -1 ENOENT (No such file or directory) \topen('/lib/libm.so.6', O_RDONLY)        = 3 \tread(3, '/177ELF/1/1/1/0/0/0/0/0/0/0/0/0/3/0/3/0/1/0/0/0 5/0/000'..., 512) = 512 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=134356, ...}) = 0 \told_mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x40119000 \told_mmap(NULL, 136912, PROT_READ|PROT_EXEC, MAP_PRIVATE, 3, 0) = 0x4011a000 \told_mmap(0x4013b000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED, 3, 0x20000) = 0x4013b000 \tclose(3)                                = 0 \topen('/home/alexis/lib/dione/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/cmov/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/cmov/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/cmov/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/cmov/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/libgcc_s.so.1', O_RDONLY)     = -1 ENOENT (No such file or directory) \topen('i686/mmx/cmov/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/mmx/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/cmov/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/libgcc_s.so.1', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('mmx/cmov/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('mmx/libgcc_s.so.1', O_RDONLY)     = -1 ENOENT (No such file or directory) \topen('cmov/libgcc_s.so.1', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('libgcc_s.so.1', O_RDONLY)         = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/libgcc_s.so.1', O_RDONLY) = -1 ENOENT (No such file or directory) \taccess('/etc/ld.so.nohwcap', F_OK)      = -1 ENOENT (No such file or directory) \topen('/lib/libgcc_s.so.1', O_RDONLY)    = 3 \tread(3, '/177ELF/1/1/1/0/0/0/0/0/0/0/0/0/3/0/3/0/1/0/0/0@/25/0/000'..., 512) = 512 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=31548, ...}) = 0 \told_mmap(NULL, 30464, PROT_READ|PROT_EXEC, MAP_PRIVATE, 3, 0) = 0x4013c000 \told_mmap(0x40143000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED, 3, 0x7000) = 0x40143000 \tclose(3)                                = 0 \topen('/home/alexis/lib/dione/libc.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/cmov/libc.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/libc.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/cmov/libc.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/libc.so.6', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('tls/mmx/cmov/libc.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/libc.so.6', O_RDONLY)     = -1 ENOENT (No such file or directory) \topen('tls/cmov/libc.so.6', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('tls/libc.so.6', O_RDONLY)         = -1 ENOENT (No such file or directory) \topen('i686/mmx/cmov/libc.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/mmx/libc.so.6', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('i686/cmov/libc.so.6', O_RDONLY)   = -1 ENOENT (No such file or directory) \topen('i686/libc.so.6', O_RDONLY)        = -1 ENOENT (No such file or directory) \topen('mmx/cmov/libc.so.6', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('mmx/libc.so.6', O_RDONLY)         = -1 ENOENT (No such file or directory) \topen('cmov/libc.so.6', O_RDONLY)        = -1 ENOENT (No such file or directory) \topen('libc.so.6', O_RDONLY)             = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/libc.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/libc.so.6', O_RDONLY) = -1 ENOENT (No such file or directory) \taccess('/etc/ld.so.nohwcap', F_OK)      = -1 ENOENT (No such file or directory) \topen('/lib/libc.so.6', O_RDONLY)        = 3 \tread(3, '/177ELF/1/1/1/0/0/0/0/0/0/0/0/0/3/0/3/0/1/0/0/0"^/1/000'..., 512) = 512 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=1243076, ...}) = 0 \told_mmap(NULL, 1253316, PROT_READ|PROT_EXEC, MAP_PRIVATE, 3, 0) = 0x40144000 \told_mmap(0x4026b000, 36864, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED, 3, 0x126000) = 0x4026b000 \told_mmap(0x40274000, 8132, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x40274000 \tclose(3)                                = 0 \tmunmap(0x40018000, 42165)               = 0 \tbrk(0)                                  = 0x805ba88 \tbrk(0x807ca88)                          = 0x807ca88 \tbrk(0)                                  = 0x807ca88 \tbrk(0x807d000)                          = 0x807d000 \trt_sigaction(SIGTSTP, {0x8052240, [TSTP], SA_RESTORER|SA_RESTART, 0x4016d498}, {SIG_DFL}, 8) = 0 \tioctl(0, TCGETS, {B38400 opost isig icanon echo ...}) = 0 \trt_sigprocmask(SIG_BLOCK, NULL, [], 8)  = 0 \topen('/etc/nsswitch.conf', O_RDONLY)    = 3 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=465, ...}) = 0 \told_mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x40018000 \tread(3, '# /etc/nsswitch.conf/n#/n# Example'..., 4096) = 465 \tread(3, '', 4096)                       = 0 \tclose(3)                                = 0 \tmunmap(0x40018000, 4096)                = 0 \topen('/home/alexis/lib/dione/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/libnss_db.so.2', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('i686/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/libnss_db.so.2', O_RDONLY)   = -1 ENOENT (No such file or directory) \topen('mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('mmx/libnss_db.so.2', O_RDONLY)    = -1 ENOENT (No such file or directory) \topen('cmov/libnss_db.so.2', O_RDONLY)   = -1 ENOENT (No such file or directory) \topen('libnss_db.so.2', O_RDONLY)        = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('/etc/ld.so.cache', O_RDONLY)      = 3 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=42165, ...}) = 0 \told_mmap(NULL, 42165, PROT_READ, MAP_PRIVATE, 3, 0) = 0x40018000 \tclose(3)                                = 0 \taccess('/etc/ld.so.nohwcap', F_OK)      = -1 ENOENT (No such file or directory) \topen('/lib/tls/i686/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/tls/i686/mmx/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/lib/tls/i686/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/tls/i686/mmx', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/lib/tls/i686/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/tls/i686/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/lib/tls/i686/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/tls/i686', 0xbfffe6d8)     = -1 ENOENT (No such file or directory) \topen('/lib/tls/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/tls/mmx/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/lib/tls/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/tls/mmx', 0xbfffe6d8)      = -1 ENOENT (No such file or directory) \topen('/lib/tls/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/tls/cmov', 0xbfffe6d8)     = -1 ENOENT (No such file or directory) \topen('/lib/tls/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/tls', {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 \topen('/lib/i686/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/i686/mmx/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/lib/i686/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/i686/mmx', 0xbfffe6d8)     = -1 ENOENT (No such file or directory) \topen('/lib/i686/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/i686/cmov', 0xbfffe6d8)    = -1 ENOENT (No such file or directory) \topen('/lib/i686/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/i686', 0xbfffe6d8)         = -1 ENOENT (No such file or directory) \topen('/lib/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/mmx/cmov', 0xbfffe6d8)     = -1 ENOENT (No such file or directory) \topen('/lib/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/mmx', 0xbfffe6d8)          = -1 ENOENT (No such file or directory) \topen('/lib/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/lib/cmov', 0xbfffe6d8)         = -1 ENOENT (No such file or directory) \topen('/lib/libnss_db.so.2', O_RDONLY)   = -1 ENOENT (No such file or directory) \tstat64('/lib', {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 \topen('/usr/lib/tls/i686/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/tls/i686/mmx/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/usr/lib/tls/i686/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/tls/i686/mmx', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/usr/lib/tls/i686/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/tls/i686/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/usr/lib/tls/i686/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/tls/i686', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/usr/lib/tls/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/tls/mmx/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/usr/lib/tls/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/tls/mmx', 0xbfffe6d8)  = -1 ENOENT (No such file or directory) \topen('/usr/lib/tls/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/tls/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/usr/lib/tls/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/tls', 0xbfffe6d8)      = -1 ENOENT (No such file or directory) \topen('/usr/lib/i686/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/i686/mmx/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/usr/lib/i686/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/i686/mmx', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/usr/lib/i686/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/i686/cmov', {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 \topen('/usr/lib/i686/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/i686', {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 \topen('/usr/lib/mmx/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/mmx/cmov', 0xbfffe6d8) = -1 ENOENT (No such file or directory) \topen('/usr/lib/mmx/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/mmx', 0xbfffe6d8)      = -1 ENOENT (No such file or directory) \topen('/usr/lib/cmov/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tstat64('/usr/lib/cmov', 0xbfffe6d8)     = -1 ENOENT (No such file or directory) \topen('/usr/lib/libnss_db.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \tst\tmunmap(0x40018000, 42165)               = 0 \topen('/home/alexis/lib/dione/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/cmov/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/mmx/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/cmov/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/i686/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/cmov/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/mmx/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/cmov/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('tls/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/mmx/cmov/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/mmx/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/cmov/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('i686/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('mmx/cmov/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('mmx/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('cmov/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('libnss_files.so.2', O_RDONLY)     = -1 ENOENT (No such file or directory) \topen('/usr/local/lib/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('/usr/server/lib/libnss_files.so.2', O_RDONLY) = -1 ENOENT (No such file or directory) \topen('/etc/ld.so.cache', O_RDONLY)      = 3 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=42165, ...}) = 0 \told_mmap(NULL, 42165, PROT_READ, MAP_PRIVATE, 3, 0) = 0x40018000 \tclose(3)                                = 0 \taccess('/etc/ld.so.nohwcap', F_OK)      = -1 ENOENT (No such file or directory) \topen('/lib/libnss_files.so.2', O_RDONLY) = 3 \tread(3, '/177ELF/1/1/1/0/0/0/0/0/0/0/0/0/3/0/3/0/1/0/0/0p/35/0/000'..., 512) = 512 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=34436, ...}) = 0 \told_mmap(NULL, 33720, PROT_READ|PROT_EXEC, MAP_PRIVATE, 3, 0) = 0x40276000 \told_mmap(0x4027e000, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED, 3, 0x8000) = 0x4027e000 \tclose(3)                                = 0 \tmunmap(0x40018000, 42165)               = 0 \topen('/etc/services', O_RDONLY)         = 3 \tfcntl64(3, F_GETFD)                     = 0 \tfcntl64(3, F_SETFD, FD_CLOEXEC)         = 0 \tfstat64(3, {st_mode=S_IFREG|0644, st_size=17170, ...}) = 0 \told_mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x40018000 \tread(3, '# Network services, Internet sty'..., 4096) = 4096 \tclose(3)                                = 0 \tmunmap(0x40018000, 4096)                = 0 \tfstat64(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 4), ...}) = 0 \told_mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x40018000 \twrite(1, 'Trying ::1.../n', 14Trying ::1... at64('/usr/lib', {st_mode=S_IFDIR|0755, st_size=28672, ...}) = 0 \tclose(-1)                               = -1 EBADF (Bad file descriptor) \tsocket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 ENOSYS (Function not implemented) \tsocket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 ENOSYS (Function not implemented) \tsocket(PF_INET6, SOCK_STREAM, IPPROTO_IP) = -1 EAFNOSUPPORT (Address family not supported by protocol) \tdup(2)                                  = 3 \tfcntl64(3, F_GETFL)                     = 0x2 (flags O_RDWR) \tfstat64(3, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 4), ...}) = 0 \told_mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x40019000 \t_llseek(3, 0, 0xbffff250, SEEK_CUR)     = -1 ESPIPE (Illegal seek) \twrite(3, 'telnet: Unable to connect to rem'..., 83telnet: Unable to connect to remote host: Address family not supported by protocol \t) = 83 \tclose(3)                                = 0 \tmunmap(0x40019000, 4096)                = 0 \tclose(-1)                               = -1 EBADF (Bad file descriptor) \tmunmap(0x40018000, 4096)                = 0 \texit_group(1)                           = ? \tdione$ \tScript done on Mon Feb 23 17:27:17 2004  > middle of some long running request?  server-status with ExtendedStatus On would  > help answer those questions.  Okay, I added this to httpd.conf:          <Location /server-status>             SetHandler server-status             Order Deny,Allow             Deny from all             Allow from 127.0.0.1         </Location>         ExtendedStatus on  But, unfortunately, it has not demonstrated the bug in the last couple of days so I'm submitting this bug without this info.  Alexis Huxley ahuxley@gmx.net	Just confirm: you only see this bug using HEAD not 2.0.48? I saw this problem in HEAD (Jan 15 2004 17:00 GMT).  I saw it also in earlier HEADs, my guess is, since about six months ago. It's  a little difficult to judge with what version it started happening because it  only started happening once my pages starting getting more hits.   But, yes, I have only experienced it in HEADs, and not official releases, but then I *only* install HEADs becaause I've been reinstalling latest  apache2 HEAD at the same time as each new Subversion release comes out.  I've since installed HEAD (Feb 28 21:?? GMT). I will be sure to add a comment regarding its behaviour in a couple of weeks. Thanks for the detailed report - this should be fixed by the following change:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/mpm_common.c?r1=1.117&r2=1.118			Alexis Huxley	Joe Orton
27424	null	CLOSED		Bob Haskell	1078361580000	1081032507000		NTP home page has changed FWIW,  In the Requirements section - Accurate time keeping paragraph - The NTP homepage is given as http://www.eecis.udel.edu/~ntp/.  The ntp.org web-site has moved and is now located at http://www.ntp.org. As of 26 May 2003.  Thanks,  Bob	Created an attachment (id=10822) Updates docs with the proper URL  Mostly fixed. Thanks Paul.			Andr?? Malo	Paul Querna
27428	null	CLOSED		keilh	1078394040000	1078841432000		ssl shutdown does not work The ssl shutdown is handeld in 'ssl_filter_io_shutdown(..)', wich will be invoked as a cleanup handler. But the cleanup handlers will by invoked _after_ 'shutdown()' is called for the socket,  disabling any further write operation.  So the client does not recieve any ssl shutdown message. (The mod_ssl default is SSL_RECEIVED_SHUTDOWN)  That behaviour can be verified using ssldump.	This is fixed in the forthcoming 2.0.49 release; thanks for the report.			Joe Orton
27525	null	RESOLVED		1icharp	1078782900000	1130520727000		 failed on startssl Hello, i am trying to startssl on Sun-sparc Solaris 9 machine with Apache2.0.48 It gives the follwing error.  [Tue Mar 09 19:40:37 2004] [crit] [Tue Mar 09 19:40:37 2004] file vhost.c, line  232, assertion 'rv == APR_SUCCESS' failed Abort - core dumped  it works fine with 'start' option. i have installed the Sun recommened Patch cluster.  Can u suggest something.  Regards, Dheerajk.	Just to verify that we know which getaddrinfo call is failing, please try the test program gawild.c, which I'll attach in a sec.  It *should* run like this:  [trawick@sol9 platform_test]$ gcc -Wall -o gawild gawild.c -lsocket -lnsl [trawick@sol9 platform_test]$ ./gawild  it worked [trawick@sol9 platform_test]$ Created an attachment (id=10713) getaddrinfo(255.255.255.255)  Please re-open bug when you get a chance to try attached program on the Solaris box with the problem and report the results.  Thanks!  I have the same problem on Solaris 9, httpd 2.0.49. I tried the program and the  output is: getaddrinfo->1  Any clue? I've run the tool on two sun sparc systems with different results.    fwa$ ~/gawild   it worked   fwa$ uname -a   SunOS fwa 5.8 Generic_108528-23 sun4u sparc SUNW,Sun-Fire-480R    tii$ ~/gawild   getaddrinfo->1   fwa$ uname -a   SunOS tii 5.8 Generic_108528-23 sun4u sparc SUNW,Sun-Fire-V210  I wouldn't expect it'd be a hardware issue.  As expected, apache runs fine on  one of them but not the other.  In a different PR, it was suggested that it can fail when DNS is disabled but work otherwise.  Is that possibly the case, or is there a difference in DNS search order between the two machines?  I think we need to change APR to deal with this consistently.  I can't find that PR now, but yes, this is reproducible when /etc/nsswitch.conf has 'hosts: files' not the normal 'hosts: files dns'. (In reply to comment #0) > Hello, > i am trying to startssl on Sun-sparc Solaris 9 machine with Apache2.0.48 > It gives the follwing error. >  > [Tue Mar 09 19:40:37 2004] [crit] [Tue Mar 09 19:40:37 2004] file vhost.c, line  > 232, assertion 'rv == APR_SUCCESS' failed > Abort - core dumped >  > it works fine with 'start' option. > i have installed the Sun recommened Patch cluster. >  > Can u suggest something. >  > Regards, > Dheerajk.  (In reply to comment #7) > I can't find that PR now, but yes, this is reproducible when /etc/nsswitch.conf > has 'hosts: files' not the normal 'hosts: files dns'.  I verified that it also fails when:             hosts:     nis [NOTFOUND=return] files  It fails with:             hosts:     files nis [NOTFOUND=return] files  It works with:             hosts:     files dns nis [NOTFOUND=return] files Someone marked this as fixed; this case should at least be handled gracefully without an abort() so it's not really fixed. This is a very annoying and unintuitive situation. We are using mod_ssl with Apache 2.0.52 in Solaris 9/x86 and as we turned on the SSL it just occured and started dumping core. We also turned off the ServerName directive hoping that it will make it go away but still continued.  Need some graceful error message at the least. *** Bug 21682 has been marked as a duplicate of this bug. *** *** Bug 28537 has been marked as a duplicate of this bug. *** This happens when the VirtualHost entry contains _default_.  If I change it to an actual IP it works! *** Bug 35646 has been marked as a duplicate of this bug. *** *** Bug 36650 has been marked as a duplicate of this bug. *** In 2.1.x the assert()s in vhost.c now fail gracefully with a configuration error for cases where the system resolver is not configured properly.  Probably not worth a backport to 2.0.x since it's just an error case and relatively rare. *** Bug 30901 has been marked as a duplicate of this bug. *** *** Bug 30901 has been marked as a duplicate of this bug. *** Regardsing this issue we find that if we change _default_ in the virtualhostsetion of http.conf to an IP Address this issue does not happen. Where does _default_ get it's address from (dns? etx/hosts?) ??  On our server when we change _default_ to an IP Address it no longer core dumps, where does _default_ get populated from?  This bug is indeed caused by a Solaris bug, namely by http://bugs.opensolaris.org/view_bug.do?bug_id=4944187 which causes the getaddrinfo('255.255.255.255',...) to fail.  Bug 4944187 is scheduled to be fixed in the following forthcoming Solaris 10 patches:  125553-03 SunOS 5.10: libnsl and nfsmapid patch 125554-03 SunOS 5.10_x86: libnsl and nfsmapid patch  These two patches still have to pass the patch test cycle. Even if the behaviour of Solaris getaddrinfo must be considered faulty, apache could easily account for this misbehaviour, since the function find_adresses comes in two versions in srclib/apr/network_io/unix/sockaddr.c, the first calling call_resolver and, from there, getaddrinfo; the second treating addresses 0.0.0.0 and 255.255.255.255 specially and otherwise calling gethostbyname or gethostbyname_r. Thus, there is an simply way to fix this: in srclib/apr/configure, change the test address for getaddrinfo (line numbers for httpd-2.2.8): @@ -46266,7 +46266,7 @@      memset(&hints, 0, sizeof(hints));      hints.ai_family = AF_UNSPEC;      hints.ai_socktype = SOCK_STREAM; -    error = getaddrinfo('127.0.0.1', NULL, &hints, &ai); +    error = getaddrinfo('255.255.255.255', NULL, &hints, &ai);      if (error) {          exit(1);      } Then the test would fail in faulty Solaris and the second version of find_adresses be used.			Arieh Markel	HWS	Jeff Trawick	Jeremy Laidman	Joe Orton	K Venkatasubramaniyan	Luis Londono	Mick Ly	Nicolas Cohen	Thomas Dehn
27542	null	CLOSED		Alexander Prohorenko	1078846140000	1080582542000		t fall through to second This bug pretty much interconnects with the following one  http://archive.apache.org/gnats/304, although, it's dated 1997 and marked as  fixed.  There is a problem with mod_proxy when it tries to connect (forward, internal  proxy) to the domain name, which points to several IP addresses.  Technically,  it appears when I'm trying to use mod_rewrite RewriteRule with the internal  proxying facility.  I am still not very sure who's an originator of the  problem, mod_rewrite or mod_proxy.  Eg. I'm using the mod_rewrite with [proxy|P] directive to have the internal  proxying for the specific address to http://www.domain.com/. But the domain  http://www.domain.com/ points to several IP addresses, which is used for fail- over and (or?) some kind of load-balancing, eg.:  www.domain.com. IN A 10.0.10.1                 IN A 10.0.10.2                 IN A 10.0.10.3  Some of IPs generate connection reset, and supposedly mod_proxy should try  another IP address to connect. Unfortunetly, it does not this, and if it  recieves connection reset before the correct answer (eg. it tried broken  address before the working one) mod_proxy just hangs up with the nasty 502  error like this one:  Proxy Error The proxy server received an invalid response from an upstream server. The proxy server could not handle the request GET /test/1231.  Reason: Could not connect to remote machine: Invalid argument  and the log file says:  [Tue Mar 9 06:30:25 2004] [error] [client 1.2.59.190] (22)Invalid argument:  proxy connect to 10.0.10.1 port 80 failed  Likely, IE, Squid and a lot of different browsers and proxies handle this  situation just fine, but not mod_proxy. Yes, I am aware that this is not RFC- documented way of handling such situation, but looks pretty reasonable.	As I discovered, it looks like mod_proxy problem, but not mod_rewrite one. Actually, as it comes from the debug logs mod_proxy tries to do other  connections after it receives 'Connection refused' or 'Operation timed out',  but somehow hangs up with 'Invalid argument' parameter.  [Wed Mar 10 02:56:24 2004] [error] [client 3.10.112.130] (61)Connection  refused: proxy connect to 3.22.185.120 port 80 failed [Wed Mar 10 02:56:24 2004] [error] [client 3.10.112.130] (22)Invalid argument:  proxy connect to 3.10.112.131 port 80 failed [Wed Mar 10 02:56:24 2004] [error] [client 3.10.112.130] (22)Invalid argument:  proxy connect to 3.22.185.108 port 80 failed [Wed Mar 10 02:56:24 2004] [error] [client 3.10.112.130] (22)Invalid argument:  proxy connect to 3.22.185.99 port 80 failed  Likely I fixed this.  I'd much appreciate if this will be commited to the  source tree - I am not happy applying patches every time when I rebuild a  system. :)  --- proxy_http.c.orig   Wed Mar 10 05:34:43 2004 +++ proxy_http.c        Wed Mar 10 05:35:00 2004 @@ -278,6 +278,8 @@          i = ap_proxy_doconnect(sock, &server, r);          if (i == 0)              break; +       /* Even if the connection was unsuccesful we should reinit the socket */ +       sock = ap_psocket_ex(p, PF_INET, SOCK_STREAM, IPPROTO_TCP, 1);          j++;      }  #endif  noting that a patch is available for review  re-opening; not considered resolved/fixed/whatever until a fix is in CVS patch looks good here; when it gets applied the fix needs to be propagated to the '#ifdef SINIX_D_RESOLVER_BUG' path  while not absolutely required, it would be reasonable to go ahead and close the now-unusable socket via ap_pclosesocket() rather than wait for pool cleanup;  			Alexander Prohorenko	Jeff Trawick
27550	null	RESOLVED		Andres Salomon	1078870200000	1116884969000		pcre symbol issues for apache modules Currently, apache2 includes a full version of pcre-3.9 in its sources; this is built during compilation, and statically linked against.  The symbols from this library, are exported to apache modules.  This is undesirable for some apache modules; for example, php.  Php links against libpcre on the system; however, it will happily pick up the pcre symbols in the apache binary before the symbols in the pcre shared library.  This breaks php functions such as pcre_match(), which expect a relatively new version of pcre to be used (3.9 doesn't cut it; it always fails w/ that).  There are a number of solutions, here.  I attempted upgrading the pcre included in apache; however, I had no way to know if the various win32 hacks introduced to the pcre build system would still work.  I opted to not bother, since I have no way to test such work except for on a unix system.  An alternate solution is to check for pcre on the build system, and link against that instead of building pcre for apache.  This works, but introduces other issues.  With apache2 looking for the posix regex functions in shared libraries, it ends up using the glibc implementations for reg{comp,exec,free,error} instead of the pcre implementations of these function.  On my system, the glibc implementations segfault somewhere inside glibc; it's much safer to stick w/ the pcre versions.  So, aside from the autoconf-ery that's necessary to do the pcre system checks, there are some additional code changes necessary to make sure that the pcre functions are called instead of the glibc functions.  This is mainly some ugly code duplication.  The patch that implements this change is here: <http://sloth.voxel.net/~dilinger/020-external_pcre.patch>  A third solution is to simply change the internal pcre library to have its own namespace.  This ensures that apache uses a pcre that it's been fully tested with, while apache modules don't use them in place of a system-supplied pcre.  What I've done in the following patch is to prefix the posix regex functions in pcre with ap_pcreposix, and to prefix the other pcre regex functions with ap_pcre.  The interface that apache is _suppose to_ export to modules has not changed.  That patch is here: <http://sloth.voxel.net/~dilinger/021-pcre_mangle_symbols.patch>  I prefer the 021-pcre_mangle_symbols.patch patch, even though it's larger; it ensures stability, at the cost of some code duplication.  The 020-external_pcre.patch patch isn't as clean as I'd hoped, and for the added complexity, not much memory is saved.  Anyways, links to both patches are supplied so that you folks can decide between the preferred method.  Please consider applying either one of my patches, or an equivalent patch, so that pcre issues in external apache modules are solved.	Created an attachment (id=10733) patch to link against external libpcre  Created an attachment (id=10734) patch to rename internal pcre functions  *** Bug 26088 has been marked as a duplicate of this bug. *** hi all,  this problem's been around for awhile ... for at least a couple of years! \thttp://groups.google.com/groups?hl=en&lr=&ie=UTF -8&scoring=d&q=pcre+apache+%22multiple+definitions+of+symbol%22&btnG=Search  it keeps getting reported primarily to the php boards, and repeatedly referred *back* as an Apache bug.  bottom line: \t ###################################################################### Andres' patch (http://nagoya.apache.org/bugzilla/showattachment.cgi?attach_id=10734)  seems to fix the problem.  can this get integrated into HEAD & the 2.0.50 RELEASE? ######################################################################  on OSX, for quite awhile, i've been able to get around it by buildg httpd with its internal/included  pcre39, building an external build of pcre39, and linking php against the external lib via the LDFLACGS  & CPPFLAGS  however, with recent (for me, since yesterday)  httpd-head, building php --with-apxs aagain causes  conflicts with apache's included pcre.  any inclusion/combination of any other (later) version, OR the  inclusion of the php config param '--with-pcre-regex=...' results in 'make' errors/failures.  reading thru Andres' patch submission here, i tried the 'replace-namespace' patch (link above).  per  Andres, it seems to do the trick for Debian ...  as for me, with patch applied in OSX, i'm now able to successfully build httpd w/ internal pcre -- now in  its own namespace -- and build php500 --with-pcre against an external build of pcre45.  here _my_ 'recipe' for success ...  three 'pieces': (1) pcre 45 (2) httpd 2.0.50 (there's a few other issues i'm having with latest HEAD, so i dropped back to 2.0.50 for  this) (3) php 500 release  also: \t% uname -v \t\tDarwin Kernel Version 7.5.0: Thu Aug  5 19:26:16 PDT 2004; root:xnu/xnu-517.7.21.obj~3/ RELEASE_PPC  \t% glibtool --version \t\tltmain.sh (GNU libtool) 1.5.8 (1.1220.2.117 2004/08/04 14:12:05) \t% automake --version \t\tautomake (GNU automake) 1.9 \t% autoconf --version \t\tautoconf (GNU Autoconf) 2.59 \t% gcc --version \t\tgcc (GCC) 3.3 20030304 (Apple Computer, Inc. build 1666) \t% /usr/local/ssl/bin/openssl version \t\tOpenSSL 0.9.7d 17 Mar 2004   ############################################################ pcre-4.5 wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-4.5.tar.gz gnutar zxf pcre-4.5.tar.gz cd /usr/ports/pcre-4.5 unsetenv CFLAGS CPPFLAGS CXX CXXFLAGS LDFLAGS LDDLFLAGS LD_PREBIND LINGUAS LC_ALL LANG glibtoolize --force --copy && aclocal && autoconf ./configure / --prefix=/usr/local/pcre45 / --enable-shared --disable-static make make install  ############################################################ httpd-2.0.50  wget ftp://apache.secsup.org/pub/apache/dist/httpd/httpd-2.0.50.tar.gz gnutar zxf httpd-2.0.50.tar.gz cd /usr/ports/httpd-2.0.50  curl -f -L -o patch.pcre.txt 'http://nagoya.apache.org/bugzilla/showattachment.cgi?attach_id=10734' patch -p2 < patch.pcre.txt unsetenv CFLAGS CPPFLAGS CXX CXXFLAGS LDFLAGS LDDLFLAGS LD_PREBIND LC_ALL LANG LINGUAS ./buildconf  # enable linking against dlcompat's libdl ============================================================= (EDITOR) /usr/ports/httpd-2.0.50/srclib/apr/configure @10433 ---\tenable_dlopen=no +++\tenable_dlopen=yes \tenable_win32_dll=no =============================================================  ./configure / --with-mpm=worker / --enable-layout=Darwin --with-port=80 / --enable-mods-shared=all --enable-so --disable-static / --sysconfdir=/etc/apache2 / --enable-dav --enable-dav-fs --enable-dav-lock / --enable-ssl --with-ssl=/usr/local/ssl / --disable-suexec / --with-z / --enable-cgi / --enable-proxy / --enable-proxy-connect / --enable-proxy-ftp / --enable-proxy-http / --enable-logio / --enable-authn-dbm --enable-authz-dbm / --with-imap   # these lib links won't pick up from cmd line ... do it manually for now ============================================================= (EDITOR) /usr/ports/httpd-2.0.50/build/config_vars.mk \tEXTRA_CFLAGS = -g -O2 \tEXTRA_CXXFLAGS = ---\tEXTRA_LDFLAGS = -L/usr/local/lib  -L/usr/local/ssl/lib +++\tEXTRA_LDFLAGS = -bind_at_load -L/usr/local/lib  -L/usr/local/ssl/lib ---\tEXTRA_LIBS = -lssl -lcrypto +++\tEXTRA_LIBS = -lssl -lcrypto -lz -ldl -lexpat =============================================================  make make install  ################################################################# php-5.0.0 wget http://us2.php.net/distributions/php-5.0.0.tar.gz gnutar zxf php-5.0.0.tar.gz  unsetenv CFLAGS CPPFLAGS CXX CXXFLAGS LDFLAGS LDDLFLAGS LD_PREBIND EXTRA_LDFLAGS  EXTRA_LIBS LC_ALL LANG LINGUAS ;/ setenv LC_ALL C ;/ setenv LANG C ;/ setenv CPPFLAGS '-I/usr/local/ssl/include -I/usr/local/pcre45/include -I/usr/local/include' ;/ setenv LDFLAGS '-bind_at_load  -L/usr/local/ssl/lib -lssl -lcrypto -L/usr/local/pcre45/lib -lpcre'  ============================================================= (EDITOR) /usr/ports/php-5.0.0/configure.in ---\tAC_PROG_RANLIB +++\tAC_PROG_LIBTOOL =============================================================  cd /usr/ports/php-5.0.0 autoconf ranlib /usr/local/pgsql/lib/libpq.a  ./configure / --disable-debug / --prefix=/usr --with-layout=PHP / --with-config-file-path=/etc/php5 --sysconfdir=/etc/php5 / --enable-shared --disable-static / --libdir=/System/Library/PHP / --includedir=/usr/include / --mandir=/usr/local/man / --localstatedir=/var/php4 / --with-db4=/usr / --with-pgsql=/usr/local/pgsql --without-mysql / --enable-cli --with-pear=/System/Library/PHP / --disable-cgi / --with-apxs2=/usr/sbin/apxs / --disable-dmalloc / --with-tsrm-pthreads / --enable-shmop --enable-sockets / --enable-inline-optimization / --enable-xml --enable-libxml --with-libxml-dir=/usr / --with-java=/Library/Java/Home / --with-openssl=/usr/local/ssl --with-openssl-dir=/usr/local/ssl / --with-zlib --with-zlib-dir=/usr / --with-imap=/usr/local/imap --enable-mailparse / --with-imap-ssl=/usr/local/ssl / --with-mcrypt --with-mhash / --with-gmp=/usr/local / --with-gd=/usr/local/gd / --with-png-dir=/usr/local / --with-jpeg-dir=/usr/local / --with-tiff-dir=/usr/local / --enable-magic-quotes / --enable-calendar / --disable-mbstring / --with-kerberos=/usr / --with-freetype-dir=/usr/X11R6 / --with-xpm-dir=/usr/X11R6 / --enable-exif / --enable-ftp / --enable-bcmath / --with-pcre-regex=/usr/local/pcre45  make make install  cheers,  richard *** Bug 23952 has been marked as a duplicate of this bug. *** This bug is really important to fix.  I can't get my mod_caml module working with Apache 2.0 until it's fixed.  This prevents a significant userbase from migrating to Apache 2.  My duplicate bug report contains some other information: Bug 23952 I just had this problem as well, trying to install a Caml based wiki. If I add the 'LoadModule caml_module modules/mod_caml.so' to my httpd.conf file, apache just keeps segfaulting.  Unfortunately this is on a server where we need apache2, so this means that until this fix is integrated, I cannot use mod_caml (and every other mod that need a recent pcre library, it seems). Adding PatchAvailable keyword just building httpd2.0.51 ...  it seems this bug is STILL not resolved.  there's a demonstrated, working patch (cref: Andreas, below) that fixed the issue in 2.0.50, and  (seemingly) applies to 2.0.51 as well ...   is there a particular reason why this known/reported/fixed issue is NOT being integrated?  thx,  richard There are some subtle issues with this:   1) with an httpd built to use an external pcre, the include/pcre.h which gets installed does not match the pcre which is actually used.  It's possible that some third-party modules will depend on this.  2) Renaming both the reg* and pcre_* functions is a binary compatibility issue. hi,  i'm back again!  i'm building httpd 2.0.52 + php 5.0.2 on OSX 10.3.5  the ONLY way i'm able to get httpd & php to 'play nice' together -- avoiding later/'downstream' pcre  conflicts -- is to make sure that they're built using the SAME version of pcre.  there are two options to that end ...  (a)         build httpd w/ INTERNAL pcre (v3.9)         build external pcre3.9         build php 502 against pcre3.9/external  (b)         apply Andreas' patch to httpd (*luckily* the patch still works against 2.0.52 ...)         build external pcre5.0         build httpd 2.0.52 against pcre5.0/external         build php 5.0.2 against pcre5.0/external  (a), of course, locks PHP into the use of pcre3.9 ... which is simply not acceptable/tenable for a variety  of other apps that need >= v4.5  so, (b) is really the only functional option here ...  acknowledging 'possible subleties' from  Joe's reference above, the php issue is neither subtle, nor  simply possible ... others as well (cref above) are noting problems with, e.g., mod_caml that requires a  more recent pcre.  what need to be done to get this solution addressed/integrated?  even ASSIGNED would be a good start!  this has been an unaddressed issue problem for QUITE awhile ...  richard Agree with the previous comment.  mod_caml cannot use anything except an external, modern PCRE, so somehow linking it against Apache's ancient version of PCRE is a non-starter, even if it were possible.  This bug is a showstopper for a variety of important modules, so it should be fixed (particularly, since there's even a patch to do it). Created an attachment (id=13377) Amended version of patch by Andres Salomon, with typo fixed by Paul Argentoff  The following notes were sent to me by Paul Argentoff to accompany the preceeding patch.    - - - - - -  This is patch by Andres Salomon <dilinger@voxel.net>, with typo fixed by Paul Argentoff <argentoff@rtelekom.ru>  This patch fixes problems seen by apache modules attempting to run regex stuff, and getting apache's internal pcre implementation.  It contains two parts; the first (the autoconf stuff) checks if libpcre is installed on the host system.  If it is, that pcre is used to build apache2.  If it's not, apache2 compiles its own pcre, and statically links against it.    The second part of this patch forces pcre to be used.  Apache, by default, calls the posix regex functions (reg{exec,comp,free,error}) internally.  If glibc was sane, this would be fine.  Unfortunately, it's not.  So, when apache calls these regex functions, it's anyones guess as to whether it will use glibc's regex functions, or the pcre regex functions.  The glibc regex functions segfault (within glibc) on my system.  So, to ensure sanity, we force use of pcre regex functions.  I need to do a bit more testing w/ apache's internal pcre, but for debian's purposes (pcre in /usr), it works fine.  Pleeeeeeeeeeeeease incorporate this fix?  I'll bake you cookies! Ok, I've created a new patch that should supercede both other patches.  This patch checks for regex support via libc, and will use that if found.  If the libc doesn't support POSIX.2 regex functions, it will then check for an external pcre; if found, it links against that.  If it doesn't find that, it finally falls back to compiling and linking against its own internal pcre library.  This patch is also significantly smaller than my other two patches, as it doesn't require any widespread symbol changes.  I've tested compilation with and without regex.h and pcre-dev.  Testers whose libc specifically lacks regex support are requested (all testers welcome, of course :)  I'll follow up w/ fixes as necessary. We won't use any POSIX regex stuff. The PCRE is used on purpose... Created an attachment (id=13661) more intelligent patch to link against PCRE  Patch against apache 2.0.52; use libc's regex functions, falling back to external pcre, and finally building internal pcre only if absolutely necessary. (In reply to comment #17) > We won't use any POSIX regex stuff. The PCRE is used on purpose...  Why not?  What specifically is broken regarding the libc-provided POSIX regex stuff?  And, why not test for breakage, instead of unconditionally using PCRE when   it's probably not even necessary? Consistency among the various installations and way more power. In that case, instead of using the POSIX functions, we should probably just be using the PCRE functions... That's a good point and I personally agree. This should be discussed on dev@ anyway. The best would be with a patch backhand :) More than that, httpd *cannot* use a real POSIX regex implementation rather than PCRE: even the default config actually uses some of the Perl extensions to the regex grammar (the '(?:' stuff IIRC?). This is all now done on the trunk based on Andres' patches - thanks a lot!  Again, it can't really be backported to 2.0, unfortunately, because it changes the module interface. hi,  > Again, it can't really be backported to 2.0, unfortunately, because it changes the module interface.  so iiuc, then, we've two options at this point:  (1) STABLE 2.0.x release source + Andres' patches (assuming/hoping they continue to apply ...) (2) UNSTABLE cvs source, w/ functionality included.  i.e., no STABLE solution until 2.1 release ...   am i correct?  thanks for the update!  richard (In reply to comment #25)  I just tried the most recent patch with Apache 2.0.53 and make failed:  libtool: link: cannot find the library "/Users/me/Desktop/webserver/httpd-2.0.53/srclib/pcre/ libpcre.la' make[2]: *** [htpasswd] Error 1 make[1]: *** [all-recursive] Error 1 make: *** [all-recursive] Error 1 (In reply to comment #25) > > Again, it can't really be backported to 2.0, unfortunately, because it changes > > the module interface. >  > so iiuc, then, we've two options at this point:  Yes, that's correct. If anyone else is following this, the 2.1.3 alpha is out now, and it solved my problems. *** Bug 28781 has been marked as a duplicate of this bug. *** I have applied most recent Andres' patch (id=13661) against most recent current stable Apache - 2.0.54. Patched sources compile cleanly, but at run-time Apaches crashes/segfaults immediately after parsing any regex in config file.  Here are some details: in my system this patch selects glibc's implementation of regex. If there are not regexes in config file, then apache starts successfully. If there is regex in config file, it compiles without problem. Using gdb,  (gdb) break regcomp (gdb) r (gdb) bt #0  0x403bf852 in regcomp () from /lib/libc.so.6 #1  0x08071714 in ap_pregcomp (p=0x809b0a8, pattern=0x80d3bd0 '^//.ht', cflags=135085008) at util.c:268 #2  0x0807ca4e in filesection (cmd=0xbffff990, mconfig=0x80d3bd0, arg=0x80d3bc1 '') at core.c:1837 #3  0x0806b5f1 in invoke_cmd (cmd=0x808e2e8, parms=0xbffff990, mconfig=0x80b59f0, args=0x80d2b90 '~ /'^//.ht/'>')     at config.c:797 #4  0x0806bf06 in ap_walk_config (current=0x80d2b70, parms=0xbffff990, section_vector=0x80b58e0) at config.c:1060 #5  0x0806cd2f in ap_process_config_tree (s=0x80d3bd8, conftree=0x80d3bd0, p=0x809b0a8, ptemp=0x80d3bd0)     at config.c:1643 #6  0x0806fa6b in main (argc=5, argv=0xbffffab4) at main.c:539  But, shortly, segfaults occurs: (gdb) cont Continuing.  Program received signal SIGSEGV, Segmentation fault. trie_node_alloc (p=0x809b0a8, parent=0x809b518, c=95 '_') at util_filter.c:113 113                 if (c == parent->children[i].c) { (gdb) bt #0  trie_node_alloc (p=0x809b0a8, parent=0x809b518, c=95 '_') at util_filter.c:113 #1  0x080766a3 in register_filter (name=0x809b518 'core_in', filter_func=       {out_func = 0x807ed90 <core_input_filter>, in_func = 0x807ed90 <core_input_filter>}, filter_init=0, ftype=0,      reg_filter_set=0x809b518) at util_filter.c:217 #2  0x08080611 in register_hooks (p=0x809b0a8) at core.c:4509 #3  0x0806fb4f in main (argc=5, argv=0xbffffab4) at main.c:578 This should be fixed in apache-2.1; Joe Orton incorported my patch into it, plus added some additional fixes.  If you're going to use 2.0, don't use my patches (I'm not keeping them up-to-date); use Debian's.  Adam Conrad backported Joe's changes for 2.0, and they're being kept up-to-date.  ftp://ftp.debian.org/debian/pool/main/a/apache2/  apt-get source apache2, or grab the patch out of the .diff.gz.			Alan Schmitt	Andr?? Malo	Andres Salomon	Joe Orton	Konstantin Andreev	Nick Kew	OpenMacNews	Owen Gunden	Paul Querna	Richard W.M. Jones	apache@mailinator.com
27719	null	CLOSED		Stefan K.	1079470620000	1079896076000		Spelling mistake In the german documentation there is a spelling mistake:  http://httpd.apache.org/docs-2.0/mod/core.html#options  it says: 'Definiert, welche Eigenscahften...' (Eigenschaften)	fixed, thanks for the report! 			Jeff Trawick
27731	null	CLOSED		Thomas Minor	1079516700000	1082061541000		Seg Fault  when executing apachectl -S When I configure a virtualhost like this:     <VirtualHost *> and then execute 'apachectl -S' I get a seg fault.  Configuring the server on every single port like this      <VirtualHost *:80 *:8085> works.  Other configuration :      Listen 80     Listen 8085     [...]     NameVirtualHost *:8085     NameVirtualHost *:80   uname -a :     SunOS myserver 5.9 Generic_112233-11 sun4u sparc SUNW,Sun-Fire-V210	Created an attachment (id=10827) catch bad vhost configuration  It's a misconfiguration if you enable name-based vhosting for a specific port, but then define no VirtualHosts for that port; with the above patch applied you should get a warning but the server will work correctly. Fixed on HEAD using the above patch; thanks for the report. *** Bug 31915 has been marked as a duplicate of this bug. *** *** Bug 36234 has been marked as a duplicate of this bug. *** *** Bug 40374 has been marked as a duplicate of this bug. ***			Joe Orton
27748	null	CLOSED		William Leumas	1079541360000	1085181526000		ldap auth periodically fails, requires restart Over time (a few days, with an average of 350k hits of which 25k are authed with auth_ldap) it will stop authenticating random users, with the error:  [Wed Mar 17 08:40:51 2004] [warn] [client 147.178.68.203] [26904] auth_ldap authenticate: user {username} authentication failed; URI {path} [User not found][No such object]  It does this in the middle of a functional session (i.e. the user was logged in, clicking around and suddenly pop, no access).  The 'fix' is to restart the webserver.  I presume this is a cacheing issue.  We are running 2.0.49rc1	This is linked against OpenLDAP stable 2.1.25.  Is there a way to perhaps turn off the cache, to see if that is what is causing the problem?  I have written a perl script that watches the log for this error and immediately cross-checks LDAP for the user, if the user exists it restarts Apache.  We are seeing about 30 restarts a day. Created an attachment (id=11078) fix for ldap rebinding failures  The problem is in the poor way the ldap session is managed (which could cause other severe problems, if individual users cannot browse the tree, and it should be re-considered).  Kurt Olsen has found this problem and come up with a quick fix (see patch).  Note: this also relates to bug# 17274.  Kurt's description:  -------------- In the file util_ldap.c, in the function util_ldap_cache_checkuserid, when a user tries to authenticate the module takes these steps:  1) check the cache, returning success or failure if results cached. 2) open a connection via the function util_ldap_connection_open, using the ldc struct.    if ldc->bound = 1, then don't do anything in util_ldap_connection_open. 3) do a search to validate, and locate the dn for, the username provided. 4) verify that there is only 1 result of the search in #3. 5) verify that the password is non empty. 6) rebind with the dn found in step 3 with the password provided, using the ldc struct.    if there is a failure then return failure status.    on success update cache and return success status.  The problem is that the ldc used in #6 is the same ldc used to lookup a user's dn in the tree.  So if the password is incorrect then the ldap_simple_bind_s used to verify the password will have screwed up the ldc->ldap binding. The next time this ldc struct is used, the ldc->bound value is set to 1, but the actual valid bind has been hosed. One simple fix is to add an 'ldc->bound = 0;' into the two tests for failure after the ldap_simple_bind_s. This causes the util_ldap_connection_open to re-bind with the proper DN prior to looking up users.  Even in the case where the users are logging in correctly, there is still the problem that when user A authenticates the ldc->ldap bind is now bound with his username and password. If user A doesn't have rights to search the tree, then when user B comes along at a later point in time the search for user B's dn in the tree will fail. The correct fix would be to create an util_ldap_connection_t *foo; that would be used for testing provided passwords, but would not have an impact on the ldc struct used for searching and what not.  Kurt Olsen Not fixed in the code yet... adding Patchavailable keyword. Additional bugs with this issue and some of them also have fixes:  17274 17599 18661 21787 24595 24683 (probably, commentary is old) 27134 27271  And  28413 may be the same thing, but it's not really clear except that they experience failures against AD.  I think that the comment that a connection should be marked as unbound after any user bind is the proper solution. The patch included in this report only marks unbound upon auth failures. Adding an ldc->bound = 0; at line 847 in util_ldap.c (release 2.0.49) should fix both issues I have addressed in my re-explanation of the problem. The attached patch has been committed to v2.1.0-dev, and is included against v2.0.49.  Please test and tell me whether this fixes the problem.  Created an attachment (id=11618) Rollup of LDAP fixes to v2.1.0 against v2.0.49  The attachment includes bnicholes fix:      *) mod_ldap calls ldap_simple_bind_s() to validate the user        credentials.  If the bind fails, the connection is left        in an unbound state.  Make sure that the ldap connection        record is updated to show that the connection is no longer        bound.  *** Bug 25764 has been marked as a duplicate of this bug. *** *** Bug 17599 has been marked as a duplicate of this bug. *** *** Bug 21787 has been marked as a duplicate of this bug. *** *** Bug 24595 has been marked as a duplicate of this bug. *** *** Bug 27134 has been marked as a duplicate of this bug. *** *** Bug 24683 has been marked as a duplicate of this bug. *** *** Bug 18661 has been marked as a duplicate of this bug. *** Fixed in v2.0.50-dev. I repeated my test set-up that I'd been using under bug 27134, with the roll-up patch 11618 from bug 27748. This was on Red Hat Linux 9.0, building Apache from patched 2.0.49 sources (not Red Hat sources)  This uses two test data sets with 11 valid username/password pairs and some pseudo-random failures. One data set walks through the usernames in nearly serial order (because this will tend to show the worst-case usage of the connection pool). This makes 103 requests. The other data set uses a more random series of usernames. This makes 804 requests.  The results look good.  I'm now getting no unexpected authentication results, and socket usage looks similar to Denis Gervalle's previous patch.  I still have the warning 'LDAP cache: Unable to init  Shared Cache: no file', but I suppose that's a different issue.  I did the tests first with the default settings of  StartServers         5 MinSpareServers      5 MaxSpareServers     10 MaxClients         150 MaxRequestsPerChild  0  For comparison, I set up a low process number test with:  StartServers         1 MinSpareServers      1 MaxSpareServers     1 MaxClients         150 MaxRequestsPerChild  0  and high process number test with:  StartServers         10 MinSpareServers      10 MaxSpareServers     20 MaxClients         150 MaxRequestsPerChild  0  All the tests give correct results (authentication works or fails as expected).  I looked at sockets in use with 'netstat -an' on the LDAP server.  With the default prefork process config: the serial data set left 9 sockets to the LDAP server in use at the end; the random data set left 4 sockets in use at the end  With the 'low process' config: the serial data set left 1 socket in use at the end; the random data set left 0 sockets in use at the end  With the 'high process' config the serial data set left 14 sockets in use at the end; the random data set left 11 sockets in use at the end;  I'm guessing that if I could get rid of the 'Unable to init  Shared Cache' warning I'd get results more like the 'low process' config. Can anyone suggest another fix/bug that applies to that issue? 			Albert Lunde	Andr?? Malo	Graham Leggett	Kurt Olsen	William Leumas
27751	null	CLOSED		Ken Avery	1079544360000	1086124559000		Segmentation Fault in shmcb_cyclic_cton_memcpy Here is the backtrace:  Program ran under gdb with set args -X -f conf/leakd.conf  Thread 17 Stack Trace:  *** Begin Stack Frame  #0  0x403079a7 in memcpy () from /lib/libc.so.6 #1  0x40404661 in shmcb_cyclic_cton_memcpy (buf_size=7190,     dest=0xbdbfcd2c '0/201/221/002/001/001/002/002/003/001/004/002',     data=0x4048ebea '/0040????????R/222??3????/001??M??/236??g/222??[??%??????-f3z??) ??/023J????/233=',      src_offset=6402, src_len=10240) at ssl_scache_shmcb.c:915 #2  0x404052cb in shmcb_remove_session_id (s=0x80e2a98,      queue=0xbdbff58c,     cache=0xbdbff57c,     id=0x82708f8 '/177????vL|/0066=<{w%BQ.????I??n??7??/001&/017sI)/224/002 ',     idlen=32) at ssl_scache_shmcb.c:1338 #3  0x40404527 in shmcb_remove_session (s=0x80e2a98,      shm_segment=0x40452000,     id=0x82708f8 '/177????vL|/0066=<{w%BQ.????I??n??7??/001&/017sI)/224/002 ',     idlen=32) at ssl_scache_shmcb.c:819 #4  0x40403a2b in ssl_scache_shmcb_remove (s=0x80e2a98,     id=0x82708f8 '/177????vL|/0066=<{w%BQ.????I??n??7??/001&/017sI)/224/002 ',     idlen=32) at ssl_scache_shmcb.c:477 #5  0x4040291c in ssl_scache_remove (s=0x80e2a98,     id=0x82708f8 '/177????vL|/0066=<{w%BQ.????I??n??7??/001&/017sI)/224/002 ',     idlen=32) at ssl_scache.c:158 #6  0x403fcfc3 in ssl_callback_DelSessionCacheEntry (ctx=0x80de048,     session=0x82708b0) at ssl_engine_kernel.c:1742 #7  0x40042f1b in timeout () from /lib/libssl.so.2 #8  0x400b1d60 in lh_doall_arg () from /lib/libcrypto.so.2 #9  0x40042fa0 in SSL_CTX_flush_sessions () from /lib/libssl.so.2 #10 0x40040691 in ssl_update_cache () from /lib/libssl.so.2 #11 0x4003270f in ssl3_accept () from /lib/libssl.so.2 #12 0x4003f340 in SSL_accept () from /lib/libssl.so.2 #13 0x4003bfe8 in ssl23_get_client_hello () from /lib/libssl.so.2 #14 0x4003b7f5 in ssl23_accept () from /lib/libssl.so.2 #15 0x4003f340 in SSL_accept () from /lib/libssl.so.2 #16 0x403fa2f9 in ssl_io_filter_connect (filter_ctx=0x82313d8)     at ssl_engine_io.c:1070 #17 0x403fa664 in ssl_io_filter_input (f=0x82b82d0, bb=0x82a8f28,     mode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)     at ssl_engine_io.c:1239 #18 0x0807218e in ap_get_brigade (next=0x82b82d0, bb=0x82a8f28,     mode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)     at util_filter.c:514 #19 0x0807218e in ap_get_brigade (next=0x82a8ec8, bb=0x82a8f28,     mode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)     at util_filter.c:514 #20 0x08072f93 in ap_rgetline_core (s=0x82a82b8, n=8192, read=0xbdbff9d8,     r=0x82a82a0, fold=0, bb=0x82a8f28) at protocol.c:256 #21 0x08073455 in read_request_line (r=0x82a82a0, bb=0x82a8f28)     at protocol.c:623 #22 0x080739d7 in ap_read_request (conn=0x8231060) at protocol.c:900 #23 0x080608db in ap_process_http_connection (c=0x8231060) at      http_core.c:312 #24 0x0807060a in ap_run_process_connection (c=0x8231060) at      connection.c:85 #25 0x08065916 in process_socket (p=0x8230f38, sock=0x8230f70,      my_child_num=0,     my_thread_num=13, bucket_alloc=0x825d100) at worker.c:632 #26 0x08065f0a in worker_thread (thd=0x80fde88, dummy=0x812bc88)     at worker.c:946 #27 0x401f5090 in dummy_worker (opaque=0x80fde88) at thread.c:127 #28 0x40205f77 in pthread_start_thread () from /lib/libpthread.so.0  ***End of Stack Frame  Info Threads:    29 Thread 27676 (LWP 1526)  0x40360b60 in poll () from /lib/libc.so.6   18 - 28 in sigsuspend () from /lib/libc.so.6 * 17 Thread 15376 (LWP 1514)  0x403079a7 in memcpy () from /lib/libc.so.6   3 - 16 in sigsuspend () from /lib/libc.so.6   2 Thread 2049 (LWP 1499)  0x40360b60 in poll () from /lib/libc.so.6   1 Thread 1024 (LWP 1492)  0x402b4136 in sigsuspend () from /lib/libc.so.6  CPU Registers:  eax            0x24ec   9452 ecx            0x36     54 edx            0xbdbfd040       -1111502784 ebx            0x4041089c       1078003868 esp            0xbdbfcc9c       0xbdbfcc9c ebp            0xbdbfccd4       0xbdbfccd4 esi            0x40490ffe       1078530046 edi            0xbdbff454       -1111493548 eip            0x40404661       0x40404661 eflags         0x202    514 cs             0x23     35 ss             0x2b     43 ds             0x2b     43 es             0x2b     43 fs             0x0      0 gs             0x0      0 fctrl          0x37f    895 fstat          0x20     32 ftag           0xffff   65535 fiseg          0x23     35 fioff          0x400b2af8       1074473720 foseg          0x2b     43 fooff          0x40101950       1074796880 fop            0x5d8    1496 xmm0           {f = {0x0, 0x0, 0x0, 0x0}}       {f = {-nan(0x7fffff),     -nan(0x7fffff), -nan(0x7fffff), -nan(0x7fffff)}}  xmm1-xmm7 the same as xmm0  mxcsr          0x1f80   8064 orig_eax       0xffffffff       -1  function where issue is located:  901     static void shmcb_cyclic_cton_memcpy( 902         unsigned int buf_size, 903         unsigned char *dest, 904         unsigned char *data, 905         unsigned int src_offset, 906         unsigned int src_len) 907     { 908         /* Can it be copied all in one go? */ 909         if (src_offset + src_len < buf_size) 910             /* yes */ 911             memcpy(dest, data + src_offset, src_len); 912         else { 913             /* no */ 914             memcpy(dest, data + src_offset, buf_size - src_offset); *915             memcpy(dest + buf_size - src_offset, data, 916                    src_len + src_offset - buf_size);  (gdb) print dest + buf_size - src_offset $57 = (unsigned char *) 0xfffff4ee <Address 0xfffff4ee out of bounds> (gdb) print src_len + src_offset - buf_size $58 = 2071963774 (gdb)  917         } 918         return; 919     }  Frame Information [frame 1]:  #1  0x40404661 in shmcb_cyclic_cton_memcpy ( buf_size=7190, dest=0xbdbfcd2c '0/201/221/002/001/001/002/002/003/001/004/002', data=0x4048ebea '/0040????????R/222??3????/001??M??/236??g/222??[??%??????-f3z??) ??/023J????/233=',  src_offset=6402,  src_len=10240 ) at ssl_scache_shmcb.c:915  915             memcpy(dest + buf_size - src_offset, data,  916                           src_len + src_offset - buf_size);  Variables in the Frame context:  (gdb) print buf_size $49 = 7190 (gdb) print dest $51 = (unsigned char *) 0xbdbfcd2c '0/201/221/002/001/001/002/002/003/001/004 /002' (gdb) print data $53 = (unsigned char *) 0x4048ebea '/0040????????R/222??3????/001??M??/236??g/222??[??%??????- f3z??)??/023J????/233=' (gdb) print src_offset $55 = 3183473748   (gdb) print &src_offset Address requested for identifier 'src_offset' which is in register $edi (gdb) print src_len $56 = 3183464512 (gdb) print &src_len Address requested for identifier 'src_len' which is in register $edx  (gdb) info register edi edx edi            0xbdbff454       -1111493548 edx            0xbdbfd040       -1111502784  These variable values do appear to be valid based on the stack trace?     src_offset = 3183473748  location register edi=0xbdbff454  -1111493548 src_len    = 3183464512  location register edx=0xbdbfd040  -1111502784  The stack trace shows these are supposed to be:  src_offset=6402  src_len=10240  Here is the conf file:  # Custom config file for memory leak test ServerRoot '/usr/webserver' PidFile logs/httpd.pid Timeout 300 KeepAlive On MaxKeepAliveRequests 100 KeepAliveTimeout 15 <IfModule worker.c> StartServers         1 MaxClients          25 MinSpareThreads     25 MaxSpareThreads     25 ThreadsPerChild     25 ServerLimit          1 MaxRequestsPerChild  0 </IfModule> <IfModule perchild.c> NumServers           5 StartThreads         5 MinSpareThreads      5 MaxSpareThreads     10 MaxThreadsPerChild  20 MaxRequestsPerChild  0 </IfModule> <IfModule mpm_winnt.c> ThreadsPerChild 250 MaxRequestsPerChild  0 </IfModule> LoadModule access_module modules/mod_access.so LoadModule actions_module modules/mod_actions.so LoadModule alias_module modules/mod_alias.so LoadModule cgi_module modules/mod_cgi.so LoadModule dir_module modules/mod_dir.so LoadModule env_module modules/mod_env.so LoadModule imap_module modules/mod_imap.so LoadModule log_config_module modules/mod_log_config.so LoadModule mime_module modules/mod_mime.so LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_connect_module modules/mod_proxy_connect.so LoadModule proxy_http_module modules/mod_proxy_http.so LoadModule negotiation_module modules/mod_negotiation.so LoadModule rewrite_module modules/mod_rewrite.so LoadModule setenvif_module modules/mod_setenvif.so LoadModule headers_module modules/mod_headers.so LoadModule ssl_module modules/mod_ssl.so LoadModule status_module modules/mod_status.so <IfModule !mpm_winnt.c> # # If you wish httpd to run as a different user or group, you must run # httpd as root initially and it will switch. # User leakd Group leakd </IfModule> UseCanonicalName Off <Directory />     Options FollowSymLinks     AllowOverride None #IP_RESTRICTION_BLOCK </Directory> DirectoryIndex index.html index.htm index.php <Files ~ '^/.ht'>     Order allow,deny     Deny from all </Files> TypesConfig conf/mime.types DefaultType text/plain <IfModule mod_mime_magic.c>     MIMEMagicFile conf/magic </IfModule> HostnameLookups Off ErrorLog /usr/webserver/logs/error_log LogLevel error LogFormat '%h %l %u %t /'%r/' %>s %b /'%{Referer}i/' /'%{User-Agent}i/''  combined LogFormat '%h %l %u %t /'%r/' %>s %b' common LogFormat '%{Referer}i -> %U' referer LogFormat '%{User-agent}i' agent CustomLog /usr/webserver/logs/access_log common ServerTokens min ServerSignature Off ScriptAlias /cgi-bin/ '/usr/webserver/cgi-bin/' AddEncoding x-compress Z AddEncoding x-gzip gz tgz AddLanguage da .dk AddLanguage nl .nl AddLanguage en .en AddLanguage et .et AddLanguage fr .fr AddLanguage de .de AddLanguage he .he AddLanguage el .el AddLanguage it .it AddLanguage ja .ja AddLanguage pl .po AddLanguage ko .ko AddLanguage pt .pt AddLanguage nn .nn AddLanguage no .no AddLanguage pt-br .pt-br AddLanguage ltz .ltz AddLanguage ca .ca AddLanguage es .es AddLanguage sv .sv AddLanguage cz .cz AddLanguage ru .ru AddLanguage tw .tw AddLanguage zh-tw .tw AddLanguage hr .hr LanguagePriority en da nl et fr de el it ja ko no pl pt pt-br ltz ca es sv tw ForceLanguagePriority Prefer Fallback AddDefaultCharset ISO-8859-1 AddCharset ISO-8859-1  .iso8859-1  .latin1 AddCharset ISO-8859-2  .iso8859-2  .latin2 .cen AddCharset ISO-8859-3  .iso8859-3  .latin3 AddCharset ISO-8859-4  .iso8859-4  .latin4 AddCharset ISO-8859-5  .iso8859-5  .latin5 .cyr .iso-ru AddCharset ISO-8859-6  .iso8859-6  .latin6 .arb AddCharset ISO-8859-7  .iso8859-7  .latin7 .grk AddCharset ISO-8859-8  .iso8859-8  .latin8 .heb AddCharset ISO-8859-9  .iso8859-9  .latin9 .trk AddCharset ISO-2022-JP .iso2022-jp .jis AddCharset ISO-2022-KR .iso2022-kr .kis AddCharset ISO-2022-CN .iso2022-cn .cis AddCharset Big5        .Big5       .big5 # For russian, more than one charset is used (depends on client, mostly): AddCharset WINDOWS-1251 .cp-1251   .win-1251 AddCharset CP866       .cp866 AddCharset KOI8-r      .koi8-r .koi8-ru AddCharset KOI8-ru     .koi8-uk .ua AddCharset ISO-10646-UCS-2 .ucs2 AddCharset ISO-10646-UCS-4 .ucs4 AddCharset UTF-8       .utf8 AddCharset GB2312      .gb2312 .gb AddCharset utf-7       .utf7 AddCharset utf-8       .utf8 AddCharset big5        .big5 .b5 AddCharset EUC-TW      .euc-tw AddCharset EUC-JP      .euc-jp AddCharset EUC-KR      .euc-kr AddCharset shift_jis   .sjis AddType application/x-tar .tgz AddType image/x-icon .ico AddType application/x-httpd-php .php AddType text/html .tpl AddHandler cgi-script cgi exe jpq BrowserMatch 'Mozilla/2' nokeepalive BrowserMatch 'MSIE 4/.0b2;' nokeepalive downgrade-1.0 force-response-1.0 BrowserMatch 'RealPlayer 4/.0' force-response-1.0 BrowserMatch 'Java/1/.0' force-response-1.0 BrowserMatch 'JDK/1/.0' force-response-1.0 BrowserMatch 'Microsoft Data Access Internet Publishing Provider' redirect- carefully BrowserMatch '^WebDrive' redirect-carefully BrowserMatch '^WebDAVFS/1.[012]' redirect-carefully BrowserMatch '^gnome-vfs' redirect-carefully <IfModule mod_proxy.c> ProxyRequests Off <Proxy *>     Order deny,allow     Deny from all     Allow from all </Proxy> ProxyVia On </IfModule> <IfModule mod_rewrite.c> RewriteEngine On </IfModule> listen 127.0.0.1:9200 <VirtualHost 127.0.0.1:9200> ServerName 127.0.0.1:9200 DocumentRoot '/usr/webserver/isdocs' <Directory '/usr/webserver/isdocs'>     Options MultiViews     Options +FollowSymLinks     AllowOverride None </Directory> RewriteEngine On RewriteRule ^/login.htm /red9200.html RewriteMap map1 txt:/usr/webserver/conf/musiclist.map RewriteCond %{REQUEST_URI} ^/([^/]+).* RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] RewriteCond %{REQUEST_URI} ^/Music/LookupTag/(.*) RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] RewriteCond %{REQUEST_URI} ^/Music/MusicTag/(.*)RewriteCond ${map1:%1|NONE} ^ (http.*) [NC] RewriteRule ^(/.*) %1$1 [P] ProxyPreserveHost on Header set Server: JKPHTTPServer/9.9 <Location /statusreport> SetHandler server-status </Location> </VirtualHost> listen 172.25.54.114:9200 <VirtualHost 172.25.54.114:9200> ServerName 172.25.54.114:9200 DocumentRoot '/usr/webserver/isdocs' <Directory '/usr/webserver/isdocs'>     Options MultiViews     Options +FollowSymLinks     AllowOverride None </Directory> RewriteEngine On RewriteRule ^/login.htm /red9200.html RewriteMap map1 txt:/usr/webserver/conf/musiclist.map RewriteCond %{REQUEST_URI} ^/([^/]+).* RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] RewriteCond %{REQUEST_URI} ^/Music/LookupTag/(.*) RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] RewriteCond %{REQUEST_URI} ^/Music/MusicTag/(.*) RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] ProxyPreserveHost on Header set Server: HTTPServer/9.9 <Location /statusreport>  SetHandler server-status </Location> </VirtualHost> AddType application/x-x509-ca-cert .crt AddType application/x-pkcs7-crl    .crl SSLPassPhraseDialog  builtin #SSLSessionCache         dbm:logs/ssl_scache #SSLSessionCache        none SSLSessionCache         shmcb:logs/scache(256000) SSLMutex  file:logs/ssl_mutex SSLSessionCacheTimeout  300 SSLRandomSeed startup builtin SSLRandomSeed connect builtin listen 127.0.0.1:9201 <VirtualHost 127.0.0.1:9201> ServerName 127.0.0.1:9201 DocumentRoot '/usr/webserver/htdocs' <Directory '/usr/webserver/htdocs'>     Options +MultiViews     AllowOverride None </Directory> <Directory '/usr/webserver/cgi-bin'>     Options +MultiViews     AllowOverride None </Directory> <Location /statusreport> SetHandler server-status </Location> RewriteEngine On RewriteMap map1 txt:/usr/webserver/conf/musiclist.map RewriteCond %{REQUEST_URI} ^/([^/]+).* RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] RewriteCond %{REQUEST_URI} ^/Music/LookupTag/(.*) RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] RewriteCond %{REQUEST_URI} ^/Music/MusicTag/(.*) RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] ProxyPreserveHost on SSLEngine on SSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL SSLCertificateFile /usr/webserver/conf/cert.pem SSLCertificateKeyFile /usr/webserver/conf/file.pem <Files ~ '/.(jpq|exe|cgi|shtml|phtml|php3?)$'>     SSLOptions +StdEnvVars </Files> <Directory '/usr/webserver/cgi-bin'>     SSLOptions +StdEnvVars </Directory> Alias /myhelp '/usr/webserver/help' <Directory '/usr/webserver/help'>      Options ExecCGI MultiViews      AllowOverride None      Order allow,deny      Allow from all      SSLOptions +StdEnvVars </Directory> SetEnvIf User-Agent '.*MSIE.*' /          nokeepalive ssl-unclean-shutdown /          downgrade-1.0 force-response-1.0 </VirtualHost> listen 172.25.54.114:9201 <VirtualHost 172.25.54.114:9201> ServerName 172.25.54.114:9201 DocumentRoot '/usr/webserver/htdocs' <Directory '/usr/webserver/htdocs'>     Options +MultiViews     AllowOverride None </Directory> <Directory '/usr/webserver/cgi-bin'>     Options +MultiViews     AllowOverride None </Directory> <Location /statusreport> SetHandler server-status </Location> RewriteEngine On RewriteMap map1 txt:/usr/webserver/conf/musiclist.map RewriteCond %{REQUEST_URI} ^/([^/]+).* RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] RewriteCond %{REQUEST_URI} ^/Music/LookupTag/(.*) RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] RewriteCond %{REQUEST_URI} ^/Music/MusicTag/(.*) RewriteCond ${map1:%1|NONE} ^(http.*) [NC] RewriteRule ^(/.*) %1$1 [P] ProxyPreserveHost on SSLEngine on SSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL SSLCertificateFile /usr/webserver/conf/cert.pem SSLCertificateKeyFile /usr/webserver/conf/file.pem <Files ~ '/.(jpq|exe|cgi|shtml|phtml|php3?)$'>     SSLOptions +StdEnvVars </Files> <Directory '/usr/webserver/cgi-bin'>     SSLOptions +StdEnvVars </Directory> Alias /myhelp '/usr/webserver/help' <Directory '/usr/webserver/help'>      Options ExecCGI MultiViews      AllowOverride None      Order allow,deny      Allow from all      SSLOptions +StdEnvVars </Directory> SetEnvIf User-Agent '.*MSIE.*' /          nokeepalive ssl-unclean-shutdown /          downgrade-1.0 force-response-1.0 </VirtualHost>	Here is inforamtion from one of our developers:  While attempting to locate the cause for what appears to be a memory  consumption problem in the SSL code, the server segmentation faults. The first  worker child & all of its child threads continue to consume memory while the  parent stays the same or gets a little smaller.  The child threads never give  the memory back unless restarted.  Please advise if this is an expected  behavior.  Running with 'SSLSessionCache none' doesn't consume memory (and doesn't seg  fault), but it performs poorly when using 2048 bit keys.  I observed the segmentation fault issue in mod_ssl while running the small  script listed below.  Based on the stack information the issue appears to be  in shmcb_cton_memcpy() during an attempt to remove a session id.  The server  keeps on reponding, but all the child threads die and are restarted. I am not  sure what is happening, but the following variables seem to get corrupted:  The stack trace shows these are supposed to be:  src_offset=6402  src_len=10240  Inside the frame they have these values:  (gdb) print src_offset (in edi register) $55 = 3183473748   (gdb) print src_len    (in edx register)  $56 = 3183464512  The configuration file, and my initial debug session are attached.  Apache error_log ... [Mon Mar 15 11:21:33 2004] [notice] Apache/2.0.48 configured -- resuming  normal operations [Mon Mar 15 11:25:28 2004] [error] server reached MaxClients  setting, consider raising the MaxClients setting [Mon Mar 15 11:38:29 2004]  [notice] child pid 1065 exit signal Segmentation fault (11) [Mon Mar 15  12:06:28 2004] [notice] child pid 1154 exit signal Segmentation fault (11)  [Mon Mar 15 12:44:49 2004] [notice] child pid 1258 exit signal Segmentation  fault (11) [Mon Mar 15 13:04:40 2004] [notice] child pid 1315 exit signal  Segmentation fault (11) [Mon Mar 15 13:17:29 2004] [notice] child pid 1363  exit signal Segmentation fault (11) [Mon Mar 15 13:45:12 2004] [notice] child  pid 1401 exit signal Segmentation fault (11) ...  OS RedHat 7.3   gcc-2.96-113 glibc-2.2.5-43 openssl-0.9.6b-35.7  Apache 2.0.48 Build Script:  ./configure  --with-program-name=leakd --with-port=9200 --with-mpm=worker -- enable-ssl=shared --enable-maintainer-mode / --enable-proxy=shared --enable- cgi=shared --enable-setenvif=shared --enable-cgi=shared --enable-access=shared  / --enable-rewrite=shared --enable-dir=shared --enable-actions=shared --enable- mime=shared --enable-proxy_connect=shared / --enable-proxy_http=shared -- enable-negotiation=shared --enable-alias=shared --enable-env=shared --enable- dir=shared / --enable-mod-actions=shared --enable-log-config=shared --enable- imap=shared --enable-headers=shared / --enable-layout=webserver --disable- autoindex --disable-userdir --disable-usertrack --disable-cgid / --disable- asis --disable-auth --disable-auth_digest --disable-auth_dbm --disable- auth_anon --disable-dav / --disable-dav_fs --disable-vhost_alias --disable- unique_id --disable-speling --disable-cern_meta --disable-include / --disable- expires --enable-status=shared --enable-info=shared  ldd leakd:          libssl.so.2 => /lib/libssl.so.2 (0x40024000)         libcrypto.so.2 => /lib/libcrypto.so.2 (0x40052000)         libaprutil-0.so.0 => /usr/webserver/lib/libaprutil-0.so.0 (0x40119000)         libgdbm.so.2 => /usr/lib/libgdbm.so.2 (0x4012d000)         libdb-3.3.so => /lib/libdb-3.3.so (0x40133000)         libexpat.so.0 => /usr/lib/libexpat.so.0 (0x401c2000)         libapr-0.so.0 => /usr/webserver/lib/libapr-0.so.0 (0x401e1000)         libpthread.so.0 => /lib/libpthread.so.0 (0x40200000)         librt.so.1 => /lib/librt.so.1 (0x40215000)         libm.so.6 => /lib/libm.so.6 (0x40226000)         libcrypt.so.1 => /lib/libcrypt.so.1 (0x40247000)         libnsl.so.1 => /lib/libnsl.so.1 (0x40274000)         libdl.so.2 => /lib/libdl.so.2 (0x40288000)         libc.so.6 => /lib/libc.so.6 (0x4028c000)         /lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)   Simple script on external machine downloads copies of the stock Apache  index.html.en page under both unsecure & secure sites:  #!/bin/sh counter=0 limit=32000 while [ '$counter' -lt '$limit' ] do   wget -O - http://myboxaddr:9200   wget -O - https://myboxaddr:9201   counter="expr $counter + 1"   echo 'Count=> $counter' done  I added some log messages to the code, and turned on debugging.  I attempted to  using either SSLMutex  file:logs/ssl_mutex  or  SSLMutex  default.  It takes  longer with SSLMutex default to seg fault, but the stack trace is basically the  same.  The debug error_log traces are available for both test runs if you want  them.   Finally the src_offest & src_len variables are not changing.  GDB just doesn't  reset the registers when you move back in the stack frame. It seems to me that src_offset and src_len are getting corrupted somehow, but it's not  obvious to me where or how this is happening. The versions you're using of redhat,  glibc, gcc (etc) are a little dated. and though I'm reluctant to dismiss the issue as  being old tools, it would certainly be something to consider - if you're able to build  using a different gcc or mess with the optimisation levels, that might hint as to whether  this is compiler sensitive or something more macabre.    Also, is it possible to insert some debugging lines in the last two frames around the  problem area to dump the exact values being passed around? I'm curious how and  where those values are getting mangled. As/when you hit a segfault, it would be useful  to have something to help pinpoint where the corruption was introduced. (Another  possible hint: could those 'corrupt' values actually be some unsigned representation  of a negative - indicating a possible bug in the 'cyclic' logic?) I've added myself to the  CC line for this ticket, please let me know how you get on with this.    Logging messages were added into the function to print out the values for  src_len and src_offset, and they were actually not changing.  The seg fault is  in memcpy() frame #0. When you move back to frame #1 to examine things, gdb 5.2- 2 does not reload the registers.  Local variables were created inside the  function, and assigned the values src_offset & src_len upon entry. The end  result was the same (seg fault).  It could be the tools, but everything is fine  for 15-20 minutes.  The function is called 305 times before a failure with the  last three calls shown below:   CALLER == shmcb_remove_session_id() CALLED == shmcb_cyclic_cton_memcpy()  [Wed Mar 17 17:13:20 2004] [info] CALLER: header->cache_data_size=7190   src_offset=3972 src_len=10240 [Wed Mar 17 17:13:20 2004] [info] CALLED: buff_size=7190 src_offset=3972,  src_len=10240 [Wed Mar 17 17:13:20 2004] [info] CALLER: header->cache_data_size=7190   src_offset=7166 src_len=10240 [Wed Mar 17 17:13:20 2004] [info] CALLED: buff_size=7190 src_offset=7166,  src_len=10240   I have two debug traces. Ouch, ok - I have this gloomy sense that I'm about to dive back into apache code ...    I notice you're on apache 2.0.48 ... I could try to help track the problem in that version  and worry about migrating it (if applicable) to cvs after, but to avoid the potential for  logjams with other issues already fixed, are you able to move to 2.0.49, or better still,  CVS (head or 2.0.**-stable)? At the least, have you diffed the ssl module source  against later releases or CVS to check if any fixes have already been made that might  cover this?    Whatever you do w.r.t. apache versions - please email me a copy of the first few  pages of a *trace* log during startup (this should give me all the shmcb geometry  settings), and then the last few pages leading up to your first crash. I noticed from the  info you've already provided that you are caching sessions around ~10Kb, which  would indicate that you're using client-authentication and probably with some biggish  certs (or longish cert-chains). My hunch is that this is triggering some wrap-around  issue, either in the cyclic logic itself or in the use of variables of insufficient size.    Please mail me the details privately, no point drowning the bugzilla database. As/when  I have potential suggestions/fixes, how should we handle that? Can I send you diffs to  try? Can I shell to a box where this can be reproduced? Thanks again for the detailed  report.  Geoff's fix for this is now committed to HEAD and the 2.0 branch - thanks for the report, and thanks to Geoff for tracking it down.			Geoff Thorpe	Jeff Potter	Joe Orton	Ken Avery
27793	null	CLOSED		Russell Miller	1079665680000	1079867921000		MAXLINE too small in logresolver We have to make a local change to set MAXLINE to something at least 10 times  the size that it presently is (1024).  We consistently have entries that are  much larger than the default setting.    Perhaps this could be changed to something more reasonable in the default so we  don't have to maintain separate versions?	I just committed this change to 2.1-dev and have proposed it for merging back to 2.0.50-dev:  Index: support/logresolve.c =================================================================== RCS file: /home/cvs/httpd-2.0/support/logresolve.c,v retrieving revision 1.22 diff -u -r1.22 logresolve.c --- support/logresolve.c        9 Feb 2004 20:40:52 -0000       1.22 +++ support/logresolve.c        21 Mar 2004 11:12:02 -0000 @@ -90,7 +90,9 @@      /* maximum line length */ +#ifndef MAXLINE  #define MAXLINE 1024 +#endif    /* maximum length of a domain name */  #ifndef MAXDNAME  You can define MAXLINE to whatever you want outside of logresolve.c.  Something like this should take care of it:  CPPFLAGS='-DMAXLINE=99999' ./configure --other-opts 			Jeff Trawick
27811	null	CLOSED		S Page	1079738280000	1079991516000		' 1. Go to Apache site looking for info on server-side includes 2. Click Apache 1.3 Documentation link 3. Click 'Server Side Includes' link. 4. Start reading http://httpd.apache.org/docs/howto/ssi.html.  Awesome!  5. Stumble over ' variables we discussed in the last article (like LAST_MODIFIED, for example) '  Result: There's no indication I'm reading one of a series of articles in any sequence, there's no Previous link, and there's no link to this other article.  (And who's 'we', sucka :-)  Expected: Rewrite it, e.g. 'variables such as LAST_MODIFIED (discussed in _Apache Environments article_)', where you provide a link to this mystery article.  I'm not sure what this mystery article is, it doesn't seem to be http://httpd.apache.org/docs/env.html	Fixed in all versions.  Thanks for using Apache!			Joshua Slive
27834	null	RESOLVED		Pascal Terjan	1079952300000	1204029602000		Proxyied FTP directories without / generate wrong links in listing /foo/bar will list the contents with links that will be relative to /foo	Created an attachment (id=10894) A patch to add / using Location: when on a directory  This patch should be improved by preserving ; and following options and maybe other stuff Created an attachment (id=13844) Patch to add / (before ; if there is one)  This 3 years old bug is still there in 2.2.4. Is there any hope than someone have a look at it ? Backported to 2.2.x as r631360 (http://svn.apache.org/viewvc?rev=631360&view=rev).			Pascal Terjan	Ruediger Pluem
27862	null	CLOSED		chunyan sheng	1079996400000	1093635116000		Mod_rewrite leak memory in lookup_map If I am using rewritemap in my http.conf file,   RewriteMap map1 txt:C:/conf/hmmolist.map RewriteCond ${map1:%1|NONE} ^(http.*) [NC]  the 'RewriteCond' in  the 2nd line above in http.conf will call lookup_map()  which calls get_cache_string() for cached info, inside of function  get_cache_string(), the last statment is   return apr_pstrdup(c->pool, ce->value);  it is needed to be changed to    return ce->value; to avoid memroy leak.  I made the change myself, I don't see memory leak.	1.3 seems to have same problem   Looks correct.  I'm going to suggest inclusion into 2.0 and 1.3. 2.1 doesn't suffer from the issue, because the cache code was totally rewritten. FYI: The fix will be in 1.3.32 and 2.0.51.  Thanks!			Andr?? Malo	Jeff Trawick
27866	null	CLOSED		Arno Diekmann	1080030240000	1085496031000		content length is limited through usage of int It is not possible to store/retrieve unchunked data > 2 GB, since the content  length is handled as an integer. The RFC 2616 does not define this restriction. The attempt to PUT a file > 2GB results in a 400 Bad Request response.  Remark: A change from int to long has impacts to all depending SW as there is  mod_jp, tomcat, servlets, httpclient, etc.	It's already (read as) a long using strtol.  I'm wondering if should use strtoll if available. Any ideas? Interesting: yes, it should probably use apr_atoi64 and check for overflow if sizeof(apr_int64_t) > sizeof(apr_off_t) . Created an attachment (id=11125) support Content-Length as large as apr_off_t  Attached the patch I'm testing.  This only helps in 2.0, of course, if you're using a platform where apr_off_t is a 64-bit integer type. Fixed on HEAD.  If you're really after >2Gb file support on a platform with a 32-bit off_t, that's not going to happen in a 2.0.x release.  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/http/http_protocol.c?r1=1.479&r2=1.480			Andr?? Malo	Joe Orton
27886	null	CLOSED		Rolf Sponsel	1080091620000	1080529079000		t seem obey ServerRoot settings I just noticed for Apache 2.0.49, running on SPARC/Solaris, that if I change the ServerRoot directive of my default server in httpd.conf, whilest leaving the default (i.e. commented out) for the Scriptsock directive unchanged, the httpd daemon continues to create a 'cgisock' socket in the default 'apache2/logs' directory, even though all other entries (like logfiles, etc) are created relative to the new definition of ServerRoot.  I have verified this with to a minimum a modified httpd.conf file that I start manually with '/usr/local/apache2/bin/httpd -f /path/to/alternate/conf/httpd.conf -k start'.  Although this can easily be solved by explicitly adding the directive 'Scriptsock /path/to/alternate/logs/cgisock' to the 'httpd.conf' file, IMHO I consider this being a bug.	what does 'ServerRoot directive of my default server' mean?  default VirtualHost container, or the main settings outside of any VirtualHost directive?  looking at the mod_cgid code I can't see why mod_cgid wouldn't be influenced by the main ServerRoot setting (outside of any VirtualHost container), so I want to be sure what 'default server' means  note that there is a loosely-related mod_cgid bug: if you have ScriptSock directive inside VirtualHost, some funky stuff can happen; in fact mod_cgid should disallow that, as there is no cgid daemon per virtual host, and thus there is only one socket ignore previous comment; problem is easy to see ;) Funny, I was just about to clarify :-)  Best Regards, Rolf Sponsel Fixed in 2.1-dev.  Thanks for your report, and thanks for using Apache! 			Jeff Trawick	Rolf Sponsel
27928	null	CLOSED		Bojan Smojver	1080173160000	1081025823000		Simplification of mod_logio Just a little simplification of the output filter since having FLUSH just before EOS seems to work fine on 2.0.49.	Created an attachment (id=10967) Output filter simplification for mod_logio  Thanks Bojan, applied to 2.1 and proposed for backport.			Andr?? Malo	Bojan Smojver
27951	null	CLOSED		Vincent Deffontaines	1080235740000	1081186553000		RequestHeader directive cannot be made conditionnal of env vars On the process of setting up a [apache2] reverse proxy, it can happen that one needs to set a RequestHeader depending on some conditions.  It seems that, though the 'Header' directive accepts an env var as condition, this cannot be used with 'RequestHeader', which seems to be a 'missing' feature, at least in the case of a Reverse Proxy.  This is irrelevant for 1.3, as 'RequestHeader' is new in 2.0	Created an attachment (id=10995) Patch against modules/metadata/mod_headers.c  Created an attachment (id=10996) Suggested documentation update if patch is accepted.  Thanks. I've committed the change to HEAD (which your patch wasn't against, so I've modified it to match ;).			Andr?? Malo	Vincent Deffontaines
27985	null	CLOSED		Sven Koch	1080312600000	1093592544000		mod_rewrite adds a per-dir-prefix to proxy requests, all requests now return error 400 When using Apache 2.0.49 mod_rewrite with rewrite-maps on proxied requests, apache applies a false per-dir prefix and garbles the url.  Apache 2.0.48 was working as expected.   I have the following statements in my httpd.conf (simplified):  RewriteMap      proxy-map       prg:/usr/local/bin/proxy-map RewriteMap      local-map       prg:/usr/local/bin/proxy-local-map  <Proxy *>         RewriteEngine On         RewriteCond %{SERVER_ADDR} ^127/.0/.0         RewriteRule ^proxy:http://id/$ http://localhost/cgi-bin/id [R,L]         RewriteRule ^(.*)$ ${proxy-map:$1|$1}         RewriteCond %{SERVER_ADDR} ^127/.0/.0         RewriteRule ^(.*)$ ${local-map:$1|$1} </Proxy>  The output of RewriteLog on Level 9:  (3) [per-dir */] applying pattern '^proxy:http://id/$' to uri 'proxy:http://www.apache.org/' (3) [per-dir */] applying pattern '^(.*)$' to uri 'proxy:http://www.apache.org/' (5) map lookup OK: map=proxy-map key=proxy:http://www.apache.org/ -> val=proxy:http://www.apache.org/ (2) [per-dir */] rewrite proxy:http://www.apache.org/ -> proxy:http://www.apache.org/ (3) [per-dir */] add per-dir prefix: proxy:http://www.apache.org/ -> */proxy:http://www.apache.org/ (3) [per-dir */] strip per-dir prefix: */proxy:http://www.apache.org/ -> proxy:http://www.apache.org/ (3) [per-dir */] applying pattern '^(.*)$' to uri 'proxy:http://www.apache.org/' (4) RewriteCond: input='127.0.0.1' pattern='^127/.0/.0' => matched (5) map lookup OK: map=local-map key=proxy:http://www.apache.org/ -> val=proxy:http://www.apache.org/ (2) [per-dir */] rewrite proxy:http://www.apache.org/ -> proxy:http://www.apache.org/ (3) [per-dir */] add per-dir prefix: proxy:http://www.apache.org/ -> */proxy:http://www.apache.org/  Nothing in the error-log, and only the following in the access-log:  127.0.0.1 - - [26/Mar/2004:15:02:58 +0100] 'GET http://www.apache.org/ HTTP/1.1' 400 - '-' 'Mozilla/5.0 (X11; U; Linux i686; de-AT; rv:1.6) Gecko/20040312' 0 '-'	Hrm. That is a problem. mod_rewrite now treats the result string 'proxy:http://www.apache.org/' as a relative path, which was a bug fix in 2.0.49 (for some other example, but ...).  Frankly speaking, your rules depend on unsupported API internals, so you cannot expect that they work forever.  Anyway: Can you try what happens if you just take the rules out of the <Proxy> container? (That's even the next problem, mod_rewrite was never designed for use within <Proxy>). > Frankly speaking, your rules depend on unsupported API internals  I didn't even know that this setup was unsupported ;)  It worked with only minor changes (<Location proxy:*> changed to <Proxy *>) from a  very old apache 1.3 through 2.0.48 without problems.  I will try your suggestion on monday, when I can reach my test-box again.  I just tried your suggestion of placing the RewriteRules outside of <Proxy>:  The Rules are tested only for local connections, not for connections proxied through the apache. Thus they are called exactly when I don't need any rewriting.  I'm back to apache 2.0.48 for now.  Well, thanks. I'm investigating how to fix it somehow. I've nailed the problem in 2.1 and proposed it for backport into the 2.0 branch.  If you want to to try it out, here's a patch against 2.0: <http://cvs.apache.org/~nd/mod_rewrite.c.patch> Just a small follow-up:  Your patch fixes my problems with 2.0.49, the rewrite/filter rules are working again.  Thanks a lot.  Thanks for the feedback :-) This bug is in 2.0.50 too, and the same patch as for 2.0.49 still fixes it.  Well, the fix was finally reviewed and will be in 2.0.51.			Andr?? Malo	Sven Koch
28047	null	CLOSED		Artur Zaprzala	1080657360000	1081034711000		Segmentation fault for wildcard ExpiresByType and no Content-Type header. When some cgi script generates response without Content-Type header and in configuration file there is a directive with a wildcard in MIME-type, like this: ExpiresByType image/* 'now plus 1 week' ExpiresActive On  httpd dies with a message like this in error_log: ... [notice] child pid 11711 exit signal Segmentation fault (11)	Fixed in 2.1 and proposed for backport into the 2.0 stable branch.  Thanks for the report and thanks for using Apache.			Andr?? Malo
28063	null	CLOSED		Eider Oliveira	1080674640000	1092481195000		Missing parameter in ap_log_error and lack of NULL checking in child.c:1051 /* Kill remaining threads off the hard way */     if (threads_created) {         ap_log_error(APLOG_MARK,APLOG_NOTICE, APR_SUCCESS, ap_server_conf,                       'Child %d: Terminating %d threads that failed to exit.', my_pid); should be ==>>>      'Child %d: Terminating %d threads that failed to exit.', my_pid, threads_created);       }     for (i = 0; i < threads_created; i++) {         int *score_idx;         TerminateThread(child_handles[i], 1);         CloseHandle(child_handles[i]);         /* Reset the scoreboard entry for the thread we just whacked */         score_idx = apr_hash_get(ht, &child_handles[i], sizeof(HANDLE)); should insert ===> if (score_idx != NULL)         ap_update_child_status_from_indexes(0, *score_idx, SERVER_DEAD, NULL);             }	2.0.49 code has same issues The first part of the patch is clearly needed.  Can you verify that you had a crash that required the second change?  No problem here with a bit of defensive programming in case the code above changes, but since threads_created and hash table entries are created in lock step, I don't see how there could be no hash entry.  Curious!    I don't know why, but it crashed for me in this line. When I was looking into the code, I've found the first wrong line and subimitted both of them. I think it is related with pool cleanups. Nobody chimed in with an explanation for exactly why the 'if (score_idx != NULL)' is needed, so I would prefer not to commit that.  However, that's no reason to hold up the other fix, which should have been committed long ago.  Please re-open the PR if you find out why the extra check was needed.  Thanks for your fix! 			Eider Oliveira	Jeff Trawick
28112	null	RESOLVED		Rolf Sponsel	1080778020000	1193988982000		Directive SSLCACertificatePath mentions a Makefile for creating hash links that I cannot find The documentation for SSLCertificatePath mentions a Makefile that one should use to create the symbolic links for the certificate files in the directory, e.g. 'ssl.crt'. I cannot find such a Makefile in the Apache Httpd 2.0.49 distribution (probably missing from previous versions too), neither in the build directory, nor in the install directory. The makefile found in 'modules/ssl' doesn't make seem to be the one either, and there is non in the 'certs' directory of the build tree. Thus IMHO, neither the description of SSLCACertificatePath in the manual, nor the explanation of the directive in 'ssl[-std].conf' file seem to reflect the reality of today.  --- from the manual --- The files in this directory have to be PEM-encoded and are accessed through hash  filenames. So usually you can't just place the Certificate files there: you also have to create symbolic links named hash-value.N. And you should always make sure this directory contains the appropriate symbolic links. Use the Makefile which comes with mod_ssl to accomplish this task. -----------------------  Where can I find that makefile or a tool for creating those symbolic links? Shouldn't such a tool be installed in 'bin/' together with 'httpd' and 'apachectrl'?  Best Regards, Rolf Sponsel	I think this makefile is a relic of the days before mod_ssl was part of httpd.  Should we just remove the docs about it? This has been fixed in 2.0.  The update was applied to 2.2, and trunk already.  http://svn.apache.org/viewvc?rev=591348&view=rev  The changes should be visible within an hour or two.  Cheers, Tony 			Paul Querna	Tony Stevenson
28145	null	RESOLVED		Edward Rudd	1080866160000	1118788603000		APR_INCLUDEDIR and APU_INCLUDEDIR not being generated correctly the APR_INCLUDES and APR_INCLUDES in the file config_vars.mk  within the build directory are not being created correctly. They are pointing to the source directory, instead of the install directory.  ./configure /     --prefix=/opt/apache2 /     --enable-mods-shared=all /     --with-mpm=prefork /     --enable-ssl /     --with-ssl /     --enable-deflate /     --enable-cgid /     --enable-cache /     --enable-mem-cache /     --enable-file-cache /     --enable-disk-cache /     --enable-ldap /     --enable-auth-ldap /     --enable-logio /     --enable-exception-hook /     --with-ldap /     --with-berkeley-db=/usr/include/db42:/usr/lib /     --with-dbm=db42  But in the /opt/apache2/build/config_vars.mk, the APR_INCLUDES and APU_INCLUDES are always pointing to the source directory and not the /opt/apache2/includes directory.. This is a RH 7.3 system. (gcc 2.96)	Created an attachment (id=12564) generated config_vars.mk  It's APR_INCLUDEDIR and APU_INCLUDEDIR that are not generated correctly. Thanks for the report; now fixed on the trunk: http://svn.apache.org/viewcvs?rev=190392&view=rev			Edward Rudd	Joe Orton
28167	null	RESOLVED		Brian Pinkerton	1080932700000	1124917771000		t close the main socket immediately on receipt of a graceful restart If you're running Apache behind a load balancer, an effective way to stop Apache gracefully is to change the listen port to something else (say 81) and gracefully restart.  Long-lived downloads will continue (making modem users happy) but new connections will (in theory) be refused, allowing your load balancer to pick another box immediately.  After all connections finish or time out, Apache will stop.  That's the theory.  In practice, the child processes fail to close the main socket after receiving a graceful restart -- they keep the main socket open as well as the worker sockets that are actually doing the work.  The fix that I'm trying is to close all the listeners' sockets when the listener thread exits.  This seems to work, but I need to do some more testing before submitting diffs.	Any luck with the testing? Yes -- it worked well.  I'm no longer working for the company, though.  I'll get someone to send me  the diffs so I can post them. Here are the diffs from .48.  Very straightforward.  This server is in heavy use and we haven't seen  any problems with it yet, and graceful restarts close the main socket correctly.  ==== //depot/httpd-2.0.48-src/server/listen.c#2 (text) ====   @@ -387,6 +387,11 @@      return num_open ? 0 : -1;  }  +void ap_close_listeners() +{ +\t(void) close_listeners_on_exec(0); +} +  int ap_setup_listeners(server_rec *s)  {      ap_listen_rec *lr;    ==== //depot/httpd-2.0.48-src/server/mpm/worker/worker.c#2 (text) ====   @@ -857,6 +857,9 @@          }      }  +\t/* bp: stop listening to the main socket(s) */ +\tap_close_listeners(); +\t      ap_queue_term(worker_queue);      dying = 1;   note to self: Investigate adding this to the Event MPM. close enough to a .patch This has been fixed on the trunk.  http://svn.apache.org/viewcvs?rev=239711&view=rev And then fixed for worker in;  http://svn.apache.org/viewcvs?rev=239740&view=rev			Brian Pinkerton	Colm MacCarthaigh	Joe Orton	Paul Querna
28174	null	CLOSED		Rolf Sponsel	1080956760000	1081633963000		Optionally allow specifying an URL as the argument to directive ServerAdmin. The directive 'ServerAdmin' today allows you to specify an email address whereto problems with the server should/could be emailed. This address is displayed in various places, e.g. on server generated pages, such as error documents.  Considering the widely mis-use of email addresses, collected by harvesting the internet in various ways, for e.g. mass-mailing, spamming, etc, I would like to have the possibility to optionally specify an URL instead of an email address that should be displayed instead. E.g. 'https://somedomain.name/contact', instead of 'contact@somedomain.name', which for example could present a mail form that the user could fill in. Thus there would be no need to expose an email address for this purpose. Of course, such an URL should ideally point to another server, because this server might present the errror response page (showing that  'serveradmin' url due to not being able to process such a form. But that decision should of course be left to the administrator to decide on.  I can, almost, achive this already with todays implementation (Apache 2.0.49) by specifying an URL to the 'ServerAdmin' directive, but such an URL will automatically get the 'mailto://' protocol prefix prepended, e.g. in customized error responses.  Therefore I'd like to suggest the following implementation, and thereby retaining backward compatibility; whenever a URL is given as the argument to the 'ServerAdmin' directive the argument should be presented to the user as specified (or at least constitute the 'href' of a link presented to the user, i think it's someting like webmaster, or so today). If the argument is NOT an URL then it should be assumed it's an email address - just as today. In this way one is allowed to explicitly specify 'mailto://admin@domain.name', as an alternative to the implicit 'admin@domain.name' too (if one would prefere).  This feature could help to reduce the amount of unsolicited emails sent to the otherwise exposed email address, and thereby hopefully allow the administrator(?) to focus on the important issues/emails instead of wading through all the junk. This kind of 'redirection', instead of using email addrsses, is becoming more an more popular for use in SSL server certificates too.  Best Regards, Rolf Sponsel	Hmmm... Why don't you just use ErrorDocument to customize the error responses.  That way you can have whatever you want.  The ServerAdmin should really be used only as a fallback when all else has failed.  And in that case, giving a URL (especially if it is on the same server) could be a big mistake.  But the real argument here is why add complexity when there is already a way to accomplish what you want? That is all fine - as long as - the only place where ServerAdmin is used/shown on a page is on the customized error pages AND does not use it for anything else, neither now nor in the future.  If this is NOT the case, IMHO this would be a minor, but useful, modification. It only requires that the argument to 'ServerAdmin' is checked for whether it's an URL, i.e. contains a string sequence '://'; otherwise the argument is prepended with that same 'mailto://' prefix as today. Not much of complexity it seems to me - is there?  Well, as I mentioned, one point of the ServerAdmin is to have a contact if all else fails.  Using a webpage for that sounds like a bad idea. ie: 500 server error, please see this other page, which also generates a 500 server error. What can I say?  I think you need to re-read my initial posting one more time. No offence please!  As I wrote in my initial posting:  '... Thus there would be no need to expose an email address for this purpose. Of course, such an URL should ideally point to another server, because this server might present the errror response page (showing that 'serveradmin' url due to not being able to process such a form. But that decision should of course be left to the administrator to decide on.'  I think your 'last post' doesn't present anything new in addition to what already has been pointed out before - right?  I accepting new ideas and suggestions from others, then fine. Then I don't have to waste my time. There are a lot of other software projects that welcome my contributions and ideas.  I have suggested this new feature due to having identified it's usefulness, and becuse it would be useful to me, it might(!?) be useful to others to.     Calm down a little Rolf.  I thought we were discussing the merits of the idea.  If I thought it was a hopeless idea, I would have closed the bug report.  Personally, I don't see a big benefit from this, and I do think it would be too tempting for people to put a URL on the same server.  But some of the developers may disagree.  Of course, ideas are much likely to be acted upon if they come with patches. To come to an end: I've the changed the two lines of code ;-) I'm happy to see that it didn't require any major changes to accomplish. I hope this will be useful to others too.  Thank You!  Best Regards, Rolf Sponsel 			Andr?? Malo	Joshua Slive	Rolf Sponsel
28204	null	CLOSED		Erik Weidel	1081168500000	1089444031000		[PATCH] ab: does not handle urls that are too long In apache bench is no checking if the length of the url given in the commandline matches the size of the internal request buf (variable _request).  So the sprintf causes a buffer overflow. In my case this overwrote the variable  containing the port so I could not connect to the server.  I patched this to use the apr_snprintf function and exit with an error 'request too long'. I also increased the buffer size for the request to 2048 because 512 was too small for my tests.  Index: ab.c =================================================================== RCS file: /home/cvspublic/httpd-2.0/support/ab.c,v retrieving revision 1.143 diff -u -r1.143 ab.c --- ab.c        25 Mar 2004 00:05:00 -0000      1.143 +++ ab.c        5 Apr 2004 12:31:15 -0000 @@ -313,7 +313,7 @@  apr_time_t start, endtime;   /* global request (and its length) */ -char _request[512]; +char _request[2048];  char *request = _request;  apr_size_t reqlen;  @@ -1534,6 +1534,7 @@      apr_int16_t rv;      long i;      apr_status_t status; +    int snprintf_res=0;  #ifdef NOT_ASCII      apr_size_t inbytes_left, outbytes_left;  #endif @@ -1568,7 +1569,7 @@       /* setup request */      if (posting <= 0) { -       sprintf(request, '%s %s HTTP/1.0/r/n' +        snprintf_res = apr_snprintf(request, sizeof(_request), '%s %s HTTP/1.0/r/n'                 'User-Agent: ApacheBench/%s/r/n'                 '%s' '%s' '%s'                 'Host: %s%s/r/n' @@ -1581,7 +1582,7 @@                 cookie, auth, host_field, colonhost, hdrs);      }      else { -       sprintf(request, 'POST %s HTTP/1.0/r/n' +        snprintf_res = apr_snprintf(request,  sizeof(_request),'POST %s HTTP/1.0/r/n'                 'User-Agent: ApacheBench/%s/r/n'                 '%s' '%s' '%s'                 'Host: %s%s/r/n' @@ -1596,6 +1597,9 @@                 cookie, auth,                 host_field, colonhost, postlen,                 (content_type[0]) ? content_type : 'text/plain', hdrs); +    } +    if (snprintf_res >= sizeof(_request)) { +        err('request too long');      }       if (verbosity >= 2)	Patch commited to 2.1 CVS.  Thanks for using Apache!  -Paul Querna			Paul Querna
28218	null	CLOSED		Kevin J Walters	1081202760000	1086216623000		errors in regular expressions for LocationMatch cause silent failures We discovered a Location block that was not working in one of our apache  configs and one of the few changes was the addition of a slightly broken  looking regular expression which featured something like this  <Location ~ ^/something/||^/something-else/>  </Location>  The problem turned out to be the ||. I had a quick glance through the code and  it reads like the regular expression library doesn't like this and regards it  as an error (i note solaris egrep errors, perl thinks its ok). The problem is  that this error is not reported to the user so the configuration appears to be  ok when the process is started. I think this is both confused to the naive  configuration creator and potentially dangerous if the Location block contains  some critical (say, security-related) directives.  It looks like the (handful of) ap_pregcomp calls in http_core.c do not check  for a NULL return code that would indicate a failed compilation. So this affects Location ~, LocationMatch, Directory ~, DirectoryMatch, Files ~,  FilesMatch.  Perhaps this problem exists in apache 2.0 as well? And maybe other areas of  apache 1.3 (not mod_alias, just had a look there!).	Thanks. Indeed it exists also in 2.x (even in more places). It's fixed now in 2.1 and proposed for backport into the stable branches.  Thanks for the report and thanks for using Apache. The fix will be in the next stable versions. (1.3.32 and 2.0.50).			Andr?? Malo
28287	null	CLOSED		Joshua Slive	1081445940000	1086217779000		No way to find if suexec is enabled Contrary to 1.3 and to the suexec docs: http://httpd.apache.org/docs-2.0/suexec.html#enable there is no easy way to find out if suexec is enabled. There is no message written to the error log, and no mention of suexec in httpd -l or -v or -V (other than the path to the suexec binary).  This makes it much harder to debug cgi problems.	Uhm, there's a message written into the error log, but unfortunately it may be wrong. After an accompanying APR patch (to determine the setuid bit) this is fixed in 2.1 now. Fixed in latest APR/httpd.			Andr?? Malo
28310	null	RESOLVED		Florian Effenberger	1081516800000	1193993016000		--enable-mods-shared=all does not build all modules --enable-mods-shared=all does not build all modules. At least ssl and proxy have  to be explicitly set via --enable-ssl and --enable-proxy.	Do we want to change this?  I assume SSL is not enabled for crypto reasons?  Why is mod_proxy not enabled? I recently compiled 2.0.50.  None of ssl, deflate, proxy, proxy_http, cache, mem_cache, nor disk_cache were enabled with the --enable-mods-shared=all.  (I suspect there are other modules as well.)  The documentation for the configure step says that --enable-mods-shared=all enables all modules.  It seems reasonable to me that it would compile mod_ssl iff I specified --with-ssl and mod_deflate iff I specified --with-z. This is s documentation bug, until we get the nerve to change what this really means. The missing modules are documented on the wiki[1]. I'll translate that page for  /manual/programs/configure.html once I've cleaned it up (it references old module names still).  [1] http://wiki.apache.org/httpd/ConfigAllMods Florian,  This has been fixed in /trunk/[1] and back-ported to /2.2/[2]  [1]http://svn.apache.org/viewvc?rev=591370&view=rev [2]http://svn.apache.org/viewvc?rev=591365&view=rev  These changes should be visible within a few hours.  Thanks, Tony  Thanks a lot!			Florian Effenberger	M. 'Alex' Hankins	Paul Querna	Tony Stevenson	Vincent Bray
28459	null	CLOSED		Rolf Sponsel	1082330820000	1082406559000		 to represent an exclamation mark. First I must admit that it's very surprising to me, considering there are more than 400 million potentional users, that nobody has reported this issue.  None of Mozilla 1.5, Mozilla 1.6, and Konqueror 3.1.3 (which to my knowledge is not Gecko based and thus makes me believe that this actually is an error in Apache) do render '&excl;' as '!'. See TITLE of spanish (es) translations.   Is '&excl;' really an acknowledged name for representing a '!' (i.e. &#033;)?  Other languages use the exclamation mark '!' explicitly in their translations, e.g. german, french, swedish, etc.  Therefore an explicit exclamation mark '!' should be fine for spanish too.  Best Regards, Rolf Sponsel	Thanks :-)  &excl; is not defined by the W3C, so I've just replaced it by !. As we dealing with these things; there is actually another related issue.  I'm not sure if it's a Mozilla only thingie though, or if it's a general one. Theses spanish sentences - of course - use have the inverted exclamationmark (i.e. an '!' upside down), in these files represented by '&iexcl;'. Although this probably generally does work when used in web-pages rendered with standard compliant browsers; this does not work, i.e. it gets rendered litterally as '&iexcl;', when used in the <TITLE> - at least not for Mozilla. Would that be a bug in the implementation of the standard in Mozilla or another oversight (in Apache)?  Best Regards, Rolf Sponsel   Ps. Pardon me re-opening an already fixed bug, but I thought it was that related that I didn't wan't to file a separate report for it. Ds.  No problem. Still an error at our side :-(. We encoded the title again. Fixed in CVS now.  Thanks again.			Andr?? Malo	Rolf Sponsel
28492	null	CLOSED		Henning Schmiedehausen	1082454360000	1093634085000		 statements When including a directory of configuration files, the reference must not contain a symbolic link. I e.g. have the following case:  /mnt/disk0/www.server1/<lots of virtual servers>.conf /mnt/disk0/www.server2/<lots of virtual servers>.conf  /virtual/www.server1 --- symbolic link --> /mnt/disk0/www.server1/ /virtual/www.server2 --- symbolic link --> /mnt/disk0/www.server2/  If I put  Include /mnt/disk0/www.server1/*.conf  into httpd.conf, it works. If I put  Include /virtual/www.server1/*.conf  into httpd.conf, it works not. In the strace of the httpd process, it is visible that apache tests, whether the /virtual/www.server1 reference is a directory but gets an error and halts.   Apache should test, whether an include reference is a symbolic link and if yes,  test its target to be a directory.	That is by intention in order to avoid infinite loops. It just needs to be better documented. Sorry to bother you, but IMHO this is still a bug.  We e.g. have a scenario where this include link points to an NFS mounted directory which can change due to failover reasons. This is how I found the problem. Basically I have a Include '/virtual/foo/*.conf' and the foo can be dynamically change doing a failover and a httpd restart. Our current solution rewrites the config files using sed and is awkward at best (pun intended).  Can we have an IncludeFollowLinksYesIveReadTheManualAndKnowAboutPossibleLoops directive? :-)  (Would you accept patches?)  For content we have 'FollowSymLinks'.Why not the same thing for the configuration?  I've finally found a way to stop include directive recursion (by using the pool context). So I no longer see a need for the symlink stopper at all, hence I'm going to patch it out. (just replacing ap_is_rdirectory with ap_is_directory in ap_process_resource_config and process_resource_config_nofnmatch).  The recursion stopper is currently in 2.1 and proposed for backport into 2.0. Thanks a lot! This will really help me with our HA environments and future releases of the httpd. FYI: The fix will be in 2.0.51. *** Bug 31099 has been marked as a duplicate of this bug. ***			Andr?? Malo	Henning Schmiedehausen
28523	null	CLOSED		Edward Rudd	1082583060000	1082666809000		ap_set_sub_req_protocol not exported on win32 the core function ap_set_sub_req_protocol is not exported for win32 builds of apache 2, but is on unix builds.  AP_DECLARE should be wrapped around the void on line 983 of server/protocol.c  -ap_set_sub_req_protocol(request_rec *rnew, const request_rec *r) +AP_DECLARE(void) ap_set_sub_req_protocol(request_rec *rnew, const request_rec *r)  i am using this function in my mod_ftpd module at the URL in the bug report. svn repository is here.. http://svn.outoforder.cc/svn/mod_ftpd/trunk/ where I have my *quick hack* to get it compiling on win32 by including that function in a separate file (win32.c).	done in 2.1 and proposed for backport. Thanks for nagging :) isnt then also a fix needed to the prototypes in ./include/http_protocol.h ?  yeah.. Just checked CVS and I  do believe the prototypes should be updated in the http_protocol.h file as well.. done.			Andr?? Malo	Edward Rudd	Guenter Knauf
28529	null	CLOSED		Dan	1082609940000	1086986984000		acceptex used on win9x The following error is reported in the error log:  [Thu Apr 22 00:28:21 2004] [error] (OS 10045)Operation not supported on socket: Child -380197: Encountered too many errors accepting client connections. Possible causes: Unknown. Try using the Win32DisableAcceptEx directive.  This is continually logged and essentially hangs the system on a new install. Even though I checked the install option for 'single user - manual start', the installation process starts apache with 250 child processes all reporting this error.  After adding 'Win32DisableAcceptEx Off', apache is runs ok	Then it's cool. And it works like expected. Thanks for the info. I was under the impression that AccepEx was automatically disabled for Win9x-based platforms.  Is that not the case? Hmm, no. And I see no reason why it should? I could be wrong (since I've never done an inch of windows socket programming), but I thought that acceptex was not available on win9x.  [Googling...]  Yes, this page http://msdn.microsoft.com/library/default.asp?url=/library/en-us/winsock/winsock/acceptex_2.asp seems to confirm that.  And I thought that windows mpm used to automatically disable it for win9x. My apologies, you're right. The Win32DisableAcceptEx thing dropped the automatic selection. Well... *** Bug 27920 has been marked as a duplicate of this bug. *** Fixed in 2.0.50-dev.			Andr?? Malo	Joshua Slive
28573	null	CLOSED		Rolf Sponsel	1082848500000	1101095901000		 href in doc of SSLRequire directive The source '<a href='#table3'>Table 3</a>' in the URL supplied, is missing the corresponding target in that same page.  I guess it should point to the varialbes section, following the example section, at the end of the documentation of the 'SSLRequire' directive.   Best Regards, Rolf Sponsel	Should be fixed now. Committed revision 106144 with a patch. table1 and table2 were also affected.			Rich Bowen
28581	null	RESOLVED		Rolf Sponsel	1082907000000	1115173567000		No matching ErrorDocument directive for HTTP_NOT_ACCEPTABLE in httpd[-std].conf JFYI,  There is no matching 'ErrorDocument ### /error/HTTP_NOT_ACCEPTABLE.html.var' template directive for the HTTP_NOT_ACCEPTABLE page included in the 'error/' directory.  Either it's not to be used (and thus should be removed), or has been omitted from the default 'httpd[-std].conf' file by accident.   Best Regards, Rolf Sponsel	Thanks, this is now fixed. Actually, I backed this out and removed the error doc, because it can't provide as much info as the internal error doc can.			Joshua Slive
28673	null	CLOSED		sebastien	1083188400000	1097581416000		mod_deflate compilation error with zlib 1.2.1 i have a compilation error with mod_deflate and zlib 1.2.1  here is my compilation options : ./configure / --prefix=/usr/local/apache-2.0.49 / --enable-so / --with-ssl='/usr/local/ssl' / --with-z='/usr/local/zlib-1.2.1' / --enable-proxy=shared / --enable-ssl=shared / --enable-deflate=shared / --with-mpm=worker  here is the compilation error : In file included from /usr/include/zutil.h:16,                  from mod_deflate.c:42: /usr/include/zlib.h:68: redefinition of "struct z_stream_s' /usr/include/zlib.h:705: conflicting types for "gzwrite' /usr/local/zlib-1.2.1/include/zlib.h:982: previous declaration of "gzwrite'  in mod_deflate.c, there is that : #include 'zlib.h'  #ifdef HAVE_ZUTIL_H #include 'zutil.h' #else (...)  i think #ifdef HAVE_ZUTIL_H should be replaced by #ifndef HAVE_ZUTIL_H (it works with #ifndef)	Confirmed errors building mod_deflate from 2.0.50dev and 2.1dev from May 23 for netware.  Works fine with zlib 1.1.4 Works fine for me with zlib 1.2.1 on Linux, with both 2.0.49 and 2.1.0.  You used --with-z='/usr/local/zlib-1.2.1' ; I didn't - because 1.2.1 is my installed zlib.  So I wonder if what you've seen is a config problem?  Regarding the confirmation on netware, we've had some relevant patches recently from the netware folks.  Perhaps you could check if you[anyone] still have a problem? I corrected my problem myself by replacing #ifdef HAVE_ZUTIL_H, but if i am  the only one with this 'problem', it doesnt matter. maybe it's a config problem with zlib :) I get the same error with 2.0.52 under the following circumstances:  I have the zlib-devel-1.1.4 package installed on my system (SuSE Linux 8.2). This comes with the file zutil.h installed in /usr/lib. Although this is a file considered internal to zlib, it is obviously used by some applications (like apache). This is probably the justification for it being installed.  Now, I want to use a newer zlib with my httpd. I installed zlib 1.2.1 myself in $HOME/gnu. The 'make install' in the zlib sources does not install zutil.h (as the zlib authors consider it internal to zlib)!   Now, if I configure apache with --with-z=$HOME/gnu, the apache configure script will find zlib.h under that path, but will find the preinstalled zutil.h from the old zlib 1.4.1 in /usr/include !! This mix will lead to the compile error.  I am helping myself with manually copying the new zutil.h to $HOME/gnu/include.  If apache really needs zutil.h, the configure script should only look for it under the path given with --with-z, if that has been passed.  The real solution though is probably not to use zutil.h at all. Some discussion about this seems to have taken place: http://www.mail-archive.com/dev@httpd.apache.org/msg01883.html Thanks for the report - this is now fixed on HEAD:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/filters/mod_deflate.c?r1=1.58&r2=1.59  			Bernd	Joe Orton	Nick Kew	Rodney Crossman	sebastien
28732	null	CLOSED		Ville Skytt	1083523260000	1083727877000		Manual spelling fixes Will attach a patch containing misc spelling fixes to the manual.	Created an attachment (id=11404) Spelling fixes etc  commited to 2.1-dev and 2.0.50-dev  thanks for your submission! 			Jeff Trawick	Ville Skytt
28898	null	CLOSED		dankogai@dan.co.jp	1084280520000	1095082897000		 4GB) for platforms w/ 32-bit size_t and 64-bit off_t Dear Apache Developers,  My name is Dan Kogai and I thank you for your great product.  That definitely makes the world go round!  I just found that Apache, both 1 and 2, does not support files that are larger than 2GB.  Apache 2 does support it but only on (truly) 64-bit systems.  On such systems (I would even say majority thereof) where large files are supported (off_t is 64-bit) but size_t is limited to 32-bit, it does not work.  I browse the source and found that while apr_off_t is correctly used APR-wise, many calculations that contain apr_size_t variables led to incorrect values.  The quick & dirty proof-of-concept patch below does fix the problem.  Tested OK on FreeBSD 4, Mac OS X v10.3.  Compiled on Linux kernel 2.4.9 but rerurns 400 with log entry '[client 127.0.0.1] (75)Value too large for defined data type: access to /dvd.dmg failed'  As I said this is way too quick and dirty and I would appreciate if you guys fix that more properly and elegantly.  It may sound ridiculous to handle such large files but I happen to be a member of Ring Server Project which hosts one of the most famous open source distribution and there appears DVD images that get influenced.  Thank you in advance for your attention and support.  Dan the Man with Too Many File Transfers  --- httpd-2.0.49/srclib/apr/include/apr.h.in    Sun Feb 29 03:41:32 2004 +++ httpd-2.0.49-x/srclib/apr/include/apr.h.in  Tue May 11 21:27:31 2004 @@ -263,7 +263,7 @@  typedef  @long_value@            apr_int64_t;  typedef  unsigned @long_value@   apr_uint64_t;   -typedef  @size_t_value@          apr_size_t; +typedef  @off_t_value@           apr_size_t;  typedef  @ssize_t_value@         apr_ssize_t;  typedef  @off_t_value@           apr_off_t;  typedef  @socklen_t_value@       apr_socklen_t;	Can you precisely describe the issues you see on platforms with a 32-bit size_t and a 64-bit off_t? Joe Orton,  Thank you for your response.  This is what happens;  ls -l /ring/ftp/4gb-test.dmg  -rw-r--r--  1 root  mirror  4699983872 May 11 22:45 /ring/ftp/4gb-test.dmg  HEAD http://localhost/4gb-test.dmg 200 OK Connection: close Date: Fri, 14 May 2004 02:26:47 GMT Accept-Ranges: bytes Server: Apache Content-Length: 405016576 Content-Type: application/octet-stream ETag: '6-18241000-557d0100' Last-Modified: Tue, 11 May 2004 13:45:08 GMT Client-Date: Fri, 14 May 2004 02:26:46 GMT Client-Peer: 210.159.71.23:80  As you see,  * Content-Length: shows only lower 32-bit thereof * File transfer fails accordingly (only 405,016,576 bytes of actual 4,699,983,872 bytes gets downloaded in the example above).  Dan the Truncated Man    Interesting.  That's a bug, but I can't reproduce it with HEAD on a 32-bit Linux using apr_off_t = off64_t, apr_size_t = size_t.  $ HEAD http://localhost:8900/big/bigfile | grep Content-Length Content-Length: 3145728000  so it's something more subtle.  Does the correct file size get logged to access_log if you GET the file?  Does autoindex show the correct size for the file in a directory listing? BTW, your HEAD test was with 2.0, I presume.  1.3 uses long rather than off_t for file sizes everywhere, so you're always limited by sizeof(long) in 1.3 even if sizeof(off_t) == 64. > $ HEAD http://localhost:8900/big/bigfile | grep Content-Length > Content-Length: 3145728000  I don't think it's big enough.  It's definitely larger than MAX_INT but well within UMAX_INT, which nicely fits in 32-bit.  3145728000 = 0xbb80_0000 < 0xffff_ffff  FYI to make large files quickly (and sparsely), you can go like    perl -e 'truncate shift, shift' file size  or    truncate -s size file  if your platform has trucate(1).  > BTW, your HEAD test was with 2.0, I presume.  Correct. 1.3.x hardcodes them all 'long' while 2.0.x uses apr_*.  Dan the Truncated Man   > Does the correct file size get logged to access_log if you GET the file?    With my (quick & dirty) patch, yes.  w/o, no.  > Does autoindex show the correct size for the file in a directory listing?  Yes, with or without the patch.   dvd.dmg                 12-May-2004 00:07  4.4G    Dan  Well, since off_t is signed any size >2Gb would fail, if at all... it works the same here for me using >4Gb sizes too (again, using HEAD with apr_off_t==off64_t, which should be equivalent to a FreeBSD system with apr_off_t==off_t where sizeof(off_t) == 8).  So I don't know what bug you're seeing here, it would be great if you could debug it, i.e. work out if apr_stat() is determining the size correctly, and work on up... > Well, since off_t is signed any size >2Gb would fail, if at all...  > it works the same here for me using >4Gb sizes too  The problem is sizeof(apr_off_t) > sizeof(apr_size_t) in those platforms while there are many places where apr_off_t objects are computed against apr_size_t objects.  We already have learned that forcibily making apr_size_t 64-bit off-t fixes the problem (in some platforms).  Oh, I have chenged the summery from '2GB' to '4GB' to be more precise.  > it would be great if you could debug it  Yikes.  I know HOW it went wrong but WHERE to fix is another problem.  Since it is size-related, that may even lead to changes in *.h, meaning API changes and that'way too much for me.    > i.e. work out if apr_stat() is determining the size correctly,  > and work on up...  That's not the only problem.  Anywhere apr_off_t is used in conjunction w/ apr_size_t are vulnerable.  i.e apr_bucket_read().  Dan the Apache *User* (and love to stay that way)   In Mac OS X, I later found that while Content-Length: header was correct w/ the previous patch, the actual file transfer gets trucated.  The following patch to emulate_sendfile() in server/core.c fixes that (YOU STILL NEED MY PREVIOUS PATCH).   I wonder why FreeBSD did work. Maybe because it was tested w/ truncated (sparse) file.  There on Mac OS X I have used the actual DVD image file for testing uI also applied byte-to-byte exhaustive file comparison as well as md5 sum to make sure the transferred file is identical to the original.  That explains reason why my patch did not quite work on Linux.  On Linux APR_HAS_SENDFILE is set and emulate_sendfile() is never used.  Dan the Typedefed Man  --- httpd-2.0.49/server/core.c  Tue Mar  9 07:54:20 2004 +++ httpd-2.0.49-x/server/core.c        Mon May 17 02:00:53 2004 @@ -2949,7 +2949,7 @@                                       apr_size_t length, apr_size_t *nbytes)  {      apr_status_t rv = APR_SUCCESS; -    apr_int32_t togo;        /* Remaining number of bytes in the file to send */ +    apr_off_t togo;        /* Remaining number of bytes in the file to send */      apr_size_t sendlen = 0;      apr_size_t bytes_sent;      apr_int32_t i;  Ah, nice work, yes, I see the issue here too with 'EnableSendfile off'.   Can you try this patch - *without* your apr_off_t = size_t hack:  http://www.apache.org/~jorton/ap_splitlfs.diff > Can you try this patch - *without* your apr_off_t = size_t hack:  Yay!  Seems like it's working now.  Both HEAD and GET works fine.  Maybe we still need to check on (HTTP/1.1) partial transfers but this is a significant progress.  Thank you so much!  Dan the Untruncated Man  Joe,  I am just curious if subbuckets also needs to turn off mmap (just to be sure).  Here's the patch AGAINST YOURS that does that.  Dan the Munmapped Man  --- server/core.c       Tue May 18 00:16:34 2004 +++ server/core.c.old   Tue May 18 00:15:37 2004 @@ -3488,11 +3488,6 @@              while (fsize > AP_MAX_SENDFILE) {                  apr_bucket *ce;                  apr_bucket_copy(e, &ce); -#if APR_HAS_MMAP -               if (d->enable_mmap == ENABLE_MMAP_OFF) { -                   (void)apr_bucket_file_enable_mmap(ce, 0); -               } -#endif                  APR_BRIGADE_INSERT_TAIL(bb, ce);                  e->start += AP_MAX_SENDFILE;                  fsize -= AP_MAX_SENDFILE;  That patch is reversed... hmmm, probably.  Actually it won't make any difference, since the file buckets are only mmap'ed if they are smaller than 4Mb, and here we're creating 16Mb buckets. The patch is now committed for 2.1.  Thanks for the report.			Joe Orton	dankogai@dan.co.jp
29003	null	CLOSED		Edward Rudd	1084602300000	1086388971000		Ifmodule to allow the symbol name and/or .SO name along with .C name A nice extension to the IfModule directive would be to allow it to compare against the symbol name (rewrite_module) or the .so name (mod_rewite.so), instead of only relying in the .c name (mod_rewrite.c).. This will make it easier to write a config file for modules while have the core .c named something else (ie. sapi_apache2.c).	Agreed. This disturbes me all the time, too :-) I see several ways of solving this issue. 1) Create an Ifsymbol directive which is analogous to IfModule except it searches mod_so's internal dynamically loaded modules (moduleinfo structs). 2) Similar to 1 and have IfModule call a function in mod_so (via an optional function) to search mod_so's internal list of dynamically loaded modules. 3) Alter the STANDARD20_MODULE_STUFF macro to take one paramter which is the *filename* to register.. (ie.. for sapi_apache2.c sepcify mod_php4.so instead) This can be setup as a NAMED macro and have the standard one call the NAMED with __FILE__ to retain backword compatability. 4) provide an function to be called by a modules register_hook function to register alternate names and have the ap_find_linked_module search this list as well.  Created an attachment (id=11620) Patch for solutions 1 and 2  Created an attachment (id=11621) patch for solution number 3.  Set PatchAvailable  I still need to work up a patch for solution number 4.  Created an attachment (id=11670) Mixed variant  I've attached a patch against HEAD partially based on yours which leaves it all to <IfModule>, but also resolves the static stuff.  Opinions? Created an attachment (id=11685) Updated patch switching mod_so.c to use the ap_module_symbol_t structure  It looks good.. and solves the issues I brought up before.. my updated patch just has mod_so use ap_module_symbol_t instead of it's privately declared version of that structure (moduleinfo) no need to have two copies of the same structure.  I think this solves the issue completely, I'm up for bringing it up for a vote on dev@httpd.  +1.  (plus that the build processes for win32 and netware need to be updated). Created an attachment (id=11690) win32 patches  Committed, since nobody cried. The build is broken now on Netware, but I assume, it will be fixed soon.			Andr?? Malo	Edward Rudd
29098	null	RESOLVED		Brock Bland	1084988220000	1150960391000		Problem with HTTP status header being truncated I have an ISAPI extension that I'm testing with Apache.  When logging the HTTP traffic I noticed that my HTTP status headers were being truncated.  Ex:  HTTP/1.1 200 O     instead of   HTTP/1.1 200 OK HTTP/1.1 302 Obje  instead of   HTTP/1.1 302 Object Moved HTTP/1.1 401 Acce  instead of   HTTP/1.1 401 Access Denied  I dug through the code and found a couple of problems with send_response_header in mod_isapi.c.  On line line 679 I made the following change:  statlen = toklen; // Instead of statlen -= tokenlen;  That left me with all of my headers truncated by one character.  After taking a look at line 685 I noticed a call was made to apr_cpystrn which assumes a null terminated string.  The call on 685 uses statlen and stat isn't null terminated.  So, changing it to  apr_cpystrn(newstat + 8, stat, statlen + 1); // Instead of apr_cpystrn(newstat + 8, stat, statlen);  Fixes the second problem.  All my status headers come through correctly with both changes in place.	apr_cpystrn takes a buffer length and must null terminate, your patch is quite correct.  thank you!  applied with commit 416288 Will Rowe has posted a zipfile containing compiled mod_isapi modules which include the patch correcting this bug (for use with 2.0.58 and 2.2.2), for testing purposes. It is available at:  http://people.apache.org/~wrowe/mod_isapi-416293.zip  You may read his full email to the dev@httpd.apache.org list here:  http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=115206683718140&w=2  If you test this version of mod_isapi, please post your feedback to the dev@httpd.apache.org list. Your feedback will help ensure that there are no regressions or other issues in this version of mod_isapi.			Matt Lewandowsky	Will Rowe
29106	null	CLOSED		Frank Benkstein	1085003460000	1085444180000		t work Hi.  I'm using apache 2.0.49 with mod_php 4.3.4 on Gentoo Linux (x86).  My conf/modules.d/70_mod_php.conf defines LimitRequestBody as follows:  --- cut here ---     # Fix some bugs     <Files *.php>           LimitRequestBody 524288         RequestHeader unset If-Modified-Since     </Files>     <Files *.php3>           LimitRequestBody 524288         RequestHeader unset If-Modified-Since     </Files>     <Files *.php4>           LimitRequestBody 524288         RequestHeader unset If-Modified-Since     </Files>     <Files *.phps>           LimitRequestBody 524288         RequestHeader unset If-Modified-Since     </Files>     <Files *.phtml>           LimitRequestBody 524288         RequestHeader unset If-Modified-Since     </Files> --- cut here ---  It is not set elsewhere. Now I want to allow upload of arbitrarily large files in one directory on one virtual host (there is a php application (eGroupware) running in this directory) but setting LimitRequestBody to 0 just doesn't work.  Astrid Ke??ler told me on users-de@httpd.apache.org [1] that this is a bug in  apache.  [1] http://marc.theaimsgroup.com/?l=apache-httpd-users-de&m=108500058222033&w=2	Fixed in 2.1 and suggested for backport into the 2.0 branch.  Thanks for the report and thanks for using Apache. The fix will be in version 2.0.50.			Andr?? Malo
29148	null	CLOSED		Zhenmin	1085171400000	1085172320000		[OPERA] a bug detected in modules/dav/main/mod_dav.c The potential bug is detected by a static analysis tool in modules/dav/main/mod_dav.c:L1022  1016  if (err != NULL) { 1017      return dav_handle_err(r, err, NULL); 1018  } 1019  1020  if (err2 != NULL) { 1021      /* just log a warning */ 1022      err2 = dav_push_error(r->pool, err->status, 0, 1023                            'The PUT was successful, but there ' 1024                            'was a problem automatically checking in ' 1025                            'the resource or its parent collection.', 1026                            err2); 1027      dav_log_err(r, err2, APLOG_WARNING); 1028  } 1029    If it runs through line 1022, 'err' must be NULL, and it will cause a  segmentation fault when it accesses 'err->status' in line 1022.	Neat tool! Thanks for the report, fixed by:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/dav/main/mod_dav.c?r1=1.106&r2=1.107			Joe Orton
29216	null	CLOSED		Graham Leggett	1085535840000	1097684520000		Infinite loop while viewing cache stats page The following code in util_ldap_cache_mgr.c gets stuck in an infinite loop:      for (i=0; i < cache->size; ++i) {         if (cache->nodes[i] != NULL) {             nchains++; >>          for (n = cache->nodes[i]; n != NULL; n = n->next) \t        totchainlen++;         }     }  In the above case, the variables n, cache->nodes[i] and n->next all point to the same object, so 'n = n->next' causes an infinite loop.	Fix committed to HEAD. Backported to v2.0.53. 			Graham Leggett
29310	null	CLOSED		Tom Alsberg	1086014160000	1089787216000		Allowing only some options in .htaccess In the URL noted is a patch I wrote to add an option 'AllowOverrideOpts' to the directory context, which will specify which options are allowed to be overriden in .htaccess files (using AllowOverride you can only specify whether options may be overridden).  That's useful for us, for example, since globally Indexes are disabled, but if someone wishes to, he can enable Indexes for his web page (and subdirectories) or whatever, while we don't want to let people change other options.  This patch might not be fully complete or up to the Apache conventions, but I tried to write it as clean as possible given the time I have.  Please tell me if there are problems with it.  In the patch there is also very short documentation for this option.  I only tested, with version 2.0.49, on FreeBSD 4.9, that without that option the default (previous) behaviour is still used (All), and that specifying it has the desired effect of only allowing those options to be overridden.  Perhaps there are other things to test with it.  I'd be glad to have this patch (or a variant of it) integrated, to save us from further patching of new versions, and so it might be useful to others as well.	The URL was bad, I fixed it now.  Created an attachment (id=11721) Patch to add AllowOverrideOpts directive  Created an attachment (id=11722) Adds AllowOverrideOpts against 2.1-CVS  +1 - Tested w/ the patch for 2.1 and a cursory code review.  Only issue I see is the naming of the directive. AllowOrderrideOpts vs AllowOverrideOptions vs SomthingMuchShorterPlease. Without a closer look at the patch for now ... What about not to introduce a new directive, but extending AllowOverride, like  AllowOverride Options=Indexes,MultiViews  ? That (AllowOverride Options=) is a possibility too, shouldn't be too difficult to change it to work this way.  I'm not sure what's better, though...  It is after all quite a different context (specific to one directive, different function checking it...), so perhaps that would mean complicating AllowOverride a bit too much for specifics.  If that's preferred, I could (am willing to) modify the patch to work this way.  Created an attachment (id=12022) Patch for httpd 2.0.50 with syntax AllowOverride Options=  Slightly modified patch Commited to 2.1 CVS.  Thanks for helping with Apache,  -Paul Querna			Andr?? Malo	Paul Querna	Tom Alsberg
29318	null	CLOSED		David Greenaway	1086084360000	1086096103000		Apache 2.0.49 / mod_deflate and flushing CGI script causes huge memory consumption The following Perl CGI script causes the Apache worker process to consume huge amounts of memory (up to 650M for a page about 100k in size.) if the 'SetOutputFilter DEFLATE' is used.  --- script start --- #!/usr/bin/perl  print 'Content-Type: text/plain/n/n';  $| = 1; # flush output  for (my $i = 0; $i < 100000; $i++) {         print 'moo/n'; } --- script end ---  By commenting out the line 'flush output' and trying again, the page is served without any problems. Removing 'SetOutputFilter DEFLATE' also allows the page to be served without any trouble.  Changing the values of 'DeflateMemLevel', 'DeflateCompressionLevel' and 'DeflateBufferSize' do not affect the behaviour. However, if 'DeflateWindowSize' is <= 7, the problem goes away. At the value 8, the problem appears randomly (approximately one in two requests.) As the value increases, the probability of the process 'blowing up' increases. At a value of 15, the apache worker process always appears to blow up.  The script is being run with 'cgi-script', and not mod_perl. The same symptoms are experienced if the perl script is replaced with an identical compiled C program:  --- script start --- #include <stdio.h>  int main(void) {         int i;         printf('Content-Type: text/plain/n/n');         for (i = 0; i < 100000; i++) {                 printf('moo/n');                 fflush(stdout); /* flush output */         }          return 0; } --- end start ---	Thanks for the report.  Fixed on HEAD:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/filters/mod_deflate.c?r1=1.48&r2=1.49  and backport which does the same for 2.0:  http://cvs.apache.org/~jorton/ap_deflate.diff  This should prevent the massive memory consumption with large responses regardless of DeflateWindowSize setting. Confirmed fixed.  Thanks Joe! :)			David Greenaway	Joe Orton
29518	null	CLOSED		Martin D??rst	1086925020000	1089658263000		' The documentation wrongly uses the language code 'en-uk'. Such a language code  doesn't exist. The second component of a language code is a country code; the  country code for the United Kingdom is 'gb' (see http://www.iso. org/iso/en/prods-services/iso3166ma/02iso-3166-code-lists/list-en1.html#sz),  which makes the language code for British English 'en-gb'. The same bug exists  in the httpd 1.3 documentation (filed at http://issues.apache. org/bugzilla/show_bug.cgi?id=29517), and in all the translations. Please also  check if it is used somewhere in an configuration file.	Fixed.  Thanks for the note.			Joshua Slive
29696	null	CLOSED		Alois Treindl	1087730700000	1087736978000		does not log request completion time even with #define I_INSIST_ON_EXTRA_CYCLES_FOR_CLF_COMPLIANCE file modules/loggers/mod_log_config.c has a special #define  I_INSIST_ON_EXTRA_CYCLES_FOR_CLF_COMPLIANCE which has the purpose that logfile timestamps log the completion time of a request, and not the new 2.0 default, which is the begin time of a request.  This #define does not work for Customlog, because of a bug: r->request_time is used anyway!  The patch is @@ -556,7 +548,7 @@              char sign;              int timz;  -            ap_explode_recent_localtime(&xt, r->request_time); +            ap_explode_recent_localtime(&xt, request_time);              timz = xt.tm_gmtoff;              if (timz < 0) {                  timz = -timz;	Fix committed to 2.1-dev, and I'll propose it for merging into stable branch for 2.0.next.  Thanks for the fix, and thanks for using Apache httpd! 			Jeff Trawick
29732	null	CLOSED		Robert Andersson	1087904940000	1089657791000		Define which type regular expressions used in Apache The document 'Terms Used to Describe Directives' gives a generic description of what a 'regex' is, but not what syntax is expected. It should say that the PCRE library is used, and a link to documentation of it. Eg. http://www.pcre.org/pcre.txt or to Perl documentation (which might be better).  Additionally, it might not hurt to have a See Also link to something like 'Regular Expressions in Apache' for applicable directives, because I fear that few people would think of looking in the 'right' place.	I like the 'See Also' reference.   Alternatively, we could revise the description for *Match directives in the Core Features document. For example, we could modify the <LocationMatch> as follows: -- Description: Applies the enclosed directives only to perl-compatible regular expression matching URL's --  I also have a suggestion for the 'Configuration Sections' document: (under 'Wildcards and Regular Expression') -- If even more flexible matching is required, each container has a perl-compatible regular-expression (regex) counterpart --  This brings the perl-compatible statement to the first occurance of the words 'regular expression', which will make it stand out more.   A link here to the PCRE library would be more obvious than a link to the glossary.  I've fixed the directive-dict to say 'Perl-compatible' and to reference the glossary.  Changing every directive that uses a regular expression would be a major undertaking.  If you'd like to work on that, please feel free to come over to the docs project and help out: http://httpd.apache.org/docs-project/			Charlie Cox	Joshua Slive
29740	null	RESOLVED		Max Bowsher	1087919400000	1107477578000		--with-apr=/usr is broken Configuring with --with-apr=/usr usually fails. This is because:  The generated exports.c #includes all *.h files found in <apr-prefix>/include If <apr-prefix> == /usr , then this means /usr/include/*.h !!!  On most systems, it's quite likely that some of these are C++ headers, or have conflicting definitions, so breaking the build.  The solution is to only include apr and apr-util headers from the apr and apr-util include directories. This is easy to do, as apr and apr-util headers follow a consistent naming scheme.  Here is a patch, to include only apr.h, apu.h, apr_*.h, and apu_*.h from the apr and apr-util include directories.  It is against httpd-2.0.49 (current release), but it applies without conflict to  current 2.0-HEAD and 2.1-HEAD.  --- httpd-2.0.49/server/Makefile.in.orig 2004-06-21 01:00:42.308012800 +0100 +++ httpd-2.0.49/server/Makefile.in 2004-06-21 01:14:25.131174400 +0100 @@ -31,7 +31,8 @@    util.lo: test_char.h   -EXPORT_DIRS = $(top_srcdir)/include $(top_srcdir)/os/$(OS_DIR) $(APR_INCLUDEDIR) $(APU_INCLUDEDIR) $(top_srcdir)/modules/http +EXPORT_DIRS = $(top_srcdir)/include $(top_srcdir)/os/$(OS_DIR) $(top_srcdir)/modules/http +EXPORT_DIRS_APR = $(APR_INCLUDEDIR) $(APU_INCLUDEDIR)    # If export_files is a dependency here, but we remove it during this stage,  # when exports.c is generated, make will not detect that export_files is no @@ -58,6 +59,10 @@   for dir in $(EXPORT_DIRS); do /       ls $$dir/*.h >> $$tmp; /   done; / + for dir in $(EXPORT_DIRS_APR); do / +     ls $$dir/ap[ru].h >> $$tmp 2>/dev/null; / +     ls $$dir/ap[ru]_*.h >> $$tmp 2>/dev/null; / + done; /   sort -u $$tmp > $@; /   rm -f $$tmp	Created an attachment (id=11910) The same patch as inline, but attached to avoid line-wrapping  We have had similar problems trying to build APR, APU, and then HTTPD all by themselves, in Source Mage GNU/Linux. Our patches are here:  http://codex.sourcemage.org/test/libs/apr/build.diff http://codex.sourcemage.org/test/libs/apr-util/build.diff most reasonable places have the APR headers installed to /usr/include/apr-{0,1} don't they? Replying to Paul Querna above:  Installing to <prefix>/include is the default in apr. For httpd to be incompatible with the default build and install of apr seems rather wrong to me.  Besides, just because the bug won't affect some environments doesn't mean it shouldn't be fixed, especially when fixing it only requires a tiny patch, which I have already written and attached to the bug. Replying to Sergey A. Lipnevich above:  AFAICS your patches are about an entirely unrelated issue. APR must be able to find it's headers if they are installed in /usr/include or in /usr/include/apr-{0,1}, which is where APR v1.0 seems to want to put them.  Fixing this bug allows httpd v2.1 to be built as an RPM again.  Applied in r151255.  Thanks!			Graham Leggett	Justin Erenkrantz	Max Bowsher	Paul Querna	Sergey A. Lipnevich
29755	null	RESOLVED		Sami J. M??kinen	1087984140000	1112828682000		mod_usertrack should use err_headers_out In short, we are running several large websites that have banner advertisements. A friendly way to serve banners is to configure the IMG SRC tags so that they refer to an apache server using mod_usertrack and mod_rewrite. This way, we get a decently reliable visitor log and banner exposure log. The redirect points to the 'real' image server that gives long expire times so that the browser does not have to download each banner every time, but we still get nice logs for our advertisers.  The problem that we ran into, is that whenever you make a redirect from mod_rewrite, the fixups hooks stop and mod_usertrack is never called. So we don't get cookies logged when http status is 302.  I fixed this quite simply:  in mod_usertrack, modify the function  --- 8< --- static void register_hooks(apr_pool_t *p) {     ap_hook_fixups(spot_cookie,NULL,NULL,APR_HOOK_MIDDLE); } --- 8< ---  to be  --- 8< --- static void register_hooks(apr_pool_t *p) {     ap_hook_fixups(spot_cookie,NULL,NULL,APR_HOOK_FIRST); } --- 8< ---  ...and make sure that mod_usertrack is loaded before mod_rewrite, if using dynamic modules. We use RHEL3ES, and the apache distributed by Red Hat is using dynamic modules for almost everything.  I would be very pleased if stock apache's mod_usertrack would use APR_HOOK_FIRST in the future. I don't think this small but important modification would break anything. :-o  P.S.  request.c says  AP_IMPLEMENT_HOOK_RUN_ALL(int,fixups,                           (request_rec *r), (r), OK, DECLINED)  it took some time for me to find out that 'RUN_ALL' here does not mean 'run all hooks in any case'. It means actually 'run every hook until one of them does not return DECLINED or OK'. Sheesh.	Changed in 2.1 CVS.  Thanks for using Apache! Uh, the following hit us:  http://ken.coar.org/burrow/index?entry=511  in short, mod_usertrack really should set the cookie header in err_headers_out, NOT headers_out.  The headers in headers_out will not get sent if the request ends in a redirect. Sigh.  Furthermore, register_hooks should look like this:  static void register_hooks(apr_pool_t *p) {     /* fixup before mod_proxy, so that the proxied url will not      * be escaped accidentally by our fixup.      */     static const char * const aszSucc[]={ 'mod_rewrite.c', 'mod_proxy.c',                                           'mod_alias.c', NULL };     ap_hook_fixups(spot_cookie, NULL, aszSucc, APR_HOOK_FIRST); } Sigh.  I just checked Apache 2.0.52 source. It should be fixed. A simple and suitable patch is attached below:  *** mod_usertrack_orig.c        2004-11-15 22:54:20.000000000 +0200 --- mod_usertrack.c     2004-11-15 22:57:57.000000000 +0200 *************** *** 145,151 ****                                    NULL);       }    !     apr_table_addn(r->headers_out,                      (dcfg->style == CT_COOKIE2 ? 'Set-Cookie2' : 'Set-Cookie'),                      new_cookie);       apr_table_setn(r->notes, 'cookie', apr_pstrdup(r->pool, cookiebuf));   /* log first time */ --- 145,151 ----                                    NULL);       }    !     apr_table_addn(r->err_headers_out,                      (dcfg->style == CT_COOKIE2 ? 'Set-Cookie2' : 'Set-Cookie'),                      new_cookie);       apr_table_setn(r->notes, 'cookie', apr_pstrdup(r->pool, cookiebuf));   /* log first time */ *************** *** 439,445 ****      static void register_hooks(apr_pool_t *p)   { !     ap_hook_fixups(spot_cookie,NULL,NULL,APR_HOOK_MIDDLE);   }      module AP_MODULE_DECLARE_DATA usertrack_module = { --- 439,450 ----      static void register_hooks(apr_pool_t *p)   { !     /* fixup before mod_proxy, so that the proxied url will not !      *      * escaped accidentally by our fixup. !      */ !     static const char * const aszSucc[]={ 'mod_rewrite.c', 'mod_proxy.c', !                                         'mod_alias.c', NULL }; !     ap_hook_fixups(spot_cookie, NULL, aszSucc, APR_HOOK_FIRST);   }      module AP_MODULE_DECLARE_DATA usertrack_module = {  This has beend fixed in 2.1.x, and not backported to 2.0.x.  I didn't feel it was important enough to backport to 2.0.x.			Paul Querna	Sami J. M??kinen
29889	null	RESOLVED		Kim Scarborough	1088798280000	1188472560000		Please add application/vnd.wordperfect to mime.types Hello,  I've registered a new MIME type for WordPerfect documents: application/vnd.wordperfect (this supercedes application/wordeperfect5.1). Please see <http://www.iana.org/assignments/media-types/application/vnd.wordperfect>.  Can you add this to mime.types and associate it with the .wpd extension? Thanks...	At Apachecon it was suggested to me that I comment on this bug to try to get somebody to look at it. So I am. Can this please be added to the MIME types file? I've attached a diff to bug 26505 which should update both the WordPerfect and Palm OS media types. Committed to trunk. 			Dave Hodder	Kim Scarborough	Roy T. Fielding
29962	null	CLOSED		Filip Sneppe	1089236340000	1118788864000		byterange filter buffers response in memory This bug may be related to 28175, although I am on a different platform with a slightly different setup, and I can reproduce the problem, so I am  opening a new bugreport for this.  For many months, using different versions of Apache 2.0.x from Debian testing, we have been experiencing what can only be described as serious memory leaks when using mod_proxy and/or mod_rewrite to reverse  proxy backend web servers. I am using MPM prefork.  I have been able to troubleshoot this problem using network captures etc. on  our production machines and I believe I can reproduce this problem on a test system.  To reproduce this, I used an apache 1.3.29 on port 3000 on the localhost used as the backend server. In our live environment, this is on a different machine. Apache 2 listens on port 80 and is used as a reverse proxy for the server on port 3000.  For the Apache1.3, I have /usr/lib/cgi-bin/do-post:  #!/usr/bin/perl print 'Content-type: text/plain/n/n'; for ($t=0; $t<400000; ++$t) {         print 'o'x99; print '/n' }  Which essentially returns about 40Mb of data.  For the Apache2 config, I have the following virtual host:  <VirtualHost *>         ServerName www.test.local         RewriteEngine On         ProxyRequests On         ProxyPreserveHost Off         RewriteCond %{HTTP_HOST}      ^www/.test/.local$         RewriteRule ^/(.*)            http://localhost:3000/$1     [P,L] </VirtualHost>  Now, the following type of request:  sneppef@xbox:~$ telnet localhost 80 > /tmp/t POST /cgi-bin/do-post HTTP/1.1 Host: www.test.local Range: bytes=20000000-35000000  suddenly bumps the memory use of an apache child process, in this case to about 80Mb on my system, and this doesn't seem to get freed  afterwards.  This is a close as I can simulate this on a test environment at this moment. Things are even more dramatic on our production systems. They have 1Gb of RAM, and the following virtualhost setting:  <VirtualHost *>         ServerName www.xxxxxx.be         RewriteEngine On         ProxyRequests On         ProxyPreserveHost Off         CustomLog /var/log/apache2/www.caffo.be.log 'full'         RewriteCond %{HTTP_HOST}      ^www/.xxxxxx/.be$         RewriteRule ^/(.*)            http://a.b.c.88/$1     [P,L] </VirtualHost>  (I mangled the hostname and IP address in the above!)  combined with the following request (this is straight from a network capture):  POST /xxxxxx/demodownload/download/Converter6_Trial_Setup.exe HTTP/1.0 Via: 1.1 RGOPROXY Content-Length: 45 Content-Type: application/x-www-form-urlencoded User-Agent: Mozilla/4.0 (compatible; MSIE 5.00; Windows 98) Host: www.xxxxxx.be Range: bytes=19092309-38183432 Accept: */* Referer: http://www.xxxxxx.be/xxxxxx/demodownload/demodownload.downloadpage Cache-Control: max-stale=0 Connection: Keep-Alive X-BlueCoat-Via: 175D569BDF449936  custid=2813&p_type=CONVDEMO&download=Download  (Again, the xxxxxx are mangled)  Bumps the memory use of an Apache2 process up to about 150Mb. Obviously a  limited number of these kinds of requests render our reverse proxy unusable.  The file in question is 38Mb large. The backend servers returns this (from tcpdump -X):  0x0030   0782 c70e 4854 5450 2f31 2e31 2032 3030        ....HTTP/1.1.200 0x0040   204f 4b0d 0a44 6174 653a 2057 6564 2c20        .OK..Date:.Wed,. 0x0050   3037 204a 756c 2032 3030 3420 3231 3a33        07.Jul.2004.21:3 0x0060   313a 3530 2047 4d54 0d0a 5365 7276 6572        1:50.GMT..Server 0x0070   3a20 4f72 6163 6c65 2048 5454 5020 5365        :.Oracle.HTTP.Se 0x0080   7276 6572 2050 6f77 6572 6564 2062 7920        rver.Powered.by. 0x0090   4170 6163 6865 2f31 2e33 2e31 3220 2857        Apache/1.3.12.(W 0x00a0   696e 3332 2920 4170 6163 6865 4a53 6572        in32).ApacheJSer 0x00b0   762f 312e 3120 6d6f 645f 7373 6c2f 322e        v/1.1.mod_ssl/2. 0x00c0   362e 3420 4f70 656e 5353 4c2f 302e 392e        6.4.OpenSSL/0.9. 0x00d0   3561 206d 6f64 5f70 6572 6c2f 312e 3234        5a.mod_perl/1.24 0x00e0   0d0a 436f 6e74 656e 742d 4c65 6e67 7468        ..Content-Length 0x00f0   3a20 3338 3138 3334 3333 0d0a 436f 6e74        :.38183433..Cont 0x0100   656e 742d 5479 7065 3a20 6170 706c 6963        ent-Type:.applic 0x0110   6174 696f 6e2f 6f63 7465 742d 7374 7265        ation/octet-stre 0x0120   616d 0d0a 0d0a 4d5a 9000 0300 0000 0400        am....MZ........  Followed by the complete file (38Mb)  apache2 returns only the requested byte range:  HTTP/1.1 200 OK Date: Wed, 07 Jul 2004 21:28:14 GMT Server: Oracle HTTP Server Powered by Apache/1.3.12 (Win32) ApacheJServ/1.1 mod_ssl/2.6.4 OpenSSL/0.9.5a mod_pe rl/1.24 Content-Length: 19091124 Content-Type: application/octet-stream Content-Range: bytes 19092309-38183432/38183433 Connection: close  ...data...  Surely if the backend server only returns about 38Mb of data and Apache2 child process shouldn't consume 150Mb :-/  I hope this helps... If you need any other info, let me know, as I have been able to reproduce this every time. I have tagged this as a major issue, since bug 23567 seems to be considered critical. I hope I am not exagerating, as this is my first bugreport on Apache. Do keep up the excellent work!  Regards	Yes, this is a problem with the byterange filter in 2.0, it will buffer the entire response in memory.  I am just wondering if there is currently *any* workaround for this ? A directive that disables byterange support ? Because, isn't this a serious security issue in itself ? It means any user that can send http requests to an apache proxy can DoS it by sending even a limited number of specially crafted requests that download some large files somewhere... You can DoS any HTTP server very easy. One could say, that's part of the protocol ;-)  Anyway,  RequestHeader unset Range  or somehting like this should work for you. Don't forget  Header unset Accept-Ranges  so the server isn't telling porkies about its capabilities I appear to be experiencing a similar problem when my users submit files to the server.  I've noticed that a submitted assignment (POST), which has an attached word document, appears to cause one of the apache processes to inflate to between 300 - 750 megabytes in size.  This does not appear to be equal to the size of the attachment. I hunted down the problem, it was an error in a purchased PHP script that loaded the entire contents of our of our db tables into memory (which is now approaching the 800 megabytes threshhold).  However, when the script terminated that memory was not being released by Apache 2.0.51. The byterange filter memory consumption issue is now fixed for 2.1.5.  http://svn.apache.org/viewcvs?rev=188797&view=rev Created an attachment (id=16102) Byterange patch for Apache 2.0.x  I hope Joe won't mind if I post a version of the patch which he modified to work with the Apache 2.0.x branch.  Thanks, Joe! Now merged for 2.0.55.  Thanks for the report.  I'm not sure that this has been fixed, I've downloaded the patch and have it applied yet, it still runs amuck.  I checked on my server this morning, and there sat a process in apache holding onto 635MB of data.  Maybe this bug is occuring somewhere else.  I am in no way capable of tracking that down, but I do know it's still occuring. 			Andr?? Malo	Brady Bowen	Filip Sneppe	Joe Orton	Nick Kew	Tyler	dswhite42@yahoo.com
29964	null	CLOSED		Francis Wai	1089244200000	1092230755000		non-terminating i/o I'm seeing a non-terminating loop in ssl_io_input_getline().  We used a 3rd party tool to send a request to our Apache server. The tool tried  to present an expired certificate to a SSL enabled vhost and Apache correctly  refused the correction. But, it set Apache to spin out of control.  I'm a complete outsider of the Apache/mod_ssl code. But this is what I found.  As mentioned, Apache did shutdown the filter's SSL connection. However, it  continued to read in GETLINE/blocking mode the rest of the request. Here comes  the problem. ssl_io_input_getline() calls ssl_io_input_read() to read to a LF  or the max. of the buffer can handle, whichever comes first. But,  ssl_io_input_read() realizes the filter's SSL connection has been shutdown, it  returns with the last known status of the BIO which was created to read from  this SSL connection. It also set the returned length to 0. Unfortunately, the  caller get APR_SUCCESS return code and because the returned length is 0, the  remaining buffer length does not get changed at all.   Because the return code is always APR_SUCCESS and because the returned length  is always 0 and the buffer is not full, ssl_io_input_getline() keeps calling  ssl_io_input_read(). It goes on forever!	Created an attachment (id=12060) ssl_io_input_read fix  Thanks for the report and analysis.  Can you try the patch attached above?  Thanks for the quick response.  We thought about this before I submitted the bug report. We thought APR_EOF or  APR_EGENERAL or in fact any return code other than APR_SUCCESS would have been  sufficient to prevent Apache from spinning out of control.  We could not decide on either, however. We are not super familiar with the  Apache/mod_ssl code and, more important, this is the most exercised part of  the server as far as we're concerned. It is important that the return code  does what it is supposed to do _and_ does not cause any un-expected side- effect.  APR_ECONNRESET, APR_EGENERAL or APR_EOF would all be reasonable choices.  Doing any of these would clearly be better than the status quo; opt for APR_EGENERAL to be conservative.  I couldn't reproduce the issue here from in brief attempt, so if you could confirm that the patch does fix the issue that would be helpful.  We patched Apache as suggested and it does fix the problem. We're in the  process of conducting more thorough tests and if anything unexpected crops up,  I'll report here.  Thanks for the response.  The fix checked in is slightly different:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.124&r2=1.125  this will be proposed for backport for the next 2.0 release.  This issue has been assigned CVE CAN-2004-0748.			Francis Wai	Joe Orton
30033	null	RESOLVED		Dr. Martin Luckow	1089541260000	1150958602000		mod_isapi: WriteClient not able to write HTTP-Headers To get more control over the HTTP-Header i send it via WriteClient (and not via  ServerSupportFunction). This works fine under IIS but under Apache WriteClient  fails and GetLastError() returns 87 (invalid parameter).	I've no idea who works on mod_isapi, but I think this bug report really needs an example that demonstrates the problem.  From the description, I'd have thought you could construct a HelloWorld-sized example? Sample:  DWORD WINAPI HttpExtensionProc(LPEXTENSION_CONTROL_BLOCK ecb) {   char* buffer = 'HTTP/1.1 200 OK/r/nDate: Sun, 11 Jul 2004 09:10:58  GMT/r/nContent-length: 0/r/n/r/n';   unsigned long bufferSize = strlen(buffer);    if (!ecb->WriteClient(ecb->ConnID,buffer,&bufferSize,HSE_IO_SYNC)) {     return HSE_STATUS_ERROR;   }; // if   return HSE_STATUS_SUCCESS_AND_KEEP_CONN; };  IIS: WriteClient works, the header is 'nph-'sent. Apache: WriteClient fails. I had a look at the code in mod_isapi.c, I changed line 687 from  apr_cpystrn(newstat + 8, stat, statlen + 1); to apr_cpystrn(newstat + 8, stat, statlen);  and that seemed to fix the problem for me. For the example above Apache would try to process the header line 'Status: 200 OK/r/nD', and points out that 'D' is not a valid header. I don't think this is actually the problem.   I use WriteClient to dump out a complete HTTP response which includes header  and body in the first chunk that gets passed to WriteClient. The header might  look like this:  <pre> HTTP/1.1 200 OK Content-type: text/html; charset=utf-8 Content-Length: 3042  ... some HTML text goes here. </pre>  This works perfect with IIS, but not with Apache. I get the same 87 error as  mentioned above. There's definitely more going on here than just an extra  character in the header block... Created an attachment (id=18374) Patch to not clobber the ISAPI's response code.  I've attached a patch to 2.2.2's mod_isapi.c which should correct this behavior. I've run it against a suite of ISAPI extensions, all of which give their correct responses as far as I can tell.  What seems to be the issue is that ap_scan_script_header_err_strs likes to return 0 (or some other value which is not the HTTP status). The current mod_isapi sticks this result in as the HTTP status. Needless to say, this is quite unexpected. Since mod_isapi's send_response_header already gets the correct value, there's no reason that I can see to second-guess it.  If someone can review this trivial patch for sanity, I'd appreciate it. I can't find any breakage, but I assume that someone did that for a reason. Created an attachment (id=18375) More correct patch, cribbed from mod_cgi  On the advice of wrowe, I've attached a more correct patch which cribs from mod_cgi. As a rule, we probably don't want to use the return from ap_scan_script_header_err_strs. But if it's non-zero, we should.  The last patch neglected a case, as well. This one should catch everything.  Again, I ran it through its paces and was able to get a variety of responses. See bug 16637 for an interrelated issue. Created an attachment (id=18392) Complete logic overhaul for send_response_header  This updated patch completely replaces the HTTP response status logic in send_response_header. It likely should correct the issue mentioned in bug 16637 as well.    This looks great.  Please review trunk, I've refactored this a bit to make   the interrelations between r->status and dwStatus a bit clearer.     I hate when I can't track this stuff down.  The commit to trunk which is   expected to resolve this is 416272 Will Rowe has posted a zipfile containing compiled mod_isapi modules which include the patch correcting this bug (for use with 2.0.58 and 2.2.2), for testing purposes. It is available at:  http://people.apache.org/~wrowe/mod_isapi-416293.zip  You may read his full email to the dev@httpd.apache.org list here:  http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=115206683718140&w=2  If you test this version of mod_isapi, please post your feedback to the dev@httpd.apache.org list. Your feedback will help ensure that there are no regressions or other issues in this version of mod_isapi.			Dr. Martin Luckow	John Taylor	Matt Lewandowsky	Nick Kew	Rick Strahl	Will Rowe
30134	null	CLOSED		M. 'Alex' Hankins	1089935820000	1092776601000		Segmentation fault in char_buffer_read when reverse proxying SSL Overview Description:  Intermittent segmentation faults occur in char_buffer_read at ssl_engine_io.c:348 when using a RewriteRule to do reverse proxying to an SSL origin server running IIS.      Steps to Reproduce:  1) Set up an IIS server using SSL and running eRoom 6.  2) Add the following directives to httpd.conf:  Listen 47290 SSLProxyEngine on RewriteEngine on RewriteRule /(.*) https://some.eroom6.iis.server.com/$1 [P]  3) Visit a URL similar to the following:  http://reverse.proxy.com:47290/eRoomASP/CookieTest.asp?facility=facility&URL=%2FeRoom%2FFacility%2FRoom%2F0_4242  If that doesn't cause the segfault, click around for a while.  (Yes, reverse proxying from non-SSL to SSL is not a good idea, but it keeps the example simpler.)      Actual Results:  Segmentation fault in error_log: [Thu Jul 15 19:38:36 2004] [notice] child pid 42 exit signal Segmentation fault (11), possible coredump in /usr/local/httpd-2.0.50      Build Date & Platform:  2004-07-14 build on SunOS 5.8 SUNW,UltraAX-i2      Additional Information:  Here is a stack trace from gdb:  #0  0xfef5060c in memcpy ()    from /usr/platform/SUNW,UltraAX-i2/lib/libc_psr.so.1 #1  0xfeafef54 in char_buffer_read (buffer=0x1649ac,     in=0x2000 <Address 0x2000 out of bounds>, inl=8192) at ssl_engine_io.c:348 #2  0xfeaff388 in ssl_io_input_read (inctx=0x164990,     buf=0x1649b8 'Content-Length: 121/r/nCort/Martonia/0_2615/r/nContent-Length: 121/r/nCent-Length: 121/r/nCmeport/Martonia/0_2615/r/nContent-Length: 121/r/nCmeport/Martonia/0_2615/r/nContent-Length: 121/r/nCrtonia/0_2615/r/nContent-Le'..., len=0xffbea8cc) at ssl_engine_io.c:561 #3  0xfeaff624 in ssl_io_input_getline (inctx=0x164990,     buf=0x1649b8 'Content-Length: 121/r/nCort/Martonia/0_2615/r/nContent-Length: 121/r/nCent-Length: 121/r/nCmeport/Martonia/0_2615/r/nContent-Length: 121/r/nCmeport/Martonia/0_2615/r/nContent-Length: 121/r/nCrtonia/0_2615/r/nContent-Le'..., len=0xffbea944) at ssl_engine_io.c:712 #4  0xfeb00118 in ssl_io_filter_input (f=0x1669c0, bb=0x158f98,     mode=4290685252, block=APR_BLOCK_READ, readbytes=0) at ssl_engine_io.c:1226 #5  0x42978 in ap_get_brigade (next=0x1669c0, bb=0x158f98,     mode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)     at util_filter.c:474 #6  0x4aab4 in net_time_filter (f=0x158e20, b=0x158f98, mode=AP_MODE_GETLINE,     block=APR_BLOCK_READ, readbytes=0) at core.c:3600 #7  0x42978 in ap_get_brigade (next=0x158e20, bb=0x158f98,     mode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)     at util_filter.c:474 #8  0x43e0c in ap_rgetline_core (s=0xffbeab94, n=8192, read=0xffbeab90,     r=0x1671b8, fold=1, bb=0x158f98) at protocol.c:214 #9  0x441a4 in ap_getline (s=0xffbeccd8 'Content-Length', n=8192, r=0x1671b8,     fold=1) at protocol.c:478 #10 0xfe8552d4 in ap_proxy_read_headers (r=0x1821d0, rr=0x1671b8,     buffer=0xffbeccd8 'Content-Length', size=8192, c=0x1671b8)     at proxy_util.c:457 #11 0xfe833014 in ap_proxy_http_process_response (p=0x157960, r=0x1821d0,     p_conn=0x157ee8, origin=0x158168, backend=0x157f00, conf=0xf0268,     bb=0x157e98, server_portstr=0xffbeed68 ':47290') at proxy_http.c:755 #12 0xfe833ba4 in ap_proxy_http_handler (r=0x1821d0, conf=0xf0268,     url=0x158038 '/eRoomASP/CookieTest.asp?facility=memeport&URL=%2FeRoom%2Fmemeport%2FMartonia%2F0_2615', proxyname=0x0, proxyport=60776) at proxy_http.c:1121 #13 0xfe85435c in proxy_run_scheme_handler (r=0x1821d0, conf=0xf0268,     url=0x1839ce 'https://eroomhost.aaa.bbb.com/eRoomASP/CookieTest.asp?facility=memeport&URL=%2FeRoom%2Fmemeport%2FMartonia%2F0_2615', proxyhost=0x0,     proxyport=0) at mod_proxy.c:1113 #14 0xfe852ed8 in proxy_handler (r=0x1821d0) at mod_proxy.c:418 #15 0x359a8 in ap_run_handler (r=0x1821d0) at config.c:151 #16 0x35fa4 in ap_invoke_handler (r=0x1821d0) at config.c:358 #17 0x32c44 in ap_process_request (r=0x1821d0) at http_request.c:246 #18 0x2df14 in ap_process_http_connection (c=0x157a70) at http_core.c:250 #19 0x40090 in ap_run_process_connection (c=0x157a70) at connection.c:42 #20 0x403a4 in ap_process_connection (c=0x157a70, csd=0x157998)     at connection.c:175 #21 0x3422c in child_main (child_num_arg=5) at prefork.c:609 #22 0x343ac in make_child (s=0x8edb0, slot=5) at prefork.c:703 #23 0x345fc in perform_idle_server_maintenance (p=0x8c690) at prefork.c:838 #24 0x34a34 in ap_mpm_run (_pconf=0x0, plog=0x63400, s=0x83000)     at prefork.c:1039 #25 0x3ad44 in main (argc=3, argv=0xffbef4ac) at main.c:617	Does this still happen if you take mod_rewrite out of the setup and use ProxyPass instead? Yes, I still get what seems to be the same segfault (according to gdb) if I replace these config lines:  RewriteEngine on RewriteRule /(.*) https://some.eroom6.iis.server.com/$1 [P]  with this one:  ProxyPass / https://some.eroom6.iis.server.com/ This backtrace is a little strange:  #1  0xfeafef54 in char_buffer_read (buffer=0x1649ac,     in=0x2000 <Address 0x2000 out of bounds>, inl=8192) at ssl_engine_io.c:348  which means either stack corruption by memcpy or in got passed in as a pointer to address 8192 somehow.  Can you, from gdb against a core dump, check:  up 2 (into ssl_io_input_read) print *inctx info locals print buf print len    Hi Joe,    I do suffer from the same bug. Attached is the info you requested. If you need  additional testing, please say so. I cleared some info from the contents of  buffer to not disclose critical information. I hope that's ok and doesn't  hinder your debugging process.    Regards, Stephan    Program received signal SIGSEGV, Segmentation fault.  0xfedf060c in memcpy () from /usr/platform/SUNW,UltraAX-i2/lib/libc_psr.so.1  (gdb) where full  #0  0xfedf060c in memcpy ()     from /usr/platform/SUNW,UltraAX-i2/lib/libc_psr.so.1  No symbol table info available.  #1  0x00048060 in char_buffer_read (buffer=0x196d54,      in=0x196d60 'Cet-Cookie: s'...,      at ssl_engine_io.c:348  No locals.  #2  0x00048448 in ssl_io_input_read (inctx=0x196d38,      buf=0x196d60 'Cet-Cookie: s'...,      len=0xffbeafa4) at ssl_engine_io.c:561          wanted = 8192          bytes = 1533728          rc = 8192  #3  0x00048714 in ssl_io_input_getline (inctx=0x196d38,      buf=0x196d60 'Cet-Cookie: s'...,      len=0xffbeafa4) at ssl_engine_io.c:712          pos = 0x173ea0 ''          status = 1666360          tmplen = 1          offset = 1533728  (gdb) up 2  #2  0x00048448 in ssl_io_input_read (inctx=0x196d38,      buf=0x196d60 'Cet-Cookie: s'...,      len=0xffbeafa4) at ssl_engine_io.c:561  561  (gdb) print *inctx  $1 = {ssl = 0x173db8, bio_out = 0x172210, f = 0x198d68, rc = 0,    mode = AP_MODE_GETLINE, block = APR_BLOCK_READ, bb = 0x198d80, cbuf = {      length = 1, value = 0xffffffff <Address 0xffffffff out of bounds>},    pool = 0x16fea8,    buffer = 'Cet-Cookie: s'...,    filter_ctx = 0x17e058}  (gdb) info locals  wanted = 8192  bytes = 1533728  rc = 8192  (gdb) print buf  $2 = 0x196d60 'Cet-Cookie: s'...,  (gdb) print len  $3 = (apr_size_t *) 0xffbeafa4      Ah ha, that's crucial info, thanks.  It looks like the cause is: ssl_io_input_read is called with inctx->mode == SPECULATIVE (this only normally happens in the proxy IIRC); ssl_io_input_read calls char_buffer_read, which executes the case where it does:          buffer->value = NULL;         buffer->length = 0;  and ssl_io_input_read then screws up the inctx->cbuf for good.              /* We want to rollback this read. */             inctx->cbuf.value -= bytes;             inctx->cbuf.length += bytes;  cbuf = { length = 1, value = 0xffffffff <Address 0xffffffff out of bounds>},   per your backtrace.   Created an attachment (id=12459) proposed fix  The patch attached above should fix the segfaults, I'm not yet sure if this is the cleanest or most correct fix. The fix checked in should be equivalent:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.125&r2=1.126  This issue has possible security implications; it's been assigned CVE CAN-2004-0751 (cve.mitre.org).  Thanks for the report and for the debugging.			Joe Orton	M. 'Alex' Hankins	Nick Kew	Stephan Tesch
30190	null	RESOLVED		Sylvain Beucler	1090265040000	1188273632000		PNG icons are not transparent I changed Savannah's mod_autoindex configuration to use PNGs /icons (no GIFs at gnu.org), and noticed that the PNG files do not have a transparent background. I used this quick script to convert them well from GIFs:  for i in *.png; do giftopnm --alphaout $i.msk ${i%png}gif | pnmtopng -alpha $i.msk > $i; rm -f $i.msk; done  (the script iterates on png's because the animation gif should not be taken into account).	Now I have a bugzilla account I'm actually doing something about this.  This bites me frequently, hence the vote.  If the pnm tools aren't installed, but gif2png is, then:  $ gif2png -tw *.gif small/*.gif | xargs gif2png -ghnrsO  Expected output from command-line is one stderr message from the first gif2png invocation, noting the animated GIF (which is the reason for doing things this way).  I see the problem, that there are just a few browsers that actually support transparent png images, resp. some browsers have real problems with them. Perhaps we should just put the conversion script snippets somewhere into the docs? The problem is that the PNGs are shipped at all without transparency.  Since the PNGs aren't actually used by default, can't they be fixed so that anyone who chooses to use them at least gets full PNGs which don't look so bad in mod_autoindex that they put people off using PNGs?  It looks as though MSIE is the one fly in the ointment:   http://www.libpng.org/pub/png/pngstatus.html but according to that, cells which aren't completely opaque are rendered as completely transparent; since the Apache images don't use blending but have pixels either transparent or with colour (AFAIK), for this purpose is there actually a problem?  I just checked with my fiancee's MSIE 6.0 and the few icons used in one of my mod_autoindex pages rendered just fine; that's with the transparent PNGs rendered by the example command-line which I gave.  In fact, I've just created a web-page using all the PNG icons (except those in small) and they _all_ rendered fine.  If anyone wants to test more widely, there seems to be a decent testbed at:   http://entropymine.com/jason/testbed/pngtrans/ but that covers a much more general case than the Apache icons, which require a much simpler subset of PNG rendering functionality. Created an attachment (id=13727) Transparent PNG icons  Transparent PNG icons, converted from the transparent GIFs from the 2.0.52 source distribution. Created an attachment (id=13728) Transparent PNG icons  New version with the small directory included Sorry for all the new comments, I'm unfamiliar with bugzilla.  I've attached a tarball of transparent PNG icons.  These were converted from the GIFs distributed with 2.0.52 using 'giftopng -O'.  They are slightly (a few bytes per icon) larger than the old, non-transparent ones, and as far as I can tell display just fine in all browsers (even IE).  Please consider moving these icons into CVS so they may one day be distributed.  I'm getting tired of having to convert the GIFs by hand every time I install a new version of Apache :)  Thanks I can indeed still reproduce it. I hope it can be fixed; as said the icons now display badly in *any* browser while that could be reduced to only some (by now already older) browers.  The following snippet when using ImageMagick solves it:  for i in *.png; do convert ${i%png}gif $i;done  Thanks. Come on guys, it's been 3 years and we've provided you three different ways to  fix this. Thanks for the ImageMagick pointer (although I had to resort to GraphicsMagick since ImageMagick was generating corrupt .png's).  Note I used the -quality 100 to avoid any lossy optimization. (In reply to comment #9)  Thanks, Will!  You are my PNG hero.			Andr?? Malo	Neale Pickett	Phil Pennock	Thijs Kinkhorst	Will Rowe
30278	null	CLOSED		Igor Fedulov	1090537860000	1096393369000		mod_disk_cache breakes Content-Type for .css files After .css file was cached with mod_disk_cache it is served with wrong content type. Instead of 'text/css' it's served with 'text/plain; charset=UTF-8'  Configuration: ... <IfModule mod_cache.c>    <IfModule mod_disk_cache.c>       CacheRoot '/tmp/abc_static_cache'       CacheEnable disk /abc/images       CacheEnable disk /abc/htmlarea       CacheEnable disk /abc/scripts       CacheEnable disk /abc/style    </IfModule> </IfModule> ...  '/abc' context is referse proxy forward to backend server using following two directives: ... ProxyPass /abc http://10.10.10.10:8080/abc ProxyPassReverse /abc http://10.10.10.10:8080/abc ...  Here is the headers printout for very first request (right after clean apache restart with purging of the caches folder):  [igor@hyperion tmp]$ wget -s https://1.2.3.4/abc/style/common.css ; head common.css; rm -rf common.css --18:04:39--  https://1.2.3.4/abc/style/common.css            => "common.css' Connecting to [1.2.3.4]:443... connected. HTTP request sent, awaiting response... 200 OK Length: 10,368 [text/css]   100%[==============================================================================================>] 10,368       105.47K/s    ETA 00:00   18:04:40 (105.47 KB/s) - "common.css' saved [10368/10368]   HTTP/1.1 200 OK Date: Thu, 22 Jul 2004 23:04:26 GMT Server: Apache/2.0.50 (Fedora) Content-Length: 10368 Last-Modified: Thu, 22 Jul 2004 16:50:00 GMT Accept-Ranges: bytes Content-Type: text/css Vary: Accept-Encoding,User-Agent Keep-Alive: timeout=30, max=100 Connection: Keep-Alive  Each subsequent request for the same URL returns following headers:  [igor@hyperion tmp]$ wget -s https://1.2.3.4/abc/style/common.css ; head common.css; rm -rf common.css --18:04:52--  https://1.2.3.4/abc/style/common.css            => "common.css' Connecting to [1.2.3.4]:443... connected. HTTP request sent, awaiting response... 200 OK Length: 10,368 [text/plain]   100%[==============================================================================================>] 10,368       117.73K/s    ETA 00:00   18:04:53 (117.73 KB/s) - "common.css' saved [10368/10368]   HTTP/1.1 200 OK Date: Thu, 22 Jul 2004 23:04:39 GMT Server: Apache/2.0.50 (Fedora) Accept-Ranges: bytes Content-Length: 10368 Last-Modified: Thu, 22 Jul 2004 16:50:00 GMT Content-Type: text/plain; charset=UTF-8 Age: 17 Keep-Alive: timeout=30, max=100 Connection: Keep-Alive [igor@hyperion tmp]$   I can provide more information if needed, feel free to email me for more questions.	is utf8 your default charset type? What is 'AddDefaultCharset' set to in your httpd.conf? It's set to UTF-8, i.e. from httpd.conf:  AddDefaultCharset UTF-8 Does this only happen with css files or also with other files? What is your setting for DefaultType ? Is it unset or text/plain?  I had a similar problem with mod_jk and mod_cache / mod_disk_cache. I would guess that they are related. See also http://nagoya.apache.org/bugzilla/show_bug.cgi?id=30398. Here are my answers: 1. DefaultType is set to 'text/plain' 2. Images from cache also come out with 'Content-Type: text/plain; charset=UTF-8'  Looks like what you are describing in your issue is exactly the same thing, I wonder if I can try your patch to see if it will fix the problem. No, you cannot use my patch as I patched mod_jk to solve my problem. You need a patch for mod_disk_cache. But as I mentioned in 30398, I was not quite sure if this problem is a bug in mod_jk or mod_cache / mod_disk_cache (BTW: mod_mem_cache does not have this problem). After I read this report here I am quite sure that it is a bug in mod_disk_cache and that it should be fixed there. mod_disk_cache.c already contains the needed code in write_headers, but it is executed too late. So I just moved this piece of code and created an appropriate patch for this which I will attach.  I removed my patch from my mod_jk and added my patch to mod_disk_cache and my problem from 30398 remains silent. I hope that this patch will also solve your problem. A short feedback on your experience with the patch would be much appreciated.  BTW: If you have any problems with mod_cache storing Cookies unintentional, or with other weird HTTP header caching behaviour you may find the following links useful:  http://nagoya.apache.org/bugzilla/show_bug.cgi?id=30399 http://nagoya.apache.org/bugzilla/show_bug.cgi?id=30419  Created an attachment (id=12339) proposed solution patch to mod_disk_cache.c  I've tested this patch and it works perfectly. After either image or .css file is cached headers contain proper Content-Type thus allowing for proper display in strict HTML validating browsers! Thanks!  Here is the output from the original wget commands:  1. First request for a resource: 16:36:57 (328.88 KB/s) - "common.css' saved [10440/10440]   HTTP/1.1 200 OK Date: Wed, 04 Aug 2004 21:36:56 GMT Server: Apache/2.0.50 (Fedora) Content-Length: 10440 Last-Modified: Fri, 23 Jul 2004 12:56:12 GMT Accept-Ranges: bytes Content-Type: text/css Vary: Accept-Encoding,User-Agent Keep-Alive: timeout=30, max=100 Connection: Keep-Alive  2. Next request for the same resource: 16:36:59 (463.42 KB/s) - "common.css' saved [10440/10440]   HTTP/1.1 200 OK Date: Wed, 04 Aug 2004 21:36:59 GMT Server: Apache/2.0.50 (Fedora) Accept-Ranges: bytes Content-Length: 10440 Last-Modified: Fri, 23 Jul 2004 12:56:12 GMT Content-Type: text/css Age: 4 Keep-Alive: timeout=30, max=100 Connection: Keep-Alive *** Bug 29016 has been marked as a duplicate of this bug. *** Created an attachment (id=12879) Patch against 2.0.51  A variant of the 'patch against 2.0.51' has been committed to HEAD as modules/experimental/mod_disk_cache.c rev 1.63.  Thanks! Backported to v2.0.53. 			Graham Leggett	Igor Fedulov	Justin Erenkrantz	Paul Querna	R??diger Pl??m
30308	null	RESOLVED		Matt Burke	1090683480000	1104101523000		Add Example For VitualHost plus Proxy While I'm aware that the VirtualHost Examples page says that another page on combining Proxy and VirtualHost in the config is on its way, it can't come soon enough for me.  Here's the example I'd like added (Let me know if I should edit and attach the html instead, I want to help :).  Using VirtualHost and mod_proxy together: We use ProxyPreserveHost because the secondary server should recieve requests with the desired hostname intact in case we're proxying multiple hostnames to a single machine.  Be careful if you've already used ProxyPass to set up a folder to the secondary server, that can conflict with  Server configuration <VirtualHost *:*>   ProxyPreserveHost On   ProxyPass / http://192.168.111.2/   ProxyPassReverse / http://192.168.111.2/   ServerName bugzilla.mydomain.com   ServerAlias bugzilla.mydomain.com </VirtualHost>	Thanks. Example has been added in latest svn, and will be in the next release. Should also be on the website RSN.			Rich Bowen
30370	null	RESOLVED		Axel-Stephane Smorgrav	1091028120000	1188891651000		Pages cached in more than one cache remain stale although it is revalidated. On a reverse proxy, centuri, we have both disk cache and mem cache activated.  The memory cache is activated first and is only supposed to cache elements of  size smaller than 10,000 bytes. The disk cache takes care of anything not  cached by the memory cache.  Somehow, at one point a file of size smaller than 10,000 bytes ends up being  cached by the disk cache. Don't ask me why (maybe the mem cache was filled up  and the element ended up on disk?) - it's beyond the point. Eventually, the  file in disk cache ends up stale. At that point, when the element (style.css)  is requested, the disk cache responds that it is stale and a proxy request is  issued to the backend server. The fresh element ends up being cached in memory  since it is smaller than 10 KB, and the stale entry remains in the disk cache...  When the caches are queried, it seems like the disk cache is always queried  first.  The logs below should clearly show what happens. mod_disk_cache does not appear  to log the element as stale, but I know that the disk cache contains a stale  copy of styles.css because I looked it up in the file system. Removing the  element from the disk cache also removes the symptoms.  Please find below the log trace of two requests for the same element style.css  on the reverse proxy centuri:3080. The backend server is backend:7010. The two  requests are separated by some CRs.  [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(66): proxy: HTTP:  canonicalising URL //centuri:3080/html/styles.css [Mon Jun 07 08:48:57 2004] [debug] mod_proxy.c(416): Trying to run  scheme_handler [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(1042): proxy: HTTP: serving URL  http://centuri:3080/html/styles.css [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(178): proxy: HTTP connecting  http://centuri:3080/html/styles.css to centuri:3080 [Mon Jun 07 08:48:57 2004] [debug] proxy_util.c(1160): proxy: HTTP: fam 2  socket created to connect to centuri [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(327): proxy: socket is connected [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(361): proxy: connection  complete to 150.175.10.189:3080 (centuri) [Mon Jun 07 08:48:57 2004] [debug] mod_cache.c(344): cache: stale cache - test  conditional [Mon Jun 07 08:48:57 2004] [debug] mod_cache.c(391): cache: nonconditional - no  cached etag/lastmods - add cache_in and DECLINE [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(66): proxy: HTTP:  canonicalising URL //backend:7010/html/styles.css [Mon Jun 07 08:48:57 2004] [debug] mod_proxy.c(416): Trying to run  scheme_handler [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(1042): proxy: HTTP: serving URL  http://backend:7010/html/styles.css [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(178): proxy: HTTP connecting  http://backend:7010/html/styles.css to backend:7010 [Mon Jun 07 08:48:57 2004] [debug] proxy_util.c(1160): proxy: HTTP: fam 2  socket created to connect to backend [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(327): proxy: socket is connected [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(361): proxy: connection  complete to backend:7010 (backend) [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(877): proxy: start body send [Mon Jun 07 08:48:57 2004] [debug] mod_cache.c(532): cache: running CACHE_IN  filter [Mon Jun 07 08:48:57 2004] [debug] mod_cache.c(790): cache: Caching  url: /html/styles.css [Mon Jun 07 08:48:57 2004] [info] mem_cache: Cached url:  centuri/html/styles.css? [Mon Jun 07 08:48:57 2004] [debug] mod_headers.c(521): headers:  ap_headers_output_filter() [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(936): proxy: end body send [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(877): proxy: start body send [Mon Jun 07 08:48:57 2004] [debug] mod_headers.c(521): headers:  ap_headers_output_filter() [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(936): proxy: end body send   [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(66): proxy: HTTP:  canonicalising URL //centuri:3080/html/styles.css [Mon Jun 07 08:48:57 2004] [debug] mod_proxy.c(416): Trying to run  scheme_handler [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(1042): proxy: HTTP: serving URL  http://centuri:3080/html/styles.css [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(178): proxy: HTTP connecting  http://centuri:3080/html/styles.css to centuri:3080 [Mon Jun 07 08:48:57 2004] [debug] proxy_util.c(1160): proxy: HTTP: fam 2  socket created to connect to centuri [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(327): proxy: socket is connected [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(361): proxy: connection  complete to 150.175.10.189:3080 (centuri) [Mon Jun 07 08:48:57 2004] [debug] mod_cache.c(344): cache: stale cache - test  conditional [Mon Jun 07 08:48:57 2004] [debug] mod_cache.c(391): cache: nonconditional - no  cached etag/lastmods - add cache_in and DECLINE [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(66): proxy: HTTP:  canonicalising URL //backend:7010/html/styles.css [Mon Jun 07 08:48:57 2004] [debug] mod_proxy.c(416): Trying to run  scheme_handler [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(1042): proxy: HTTP: serving URL  http://backend:7010/html/styles.css [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(178): proxy: HTTP connecting  http://backend:7010/html/styles.css to backend:7010 [Mon Jun 07 08:48:57 2004] [debug] proxy_util.c(1160): proxy: HTTP: fam 2  socket created to connect to backend [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(327): proxy: socket is connected [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(361): proxy: connection  complete to backend:7010 (backend) [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(877): proxy: start body send [Mon Jun 07 08:48:57 2004] [debug] mod_cache.c(532): cache: running CACHE_IN  filter [Mon Jun 07 08:48:57 2004] [debug] mod_cache.c(790): cache: Caching  url: /html/styles.css [Mon Jun 07 08:48:57 2004] [info] mem_cache: Cached url:  centuri/html/styles.css? [Mon Jun 07 08:48:57 2004] [debug] mod_headers.c(521): headers:  ap_headers_output_filter() [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(936): proxy: end body send [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(877): proxy: start body send [Mon Jun 07 08:48:57 2004] [debug] mod_headers.c(521): headers:  ap_headers_output_filter() [Mon Jun 07 08:48:57 2004] [debug] proxy_http.c(936): proxy: end body send  And the cache configuration:              MCacheMaxObjectSize 10000             MCacheSize          70000             CacheEnable         mem /              CacheRoot           /apache/cache             CacheSize           150000             CacheEnable         disk /  So, during the first request for style.css, the disk cache is stale. A new copy  of the file is retrieved from the backend and stored in memory cache. Then we  issue a second request, and it turns out the cached copy is still stale...  This behaviour was observed on Sun Solaris 8, but from what I saw in the code,  there is no reason to think it would behave differently on other platforms.	Can you please try the mod_disk_cache that is part of 2.0.52 or CVS HEAD?  There have been many fixes for it recently. Though not sure if it is the same cause, I'm having exactly the same issue and  I think I have tracked down the bug. I've reviewed the code in latest snapshot  and believe this bug still exists both in 2.0 and 2.2 (I have verified it with  2.0 tree). Also, this could also be a bug in mod_mem_cache.c.  The cause of this bug is that cached entry never gets removed from cache  repository maintained by mod_*_cache. There's a issue in  cache_storage.c:cache_select_url method that incorrectly(?) handles cache- >stale_handle. Here's the code:    fresh = ap_cache_check_freshness(h, r);   if (!fresh) {     if (info && info->etag) {        ...        cache->stale_handle = h;     }     else if (info && info->lastmods) {       ...       cache->stale_handle = h;     }     return DECLINED;   }   ...   cache->handle = h;  As you can see, even when cache has expired, there's a case when cache- >stale_handle does not get set. Because of this, following part of the code in  mod_cache.c:cache_save_filter is never executed:    if (cache->stale_handle) {     if (r->status == HTTP_NOT_MODIFIED) {       ...     }     else {       /* Oh, well.  Toss it. */       cache->provider->remove_entity(cache->stale_handle);       /* Treat the request as if it wasn't conditional. */       cache->stale_handle = NULL;     }   }  So when cache->stale_handle is not set, above remove_entity is never called,  meaning (expired) cache remains in cache repository.  Now, because obsolete cache remains, following code in  mod_cache.c:cache_save_filter fails with mod_mem_cache:    /* no cache handle, create a new entity */   if (!cache->handle) {     rv = cache_create_entity(r, url, size);     ...   }    if (rv != OK) {     /* Caching layer declined the opportunity to cache the response */     ...  Looking into mod_mem_cache.c:create_entity, there's a following code:    tmp_obj = (cache_object_t *) cache_find(sconf->cache_cache, key);   ...   if (tmp_obj) {     /* This thread collided with another thread loading the same object      * into the cache at the same time. Defer to the other thread which      * is further along.      */     cleanup_cache_object(obj);     return DECLINED;   }  So mod_mem_cache.c:create_entity (incorrectly) returns a 'thread conflict'  error when obsolete cache remains in cache repository. And due to this return  code, mod_cache.c:cache_save_filter skips caching.  To fix (or workaround) this issue, cache_storage.c:cache_select_url can be  fixed as follows:    fresh = ap_cache_check_freshness(h, r);   if (!fresh) {     cache->stale_headers = apr_table_copy(r->pool, r->headers_in);     cache->stale_handle = h;      /* Make response into a conditional */     /* FIXME: What if the request is already conditional? */     if (info && info->etag) {       /* if we have a cached etag */       apr_table_set(r->headers_in, 'If-None-Match', info->etag);     }     else if (info && info->lastmods) {       /* if we have a cached Last-Modified header */       apr_table_set(r->headers_in, 'If-Modified-Since', info->lastmods);     }     return DECLINED;   }  Similar fix can be done with Apache 2.2 as well.  I'm now looking into caching behavior of mod_disk_cache.c, as unlike  mod_mem_cache.c, it seems it does not check for thread-level conflict. After all review is done, I'll send in a patch.  > Though not sure if it is the same cause, I'm having exactly the same issue ...  After reading first poster's message again, I guess my issue isn't exactly the  same issue. My issue is that mod_cache never refreshes cached entry once  initial cache expired. So access_log goes on like below:    'GET /real/hello.php HTTP/1.0' 200 <-- query to backend   'GET /hello.php HTTP/1.0' 200      <-- caches and returns cached response   'GET /hello.php HTTP/1.0' 200      <-- cached response   'GET /hello.php HTTP/1.0' 200      <-- cached response   'GET /hello.php HTTP/1.0' 200      <-- cached response   ...                                <-- time passes and expires   'GET /real/hello.php HTTP/1.0' 200 <-- query to backend   'GET /hello.php HTTP/1.0' 200      <-- don't cache and pass-thru response   'GET /real/hello.php HTTP/1.0' 200 <-- query to backend   'GET /hello.php HTTP/1.0' 200      <-- don't cache and pass-thru response   'GET /real/hello.php HTTP/1.0' 200 <-- query to backend   'GET /hello.php HTTP/1.0' 200      <-- don't cache and pass-thru response   ...  I'm doing a reverse proxied configuration, and here's an excerpt from  httpd.conf:    <VirtualHost *:8080>    CacheEnable mem /    CacheIgnoreHeaders Set-Cookie    MCacheSize 65535    MCacheMaxObjectCount 8192    MCacheMaxObjectSize 65535     ProxyPass        / http://127.0.0.1/real/    ProxyPassReverse / http://127.0.0.1/real/    ProxyPreserveHost On    ProxyTimeout 5   </VirtualHost>  And the content of hello.fphp is:    <?php   header('Expires: ' . date(DATE_RFC822, time() + 10));   print_r($_SERVER);   ?>  As you can see, this should expire in 10 seconds after cache is made, and it does work as expected. But it never gets cached after its first expiration, probably due to apache issue I posted above.  Thanks for the report. Please use httpd 2.2.x for caching since it contains many fixes and improvements since the days of the experimental cache module of 2.0.x. Nevertheless I think that the problem you describe is also present in 2.2.x. Could you please give the attached patch a try? It is against trunk, but it should also work against 2.2.x. Created an attachment (id=18401) Patch against trunk  Thanks for the patch!  Your patch worked perfectly though I had to make following change to adapt it to 2.0:  - irv = cache->provider->remove_url(h, r->pool); + irv = cache->provider->remove_url(url);  Yes, I know 2.2 is now the recommended version (especially when using caching feature), but for now, I need to go with 2.0 due to support issue.  Committed to trunk as r481886 (http://svn.apache.org/viewvc?view=rev&rev=481886). Proposed for backport as r571936 (http://svn.apache.org/viewvc?rev=571936&view=rev). Backported to 2.2.x as r572626 (http://svn.apache.org/viewvc?rev=572626&view=rev).			Paul Querna	Ruediger Pluem	Taisuke Yamada
30385	null	RESOLVED		Graham Leggett	1091114220000	1128447791000		' While building httpd v2.1 under RHEL3, the following warning is issued:  /home/gatekeeper/minfrin/src/apache/sandbox/proxy/httpd-2.1/modules/experimental/util_ldap.c:1218: the use of "tmpnam' is dangerous, better use "mkstemp' make[1]: Leaving directory "/home/gatekeeper/minfrin/src/apache/sandbox/proxy/httpd-2.1'	PHP has a thing at the end of their make saying this is safe to ignore. Any reason we can't ignore it too? ./modules/ldap/util_ldap.c:            st->lock_file   = ap_server_root_relative(st->pool, tmpnam(NULL));  it may be safe but it's totally wacky since tmpnam returns filenames with a /tmp prefix.  The APR tmpfile interface should be used instead.  Is the APR tmpfile interface available in v0.9 of APR? Actually since this is just for a mutex, the right thing to do is to pass a NULL filename parameter to apr_global_mutex_create if no CacheFile is specified, rather than some random temporary filename. According to the APR docs for apr_global_mutex_create():  fname \tA file name to use if the lock mechanism requires one. This argument should always be provided. The lock code itself will determine if it should be used.  So the compiler claims tmpnam() is evil, but all the alternatives involve actually opening a file, which isn't what we need.  Does APR have a temp file creation function? Are the APR docs above about the argument always being provided correct, or is it really safe to pass NULL to this function on all platforms?  APR now has apr_file_mktemp():   http://docx.webperf.org/group__apr__file__io.html#ga50  I assume this does the right thing on the various platforms.  apr_file_mktemp() opens a file, apr_global_mutex_create() needs a filename, not an actual file.  Ideally apr_global_mutex_create() should be able to just accept NULL and internally use apr_file_mktemp(), rather than insisting on a temp file name from the calling application.  Regards, Graham -- It actually does do precisely that in all the Unix implementations.  Alternatively using a serverroot-relative filename 'logs/<something-unique>.<pid>' should work as well. Fixed in 2.1.x releases, probably not worth a backport.			Graham Leggett	Joe Orton	Paul Querna	Sander Temme
30399	null	CLOSED		R??diger Pl??m	1091142720000	1100481018000		mod_cache caching Set-Cookie headers Hi,  I have a question regarding mod_cache's behaviour about caching response headers. I noticed that mod_cache also stores cookies (or better the Set-Cookie header) with all the other End-to-end headers (see 13.5.1 RFC 2616). As I can see from the RFC this is required to be RFC 2616 compliant.  In my special case this is a problem because I try to use mod_cache to cache Tomcat generated jsps for performance reasons.  Currently I help myself by adding  apr_table_unset(headers_out, 'Set-Cookie');  to ap_cache_cacheable_hdrs_out. As this approach breaks RFC 2616 compliance I am sure that this approach will never be part of the official Apache code.  To prevent patching of future Apache versions I would like ask to if there is any chance that an additional configuration directive will be added to mod_cache that allows to define headers that should not be cached. Of course setting this directive in your configuration would break RFC 2616 compliance of mod_cache, so the default value for this directive should be empty or none.   Regards  R??diger Pl??m	Hi,  meanwhile I wrote a patch to mod_cache / mod_disk_cache / mod_mem_cache that introduces the new server config directive CacheStoreCookies. By default this directive is set to 'On' thus leaving everything as it currently behaves in 2.0.50. Setting CacheStoreCookies to 'Off' prevents the Set-Cookie headers from being stored by the cache. This way I can configure the behaviour that I need in my special case.  Regards  R??diger Pl??m Created an attachment (id=12295) CacheStoreCookies Patch  My patch has a little different implementation approach compared to the patch of 23687. Also the patch for the documentation is currently missing. I will add this when I find time or someone gets interested in my version of the patch. Created an attachment (id=12877) Patch against 2.0.51  Created an attachment (id=13097) More general approach patch against 2.0.52.  After a discussion on the developer list the new patch has a more general approach and replaces the previous CacheStoreCookies directive with the more general CacheIgnoreHeaders directive which allows to prevent arbitrary headers from being stored, not just cookies. CacheIgnoreHeaders is now in 2.1 and will be incorporated in a future release.  Thanks! Created an attachment (id=14434) Patch against 2.0.53 			Justin Erenkrantz	R??diger Pl??m
30464	null	CLOSED		R??diger Pl??m	1091624880000	1093615830000		SSL_ variables from mod_ssl not available for RewriteCond tests in mod_rewrite Hi,  1. Environment:  OS: Linux Apache: 2.0.50  2. Problem:  As I upgraded some Apache 1.3.x systems to Apache 2.0.50 I noticed that the SSL_ variables defined by mod_ssl are no longer available for checks with RewriteCond.  In Apache 1.3.x RewriteConds like the following delivered reasonable results:  RewriteCond %{SSL_CIPHER_USEKEYSIZE} !^[0-9][0-9][0-9]  On Apache 2.0.50 the input stays empty as the following excerpt from the RewriteLog (Level 9) shows:  92.168.2.4 - - [04/Aug/2004:11:57:06 +0200] [www.something.de/sid#8122700][rid# 818a1b0/initial] (4) RewriteCond: input='' pattern='!^[0-9][0-9][0-9]' => matche d  Even after adding SSLOptions +StdEnvVars and modifying the RewriteCond to  RewriteCond %{ENV:SSL_CIPHER_USEKEYSIZE} !^[0-9][0-9][0-9]  nothing changed. The input remains empty.  3. Analysis  The root cause for this problem is that mod_ssl writes its SSL_ variables to r->subprocess_env in its fixup handler (provided SSLOptions contains StdEnvVars), but all fixup handlers are executed after the translate_name handlers. On the other hand the evaluation of the rewrite rules happens in mod_rewrites translate_name handler, so the variables are not available at this point of time.  4. Solution proposal  I noticed that the documentation for mod_rewrite of Apache 2.1 points out a special prefix for the SSL_ variables named SSL: (like ENV: for environment variables). So the solution approach is to add a piece of code to lookup_variable in mod_rewrite.c that checks for variablenames that start with SSL: after the check for the variables which names start with ENV:. The mod_ssl function ssl_var_lookup can be used to get the values for the specific variables as it has been registered by mod_ssl with APR_REGISTER_OPTIONAL_FN in ssl_engine_vars.c. After that it would be possible to check the SSL_ variables in RewriteCond's via prefixing the variable name with SSL:. For example the following RewriteCond   RewriteCond %{SSL:SSL_CIPHER_USEKEYSIZE} !^[0-9][0-9][0-9]  would be a replacement for my old (Apache 1.3.x) RewriteCond  RewriteCond %{SSL_CIPHER_USEKEYSIZE} !^[0-9][0-9][0-9]  I wrote an appropriate patch for mod_rewrite which I tested on my environment. It worked as designed. I attach the patch.   Regards  R??diger Pl??m	Created an attachment (id=12327) Solution proposal patch  Currently my patch is missing the according patch of the mod_rewrite documentation. As my patch is a backport (even from the coding point of view as I compared my patch and an actual CVS snapshot of Apache 2.1) of the same functionality offered by Apache 2.1 I simply backported the according paragraph for the Apache 2.1 documentation of mod_rewrite.xml. So the contents of the documentation patch I will attach has been written by one of the Apache 2.1 mod_rewrite contributors / authors. Created an attachment (id=12515) Documentation patch  Thanks for the patch.  This has been proposed for backport to 2.0.  It can't be done by including mod_ssl.h, since that fails if mod_ssl is not enabled in 2.0, so the optional function declarations have to be duplicated. For references, the proposed patches are:  http://www.apache.org/~jorton/mod_rewrite-2.0-sslvar.diff http://www.apache.org/~jorton/mod_ssl-2.0-ishttps.diff Thanks for the feedback and the references. You are right it is not possible to include mod_ssl.h in Apache 2.0 without enabling it via configure. I did not notice that as I compile my Apache always with mod_ssl. So I included mod_ssl.h to avoid the duplication of the optional function declarations. It is nice to hear that this feature should be backported to Apache 2.0. Do you already know a release of Apache 2.0 in which this will be included? The backport requires votes from two additional developers, so it depends when people have time to review the changes. Now committed for 2.0.51. Thats very good news. Thanks.			Joe Orton	R??diger Pl??m
30487	null	CLOSED		alexei bozrikov	1091702640000	1094655513000		 compiler Built Apache-2.0.50 on PowerPC 601 machine (IBM 7009 C10) running AIX 5.1  (maintenance level 006), using Visual Age C for AIX v 6.0 (with latest  maintenance levels applied). Following options were used: './configure' / '--with-mpm-worker' / '--enable-so' / '--enable-layout=Apache' / '--enable-mods-shared=most' / '--with-expat=/home/bozy/src/httpd-2.0.50/srclib/apr-util/xml/expat' / '--enable-static-support' / 'CC=xlc_r' / 'CFLAGS=-O2 -I/usr/local/include' / 'LDFLAGS=-L/usr/local/lib' /  Note: I neded specifically '_r' compiler for Apache to build properly with  libdb-4.2, since Berkeley DB on AIX builds as multithreaded.  Everything compiled and built OK apart from some compiler warnings about  incorrect file suffixes on '.la' files (I guess these could be ignored). I made  an 'apachectl start' - everything started OK, error_log showing: [quote] [Thu Aug 05 13:20:40 2004] [notice] Apache/2.0.50 (Unix) PHP/5.0.0 DAV/2  configured -- resuming normal operations [unquote] When trying to telnet to port 80 of the server I get following: [quote] $ telnet powerpc 80   Trying... Connected to powerpc.unicom.cg. Escape character is '^]'. Connection closed. [unquote] No errors/messages logged in access_log/error_log. I tried all thinkable  combinations of optimization flags during compile, unloaded nearly all modules  (including PHP5) etc. to no avail.  Finally (being almost sure nothing will change) I used 'cc_r' compiler instead  of 'xlc_r' - not sure exactly what is the difference between the two, I guess  it may be different C language level/standard and linking with some other set  of default libraries. And everything works great! I've just checked couple of  PHP scripts with MySQL - works perfectly fine. It can't be really called  a 'bug' in Apache software, rather some weirdness of IBM C compiler, but I felt  like reporting it to save some time to thers trying to compile it, as I've  spent 3 days myself, must admit - I am no computer programmer. By the way, perl  5.8.5 compiles, builds and tests with both flavors - either with 'cc_r'  or 'xlc_r'.   Regards  Alexei	As far as we can tell, this problem is due to a bug in the native AIX compiler when building Apache at -O2.  A special patch will resolve this; go to http://www.apache.org/~trawick/aixstatus.html and search for 'optimization problem'.  Please re-open if this patch does not resolve the problem. Well, I've been reading about this as well (perl, for example, does not even  compile with '-O2', while it does with '-O2 -qstrict'). I have tried 'xlc_r -O'  with Apache as well to no avail, while 'cc_r' compiles equally well with '-O'  and '-O2' and I could not see any difference in Apache behavior so far (at  least with PHP5/MySQL CGI scripts). To me looks more like a difference in set  of default libraries to link with.  Maybe this deserves to be put in some sort of README for Apache, since both AIX  5.1 and C for AIX 6.0 are fairly recent products. An excerpt from 'man xlc': [quote] -O        Optimize generated code. -O2       Same as -O. [unquote]  Actual 'httpd' binaries do not compare, when compiled with '-O' and '-O2'. Maybe IBM does not tell all the truth...  regards  Alexey Yes, putting it in README.platforms is a good idea; I'll do that. Yes, I have applied the 'optimize bug' patch, but I forgot to mention it in my  initial report, thanks for pointing it out. "Apache AIX status' document  mentions 'xlc' as working (with '-O') when called as 'xlc_r' or 'xlC_r'. Seems  that in C for AIX V6.0 this behavior had changed and it is better to resort  to 'cc_r'. I guess the case could be closed :-)  Alexei okay, I can verify that with xlc 5.0.2.5 I don't need the patch if I use CC=cc_r CFLAGS=-O2 but I do need the patch if I use CC=xlc_r CFLAGS=-O2  the difference in xlc_r and cc_r behavior can be seen in /etc/vac.cfg, which specifies what libraries and other options are used based on the wrapper (CC)  the difference is in the default options   cc_r has -qlanglvl=extended,-qnoro,-qnoroconst  xlc_r has -qansialias  all other options, libraries, stubs, and library paths are the same  I've updated README.platforms to point out   stable location of the server/core.c patch   xlc_r -O2 needs the patch   cc_r  -O2 doesn't need the patch  Thanks for your research on this topic!  (I'll update my unofficial notes on AIX + Apache2 shortly.)			Jeff Trawick	alexei bozrikov
30585	null	CLOSED		Swedish IT Incident Centre	1092224520000	1093292433000		Apache mod_ssl CRL format string bug (Initially reported as SITIC Vulnerability Advisory SA04-001, redefined as bug  after discussion with ASF httpd security team)  Apache's mod_ssl module suffers from a format string bug when logging information about CRLs. If an administrator installs a malicious CRL file, this bug can lead to the execution of arbitrary code.  The function ssl_callback_SSLVerify_CRL() in modules/ssl/ssl_engine_kernel.c calls ap_log_error() with data from the CRL as the format string instead of using the data as parameters, leading to a security breach.  This bug was discovered by Ulf Harnhammar for SITIC, Swedish IT  Incident Centre.  The included patch 'issue1.patch' is our attempt at correcting this issue:  --- modules/ssl/ssl_engine_kernel.c\t2004-06-07 12:18:37.000000000 +0200 +++ modules/ssl/ssl_engine_kernel.c.ulf\t2004-08-02 12:49:18.000000000 +0200 @@ -1372,7 +1372,7 @@                BIO_free(bio);   -            ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, buff); +            ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, '%s', buff);          }            /*	Thanks for the report.  Should we credit Ulf Harnhammar for the fix in the CHANGES file? Please credit me/us as 'Ulf Harnhammar (SITIC)'. Thanks for the patch; this has been committed to HEAD:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_kernel.c?r1=1.108&r2=1.109			Joe Orton	Swedish IT Incident Centre
30592	null	RESOLVED		Eberhard Ruff	1092230520000	1106348876000		failover for authentication with AuthLDAPURL is not possible Using a .htaccess to authenticate against an LDAP server:  AuthType Basic AuthLDAPURL 'ldap://localhost ldap.host.com:10389/ou=myorg?uid?sub' Require valid-user  Failover is only working if all LDAP servers using the same port. The port number can only be specified after the last server.  It should be possible to specify port numbers for all ldap servers.	The URL handling follows the RFC for LDAP URL handling, and is controlled by the LDAP library being used - which may or may not allow what you describe.  In v2.1 of httpd, which now uses apr v1.0, the URL handling is no longer done by the LDAP library, but by custom code in apr-util instead, making this possible.  Will have to check RFC implications first though.  I have already been looking into this one.  The issue is that the URL_parse  function assigns the port value to the first :port that it find in the URL.   It uses that port in the ldap_init() call which becomes the default port for  any host that does not also specify a port.  The solution is to always pass  the default ports (ie. 389 or 636) in the ldap_init() calls in apr_ldap_init ().  This will cause the default ports to be used if the host does not specify  a port.  LDAP will do the right thing for any other host:port in the URL. There are 2 patches for this bug, one in apr_ldap_url.c and the other in  util_ldap.c.  The parsing function in apr_ldap_url.c was assuming that the  host string would only contain a single host.  Therefore it truncated the host  portion of the URL after the first :port that it found.  If the last host in  the URL also specified a :port, then it assumed that all hosts could be  reachable on the same port.  Once this was fixed then util_ldap.c needed to call apr_ldap_init() always  specifying the default ports for LDAP and LDAPS.  If the host string also  includes ports, they will override any port specified in the port parameter.   Both of these fixes have been committed to HEAD and need to be backported.   As Graham mentioned above, the ldap url parsing in 2.0 is handled by the LDAP  libraries.  ldap_parse_url() truncates the host list after the first host:port  is found.  There appears to be some inconsistencies between the different  SDK's with regards to this function.  To fix this issue in 2.0, at least the  recent patches to apr_ldap_url.c would have to be backported and all of the  platforms would have to use the apr version of ldap_parse_url() rather than  the LDAP library version. I am assuming that the patches have been applied. If not, please reopen this bug. 			Brad Nicholes	Graham Leggett
30723	null	CLOSED		Friedrich Haubensak	1092823920000	1092828387000		apachectl uses wrong directory to find envvars apachectl uses bindir instead of sbindir to look for envvars:  you should change @exp_bindir@/envvars to @exp_sbindir@/envvars in lines 46 and 47 of ./support/apachectl.in	Thanks for your fix, and thanks for using Apache.  I've committed the fix to Apache 2.1-dev and have also proposed that it be merged into the next 2.0.x release. 			Jeff Trawick
30732	null	CLOSED		Noah	1092845820000	1095280150000		Default error pages are not valid HTML If you run any of the default error pages through the W3C's validator you will find they are not valid.	I just checked a default Not Found (404) page.  It is valid HTML 2.0 (though only by accident).  Either it's a content negotiation issue (what language are you seeing pages in?) or you have misunderstood valid HTML. I don't think it was by accident ;) It is by accident.  It contains XHTML syntax <hr />.  That is an SGML abbreviated form that is valid only due to a defect in the HTML specs (see for example http://valet.webthing.com/page/parsemode.html for explanation).  Any truly compliant browser will display the closing '>' as text after the horizontal rule.  Since that is clearly not the intention, it is relying on tag-soup parsing.  Replace that with HTML <hr> and it becomes valid without relying on SHORTTAGS. Oh, this was modified by someone who didn't know better. *That* is the accident ;-) (and a bug). A <hr /> tag is only valid in an XHTML document.  If the document is XHTML it should also technical be served with the correct MIME type 'text/application-xml' not 'text/html'. This however is the subject of much debate and it is generaly safer to leave it as 'text/html' untill browsers reliably know what to do with it. As Nick already said, <hr /> *is* valid HTML (because of shorttags). But it's a bug though, since not intended to be there. Fixed in 2.1 and proposed for backport. Backported to v2.0. 			Andr?? Malo	Graham Leggett	Nick Kew	Noah
30919	null	CLOSED		Rici Lake	1093730520000	1094178824000		mod_info failed to show all info In the scan of sub-config trees, mod_info sometimes seems to lose track of where it was, failing to  provide all information and/or scrambling the </close> tags. This seems particularly evident in  <VirtualHost> sections.  The easiest way to fix it seemed to be to rewrite the tree scan recursively; the enclosed patch  implements that, as well as correctly indenting subsection headers and allowing for indentation nesting   of more than two levels.  It also implements a new feature: ?config simply dumps the entire configuration tree without sorting it  into modules. I left the indentation incorrect in the second part in order to avoid adding 130 specious  lines to the patch.  The file in the url is the complete mod_info.c, detabbed and indented properly	Created an attachment (id=12561) patch for mod_info (head)  A Patch based on the one here has been committed to CVS HEAD / 2.1.0.  Thanks for the Patch,  -Paul Querna			Paul Querna	Rici Lake
30920	null	CLOSED		Al Begley	1093737360000	1096540025000		Digest authentication via mod_digest no longer works in 1.3.31. Digest authentication via mod_digest no longer works in 1.3.31, apparently due to ap_auth_nonce()  returning different values.  I added a log message to the ap_auth_nonce() function in the standard version of http_core.c from  Apache 1.3.31. (This function was added in 1.3.31). It's short so here's the whole function with the log  message:  API_EXPORT(const char *) ap_auth_nonce(request_rec *r) {     core_dir_config *conf;     conf = (core_dir_config *)ap_get_module_config(r->per_dir_config,                                                    &core_module);     if (conf->ap_auth_nonce)        return conf->ap_auth_nonce;      /* Ideally we'd want to mix in some per-directory style      * information; as we are likely to want to detect replay      * across those boundaries and some randomness. But that      * is harder due to the adhoc nature of .htaccess memory      * structures, restarts and forks.      *      * But then again - you should use AuthDigestRealmSeed in your config      * file if you care. So the adhoc value should do.      */ \tchar* nonce = ap_psprintf(r->pool,'%pp%pp%pp%pp%pp',            (void *)&((r->connection->local_addr).sin_addr ),            (void *)ap_user_name,            (void *)ap_listeners,            (void *)ap_server_argv0,            (void *)ap_pid_fname); \tap_log_error(APLOG_MARK, APLOG_NOERRNO|APLOG_INFO, r->server,              'nonce = '%s'', nonce);  \treturn nonce; }  The log message shows that this function returns one value when called to provide the nonce to pass to  the client, and a different value when called later to verify that the nonce received from the client was  the one sent (check_nonce()). So the check fails, and the client cannot access the realm. The change is  in the first of the 5 concatenated addresses (the one based on the request record address):  [Sat Aug 28 16:40:53 2004] [info] nonce = '82b834813e608261c0bffffd52803b98'  (User enters name and password at a WebDAV client...)  [Sat Aug 28 16:40:58 2004] [info] nonce = '82e834813e608261c0bffffd52803b98' [Sat Aug 28 16:40:58 2004] [error] [client 17.221.41.169] Client is using a nonce which was not issued  by this server for this context: / [Sat Aug 28 16:40:58 2004] [info] nonce = '82e834813e608261c0bffffd52803b98'  (User gets the name and password dialog again...)  The problem can be worked around by specifying the AuthDigestRealmSeed directive, or by switching  to mod_auth_digest, but existing configurations are broken by this.	Thanks for the report.  The fix has been checked in for the next 1.3 release:  http://cvs.apache.org/viewcvs.cgi/apache-1.3/src/main/http_core.c?r1=1.337&r2=1.338 			Joe Orton
31036	null	CLOSED		Swedish IT Incident Centre	1094210820000	1097691984000		Apache mod_rewrite DBM file zero byte overflow (Initially reported as SITIC Vulnerability Advisory SA04-003, redefined as bug  after discussion with ASF security team)  Apache's mod_rewrite module can be made to write one zero byte in an arbitrary memory position outside of a char array, causing DoS or possibly buffer overflows.  The function lookup_map_dbmfile() in modules/mappers/mod_rewrite.c copies data from a DBM file to the char array buf in a _secure_ manner, but it zero-terminates the array afterwards in an _insecure_ manner. If the key that is looked up has an n bytes long value, a zero byte will be written in the memory position n bytes from the start of the char array buf, causing a crash.  HTTP requests that exploit this problem are not shown in the access log. The error log will show Segmentation faults, though.  Mitigating factors:  Exploitation requires someone manually configuring the system to use a DBM file and then someone (else) storing malicious data in that DBM file.  This bug was discovered by Ulf Harnhammar for SITIC, Swedish IT  Incident Centre.  The included patch 'issue3.patch' is our attempt at correcting this issue:  --- modules/mappers/mod_rewrite.c\t2004-06-11 23:05:22.000000000 +0200 +++ modules/mappers/mod_rewrite.c.ulf\t2004-07-22 13:58:17.000000000 +0200 @@ -3160,6 +3160,7 @@      char *value = NULL;      char buf[MAX_STRING_LEN];      apr_status_t rv; +    unsigned int copylen;        dbmkey.dptr  = key;      dbmkey.dsize = strlen(key); @@ -3168,10 +3169,10 @@                                r->pool)) == APR_SUCCESS) {          rv = apr_dbm_fetch(dbmfp, dbmkey, &dbmval);          if (rv == APR_SUCCESS && dbmval.dptr) { -            memcpy(buf, dbmval.dptr, -                   dbmval.dsize < sizeof(buf)-1 ? -                   dbmval.dsize : sizeof(buf)-1  ); -            buf[dbmval.dsize] = '/0'; +            copylen = dbmval.dsize < sizeof(buf)-1 ? +                      dbmval.dsize : sizeof(buf)-1; +            memcpy(buf, dbmval.dptr, copylen); +            buf[copylen] = '/0';              value = apr_pstrdup(r->pool, buf);          }          apr_dbm_close(dbmfp);	This also affects Apache 1.3.x.  // Ulf Harnhammar  Thanks Folks.  We've created other patches based on the 2.1 code, which don't cut the value string. It would be nice, if you could review/test them.  I've uploaded the diffs here:  http://www.apache.org/~nd/dbmmap_1.3.patch http://www.apache.org/~nd/dbmmap_2.0.patch I have reviewed and tested your patches, and I didn't find any problems with  them.  // Ulf Harnhammar (SITIC)  If this code is supposed to be robust against arbitrary values of dbmval.dsize the this:    apr_pstrmemdup(r->pool, dbmval.dptr, dbmval.dsize);  still doesn't seem like a good idea.  But I don't know how much validation the particular apr_dbm implementations will give you on .dsize. Hmm, I don't understand ... why? See how the pstrmemdup implementation behaves if passed in n=ULONG_MAX.  But regardless.  only if apr_size_t == ulong. Good question... I think, much of our code relies on apr_size_t being big enough. The fix at http://www.apache.org/~nd/dbmmap_2.0.patch got 4 votes for backport to v2.0.53, and the backport has been committed.  Has this fix been applied to v2.1?  It's *taken* from 2.1 ;-) Cool :) Didn't see a link in STATUS to the commit though, only an external link to the patch - just making sure :)  Patch already applied to v1.3. Closing and marking as fixed. 			Andr?? Malo	Graham Leggett	Joe Orton	Ulf Harnhammar
31083	null	CLOSED		hirofumi harada	1094545860000	1095871006000		Internal Server Error when HTTP/1.0 proxy request and server returns invalid cert ssl_engine_io.c line 1029  When HTTP/1.0 https proxy request (NOT HTTP/1.1 CONNECT),and SSL_connect fail(because of invalid cert etc.), ssl_io_filter_connect returns success. Then next phase,apache send request fail,and http staus Internal Server Error.  In this case,ssl_io_filter_connect might returns HTTP_BAD_GATEWAY.	Thanks for the report.  Fixed as you suggest:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.126&r2=1.127 			Joe Orton
31128	null	CLOSED		Ernst Jan Plugge	1094670720000	1098539175000		t work When any CacheDisable directive is used, no content whatsoever is cached by mod_cache.  Bug found in 2.0.51-rc2, present in 2.0-HEAD, not present in 2.0.50. Found on Solaris 8/SPARC/gcc, verified on Fedora Core 2/Athlon/gcc.  Steps to reproduce: - Use 2.0.51-rc2, including mod_cache, all modules built static, no third party modules, built from pristine sources from httpd.apache.org/dev/dist/ - Use configuration directives: CacheEnable disk / CacheRoot /cache - Content will be cached normally - Clean out cache and add directive: CacheDisable /foo/ - No content at all is cached anymore, including content not under /foo  Some debugging shows that the urllen field of struct cache_disable is always 0, causing the CacheDisable test to always succeed, causing mod_cache to always decline to cache (this all in cache_util.c). Strangely enough, the urllen does appear to be set correctly when the config file is parsed (mod_cache.c).  Removing the urllen field from structs cache_enable and cache_disable, and replacing references to the field with strlen() calls fixes the problem.	Yup I am encoutering this bug too in 2.0.52..  The issue is in ap_cache_providers_list when it iterates through the 'disabled' urls, all the urllen's are 0 in line 86 of cache_control.c.  They are set correclt when tehy are assigned in the the command handler.. Created an attachment (id=13129) Patch to fix the issue  Patch applied to CVS Head. Patch backported to httpd v2.0.53.  *** Bug 32849 has been marked as a duplicate of this bug. ***			Edward Rudd	Graham Leggett	Paul Querna
31183	null	CLOSED		Julian Reschke	1095010380000	1095756601000		LOCK refresh request crashes server Sending a LOCK refresh request to an indirectly locked resource crashes the server.  Steps to reproduce:  MKCOL x  PUT x/y  LOCK x  try to refresh the lock through x/y, so  LOCK x/y   (Test case will be attached separately).	Created an attachment (id=12710) test case (needs JScript/Windows; but can easily rewritten for other environments)  Is it crashing using all three If headers formats? I couldn't reproduce from a quick test here (on Unix).  Can you get a backtrace out of the server? Yes, all of them, it seems.  How do I get the backtrace? Never mind, I've reproduced it.    It's a NULL pointer dereference in fs/lock.c:  \t    /* the lock was refreshed. return the lock. */ \t    newlock = dav_fs_alloc_lock(lockdb, ip->key, dp->locktoken); \t    newlock->is_locknull = !resource->exists;  dp is NULL at time of invocation. Thanks for the report, Julian.  This is what I committed:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/dav/fs/lock.c?r1=1.32&r2=1.33  if you could re-run your tests with that patch applied that would be great.  It passes the litmus test I added. This is fixed in 2.0.51, thanks again. (In reply to comment #0) > Sending a LOCK refresh request to an indirectly locked resource crashes the  server. > Steps to reproduce: > MKCOL x > PUT x/y > LOCK x > try to refresh the lock through x/y, so > LOCK x/y > (Test case will be attached separately).  			CELL	Joe Orton	Julian Reschke
31226	null	RESOLVED		frederic bregier	1095188160000	1129909939000		AddOutputFilterByType deflate not active with mod_proxy I use Apache 2.0 to have a reverse proxy web server that compress with mod_deflate the web pages in direction of the users. Applications behind (on application 'proxified' server) generate : - text/html document - application/pdf or others like jpg document  both using an url such as http://myreverseproxy/application/application.exe or application.php whatever like this.  The url is always the same for one application, only the context (session) implies the answear (html or pdf document). We want to compress document with type mime = text, but not those with jpg or pdf type mime.  But here is the problem, with proxypass and proxypassreverse :  1) using SetOutputFilter DEFLATE implies that everything is compressed even if the mime type is a pdf or jpg since the exclusion can be based  only on url, which is not possible here. We can exclude files like http://myreverseproxy/application/image.jpg but not the same jpg create dynamically by  http://myreverseproxy/application/application.exe  2) using AddOutputFilterByType DEFLATE text/html text/plain compressed nothing at all, neither html neither pdf or jpg. And accordingly to the documentation and sources on the web, this second solution should be the correct one. Every mime types are defined and ok, the returned documents are using the correct mime type (text/html, application/pdf, ...).  I found not much information on the web on a reverse proxy with compression at the same time. It is quite a big problem for us since we cannot use the web compression in this conditions. Has someone have this problem too ? What can I do to correct this ?  thank you for your help	AddOutputFilterbyType is known to be broken.  Use mod_filter instead: http://httpd.apache.org/docs-2.1/mod/mod_filter.html  Thank you for your note on the broken AddOutputFilterByType. I read the manual page of mod_filter. First, it is only valid with Apache 2.1.  Is it enough stable for this use (reverse proxy and deflate) for production ?  Second, I try to think what could be the syntax of the filter.  FilterDeclare compressed Content-Type FilterProvider compressed deflate $text/html # is it deflate or mod_deflate ? FilterProvider compressed deflate $text/plain FilterProtocol compressed 'change=yes' <Location /application> FilterChain compressed </Location>   But I miss a point. What about the proxy definition ? Is the proxy (proxypass and reverse) applied before this filter, or should I make another Filter with the final filterchain as FilterChain proxyfied compressed ? Therefore, how can I specify the directives for this filter  (proxypass and reverse) ? What about special mod_deflate directives (deflatecompressionlevel for  instance) ?  Also there is the registering of the modules with ap_register_output_filter. Is is done with all standard modules and with what names ? (for mod_proxy, mod_deflate ?)  I know now this module is new, so I can understand that the manual is not  completed. Thank you again This is not really a support forum.  Please direct support questions somewhere more appropriate, such as the apache-users mailinglist or a suitable webservers newsgroup.  But in brief,  (1) it works fine with 2.0  (2) your filter syntax looks fine to me  (3) It doesn't affect your proxy setup or your mod_deflate directives.  Stop looking for complexity where there is none! Thank you for this help. For everyone having the same problem and looking in this bug, I place the solution that works for me. With standard proxy and deflate directives, I placed the following  FilterDeclare compressed Content-Type FilterProvider compressed deflate $text/html FilterProvider compressed deflate $text/plain FilterProvider compressed deflate $text/css #FilterProtocol compressed deflate 'change=yes' FilterChain compressed  I had to download spcifically the mod_filter.c through your web page, Nick (http://www.apache.org/~niq/) since it is not in Apache sources (neither 2.0 or 2.1). I understand since the first release is of august 2004.  I comment FilterProtocol since it produces an error in apache ('FilterProtocol: No such filter'). I try with and without 'deflate'.  Well, at this time, it seems to work as intended. Since it is a quite new module, I have to test it intensively since it is for production later on.  Thank you ! Bug closed !   *** Bug 14335 has been marked as a duplicate of this bug. *** (In reply to comment #1) > AddOutputFilterbyType is known to be broken.  Use mod_filter instead:  The question to me is: Why is it broken? While having a look a PR14335 I found out that the reason for this 'brokenness' seems to be the following lines from ap_add_output_filters_by_type in core.c:      /* We can't do anything with proxy requests, no content-types or if      * we don't have a filter configured.      */     if (r->proxyreq != PROXYREQ_NONE || !r->content_type ||         !conf->ct_output_filters) {         return;     }  Does anybody remember the reason why we cannot do anything on proxied resources? This change had been made in r94028 about 3,5 years ago by Bill Stoddard.  (In reply to comment #4)  [..cut..]  > I had to download spcifically the mod_filter.c through > your web page, Nick (http://www.apache.org/~niq/) > since it is not in Apache sources (neither 2.0 or 2.1).  It is part of httpd 2.1 and was protmoted from its experimental state to be a regular module a while ago. The configure switch for mod_filter is --enable-filter.  [..cut..] I looked at that a while back and nobody could work out why the check is there either.  If the check was removed basic things seem to work fine.  http://mail-archives.apache.org/mod_mbox/httpd-dev/200409.mbox/%3c20040916161122.GA16320@redhat.com%3e  removing it in 2.2/trunk and seeing what breaks seems reasonable. I just committed Joe's patch to the trunk (r327179): http://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/server/core.c?rev=327179&r1=306495&r2=327179 It fixes the problem. Commited to 2.2.x branch (r327793): http://svn.apache.org/viewcvs.cgi/httpd/httpd/branches/2.2.x/server/core.c?rev=327793&r1=307031&r2=327793 *** Bug 41146 has been marked as a duplicate of this bug. *** Created an attachment (id=19243) patch against 2.0.54  adding patch here per Joe Orton on bug 41146.  As noted there, this patch has been applied to a production 2.0.54 server (fedora core 4) which has served about 14 million deflated pages through the proxy without problems. 			Bill McGonigle	Joe Orton	Nick Kew	Ruediger Pluem	frederic bregier
31247	null	CLOSED		Tyler	1095263520000	1096216445000		Intermittent Segmentation Faults in mod_cgi I'm Running RedHat 9 and I seem to be getting Segmentation Faults in mod_cgi.  I've seen a lot of intermittent Segmentation Faults in my error logs:  [Wed Sep 15 01:29:24 2004] [notice] child pid 8684 exit signal Segmentation fault (11) [Wed Sep 15 01:29:28 2004] [notice] child pid 10121 exit signal Segmentation fault (11) [Wed Sep 15 04:20:56 2004] [notice] child pid 13464 exit signal Segmentation fault (11) [Wed Sep 15 04:20:58 2004] [notice] child pid 12372 exit signal Segmentation fault (11) [Wed Sep 15 07:13:50 2004] [notice] child pid 15836 exit signal Segmentation fault (11) [Wed Sep 15 09:47:34 2004] [error] [client 216.209.83.196] request failed: URI too long (longer than 8190) [Wed Sep 15 10:03:56 2004] [notice] child pid 20783 exit signal Segmentation fault (11), possible coredump in /tmp [Wed Sep 15 10:03:57 2004] [notice] child pid 18637 exit signal Segmentation fault (11)  Upon examing the coredump created at 10:03:56 this morning I got the following backtrace: #0  0x40852ce2 in cgi_bucket_read (b=0x8311f10, str=0xbfffdbb8,     len=0xbfffdbbc, block=APR_BLOCK_READ) at mod_cgi.c:660 #1  0x4001d56c in apr_brigade_length (bb=0x74203a65, read_all=1,     length=0xbfffdc18) at apr_brigade.c:182 #2  0x08064141 in ap_byterange_filter (f=0x83143b0, bb=0x831cd00)     at http_protocol.c:2925 #3  0x08071372 in ap_pass_brigade (next=0x40855520, bb=0x831cd68)     at util_filter.c:511 #4  0x401c13ed in send_parsed_content (f=0x8320498, bb=0x831c848)     at mod_include.c:3431 #5  0x08071372 in ap_pass_brigade (next=0x40855520, bb=0x831cd68)     at util_filter.c:511 #6  0x08077ace in default_handler (r=0x8313760) at core.c:3553 #7  0x08067152 in ap_run_handler (r=0x8313760) at config.c:152 #8  0x0806766a in ap_invoke_handler (r=0x8313760) at config.c:358 #9  0x08064a8f in ap_process_request (r=0x8313760) at http_request.c:246 #10 0x08060b79 in ap_process_http_connection (c=0x830d320) at http_core.c:250 #11 0x0806f32a in ap_run_process_connection (c=0x830d320) at connection.c:42 #12 0x08065cd7 in child_main (child_num_arg=1948269157) at prefork.c:609 #13 0x08065df4 in make_child (s=0x809c010, slot=5) at prefork.c:703 #14 0x0806603a in perform_idle_server_maintenance (p=0x809a270)     at prefork.c:838 #15 0x080665ce in ap_mpm_run (_pconf=0x0, plog=0x80c4318, s=0x0)     at prefork.c:1039 #16 0x0806b572 in main (argc=3, argv=0xbfffe024) at main.c:617 #17 0x42015704 in __libc_start_main () from /lib/tls/libc.so.6  So I far I haven't been able to correlate the segmentation faults with the invocation on any particular cgi scripts, however, they only started to appear after we upgraded from Apache 1.3.  I'm also having a possibly related problem with explosive growth in memory usage by Apache.  It's also intermittent, sometimes showing up minutes after Apache is restarted, sometimes showing up hours later.  Over the course of a few seconds an apache process will grow from it's normal size of approximately 50 megs to 500 megs.	Do you have CGI script which output a lot of data? The byterange filter will consume memory proportional to output for such scripts, bug 29962.  From gdb can you:  print *b print *(struct cgi_bucket_data *)b->data  if you do:  up up print *f->r  you should be able to see which particular CGI script has triggered the segfault. Output from print *b:  $1 = {link = {next = 0x8311a10, prev = 0x8311d80}, type = 0x40855520,   length = 4294967295, start = -1, data = 0x8327440,   free = 0x805ea74 <apr_bucket_free>, list = 0x8311720}  Output from print *(struct cgi_bucket_data *)b->data:  $2 = {pollset = 0x8327448, r = 0x8321968}  Thanks for the tip on identifying which script was being run, it turns out it died in an index.html file that uses SSI to include output from two different CGI scripts.  However, that page is not seg faulting everytime it is visited.  Also it died before the server created a log of the request. Thanks.  Can you also do 'print *((struct cgi_bucket_data *)b->data)->r' from that same scope?  May be significant about SSI being involved, I'll try and reproduce like that. print *((struct cgi_bucket_data *)b->data)->r:  $1 = {pool = 0x746e6574, connection = 0x7079542d, server = 0x74203a65,   next = 0x2f747865, prev = 0x6c6d7468, main = 0x6863203b,   the_request = 0x65737261 <Address 0x65737261 out of bounds>,   assbackwards = 1397308788, proxyreq = 943205711, header_only = 825047349,   protocol = 0xa0d0a0d <Address 0xa0d0a0d out of bounds>,   proto_num = 1735223612,   hostname = 0x63727320 <Address 0x63727320 out of bounds>,   request_time = 7306916042975945277,   status_line = 0x656e2f73 <Address 0x656e2f73 out of bounds>,   status = 1869573239, method = 0x65662f6b <Address 0x65662f6b out of bounds>,   method_number = 1920300129, allowed = 3275079475987754341,   allowed_xmethods = 0x64616568, allowed_methods = 0x672e7265,   sent_bodyct = 539125353, bytes_sent = 1685221218,   mtime = 738064979063566949, chunked = 1768176650,   range = 0x6c632076 <Address 0x6c632076 out of bounds>, clength = 1030976353,   remaining = 1634035234, read_length = 1852402804, read_body = 171844203,   read_chunked = 1746952508, expecting_100 = 1030120818,   headers_in = 0x74746822, headers_out = 0x2f2f3a70,   err_headers_out = 0x2e777777, subprocess_env = 0x656d6f68,   notes = 0x6b726f77,   content_type = 0x2e737265 <Address 0x2e737265 out of bounds>,   handler = 0x2f67726f <Address 0x2f67726f out of bounds>,   content_encoding = 0x2d696763 <Address 0x2d696763 out of bounds>,   content_languages = 0x2f6e6962,   vlist_validator = 0x72616573 <Address 0x72616573 out of bounds>,   user = 0x672f6863 <Address 0x672f6863 out of bounds>,   ap_auth_type = 0x67632e6f <Address 0x67632e6f out of bounds>,   no_cache = 1031094121, no_local_copy = 1986290532,   unparsed_uri = 0x69666f66 <Address 0x69666f66 out of bounds>,   uri = 0x76646f64 <Address 0x76646f64 out of bounds>,   filename = 0x61686366 <Address 0x61686366 out of bounds>,   canonical_filename = 0x6e7a647a <Address 0x6e7a647a out of bounds>,   path_info = 0x70666666 <Address 0x70666666 out of bounds>,   args = 0x70666866 <Address 0x70666866 out of bounds>, finfo = {     pool = 0x643d6b26, valid = 1718576225, protection = 645097064,     filetype = 1030517365, user = 1868981862, group = 2036752742,     inode = 1835427939, device = 7600496621405104228, nlink = 2053339491,     size = 1852072292, csize = 2054712934, atime = 8753443414512138598,     mtime = 8747250956752020324, ctime = 7018993500102620004,     fname = 0x787a6968 <Address 0x787a6968 out of bounds>,     name = 0x68637066 <Address 0x68637066 out of bounds>,     filehand = 0x73646166}, parsed_uri = {     scheme = 0x68786664 <Address 0x68786664 out of bounds>,     hostinfo = 0x76616963 <Address 0x76616963 out of bounds>,     user = 0x6b7a787a <Address 0x6b7a787a out of bounds>,     password = 0x6b647864 <Address 0x6b647864 out of bounds>,     hostname = 0x633d6226 <Address 0x633d6226 out of bounds>,     port_str = 0x636b787a <Address 0x636b787a out of bounds>,     path = 0x26706368 <Address 0x26706368 out of bounds>,     query = 0x74263d61 <Address 0x74263d61 out of bounds>,     fragment = 0x7861633d <Address 0x7861633d out of bounds>,     hostent = 0x636d786e, port = 25455, is_initialized = 1, dns_looked_up = 1,     dns_resolved = 1}, used_path_info = 1633908846,   per_dir_config = 0x617a6170, request_config = 0x573e226e,   htaccess = 0x646c756f, output_filters = 0x756f7920,   input_filters = 0x766f4c20, proto_output_filters = 0x6f742065,   proto_input_filters = 0x726f5720, eos_sent = 1919295595}  Can you give a condensed example of the SSI page which did trigger this?  Just to confirm, you are using an unpatched 2.0.50 built directly from source?  The backtrace is actually quite confusing.  It references functions from the new CGI bucket type, but these are only actually used by the CGI handler, not when an SSI page invokes CGI scripts directly, so they shouldn't be in the picture at all.   Some updates/corrections:  1) Yes, it's been compiled from source, without any patches.  2) There are two separate cgi scripts on our index page, one does banner rotation for a banner, it is included four times (once each for 4 banners), the other creates a list of links based on the amount bid for placement, it's included twice.  The first script uses a text file db, while the second script uses MySQL.  Both are included with virtual includes.  Here's a sample of one of the sections with the includes (I can't give you the scripts themselves, they were purchased from someone else).  <!--#include virtual='/cgi-bin/ads/run.cgi?id=homeworkersa2'--> <!-- homeworkersa2 --> </CENTER> <!--#include virtual='/cgi-bin/search/include.cgi?keywords=main&desc=1&url=1&cost=1&show=1&include=1' --> <CENTER> <!--#include virtual='/cgi-bin/ads/run.cgi?id=homeworkersa3'--> <IMG SRC='/images/spacer.gif' WIDTH='160' HEIGHT='5'> <!--#include virtual='/cgi-bin/ads/run.cgi?id=homeworkersa4'--> <!-- homeworkersa4 --> </CENTER>  <hr class='green'>  <!--#include virtual='/cgi-bin/search/include.cgi?keywords=main&start=1&bt=10&desc=1&url=1&cost=1&show=9&include=1' -->  3) I tried the advice in bug 29962, it didn't help at all.  I'm still getting processes that bloat up to a huge size and I don't think it's related to sending large files through the server.  We only have a two scripts that I know of that send out large files and neither one appears to be accessed as often as these processes appear (I often have to restart apache multiple times during the day, it take as little as 5 minutes or as long as several hours to nearly exhaust all available memory).  4) We've upgraded to 2.0.51 as of this morning, I'm still seeing the memory problem and the segmentation faults.  I'm going to attempt to create another core dump with the new httpd. Created an attachment (id=12835) possible fix  OK, I think I see what's happening, but I haven't got a reproduction case, so testing with the above patch would be good. I've applied the patch but I'm still getting Segmentation Faults and the memory growth, and I haven't been able to produce a core dump to examine yet. The patch committed which fixes the issue triggered in the given segfault was:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/util_filter.c?r1=1.100&r2=1.101  so if you could try that and still get more segfaults, please try and get new core dumps.  (Please open a new bug for any new issues)  Thanks for the report and debugging help. It looks like the fix has worked, I don't seem to be able to generate any more core files, and the number of segmentation faults has dropped significantly.  Instead of 6-10 per day, we seem to now be averaging 1 a day (probably on an unrelated issue). Thanks Tyler. Actually, I think I should be thanking you for the quick fix.  :)			Joe Orton	Tyler
31268	null	RESOLVED		Daniel Rench	1095363720000	1176119540000		ab: add an option to override the target host When testing a server, the 'Host:' header can matter. I needed a way to disconnect the target host as derived from the URL on the command line and the 'Host:' header that ab sends.  I wrote a patch against ab from 2.0.50 that adds a '-F hostname' option (which I will attach once this ticket exists).  Say I have a new server and want to see how it compares with an existing one with a vhost named www.example.com. Rather than play with hosts files or DNS, this patch allows you to test 'newbox' by running:  ab -F newbox http://www.example.com/	Created an attachment (id=12753) patch to add hostname override option to ab  This seems invalid to me.  We can send the Host: Header as part of the address... but specifying it again with a special flag just seems wrong. I've had to add same feature (host to connect to != host in Host request header field) to specialized testing clients so that I could do some automated vhost testing without hacking the system.  Any other opinions from the crowd? I also considered doing something along the lines of the enhancement request #26554 method for overriding the 'User-Agent:' header. Maybe a better way? hmm. Yes, I would condier a generic method to set any Header in a Key = Value Format to be better than specific methods for each header. Created an attachment (id=19526) Patch to override headers using the existing -H option  Have attached a patch using which one can override the value of the Host, User-Agent and/or Accept header that ab tacks onto requests, by specifying an alternate value for the header using the existing -H option. -1 on implementation, but +1 on concept. Arvind, I think your solution is pretty elegant, and am in  favor of using the existing -H option to override the headers in question. However, you are no longer  sending the Accept: and User-Agent headers to POST Requests when they are not overridden.   Also, the logic regarding the overridable headers in the if (posting <= 0) block is hard to read because  of the inversion (only print the headers when their opt_foo is NOT set). Perhaps you can pull the part  where you construct these headers outside the if (posting <= 0) block (bonus: you avoid duplicating  the logic), use proper if () statements instead of the ? operator and put a comment on both branches of  the if() to tell the reader what is going on like /* Header not overridden, print default */ and /* Header  overridden, no need to send because it is already in the hdrs string */.   Would you like to fix the above and resubmit?  Thanks for your feedback. I'll address the issues you've pointed out and resubmit. Created an attachment (id=19535) Revised patch to override headers using the existing -H option  The attached patch address the following issues that were identified with the previous revision of this patch: * POST requests send an Accept: and User-Agent: header when they are not overridden * Logic regarding the overrideable headers has been pulled outside the if (posting <= 0) block * Uses if () statements (with appropriate comments) instead of the ? operator +1 to Arvind's revised patch.  Thanks for reviewing the patch Sander.  The patch also fixes http://issues.apache.org/bugzilla/show_bug.cgi?id=26554 Committed in r526872. Thanks Arvind for your patch. 			Arvind Srinivasan	Daniel Rench	Jeff Trawick	Paul Querna	Sander Temme
31431	null	CLOSED		David Wheeler	1096257420000	1097683857000		mod_ldap Cache File Permissions Error Using mod_ldap, I'm seeing a lot of entries in the error log like this:  [Sun Sep 26 19:20:40 2004] [crit] (13)Permission denied: failed to init caching lock in child process  I'd be happy to change the permissions to allow 'nobody' to write the file, but I have no idea where it is trying to write the file (or lock it, for that matter). Can the file location be added to the error message, and can you tell me where it is trying to write and lock the file?  Thanks!	Fixed in HEAD, waiting for backport to v2.0. Backported to v2.0.53. 			Graham Leggett
31440	null	RESOLVED		Andreas Krennmair	1096310760000	1203412158000		htpasswd salt generation weakness I noticed a salt generation weakness when using htpasswd in MD5 mode on platforms where rand()  returns only a 32 bit value: since the MD5 salt is 48 bits wide, the last 2 or 3 characters are always filled  with '.'.  $ htpasswd -m -c /tmp/htpasswdtest a New password:  Re-type new password:  Adding password for user a $ cat /tmp/htpasswdtest a:$apr1$sTQf/...$v6RZCfMprmLq5vMTzpwH2/ $	Created an attachment (id=12871) fix to the htpasswd salt generation weakness  This attached patch would lead to a more random MD5 salt:  $ ./htpasswd -m -c /tmp/htpasswdtest2 b New password:  Re-type new password:  Adding password for user b $ cat /tmp/htpasswdtest2 b:$apr1$iOJN8Jax$rQLDvG0ALByOBtHgN2wk7/ $ Created an attachment (id=21429) patch against httpd-2.2.8 to resolve weak PRNG seeding  Andreas, I think you're on the right track, but your patch only adds the appearance of greater randomness. The core problem here is poor seeding of the PRNG. Every salted output from htpasswd starts with using time() to feed srand(). Even with your patch, htpasswd will always use the same seed at the any given time.  The most important thing that needs to change is the calls to srand(). Here's a patch that keeps your nice 48-bit padding and adds better seeding. If the user sets a RANDOM_SEED environment variable, htpasswd will use that file/device. If not, it will try to use /dev/urandom. If it cannot use /dev/urandom or the user provides an unusable file/device name, it will fall back to using time() but will print a warning to STDERR. Also (untested!) if the user is on a platform with 32-bit integers, htpasswd will re-seed the PRNG as needed, to improve the chances of a true 48-bit salt.  -Peter  Created an attachment (id=21433) patch for httpd 1.3.39  same idea, but for the 1.3.x codebase > Andreas, I think you're on the right track, but your patch only adds the > appearance of greater randomness. The core problem here is poor seeding of the > PRNG. Every salted output from htpasswd starts with using time() to feed > srand(). Even with your patch, htpasswd will always use the same seed at the > any given time.  This is not a matter of randomness (or at least that was not my point), it's a matter of how the salt of the hash looks like. With the old method (which I fixed with my patch from 2004), an attacker could base a precomputation attack on the assumption that the salt only has 32 bits, even though the format would allow up to 48 bits of salt.   Of course, even with 32 bits of salt, a precomputation still seems quite infeasible, but it still doesn't exhaust the possible maximum of 48 bits of salt (which obviously must have been in the mind of the original authors, otherwise they would have spread the 32 bits of rand() to 6 bytes instead of 8 bytes). And that was the original point of my patch. Any attacker who has the same PRNG as the system where htpasswd runs would be foolish to blindly precompute even a 32 bit apr1 dictionary. 32 bits of time() represents 136 years worth of htpasswd execution with the current srand() code. In a given month, there are less than 22 bits worth of salt when using srand(time(NULL)), 17 bits in a day, 12 bits in an hour, 6 bits in a minute, 0 in a second. 29 bits is all it takes to stretch back to the beginning of Apache, before the apr1 MD5 algorithm appeared in 1.3.6 -- even with your improvement.   To 'fix' htpasswd so it takes full advantage of the apr1 spec's 48 bits of salt, it is necessary to fix the srand() problem, too. With your generate_salt() and my seed_prng(), htpasswd finally produces nicely random 48-bit salts for apr1.   You are right, I stand corrected. Now if only somebody could apply the patches to SVN trunk... Using generate_salt instead of to64 makes sense.....  The second patch to use better PRNG seeding, we should just use the APR APIs for randomness, apr_generate_random_bytes: http://apr.apache.org/docs/apr/1.2/group__apr__random.html Committed improved salt string generation in r629159: http://svn.apache.org/viewvc?view=rev&revision=629159  Committed improved rand seed generation in r629164: http://svn.apache.org/viewvc?view=rev&revision=629164  			Andreas Krennmair	Paul Querna	Peter Watkins
31448	null	CLOSED		Alfred Perlstein	1096364580000	1096388857000		apxs incorrectly passes CFLAG options to libtool. This is pretty easy to replicate...  Try to compile a module, but add this to the apxs compile line:  -Wc,-Wall  What happens is that apxs passes -Wall to BOTH gcc and libtool, then libtool passes cflags to ld(1) which breaks.  /usr/local/apache2/bin/apxs -c  -Wc,-O -Wc,-pipe -Wc,-g -Wc,-I/usr/home/bright/w ork/tourserve/itour2/../include -Wc,-I/usr/local/include -Wc,-I/usr/home/bright/ work/tourserve/itour2/../keys -Wc,-Wall -Wc,-Wno-format-y2k -Wc,-W -Wc,-Wmissing -prototypes -Wc,-Wpointer-arith -Wc,-Wreturn-type -Wc,-Wcast-qual -Wc,-Wwrite-st rings -Wc,-Wswitch -Wc,-Wcast-align -Wc,-Wno-uninitialized -Wc,-Werror -Wc,-I/us r/local/apache2/include -Wc,-DAPACHE_2 -Wc,-I../libfetch -Wc,-g -Wc,-I/usr/home/ bright/work/tourserve/itour2/../include -Wc,-I/usr/local/include -Wc,-I/usr/home /bright/work/tourserve/itour2/../keys  -Wl,-L/usr/local/lib -Wl,-L../libfetch -W l,-L/usr/local/lib -Wl,../libfetch/libfetch.a -o mod_itour.so ../itour//mod_itou r.c /usr/local/apache2/build/libtool --silent --mode=compile gcc -prefer-pic  -DAP_H AVE_DESIGNATED_INITIALIZER -D_REENTRANT -D_THREAD_SAFE -g -O2 -I/usr/local/apach e2/include  -I/usr/local/apache2/include   -I/usr/local/apache2/include -I/usr/l ocal/include -O -pipe -g -I/usr/home/bright/work/tourserve/itour2/../include -I/ usr/local/include -I/usr/home/bright/work/tourserve/itour2/../keys -Wall -Wno-fo rmat-y2k -W -Wmissing-prototypes -Wpointer-arith -Wreturn-type -Wcast-qual -Wwri te-strings -Wswitch -Wcast-align -Wno-uninitialized -Werror -I/usr/local/apache2 /include -DAPACHE_2 -I../libfetch -g -I/usr/home/bright/work/tourserve/itour2/.. /include -I/usr/local/include -I/usr/home/bright/work/tourserve/itour2/../keys   -c -o ../itour//mod_itour.lo ../itour//mod_itour.c && touch ../itour//mod_itour. slo /usr/local/apache2/build/libtool --silent --mode=link gcc -o mod_itour.so -O -pi pe -g -I/usr/home/bright/work/tourserve/itour2/../include -I/usr/local/include - I/usr/home/bright/work/tourserve/itour2/../keys -Wall -Wno-format-y2k -W -Wmissi ng-prototypes -Wpointer-arith -Wreturn-type -Wcast-qual -Wwrite-strings -Wswitch  -Wcast-align -Wno-uninitialized -Werror -I/usr/local/apache2/include -DAPACHE_2  -I../libfetch -g -I/usr/home/bright/work/tourserve/itour2/../include -I/usr/loc al/include -I/usr/home/bright/work/tourserve/itour2/../keys  -Wc,-O -Wc,-pipe -W c,-g -Wc,-I/usr/home/bright/work/tourserve/itour2/../include -Wc,-I/usr/local/in clude -Wc,-I/usr/home/bright/work/tourserve/itour2/../keys -Wc,-Wall -Wc,-Wno-fo rmat-y2k -Wc,-W -Wc,-Wmissing-prototypes -Wc,-Wpointer-arith -Wc,-Wreturn-type - Wc,-Wcast-qual -Wc,-Wwrite-strings -Wc,-Wswitch -Wc,-Wcast-align -Wc,-Wno-uninit ialized -Wc,-Werror -Wc,-I/usr/local/apache2/include -Wc,-DAPACHE_2 -Wc,-I../lib fetch -Wc,-g -Wc,-I/usr/home/bright/work/tourserve/itour2/../include -Wc,-I/usr/ local/include -Wc,-I/usr/home/bright/work/tourserve/itour2/../keys -Wl,-L/usr/lo cal/lib -Wl,-L../libfetch -Wl,-L/usr/local/lib -Wl,../libfetch/libfetch.a -rpath  /usr/local/apache2/modules -module -avoid-version    ../itour//mod_itour.lo /usr/bin/ld: unrecognized option '-Wall' /usr/bin/ld: use the --help option for usage information collect2: ld returned 1 exit status apxs:Error: Command failed with rc=65536 . *** Error code 1	Thanks for the report.  Can you try this patch for apxs.in:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/apxs.in?r1=1.62&r2=1.63  Thank you for the quick turnaround... This fixed passing CFLAGS, but now it's trying to link the module standalone and barfing:  ~/work/tourserve/itour2 % make all     /usr/local/apache2/bin/apxs -c  -Wc,-O -Wc,-pipe -Wc,-g -Wc,-I/usr/home/bright/work/tourserve/itour2/../include -Wc,-I/usr/local/include -Wc,-I/usr/home/bright/work/tourserve/itour2/../keys -Wc,-Wall -Wc,-Wno-format-y2k -Wc,-W -Wc,-Wmissing-prototypes -Wc,-Wpointer-arith -Wc,-Wreturn-type -Wc,-Wcast-qual -Wc,-Wwrite-strings -Wc,-Wswitch -Wc,-Wcast-align -Wc,-Wno-uninitialized -Wc,-Werror -Wc,-I/usr/local/apache2/include -Wc,-DAPACHE_2 -Wc,-I../libfetch -Wc,-g -Wc,-I/usr/home/bright/work/tourserve/itour2/../include -Wc,-I/usr/local/include -Wc,-I/usr/home/bright/work/tourserve/itour2/../keys  -Wl,-L/usr/local/lib -Wl,-L../libfetch -Wl,-L/usr/local/lib -Wl,../libfetch/libfetch.a -o mod_itour.so ../itour//mod_itour.c /usr/local/apache2/build/libtool --silent --mode=compile gcc -prefer-pic  -DAP_HAVE_DESIGNATED_INITIALIZER -D_REENTRANT -D_THREAD_SAFE -g -O2 -I/usr/local/apache2/include  -I/usr/local/apache2/include   -I/usr/local/apache2/include -I/usr/local/include -O -pipe -g -I/usr/home/bright/work/tourserve/itour2/../include -I/usr/local/include -I/usr/home/bright/work/tourserve/itour2/../keys -Wall -Wno-format-y2k -W -Wmissing-prototypes -Wpointer-arith -Wreturn-type -Wcast-qual -Wwrite-strings -Wswitch -Wcast-align -Wno-uninitialized -Werror -I/usr/local/apache2/include -DAPACHE_2 -I../libfetch -g -I/usr/home/bright/work/tourserve/itour2/../include -I/usr/local/include -I/usr/home/bright/work/tourserve/itour2/../keys  -c -o ../itour//mod_itour.lo ../itour//mod_itour.c && touch ../itour//mod_itour.slo /usr/local/apache2/build/libtool --silent --mode=link gcc -o mod_itour.so -L/usr/local/lib -L../libfetch -L/usr/local/lib ../libfetch/libfetch.a  -rpath /usr/local/apache2/modules -module -avoid-version    ../itour//mod_itour.lo /usr/lib/crt1.o(.text+0x81): In function "_start': : undefined reference to "main' ../itour//mod_itour.o(.text+0x494): In function "create_server_config': ../itour//mod_itour.c:254: undefined reference to "apr_palloc' ../itour//mod_itour.o(.text+0x4b3):../itour//mod_itour.c:259: undefined reference to "ap_add_version_component' ../itour//mod_itour.o(.text+0x4d5):../itour//mod_itour.c:260: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x515): In function "itour_conf_master': ../itour//mod_itour.c:275: undefined reference to "apr_pstrdup' ../itour//mod_itour.o(.text+0x53c):../itour//mod_itour.c:276: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x5ad): In function "itour_conf_timeout': ../itour//mod_itour.c:291: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x664): In function "itour_dbadd': ../itour//mod_itour.c:363: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x6dc): In function "itour_dbcheck': ../itour//mod_itour.c:386: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x701):../itour//mod_itour.c:392: undefined reference to "apr_psprintf' ../itour//mod_itour.o(.text+0x754):../itour//mod_itour.c:397: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x7b1):../itour//mod_itour.c:404: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x7e8):../itour//mod_itour.c:408: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x83b):../itour//mod_itour.c:416: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x866):../itour//mod_itour.c:421: undefined reference to "apr_table_set' ../itour//mod_itour.o(.text+0x898):../itour//mod_itour.c:426: undefined reference to "ap_rprintf' ../itour//mod_itour.o(.text+0x8e9): In function "itour_remotequery': ../itour//mod_itour.c:437: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0x984):../itour//mod_itour.c:458: undefined reference to "apr_table_set' ../itour//mod_itour.o(.text+0x9a3):../itour//mod_itour.c:462: undefined reference to "ap_rprintf' ../itour//mod_itour.o(.text+0x9e5): In function "itour_status_handler': ../itour//mod_itour.c:470: undefined reference to "ap_log_error' ../itour//mod_itour.o(.text+0xa75): In function "itour_register_hooks': ../itour//mod_itour.c:537: undefined reference to "ap_hook_handler' collect2: ld returned 1 exit status apxs:Error: Command failed with rc=65536 . *** Error code 1  Note this is a FreeBSD 6.0 box. If you must pass an '-o' option to apxs, it must be like '-o mod_foo.la' otherwise you'll confuse libtool.  Can you try that?  I fixed apxs to handle '-o mod_foo.so' correctly too:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/apxs.in?r1=1.63&r2=1.64  These changes will be proposed for backport for a future 2.0.x release.  You don't have to escape -I and -D options using '-Wc,-I', by the way, apxs understands those already. Well, here's the problem with that... :)  I'm actually compiling in a seperate directory and using the VPATH/PATH feature of make to locate my sources.  Even if I manually specify the source file as ../itour/mod_itour.c apxs and libtool conspire to dump files out into ../itour/ instead of the current working directory.  Also... why do I need to say '-o mod_so.la'?  What I really want is 'mod_so.so'.  This won't work for me.  Basically:  I have: tourserve/itour - sources + Apache13 makefile tourserve/itour2 - Apache2 makefile  The apache2 makefile just overrides a couple of knobs and includes the apache13 makefile.  But for some reason apxs decides to dump files into my source directories instead of my current directory.  Here's a fix that prevents it, but only if you give a -o option to apxs, I haven't figured out how to fix it without -o.  Basically this patch just removes any leading pathnames from the source files when making the object file names:  --- apxs.in     Mon Feb  9 12:59:49 2004 +++ apxs.new    Tue Sep 28 07:47:18 2004 @@ -400,13 +400,15 @@      my $s;      my $mod;      foreach $s (@srcs) { -        my $slo = $s; +        my $ss = $s; +        $ss =~ s|.*/||; +        my $slo = $ss;          $slo =~ s|/.c$|.slo|; -        my $lo = $s; +        my $lo = $ss;          $lo =~ s|/.c$|.lo|; -        my $la = $s; +        my $la = $ss;          $la =~ s|/.c$|.la|; -        my $o = $s; +        my $o = $ss;          $o =~ s|/.c$|.o|;          push(@cmds, '$libtool $ltflags --mode=compile $CFG_CC $cflags -I$CFG_IN CLUDEDIR $apr_includedir $apu_includedir $opt -c -o $lo $s && touch $slo');          unshift(@objs, $lo); @@ -419,12 +421,9 @@   Also, why do I need a '-o mod_foo.la', all i really want is 'mod_foo.o', can't that be fixed? Created an attachment (id=12885) fix for object files being created in source dirs.  Ok, I fixed it!  This should be applied, what it does it strip the leading pathnames from derived sources so that object files don't wind up in source directories:  The diff is attached.  http://issues.apache.org/bugzilla/showattachment.cgi?attach_id=12885    WONTFIX to that: VPATH builds are complicated and apxs is supposed to be a simple build tool.  If you want to do a VPATH build then you could symlink the sources across and then apxs should work OK.  The .so vs .la thing is fixed per my comment above, too.  Thanks for the report. (or use a proper Makefile as per the example created by 'apxs -g', that should work with VPATH builds or could be fixed to, at least) http://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/apxs.in?r1=1.62&r2=1.64 committed to httpd v2.0.53.			Alfred Perlstein	Graham Leggett	Joe Orton
31472	null	CLOSED		Jack Repenning	1096487280000	1099438627000		' The magic file provided with mod_mime_magic contains a typo in the line for QuickTime videos of type  'moov'.    Discovered in 2.0.50; confirmed by inspection in 2.0.52.  The result is a parse error:  [Wed Sep 29 10:03:57 2004] [error] [client 10.1.6.217] mod_mime_magic: unexpected state 3; could be  caused by bad data in magic file  ... and an Internal Server Error  Of course, this only arises if the file has not already been recognized based on file name, which I  believe is done by mod_mime.  The typo is a trailing space at the end of the line.   To reproduce: - get yourself an Apple Quicktime movie of type 'moov' (you can grab    http://u2.netgate.net/~jack/file_14.mov or .../file_14.dat - rename it, if necessary, to some unobvious name, if necessary ('file_14.dat' is unobvious enough) - drop it into your htdocs directrory - add a link to it in some page  - make sure mod_mime and mod_mime_magic are enabled     (http://httpd.apache.org/docs-2.0/mod/mod_mime_magic.html)   - hit the link  Expected: it should show the movie Actual result: it chokes  Fix: remove the trailing space on the line (patch attached momentarily, as if you really needed that);  restart server  Hit the link again: Result: see the movie	Created an attachment (id=12897) patch for magic file docs/conf/magic  Oops, sorry wrong URL.  The sample 'moov' file is http://www.repenning.homeip.net/file_14.mov  There's nothing special about it, though: any QTime movie file will do.   Note that there's also some evidence that this typo affects other file types.    That is: there's only one typo, the one for files of type 'moov'.  But it affects parsing of the magic  file: mod_mime_magic croaks--really, before it's read the entry, and hence it's not reacting  specifically to the fact that the file being touched is 'moov', but rather to the fact that it's not any  of the *other* types named earlier in the file.  So something amounting to the same problem arises  for any file of any type that's completely unknown to the magic file (the reported case is Stuffit!  archives, which are not described anywhere in the magic file).    Reproducing the false behavior in these cases is harder, I can't provide you a complete recipe:  these cases produce the same error_log output as the 'moov', but since they're not described at all,  the resulting behavior is not so far from correct.  In our case, we're also providing a .htaccess file  for these, which includes MIME info, and the croak in mod_mime_magic seems to mean that  .htaccess is never consulted, and hence we're not getting the right behavior from these other file  types, either.  I'm not sure of all the steps necessary to set up such a .htaccess file, but I have  experimentally confirmed that, if I fix the typo on the 'moov' line, the .htaccess files for StuffIt! files  comes back into play, and everything's peachy again. Thanks Jack, committed for 2.0.53.			Jack Repenning	Joe Orton
31483	null	RESOLVED		Popolon	1096542120000	1188213405000		add svgz in mime.types file There is no description of standard svgz file (gziped SVG) in mime.type definition file, this is in w3 SVG draft, and most SVG viewer can ungzip them.  image/svg+xml                   svg  could be replaced by:  image/svg+xml                   svg svgz  to resolve the issue.   As showed in the following SVG draft appendice, it can save 80% bandwidth and disk space, and for example   http://www.w3.org/TR/2002/CR-SVG11-20020430/minimize.html	It seems quite ambiguous to me if this is really the right thing to do.  Is a gzipped svg file still a plain image/xvg+xml or is it an image/xvg+xml with a content-encoding implied?  I'd tend to believe the latter, in which case it does not make sense to change the mime.types file unless there is also a corresponding AddEncoding directive.  The svg spec does not seem perfectly clear on this topic.  But I don't see anywhere where it says that applications conforming to the spec must understand gzipped documents.  So that implies that the gzip is not part of the content type, and we shouldn't change mime.types.  Feel free to provide evidence to the contrary (and reopen the bug if you do so). Hi,  The SVG 1.1 Errata should clarify this issue, svg viewers should be able to  load gzipped svgz content no matter how it's loaded, svgz does not require a  content-encoding header to be loaded.  Unfortunately we're still waiting for  that errata to be published, but you can see details at:  http://article.gmane.org/gmane.text.xml.svg.devel/25178/  or on the www-svg mailing list archives.  I think it would be nice to also have AddEncoding for svgz for the non svg user  agents, but it's not essential Added to trunk in rev 570206.			Jim Ley	Joshua Slive	Roy T. Fielding
31759	null	RESOLVED		stef	1098113640000	1158095945000		default handler returns output filter apr_status_t value Hi  I have an apache 2.0.49 in reverse proxy SSL mode and a iis behind . Lot of errors ( 70007 ) occured when POST request . it's a upload script ( ASP ) running on the iis .  sometimes iis generates a 500 error code( timeout of the asp script execution )  which generates a 500 error ( apache logs ) 'POST /wp_doc_upload.asp?PID=987665 HTTP/1.1' 500 490 https://aa.com/test .asp' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0; Hotbar 4.5.1.0)'  or 70007 error 'POST /wp_doc_upload.asp?PID=987665 HTTP/1.1' 70007 23 'https://aa.com/tes t.asp' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0; Hotbar 4.5.1.0)'   After reading bugs 22030, 19315, 22030, i can't find similar behaviour between  these bugs and mine .	Add-on ssl request from the client to  the apache, and no ssl between apache and IIS  Firstly, please try upgrading to 2.0.52, there have been quite a few mod_ssl changes since 2.0.49.  Secondly, please include the complete error messages logged to error_log. [Tue Oct 19 14:52:30 2004] [info] (70007)The timeout specified has expired: SSL  input filter read failed.    without mod_ssl, i have 70007 return code in the access_log, but nothing in the  error_log like in the previous post, except a lot of : [Tue Oct 19 15:55:14 2004] [info] (32)Broken pipe: core_output_filter: writing  data to the network     10.50.8.69 - - [19/Oct/2004:15:31:35 +0200] 'POST /wp_doc_upload.asp?PID=987665  HTTP/1.1' 70007 538 I have  same errors with 2.0.50 2.0.52 without mod_ssl .  'POST /wp_doc_upload.asp?PID=987665 HTTP/1.1' 70007 538  what is the difference between the 70007 return code in the access_log and the  (70007) return code in the error_log ?       There is a bug in mod_ssl somewhere which means that the APR error code 70007 is being returned in the wrong place, which is why it gets logged in access_log.  But it's still not clear to me: what actual problems are you seeing other than the oddity in the logging?  (In reply to comment #7) > There is a bug in mod_ssl somewhere which means that the APR error code 70007  is > being returned in the wrong place, which is why it gets logged in access_log. > But it's still not clear to me: what actual problems are you seeing other than > the oddity in the logging?   In the error_log , lot of errors like [info] (70007)The timeout specified has  expired: SSL input filter read failed.  In the access_log : some 70007 : POST /wp_doc_upload.asp?PID=987665 HTTP/1.1'  70007 23 'https://aa.com/test.asp' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows  NT 5.0; Hotbar 4.5.1.0)'  each time a 70007 or 500 error occured, ie is out ( blank page ) .  On version 1.3.31, there are only 500 error code ( asp script time out ), but  no 70007 error code .    (In reply to comment #8) > (In reply to comment #7) > > There is a bug in mod_ssl somewhere which means that the APR error code 70007  > is > > being returned in the wrong place, which is why it gets logged in access_log. > > But it's still not clear to me: what actual problems are you seeing other than > > the oddity in the logging? >  >  > In the error_log , lot of errors like [info] (70007)The timeout specified has  > expired: SSL input filter read failed. >  > In the access_log : some 70007 : POST /wp_doc_upload.asp?PID=987665 HTTP/1.1'  > 70007 23 'https://aa.com/test.asp' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows  > NT 5.0; Hotbar 4.5.1.0)' >  > each time a 70007 or 500 error occured, ie is out ( blank page ) . >  > On version 1.3.31, there are only 500 error code ( asp script time out ), but  > no 70007 error code .  I have log entries with http error code 70007, too, but I don't have any entries in the error_log. mod_ssl isn't used. here the errors come from POST requests  apache 2.0.54 / php 4.4.0 LogLevel warn This is a bug in the default_handler, not in mod_ssl.  The default_handler itself returns the ap_pass_brigade return value; the handler hook is supposed to return an OK/DECLINED/HTTP_* error code, so this is broken. *** Bug 36828 has been marked as a duplicate of this bug. *** Since Joe claims that this is where the logging bug should be followed up, I'm continuing conversation here.  If this is the same problem as reported, this problem affects EVERY request, not just reverse proxy.  (if not, then Joe referred me incorrectly)  This is currently affecting roughly 2k log entries per night on my personal colo machine.  It's tens of thousands more on real production websites.  It's a fatal flaw in one of Apache's most basic operations -- log the request.  What do we need to do to get developers to stop playing with grand new features that aren't crucial to basic operation, and fix the core? Here's a patch to default handler to try:  Index: server/core.c =================================================================== --- server/core.c       (revision 386843) +++ server/core.c       (working copy) @@ -3645,7 +3645,17 @@          e = apr_bucket_eos_create(c->bucket_alloc);          APR_BRIGADE_INSERT_TAIL(bb, e);  -        return ap_pass_brigade(r->output_filters, bb); +        status = ap_pass_brigade(r->output_filters, bb); +        if (status == APR_SUCCESS +            || c->aborted) { /* broken I/O isn't an HTTP issue, so no +                              * error status applies +                              */ +            return OK; +        } +        else { +            /* no way to know what type of error occurred */ +            return HTTP_INTERNAL_SERVER_ERROR; +        }      }      else {              /* unusual method (not GET or POST) */          if (r->method_number == M_INVALID) {   >What do we need to do to get developers to stop playing  >with grand new features that aren't crucial to basic  >operation, and fix the core?  what can you do to help?      * please refrain from complaining or otherwise expressing frustration via the PR database... that sends a signal to those who volunteer their time that their effort is inadequate... while that may be true for your problem, overall there are many problems diagnosed and solved via the PR database, and there is no benefit from airing your grievance...     * continue to submit problem reports... every one is looked at even if there doesn't appear to be any activity on it...     * help us out as much as possible with your report... this includes providing relevant documentation when you create the report as well as trying to respond quickly to questions we ask or suggestions we make... if you aren't willing to help us work on your issue, why are we wasting our time in the first place?     * use the source... you have access to the source code... you (or someone you know or can hire with the proper skills) have the opportunity to find the code that is causing you a problem and fix it, even if the fix is particular to your environment and not suitable for general distribution     * if your company depends on Apache httpd, consider sponsoring a skilled developer to get involved in the maintenance and ongoing development of Apache httpd     * consider paying for support from one of the companies that sells support for Apache httpd (or servers based on Apache httpd) and contributes to the open source development effort of Apache httpd   Thanks Jeff.  I couldn't really convince myself what the correct behaviour was when I looked at this before.  If there is a 404 response which suffers from an SSL-layer error, why is it better to log a 500 than a 404; i.e. is it better to just log r->status in the non-success case?  The real response code might be a useful diagnostic. Also thanks from me Jeff. I guess it is a good idea to log the original return code in the error log in the INTERNAL_SERVER_ERROR case. I think it should be sufficient to log this for DEBUG loglevel only. Thoughts? (based on Joe's comments) >If there is a 404 response which suffers from an SSL-layer >error, why is it better to log a 500 than a 404  It isn't, but that doesn't go through this path.  (default handler will return HTTP_NOT_FOUND instead of calling ap_pass_brigade() with a file bucket)  but a filter could have modified r->status to indicate an error (e.g., invalid range)  >i.e. is it better to just log r->status in the non-success case?  Agreed in general.  I'm still nervous about r->status still OK when we get here.  So that last issue leaves us with this so far:  Index: server/core.c =================================================================== --- server/core.c       (revision 386843) +++ server/core.c       (working copy) @@ -3645,7 +3645,16 @@          e = apr_bucket_eos_create(c->bucket_alloc);          APR_BRIGADE_INSERT_TAIL(bb, e);  -        return ap_pass_brigade(r->output_filters, bb); +        status = ap_pass_brigade(r->output_filters, bb); +        if (status == APR_SUCCESS +            || r->status != HTTP_OK +            || c->aborted) { +            return r->status; +        } +        else { +            /* no way to know what type of error occurred */ +            return HTTP_INTERNAL_SERVER_ERROR; +        }      }      else {              /* unusual method (not GET or POST) */          if (r->method_number == M_INVALID) {  If any kind of client communication error occurred, c->aborted should be set, right? If any kind of HTTP error occurred, r->status should have been modified, right?  Perhaps we should log a message here in the other situations but still return OK, to make sure that the processing problem doesn't always go unnoticed?  (example of interest to me at the moment: a filter gets APR_EOF from bucket-read because a file has been truncated during request processing)  Ruediger's comments: >I guess it is a good idea to log the original return >code in the error log in the INTERNAL_SERVER_ERROR case.   Agreed.  Perhaps it is okay not to even return 500 as long as we log something.  >I think it should be sufficient to log this for DEBUG >loglevel only. Thoughts?  I think INFO is the appropriate level, just like the expected 'core_output_filter: writing data to network' messages.  Some of these odd cases are probably much less expected than a user hitting the stop button. (In reply to comment #16) > (based on Joe's comments) > >If there is a 404 response which suffers from an SSL-layer > >error, why is it better to log a 500 than a 404 >  > It isn't, but that doesn't go through this path.  (default handler will return > HTTP_NOT_FOUND instead of calling ap_pass_brigade() with a file bucket)  good point sir  > If any kind of client communication error occurred, c->aborted should be set, right? > If any kind of HTTP error occurred, r->status should have been modified, right?  Both sound right to me.  > Perhaps we should log a message here in the other situations but still return > OK, to make sure that the processing problem doesn't always go unnoticed? >  > (example of interest to me at the moment: a filter gets APR_EOF from bucket-read > because a file has been truncated during request processing)  I'm not sure about this.  It would be better to avoid having such errors logged N times by all N filters in the output chain, that kind of thing creates confusion.  moving discussion to dev@httpd for the time being...  The latest patch fails.  Every third or fourth request of plain ol' html files in normal HTTP mode generates 500 errors and garbage in the HTTP header.  I never even got to testing SSL or CGI responses.  Plain, simple HTTP fails.  Any chance to get a tested and working patch? FYI I see no discussion in the dev mailing list of this topic. (In reply to comment #21) > FYI I see no discussion in the dev mailing list of this topic.  http://mail-archives.apache.org/mod_mbox/httpd-dev/200603.mbox/%3ccc67648e0603310853m2e05c13cn9f883821a88aa3e1@mail.gmail.com%3e (In reply to comment #20) > The latest patch fails.  Every third or fourth request of plain ol' html files > in normal HTTP mode generates 500 errors and garbage in the HTTP header.  I > never even got to testing SSL or CGI responses.  Plain, simple HTTP fails. >  > Any chance to get a tested and working patch?  Please use the following patch instead and set the LogLevel to debug:  Index: server/core.c =================================================================== --- server/core.c       (Revision 390677) +++ server/core.c       (Arbeitskopie) @@ -3646,6 +3646,20 @@          APR_BRIGADE_INSERT_TAIL(bb, e);           return ap_pass_brigade(r->output_filters, bb); +        status = ap_pass_brigade(r->output_filters, bb); +        if (status == APR_SUCCESS +            || r->status != HTTP_OK +            || c->aborted) { +            return r->status; +        } +        else { +            /* no way to know what type of error occurred */ +            ap_log_rerror(APLOG_MARK, APLOG_DEBUG, status, r, +                          'default_handler: ap_pass_brigade returned %i', +                          status); +            return HTTP_INTERNAL_SERVER_ERROR; +        } +      }      else {              /* unusual method (not GET or POST) */          if (r->method_number == M_INVALID) {  Furthermore please post the garbled HTTP header.     About the patch:  It needs to return OK instead of r->status.  Otherwise, an error is triggered.  OK will allow r->status to be respected when appropriate.          if (status == APR_SUCCESS             || r->status != HTTP_OK             || c->aborted) {             return OK; /* r->status will be respected */  When returning r->status, you can get a complete 200 response then a 500 error document ;)  Confirmed -- that's exactly what we were seeing.  200 return code, with the text of the 500 error message at the top or bottom of pages, or in random frame windows. Here's the patch committed to trunk (as before with the change to return OK instead of r->status):  http://svn.apache.org/viewcvs.cgi?rev=390922&view=rev  (In reply to comment #26) >  > http://svn.apache.org/viewcvs.cgi?rev=390922&view=rev >   Please also apply http://svn.apache.org/viewcvs?rev=391025&view=rev as the previous one has a small bug that is fixed by r391025. Proposed for backport to 2.2.x as r392700 (http://svn.apache.org/viewcvs?rev=392700&view=rev) and to 2.0.x as r392701 (http://svn.apache.org/viewcvs?rev=392701&view=rev) Backported to 2.2.x as r393005 (http://svn.apache.org/viewcvs?rev=393005&view=rev). *** Bug 39405 has been marked as a duplicate of this bug. *** Will this get backported to 2.0.x? This has been backported. It is part of 2.0.56 and later. I thought that this was fixed in 2.2.2 but testing with a PUT handler today demonstrates that it's not fixed everywhere -- result code 70007 has been logged here.  64.13.135.30 - - [12/Sep/2006:11:28:40 -0700] 'PUT /polycom/extensions/0004f204217c-app.log HTTP/1.1' 70007 - '-' 'Polycom-FileManager/1.0 (libcurl/7.12.1 OpenSSL/0.9.7d) (SIP-1.6.5:0043;SPIPPolycomSoundPointIP-SPIP_501)' arran.svcolo.com  64.13.135.30 - - [12/Sep/2006:11:30:43 -0700] 'PUT /polycom/extensions/0004f204217c-app.log HTTP/1.1' 70007 - '-' 'Polycom-FileManager/1.0 (libcurl/7.12.1 OpenSSL/0.9.7d) (SIP-1.6.5:0043;SPIPPolycomSoundPointIP-SPIP_501)' arran.svcolo.com  It is fixed in the default handler. It is up to each handler to return the correct value. Simply returning the return value from ap_pass_brigade is wrong and leads to this errors. Please fix your PUT handler. The PUT handler is a small 10 line script.  It absolutely doesn't return a code 70007 or anything other than 0 no matter how it finishes.  This is not resolved nor fixed. (In reply to comment #35) > The PUT handler is a small 10 line script.  It absolutely doesn't return a code > 70007 or anything other than 0 no matter how it finishes.  Your script isn't the issue.  It's the apache or third-party handler it's running under that wants fixing.  If it's apache's mod_cgi or mod_cgid, it's an apache bug.  Otherwise you need to look elsewhere. I'm sorry, but I'm confused.  You are saying this isn't an Apache bug... but it might be an Apache bug, report it to them?  Huh?  (yes I'm being a little dense on purpose, but it is honestly confusing)  This is a bone stock apache configuration.  No external modules.  This is an Apache bug one way or the other, and reported in the apache bugzilla... how is it that you are claiming 'not your bug?' (In reply to comment #37) > I'm sorry, but I'm confused.  You are saying this isn't an Apache bug... but it > might be an Apache bug, report it to them?  Huh?  The default handler (which *this* bug report references) doesn't handle PUT.  So what you're describing is  either a different bug or a notabug.  It absolutely cannot be *this* bug, though it could be the same thing  in another handler.  > This is a bone stock apache configuration.  No external modules.  You need to tell us what your script is running under.  Is it mod_cgi or mod_cgid? Not cgid.  I assume it's part of mod_cgi.  It's really just  Script  PUT   /path/to/put-handler.pl  To what extent is this changed if *.pl is handled by   AddHandler cgiwrapper *.cgi *.pl Action cgiwrapper /path/to/wrapper  And again, it still seems like the it's using the return code (which is very OS-dependent) instead of a result code returned by the application. (In reply to comment #32) > This has been backported. It is part of 2.0.56 and later.  Thanks for the reply.  The reason I asked is that I am seeing the following with 2.0.59:  68.174.9.93 - - [13/Sep/2006:16:57:24 +0100] 'POST /articles/comment/66 HTTP/1.1' 70007 607 'http://typo.submonkey.net/articles/2006/03/09/setting-interface-link-settings-in-suns-openboot' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; MRA 4.3 (build 01218))'  The target URL of the post is proxied by mod_proxy to a lighttpd backend (which is probably not working properly). This bug has been fixed.  But after yesterday's exchange with Jo Rhett, I looked at mod_cgi and  mod_cgid, and found what appears to be a similar problem in both of them, when  they return an error status from the *input* filters if they fail to read a  request body (as in a POST/PUT request).  I've fixed that similar bug - which I think you're both describing - in http://svn.apache.org/viewvc?view=rev&revision=442758 You jumped right to the chase -- I was busy building a test case to prove that effect to you.  Looks good!  Obviously update this when it hits a release... (In reply to comment #41)  > I've fixed that similar bug - which I think you're both describing - in > http://svn.apache.org/viewvc?view=rev&revision=442758  Thanks.  I've applied those patches but still see the issue as per the access log extract above.  (In reply to comment #43) > (In reply to comment #41) >  > > I've fixed that similar bug - which I think you're both describing - in > > http://svn.apache.org/viewvc?view=rev&revision=442758 >  > Thanks.  I've applied those patches but still see the issue as per the  access > log extract above.  Ah.  I read your mention of POST as meaning you were using CGI.  But looking  up at comment #40, it was the proxy, so patching mod_cgi has no effect on you.  I've just looked at mod_proxy in 2.0, and there is indeed the same bug there  yet again (though it's deeper - in the mod_proxy_http provider).  It's also  rather more complex, but always (AFAICT) comes from ap_proxy_http_request,  which in fact returns apr_status_t values.  So you can fix it by applying the  same fix at line 1899 of proxy_http.c. (In reply to comment #44) > (In reply to comment #43) > > (In reply to comment #41) > >  > > > I've fixed that similar bug - which I think you're both describing - in > > > http://svn.apache.org/viewvc?view=rev&revision=442758 > >  > > Thanks.  I've applied those patches but still see the issue as per the  > access > > log extract above. >  > Ah.  I read your mention of POST as meaning you were using CGI.  But looking  > up at comment #40, it was the proxy, so patching mod_cgi has no effect on you.  I did wonder :) >  > I've just looked at mod_proxy in 2.0, and there is indeed the same bug there  > yet again (though it's deeper - in the mod_proxy_http provider).  It's also  > rather more complex, but always (AFAICT) comes from ap_proxy_http_request,  > which in fact returns apr_status_t values.  So you can fix it by applying the  > same fix at line 1899 of proxy_http.c.  OK, that seems to have got it, thanks. FWIW, I've implemented a higher-level fix, so that if this bug turns up in yet  more handlers, apache will handle it internally rather than send a bogus  response to the client.  See http://svn.apache.org/viewvc?view=rev&revision=448711 http://svn.apache.org/viewvc?view=rev&revision=450808 Thanks Nick, that looks like the most sensible fix.			Ceri Davies	Jeff Trawick	Jo Rhett	Joe Orton	Markus L.	Nick Kew	Ruediger Pluem	stef
31782	null	RESOLVED		Ray Ferguson	1098206760000	1115157337000		AllowOverride limitations can be overcome w/ Location directive, a note to that effect in the docs would be nice. The allowoverride categories are sometimes too general.  For instance, you may want to let webmasters override some of the Options category, but not all of it.  Most often, you might want to restrict ExecCGI or Includes, but otherwise, give controll to the webmaster.  This can be done with the following:  <Directory /> AllowOverride All </Directory>  <Location /> Options +IncludesNoEXEC -ExecCGI </Location>  Since Location supercedes Directory and htaccess settings, this effectively gives control of a subset of the Options category to htaccess users.  I think this is a fairly common thing to want to do, so making a note of it somewhere in the documentation would be a nice addition.	Thanks for the interesting example.  I've added it along with some other comments to the htaccess tutorial.			Joshua Slive
31848	null	CLOSED		Ren	1098445380000	1099350399000		SEGV ssl_hook_UserCheck (r=0x3c19c050) at ssl_engine_kernel.c:848 Apache 2 (self-compiled) on OpenBSD 3.5  The child process crashes when I try to access a password-protected (AuthType Digest, Require valid- user) area on a virtual host which also has SSLEngine on. The request that causes the crash need not be  over SSL. After the request, I get tons of the following messages in my error_log:  [Wed Oct 20 23:33:02 2004] [notice] child pid 748 exit signal Segmentation fault (11) [Wed Oct 20 23:33:02 2004] [notice] child pid 21686 exit signal Segmentation fault (11) [Wed Oct 20 23:33:02 2004] [notice] child pid 11754 exit signal Segmentation fault (11) [Wed Oct 20 23:33:02 2004] [notice] child pid 25724 exit signal Segmentation fault (11) ...  I started Apache under gdb in -X mode and got the following back trace:  Program received signal SIGSEGV, Segmentation fault. 0x1c0441d0 in ssl_hook_UserCheck (r=0x3c19c050) at ssl_engine_kernel.c:848 848         if (!(sc->enabled && sslconn->ssl && sslconn->client_cert) || (gdb) bt #0  0x1c0441d0 in ssl_hook_UserCheck (r=0x3c19c050) at ssl_engine_kernel.c:848 #1  0x1c099c5b in ap_run_check_user_id (r=0x3c19c050) at request.c:69 #2  0x1c09a5ed in ap_process_request_internal (r=0x3c19c050) at request.c:192 #3  0x1c056d0f in ap_process_request (r=0x3c19c050) at http_request.c:244 #4  0x1c051c3c in ap_process_http_connection (c=0x3c196128) at http_core.c:250 #5  0x1c08de1b in ap_run_process_connection (c=0x3c196128) at connection.c:42 #6  0x1c08e18d in ap_process_connection (c=0x3c196128, csd=0x3c196050)     at connection.c:175 #7  0x1c081084 in child_main (child_num_arg=0) at prefork.c:609 #8  0x1c081148 in make_child (s=0x3c0469e8, slot=0) at prefork.c:649 #9  0x1c081257 in startup_children (number_to_start=5) at prefork.c:721 #10 0x1c0815d2 in ap_mpm_run (_pconf=0x3c042018, plog=0x3c088018, s=0x3c0469e8)     at prefork.c:940 #11 0x1c087e81 in main (argc=3, argv=0xcfbf7de8) at main.c:617 #12 0x1c022671 in ___start () #13 0x1c0225e7 in __start () #14 0xcfbf7f5c in ?? ()  Apache was configured like this:  ./configure --prefix=/usr/local/apache2 --enable-ext-filter --enable-exp --enable-headers -- enable-unique-id --enable-ssl --enable-dav --enable-speling --enable-rewrite --enable-info -- enable-auth-digest --enable-deflate --enable-proxy --enable-expires --enable-so	Created an attachment (id=13182) possible fix  Can you try the patch attached above? If it still fails, 'backtrace full' output from GDB would be useful. Thanks Joe, your patch seems to fix the crash. Thanks for testing it and the detailed bug report!  Fixed in HEAD, will propose for 2.0.53. Fixed for 2.0.53, thanks again for the report.			Joe Orton	Ren
31875	null	CLOSED		Arkadiusz Miskiewicz	1098695700000	1098700305000		Double slash in URL strips first path part When accessing http://server//aaa/bbb/file.html httpd tries to open path-to- virtual/bbb/file.html. It always strips first part of path if double slash is  used. This happens in apache 2.1: http://svn.northnitch.com//there-is-some-bug- in-apr/index.html and in apache 2.0 (ported to APR 1.0 API): http://bugs.pld- linux.org//aaaa/index.php.  Bug 28450 related.	Fixed in CVS:  http://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/protocol.c?r1=1.156&r2=1.157 			Nick Kew
32367	null	RESOLVED		Christian von Roques	1101251280000	1107281906000		ProxyPass /foo !  results in error message ProxyPass /foo !  is documented to prevent mod_proxy from proxying everything below /foo. Revision 1.109 of mod_proxy.c rewrote add_pass(), which now complains about ! 'ProxyPass Bad syntax for a remote proxy server'.  Furthermore, FIX_15207 removed support for detecting and not proxying to '!'.	Created an attachment (id=13527) Patch re-adding support for ProxyPass /foo !  ping to a mod_proxy hacker, I am pretty sure this should be committed.  If no one gets to it, I will take a swing this weekend. Fixed. Thanks Christian.			Christian von Roques	Mladen Turk	Paul Querna
32443	null	RESOLVED		tao	1101805740000	1106136676000		mod_proxy will keep alive to streaming server after user shutdown connection I am try to use mod_proxy to proxy a Windows Media stream on HTTP protocol  that generate by Windows Media Service. This is a typical Keep-alive stream. I use Windows Media Player as the client and mod_proxy on Apache2.0.52 get stream data from remote stream server, and  pass it to player via HTTP also. It works very well. But when I shutdown the media player, the mod_proxy still connect to the  remote stream server, and retrive data as before. And, the error.log grows at at a about 18KB/s speed.  All the error like: XXXXXXXX info (OS 10053)xxxxxxxxxxxxxxxxx  core_output_filter: writing data to  the network  It seems that mod_proxy does not know the client is shutdown and still try to  feed data to client.  And, as new access entered, the mod_proxy will open a new session to stream  server, and after user shutdown, the connection to stream server is still  alive. After servral times, I have to stop the Apache.	 > And, the error.log grows at at a about 18KB/s speed.  Sorry, it should be 18KB/min.  (In reply to comment #0)  I had the same problem and I did some debugging.  This happends because ap_pass_brigade returns always APR_SUCCESS on ap_proxy_http_process_response (from server/core.c).  here is a quick patch for this:  change line                     if (ap_pass_brigade(r->output_filters, bb) != APR_SUCCESS) {  on file modules/proxy/proxy_http.c to:                      if (ap_pass_brigade(r->output_filters, bb) != APR_SUCCESS || c->aborted) {    *** Bug 29644 has been marked as a duplicate of this bug. *** Thanks for the patch.  I added the same logic in two other places where it was also needed and committed that.  http://svn.apache.org/viewcvs?view=rev&rev=125612 [viewsvn currently disabled]  Created an attachment (id=14046) backported patch  backported version of patch for submission to 2.0 *** Bug 39442 has been marked as a duplicate of this bug. ***			Janne Hietam	Joe Orton	tao
32486	null	RESOLVED		Paul Querna	1101961800000	1194334533000		TLS Upgrade: Duplicate Upgrade Headers I haven't had a chance to debug it, but with 'SSLEngine Optional' in -trunk, the server has a duplicated 'Ugrade' header.  Headers from  http://svn.northnitch.com/  HTTP/1.1 200 OK Date: Thu, 02 Dec 2004 03:28:42 GMT Server: Apache/2.1.2-dev (Unix) mod_ssl/2.1.2-dev OpenSSL/0.9.7c-p1 DAV/2 SVN/1.1.1 Upgrade: TLS/1.0, HTTP/1.1 Upgrade: TLS/1.0, HTTP/1.1 Last-Modified: Sat, 29 May 2004 06:45:19 GMT ETag: '5868bd-487-91401dc0' Accept-Ranges: bytes Content-Length: 1159 Content-Type: text/html; charset=ISO-8859-1	Looks like it's added in both the Fixup and Access hooks. Still present in 2.3-trunk. This was happening since Upgrade was being added in both main and subrequest.  Fixed on trunk:  http://svn.apache.org/viewvc?view=rev&revision=592457			Joe Orton	Paul Querna
32492	null	RESOLVED		Andy Armstrong	1101999660000	1114198998000		t be disabled The module has logic to handle enabling buffered logs but once enabled they can't be disabled. BufferedLogs Off is a nop.	Created an attachment (id=13625) Makes BufferedLogs Off work  Well, it's more a documentation bug.  (1) that it's not documented at all (2) that it's a global setting. Either all logs are buffered or all are not. Hence turning BufferedLogs Off makes no real sense. *** Bug 34463 has been marked as a duplicate of this bug. *** Documentation fixed.			Andr?? Malo	Andy Armstrong	Joshua Slive
32529	null	RESOLVED		Mitch Frazier	1102138260000	1102502700000		ProxyPass segmentation fault on SMP x86_64 The included patch is for openssl but its not 100% clear to me if the real bug is in apache or in openssl, fixing it in openssl was easiest.  I emailed the bug to the openssl folks also.  apache version:  2.0.48-146 openssl version: 0.9.7b-125 OS:              SuSE 9.0 SMP/x86_64 Kernel:          2.4.21-260-smp  The problem I'm seeing is that apache will not perform a 'ProxyPass' to another SSL host.  The openssl function ssl_verify_cert_chain() [ssl/ssl_cert.c] stores the SSL* pointer in the X509_STORE_CTX context with the following code:    X509_STORE_CTX_set_ex_data(&ctx,SSL_get_ex_data_X509_STORE_CTX_idx(),s);  the apache callback function ssl_callback_SSLVerify() [modules/ssl/ssl_kernel_engine.c] then retrieves this value with the following code:    SSL *ssl = (SSL *)X509_STORE_CTX_get_app_data(ctx);  which is just a macro to retrieve index 0 of the ex_data.  This fails on the above system.  I don't have an exact match single processor 32-bit machine for comparison testing but I tested on a close match and it works fine.  The following patch fixes the problem on the above system:  ----------------------- diff -Naur openssl-0.9.7b-orig/ssl/ssl_cert.c openssl-0.9.7b/ssl/ssl_cert.c --- openssl-0.9.7b-orig/ssl/ssl_cert.c    2004-12-03 18:35:40.000000000 -0800 +++ openssl-0.9.7b/ssl/ssl_cert.c    2004-12-03 18:36:20.000000000 -0800 @@ -467,6 +467,7 @@      if (SSL_get_verify_depth(s) >= 0)          X509_STORE_CTX_set_depth(&ctx, SSL_get_verify_depth(s));      X509_STORE_CTX_set_ex_data(&ctx,SSL_get_ex_data_X509_STORE_CTX_idx(),s); +    X509_STORE_CTX_set_app_data(&ctx,s);       /* We need to set the verify purpose. The purpose can be determined by       * the context: if its a server it will verify SSL client certificates -----------------------  The bug is that a callback function has no way of retrieving the value returned by SSL_get_ex_data_X509_STORE_CTX_idx(), in apache's case it uses 0 via the X509_STORE_CTX_get_app_data() macro.  This may not be the 'correct' ultimate fix as I'm not sure if there's a reason why index 0 might not be available.  The 'ctx' structure above is stack allocated and only used for the duration of the ssl_verify_cert_chain() call.	Could you:  1) describe the failure you see 2) reproduce this with the vanilla 2.0.52 release rather than the SuSE package  The failure is that if I include a ProxyPass statement from one SSL enabled host to another SSL enabled, as soon as I try to access a page that should be proxied from the other host the child process in apache seg faults and I see nothing in my browser.  Here's a trimmed generic configuration that will generate the problem:  Host 1: -------     <VirtualHost 1.2.3.4:443>         ServerName      host1.domain.com          DocumentRoot    /srv/www/host1          SSLEngine                       on         SSLProxyEngine                  on         SSLCipherSuite                  ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL         SSLCertificateFile              /etc/apache2/ssl.crt/host1.domain.com.crt         SSLCertificateKeyFile           /etc/apache2/ssl.key/host1.domain.com.key          ProxyPass      /test.html       https://host2.domain.com.:444/test.html     </VirtualHost>     <Directory /srv/www/host1>         Order allow,deny         Allow from all         AllowOverride All     </Directory>  Host 2: -------     Listen 444      <VirtualHost 1.2.3.5:444>         ServerName      host2.domain.com          DocumentRoot    /srv/www/host2          SSLEngine                       on         SSLCertificateKeyFile           /etc/apache2/ssl.key/host2.domain.com.key         SSLCertificateFile              /etc/apache2/ssl.crt/host2.domain.com.crt     </VirtualHost>      <Directory /srv/www/host2>         Order allow,deny         Allow from all         AllowOverride All    </Directory>  If you browse to https://host1.domain.com/test.html it should be reverse proxied from https://host2.domain.com/test.html but instead the apache process seg faults.  I suspect that this is SMP related or perhaps related to the x86_64 architecture but that's only a suspicion.   Here's a backtrace from a core dump:  #0  0x0000002a97a72486 in CRYPTO_get_ex_data () from /usr/lib64/libcrypto.so.0.9.7 #1  0x0000002a978d766a in SSL_get_ex_data () from /usr/lib64/libssl.so.0.9.7 #2  0x0000002a977acd40 in ssl_callback_SSLVerify () from /usr/lib64/apache2-prefork/mod_ssl.so #3  0x0000002a97aa67c2 in X509_verify_cert () from /usr/lib64/libcrypto.so.0.9.7 #4  0x0000002a978edd0c in ssl_verify_cert_chain () from /usr/lib64/libssl.so.0.9.7 #5  0x0000002a978e32eb in ssl3_get_server_certificate () from /usr/lib64/libssl.so.0.9.7 #6  0x0000002a978e23dc in ssl3_connect () from /usr/lib64/libssl.so.0.9.7 #7  0x0000002a978ec245 in SSL_connect () from /usr/lib64/libssl.so.0.9.7 #8  0x0000002a978e9f10 in ssl23_get_server_hello () from /usr/lib64/libssl.so.0.9.7 #9  0x0000002a978e992c in ssl23_connect () from /usr/lib64/libssl.so.0.9.7 #10 0x0000002a978ec245 in SSL_connect () from /usr/lib64/libssl.so.0.9.7 #11 0x0000002a977aa8dc in ssl_io_filter_connect () from /usr/lib64/apache2-prefork/mod_ssl.so #12 0x0000002a977aaebe in ssl_io_filter_output () from /usr/lib64/apache2-prefork/mod_ssl.so #13 0x0000000000433b6a in ap_pass_brigade () #14 0x0000002a9c255f3b in ap_proxy_http_request () from /usr/lib64/apache2-prefork/mod_proxy_http.so #15 0x0000002a9c25707f in ap_proxy_http_handler () from /usr/lib64/apache2-prefork/mod_proxy_http.so #16 0x0000002a9c14e3ab in proxy_run_scheme_handler () from /usr/lib64/apache2-prefork/mod_proxy.so #17 0x0000002a9c14cf9b in proxy_handler () from /usr/lib64/apache2-prefork/mod_proxy.so #18 0x0000000000427631 in ap_run_handler () #19 0x0000000000427ca9 in ap_invoke_handler () #20 0x0000000000424506 in ap_process_request () #21 0x000000000041fad8 in ap_process_http_connection () #22 0x00000000004316a1 in ap_run_process_connection () #23 0x0000000000431a02 in ap_process_connection () #24 0x0000000000425d22 in child_main () #25 0x0000000000425ee8 in make_child () #26 0x00000000004260b3 in perform_idle_server_maintenance () #27 0x0000000000426621 in ap_mpm_run () #28 0x000000000042cada in main ()  If I patch openssl as I stated in the original post it fixes the problem.  I'll see if I can duplicate the problem with the stock 2.0.52.  I have to proceed with caution since this server is running a number of sites with a lot of traffic. The failure is that if I include a ProxyPass statement from one SSL enabled host to another SSL enabled, as soon as I try to access a page that should be proxied from the other host the child process in apache seg faults and I see nothing in my browser.  Here's a trimmed generic configuration that will generate the problem:  Host 1: -------     <VirtualHost 1.2.3.4:443>         ServerName      host1.domain.com          DocumentRoot    /srv/www/host1          SSLEngine                       on         SSLProxyEngine                  on         SSLCipherSuite                  ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL         SSLCertificateFile              /etc/apache2/ssl.crt/host1.domain.com.crt         SSLCertificateKeyFile           /etc/apache2/ssl.key/host1.domain.com.key          ProxyPass      /test.html       https://host2.domain.com.:444/test.html     </VirtualHost>     <Directory /srv/www/host1>         Order allow,deny         Allow from all         AllowOverride All     </Directory>  Host 2: -------     Listen 444      <VirtualHost 1.2.3.5:444>         ServerName      host2.domain.com          DocumentRoot    /srv/www/host2          SSLEngine                       on         SSLCertificateKeyFile           /etc/apache2/ssl.key/host2.domain.com.key         SSLCertificateFile              /etc/apache2/ssl.crt/host2.domain.com.crt     </VirtualHost>      <Directory /srv/www/host2>         Order allow,deny         Allow from all         AllowOverride All    </Directory>  If you browse to https://host1.domain.com/test.html it should be reverse proxied from https://host2.domain.com/test.html but instead the apache process seg faults.  I suspect that this is SMP related or perhaps related to the x86_64 architecture but that's only a suspicion.   Here's a backtrace from a core dump:  #0  0x0000002a97a72486 in CRYPTO_get_ex_data () from /usr/lib64/libcrypto.so.0.9.7 #1  0x0000002a978d766a in SSL_get_ex_data () from /usr/lib64/libssl.so.0.9.7 #2  0x0000002a977acd40 in ssl_callback_SSLVerify () from /usr/lib64/apache2-prefork/mod_ssl.so #3  0x0000002a97aa67c2 in X509_verify_cert () from /usr/lib64/libcrypto.so.0.9.7 #4  0x0000002a978edd0c in ssl_verify_cert_chain () from /usr/lib64/libssl.so.0.9.7 #5  0x0000002a978e32eb in ssl3_get_server_certificate () from /usr/lib64/libssl.so.0.9.7 #6  0x0000002a978e23dc in ssl3_connect () from /usr/lib64/libssl.so.0.9.7 #7  0x0000002a978ec245 in SSL_connect () from /usr/lib64/libssl.so.0.9.7 #8  0x0000002a978e9f10 in ssl23_get_server_hello () from /usr/lib64/libssl.so.0.9.7 #9  0x0000002a978e992c in ssl23_connect () from /usr/lib64/libssl.so.0.9.7 #10 0x0000002a978ec245 in SSL_connect () from /usr/lib64/libssl.so.0.9.7 #11 0x0000002a977aa8dc in ssl_io_filter_connect () from /usr/lib64/apache2-prefork/mod_ssl.so #12 0x0000002a977aaebe in ssl_io_filter_output () from /usr/lib64/apache2-prefork/mod_ssl.so #13 0x0000000000433b6a in ap_pass_brigade () #14 0x0000002a9c255f3b in ap_proxy_http_request () from /usr/lib64/apache2-prefork/mod_proxy_http.so #15 0x0000002a9c25707f in ap_proxy_http_handler () from /usr/lib64/apache2-prefork/mod_proxy_http.so #16 0x0000002a9c14e3ab in proxy_run_scheme_handler () from /usr/lib64/apache2-prefork/mod_proxy.so #17 0x0000002a9c14cf9b in proxy_handler () from /usr/lib64/apache2-prefork/mod_proxy.so #18 0x0000000000427631 in ap_run_handler () #19 0x0000000000427ca9 in ap_invoke_handler () #20 0x0000000000424506 in ap_process_request () #21 0x000000000041fad8 in ap_process_http_connection () #22 0x00000000004316a1 in ap_run_process_connection () #23 0x0000000000431a02 in ap_process_connection () #24 0x0000000000425d22 in child_main () #25 0x0000000000425ee8 in make_child () #26 0x00000000004260b3 in perform_idle_server_maintenance () #27 0x0000000000426621 in ap_mpm_run () #28 0x000000000042cada in main ()  If I patch openssl as I stated in the original post it fixes the problem.  I'll see if I can duplicate the problem with the stock 2.0.52.  I have to proceed with caution since this server is running a number of sites with a lot of traffic.   (In reply to comment #2) This is a duplicate of #3 below. I am unable to reproduce this bug with a stock 2.0.52 apache on the same system with more or less the same configuration (mainly just a change of port numbers).  I also am unable to reproduce it with a stock 2.0.48 apache.  Furthermore, even after applying all of the patches (to 2.0.48) that SuSE uses to build their RPM and using the same compiler options that they use and I still can't reproduce it.  So either the run-time configuration changes somehow affect it or something happens when building the RPM which affects it.  Or maybe I'm just going crazy. To be clear, you were testing the vanilla 2.0.52 and 2.0.48 sources against the *unpatched* version of OpenSSL, not the one you have patched?  Could you try changing the first line of ssl_callback_SSLVerify as follows, instead:  -    SSL *ssl            = (SSL *)X509_STORE_CTX_get_app_data(ctx); +    SSL *ssl = X509_STORE_CTX_get_ex_data(ctx, +                                         SSL_get_ex_data_X509_STORE_CTX_idx());  I can't really see why that segfault could happen in the first place, though. (In reply to comment #6) > To be clear, you were testing the vanilla 2.0.52 and 2.0.48 sources against the > *unpatched* version of OpenSSL, not the one you have patched? That is correct, the unpatched OpenSSL. >  > Could you try changing the first line of ssl_callback_SSLVerify as follows, instead: >  > -    SSL *ssl            = (SSL *)X509_STORE_CTX_get_app_data(ctx); > +    SSL *ssl = X509_STORE_CTX_get_ex_data(ctx, > +                                         SSL_get_ex_data_X509_STORE_CTX_idx()); I'll try it, but see below because there may be bigger problems.  >  > I can't really see why that segfault could happen in the first place, though. The reason that its happening is that in some cases the openssl code is storing the SSL* pointer at an index of 1 rather than 0 (the  X509_STORE_CTX_get_app_data() macro always uses 0).  I discovered this by putting a fprintf statement in the function X509_STORE_CTX_get_ex_new_index() to see what values are being returned as indexes in the SSL_get_ex_data_X509_STORE_CTX_idx() function.  Again, this only happens on the live apache server not the test one.  By looking at the function  SSL_get_ex_data_X509_STORE_CTX_idx() one would presume that this would be impossible.  For reference here's the function:  int SSL_get_ex_data_X509_STORE_CTX_idx(void) \t{ \tstatic volatile int ssl_x509_store_ctx_idx= -1;  \tif (ssl_x509_store_ctx_idx < 0) \t\t{ \t\t/* any write lock will do; usually this branch \t\t * will only be taken once anyway */ \t\tCRYPTO_w_lock(CRYPTO_LOCK_SSL_CTX);  \t\tif (ssl_x509_store_ctx_idx < 0) \t\t\t{ \t\t\tssl_x509_store_ctx_idx=X509_STORE_CTX_get_ex_new_index( \t\t\t\t0,'SSL for verify callback',NULL,NULL,NULL); \t\t\t}  \t\tCRYPTO_w_unlock(CRYPTO_LOCK_SSL_CTX); \t\t} \treturn ssl_x509_store_ctx_idx; \t}   Also for reference, here is a dump of the assembler for this code:  Dump of assembler code for function SSL_get_ex_data_X509_STORE_CTX_idx: 0x0000000000024710 <SSL_get_ex_data_X509_STORE_CTX_idx+0>:      sub    $0x8,%rsp 0x0000000000024714 <SSL_get_ex_data_X509_STORE_CTX_idx+4>:      mov    1094190(%rip),%eax        # 0x12f948 <ssl_x509_store_ctx_idx.0> 0x000000000002471a <SSL_get_ex_data_X509_STORE_CTX_idx+10>:     test   %eax,%eax 0x000000000002471c <SSL_get_ex_data_X509_STORE_CTX_idx+12>:     js     0x24730 <SSL_get_ex_data_X509_STORE_CTX_idx+32> 0x000000000002471e <SSL_get_ex_data_X509_STORE_CTX_idx+14>:     mov    1094180(%rip),%eax        # 0x12f948 <ssl_x509_store_ctx_idx.0> 0x0000000000024724 <SSL_get_ex_data_X509_STORE_CTX_idx+20>:     add    $0x8,%rsp 0x0000000000024728 <SSL_get_ex_data_X509_STORE_CTX_idx+24>:     retq 0x0000000000024729 <SSL_get_ex_data_X509_STORE_CTX_idx+25>:     data16 0x000000000002472a <SSL_get_ex_data_X509_STORE_CTX_idx+26>:     data16 0x000000000002472b <SSL_get_ex_data_X509_STORE_CTX_idx+27>:     data16 0x000000000002472c <SSL_get_ex_data_X509_STORE_CTX_idx+28>:     nop 0x000000000002472d <SSL_get_ex_data_X509_STORE_CTX_idx+29>:     data16 0x000000000002472e <SSL_get_ex_data_X509_STORE_CTX_idx+30>:     data16 0x000000000002472f <SSL_get_ex_data_X509_STORE_CTX_idx+31>:     nop 0x0000000000024730 <SSL_get_ex_data_X509_STORE_CTX_idx+32>:     lea    20449(%rip),%rdx        # 0x29718 <empty.0+908> 0x0000000000024737 <SSL_get_ex_data_X509_STORE_CTX_idx+39>:     mov    $0x8d,%ecx 0x000000000002473c <SSL_get_ex_data_X509_STORE_CTX_idx+44>:     mov    $0xc,%esi 0x0000000000024741 <SSL_get_ex_data_X509_STORE_CTX_idx+49>:     mov    $0x9,%edi 0x0000000000024746 <SSL_get_ex_data_X509_STORE_CTX_idx+54>:     callq  0xc268 0x000000000002474b <SSL_get_ex_data_X509_STORE_CTX_idx+59>:     mov    1094135(%rip),%eax        # 0x12f948 <ssl_x509_store_ctx_idx.0> 0x0000000000024751 <SSL_get_ex_data_X509_STORE_CTX_idx+65>:     test   %eax,%eax 0x0000000000024753 <SSL_get_ex_data_X509_STORE_CTX_idx+67>:     jns    0x24770 <SSL_get_ex_data_X509_STORE_CTX_idx+96> 0x0000000000024755 <SSL_get_ex_data_X509_STORE_CTX_idx+69>:     lea    20423(%rip),%rsi        # 0x29723 <empty.0+919> 0x000000000002475c <SSL_get_ex_data_X509_STORE_CTX_idx+76>:     xor    %r8d,%r8d 0x000000000002475f <SSL_get_ex_data_X509_STORE_CTX_idx+79>:     xor    %ecx,%ecx 0x0000000000024761 <SSL_get_ex_data_X509_STORE_CTX_idx+81>:     xor    %edx,%edx 0x0000000000024763 <SSL_get_ex_data_X509_STORE_CTX_idx+83>:     xor    %edi,%edi 0x0000000000024765 <SSL_get_ex_data_X509_STORE_CTX_idx+85>:     callq  0xc8a8 0x000000000002476a <SSL_get_ex_data_X509_STORE_CTX_idx+90>:     mov    %eax,1094104(%rip)        # 0x12f948 <ssl_x509_store_ctx_idx.0> 0x0000000000024770 <SSL_get_ex_data_X509_STORE_CTX_idx+96>:     lea    20385(%rip),%rdx        # 0x29718 <empty.0+908> 0x0000000000024777 <SSL_get_ex_data_X509_STORE_CTX_idx+103>:    mov    $0x95,%ecx 0x000000000002477c <SSL_get_ex_data_X509_STORE_CTX_idx+108>:    mov    $0xc,%esi 0x0000000000024781 <SSL_get_ex_data_X509_STORE_CTX_idx+113>:    mov    $0xa,%edi 0x0000000000024786 <SSL_get_ex_data_X509_STORE_CTX_idx+118>:    callq  0xc268 0x000000000002478b <SSL_get_ex_data_X509_STORE_CTX_idx+123>:    mov    1094071(%rip),%eax        # 0x12f948 <ssl_x509_store_ctx_idx.0> 0x0000000000024791 <SSL_get_ex_data_X509_STORE_CTX_idx+129>:    add    $0x8,%rsp 0x0000000000024795 <SSL_get_ex_data_X509_STORE_CTX_idx+133>:    retq  The call to CRYPTO_w_lock() should ensure that ssl_x509_store_ctx_idx can only take on a value of zero.  The assembler looks correct to me.  It looks like a thread synchronization problem, but its hard to believe that thread synchronization is broken.  Remember that this is an SMP box.  I'm thinking that the reason I can't reproduce the problem is because the test server is not as heavily loaded as the live server.  Also note that this is running the prefork mpm module.   (In reply to comment #7) I was just reading how the prefork module works and it doesn't even have threads so now I'm more confused. (In reply to comment #7) Also note that the only call to X509_STORE_CTX_get_ex_new_index() in apache and openssl is from the function SSL_get_ex_data_X509_STORE_CTX_idx().  (In reply to comment #6) > Could you try changing the first line of ssl_callback_SSLVerify as follows, instead: >  > -    SSL *ssl            = (SSL *)X509_STORE_CTX_get_app_data(ctx); > +    SSL *ssl = X509_STORE_CTX_get_ex_data(ctx, > +                                         SSL_get_ex_data_X509_STORE_CTX_idx());  This is what I was thinking should be the fix should be, which is what I was driving at in my first post:  >> The bug is that a callback function has no way of retrieving >> the value returned by SSL_get_ex_data_X509_STORE_CTX_idx(), >> in apache's case it uses 0 via the X509_STORE_CTX_get_app_data() macro.  Although I was thinking that SSL_get_ex_data_X509_STORE_CTX_idx() wasn't exported from the library and therefore was not callable so I got started down other paths.  Although I can't see where else X509_STORE_CTX_get_ex_new_index() is being called from, but maybe I'm not seeing the big picture.  I'm attempting to rebuild the apache RPM now...  Good analysis, thanks.  This could well be one of the insane cases which occurs where libssl.so gets loaded and unloaded during startup but libcrypto.so always stays mapped.  Global variables in libcrypto.so hence don't get reset to their initialization state, but those in libssl.so do:   note that X509_STORE_CTX_get_ex_new_index is probably just incrementing some global variable behind the scenes, no doubt (haven't verified that): so if  ssl_x509_store_ctx_idx gets reset to -1, but that global variable does not, then the _idx variable will quite likely get set to '1' next time round.  That might also explain the crash.  You could try some fprintf debugging in both libcrypto and libssl to try and verify this; or LD_DEBUG stuff to see when each is getting loaded and unloaded.  (In reply to comment #11) > This could well be one of the insane cases which occurs where libssl.so gets > loaded and unloaded during startup but libcrypto.so always stays mapped.  Global > variables in libcrypto.so hence don't get reset to their initialization state, > but those in libssl.so do:  >  Yep, you guessed it.  I put some printfs in libssl and libcrypto:   1  29336:  2    29336  644.580855: in crypto_init, ppid: 29335, count: 1  3    29336  644.580921: in ssl_init, ppid: 29335, count: 1  4    29336  645.198972: CRYPTO_get_ex_new_index, ix: 0, ppid: 29335, count2: 1  5    29336  645.198980: /usr/lib64/libcrypto.so.0.9.7(my_dumper+0x2e) [0x2a97aac149]  6    29336  645.198985: /usr/lib64/libcrypto.so.0.9.7(X509_STORE_CTX_get_ex_new_index+0x2b) [0x2a97aac25b]  7    29336  645.198989: /usr/lib64/libssl.so.0.9.7(SSL_get_ex_data_X509_STORE_CTX_idx+0x50) [0x2a978ee580]  8    29336  645.198993: /usr/lib64/libssl.so.0.9.7(SSL_CTX_new+0x1a) [0x2a978ed69a]  9    29336  645.198997: /usr/lib64/apache2-prefork/mod_ssl.so [0x2a977a80fd] 10    29336  645.202025: in ssl_exit, ppid: 29335, count: 2 11    29336  645.209564: in ssl_init, ppid: 29335, count: 1 12    29336  645.608884: in ssl_exit, ppid: 29335, count: 2 13    29336  645.609069: in crypto_exit, ppid: 29335, count: 2 14  29337: 15    29336  644.580855: in crypto_init, ppid: 29335, count: 1 16    29336  645.198972: CRYPTO_get_ex_new_index, ix: 0, ppid: 29335, count2: 1 17    29336  645.198980: /usr/lib64/libcrypto.so.0.9.7(my_dumper+0x2e) [0x2a97aac149] 18    29336  645.198985: /usr/lib64/libcrypto.so.0.9.7(X509_STORE_CTX_get_ex_new_index+0x2b) [0x2a97aac25b] 19    29336  645.198989: /usr/lib64/libssl.so.0.9.7(SSL_get_ex_data_X509_STORE_CTX_idx+0x50) [0x2a978ee580] 20    29336  645.198993: /usr/lib64/libssl.so.0.9.7(SSL_CTX_new+0x1a) [0x2a978ed69a] 21    29336  645.198997: /usr/lib64/apache2-prefork/mod_ssl.so [0x2a977a80fd] 22    29336  645.209564: in ssl_init, ppid: 29335, count: 1 23    29337  645.699132: CRYPTO_get_ex_new_index, ix: 1, ppid: 1, count2: 2 24    29337  645.699147: /usr/lib64/libcrypto.so.0.9.7(my_dumper+0x2e) [0x2a97aac149] 25    29337  645.699152: /usr/lib64/libcrypto.so.0.9.7(X509_STORE_CTX_get_ex_new_index+0x2b) [0x2a97aac25b] 26    29337  645.699156: /usr/lib64/libssl.so.0.9.7(SSL_get_ex_data_X509_STORE_CTX_idx+0x50) [0x2a978ee580] 27    29337  645.699161: /usr/lib64/libssl.so.0.9.7(SSL_CTX_new+0x1a) [0x2a978ed69a] 28    29337  645.699164: /usr/lib64/apache2-prefork/mod_ssl.so [0x2a977a80fd] 29    29337  656.534013: in ssl_exit, ppid: 1, count: 2 30    29337  656.536308: in crypto_exit, ppid: 1, count: 2  The first column is line numbers, the second is process id, the third is time (fractional part is microseconds).  Lines 2-13 are from process id 29336: Line 2:      libcrypto.so gets loaded and initialized              (this output is coming from a __attribute__((constructor))              function that I added). Line 3:      libssl.so gets loaded and initialized              (output also from a __attribute__((constructor)) function) Line 4:      CRYPTO_get_new_index gets called and returns 0 (the ix value) Lines 5-9:   traceback of the call into mod_ssl Line 10:     libssl.so gets unloaded              (output coming from a __attribute__((destructor)) function) Line 11:     libssl.so gets reloaded and reinitialized Line 12:     libssl.so gets unloaded Line 13:     libcrypto.so gets unloaded              (output coming from a __attribute__((destructor)) function)  Lines 15-30 are from process id 29337: Lines 15-22: match lines 2-9 and line 11 in process 29336, so they              were forked from the same point after line 11 (22).              line 10 isn't matched in 29337 because line 10 was lost              when libssl.so was unloaded. Line 23:     CRYPTO_get_new_index gets called and returns 1 (the ix value)              rather than 0 because libcrypto.so was not unloaded and              reinitialized but libssl.so was. Line 24-30:  backtrace and libraries getting unloaded  The patch you suggested fixed the problem.  Here is the patch file:  -------------------------------------------------------------- diff -r -u httpd-2.0.48-orig/modules/ssl/ssl_engine_kernel.c httpd-2.0.48/modules/ssl/ssl_engine_kernel.c --- httpd-2.0.48-orig/modules/ssl/ssl_engine_kernel.c   2004-12-05 17:54:42.000000000 -0800 +++ httpd-2.0.48/modules/ssl/ssl_engine_kernel.c        2004-12-05 17:58:36.000000000 -0800 @@ -1205,7 +1205,8 @@  int ssl_callback_SSLVerify(int ok, X509_STORE_CTX *ctx)  {      /* Get Apache context back through OpenSSL context */ -    SSL *ssl            = (SSL *)X509_STORE_CTX_get_app_data(ctx); +    SSL *ssl            = (SSL *)X509_STORE_CTX_get_ex_data(ctx, +                                     SSL_get_ex_data_X509_STORE_CTX_idx());      conn_rec *conn      = (conn_rec *)SSL_get_app_data(ssl);      server_rec *s       = conn->base_server;      request_rec *r      = (request_rec *)SSL_get_app_data2(ssl); --------------------------------------------------------------   Thanks a lot for your thorough investigation!  I'll apply the patch.  But I'd not be surprised if there are more bugs like this lurking, abuse of global state is rife in OpenSSL.  The safest fix is to ensure that httpd itself is always linked against both libssl and libcrypto, so neither ever gets unloaded at runtime.  That actually should be done in all 2.0.x releases, it may be an artefact of the SuSE build process that this breaks.  http://svn.apache.org/viewcvs?view=rev&rev=111241 *** Bug 34846 has been marked as a duplicate of this bug. ***			Joe Orton	Mitch Frazier
32561	null	CLOSED		Denny	1102426320000	1102469700000		Link to mod_speling misspelt causing 403 error. The link to mod_speling is misspelt as 'http://httpd.apache.org/docs-2.0/mod/mod_spelling.html' (the link text is misspelt 'mod_spelling' also), which link produces a 403 error.  Correcting the spelling in the URL to mod_speling gives the desired page, http://httpd.apache.org/docs-2.0/mod/mod_speling.html	Thanks for your care.			Andr?? Malo
32699	null	RESOLVED		ducrot	1103049000000	1125587742000		t handle aborted connections With apache 2.0.52 and mod_ssl, when trying to make a cgi which will constantly output something, f.e.  #!/usr/bin/perl  $!=1;  print'HTTPS/1.0 200 OK/n'; print'Content-type: text/plain;/n/n';  my $i = 0; while (1) { print 'something $i/n';         $i++;         sleep(1); }  then the script is still running even though the client is disconnected.  This happens only if SSL is in use.  Also, I checked that the same kind of behaviour happens if a plain file is requested (something like lynx https://sever/a_big_file will result for server to still try to send the file even though lynx is killed).  I think the problem is in httpd-2.0.52/modules/ssl/ssl_engine_io.c::bio_filter_out_write()  220         if (bio_filter_out_flush(bio) < 0) { 221             return -1; 222         }  so that actually httpd will try to flush ad eternam the same buffer.  I guess that in fact bio_filter_out_flush() should verify if the connection to the client have been aborted.	Created an attachment (id=13752) fix ssl flush output  make sure bio_filter_out_flush() return an error if the connection have been aborted. Good work, thanks for the patch.  It's always annoying that core_output_filter hides these EPIPE errors :( I committed a different fix, to set outctx->rc = ECONNRESET rather than just fail here, so that an error is logged properly.  Thanks again for tracking this down.  http://svn.apache.org/viewcvs?view=rev&rev=125166 [viewsvn currently disabled]  Since this specific fix, I occasionally get 104 http error codes in my access log. I have tracked it to aborted SSL connections. The patch for this bug returns an APR_ECONNRESET which resolves to 104 on my linux system (Redhat 9 and Fedora4). It shouldn't be returning invalid http error codes when trying to log aborted http connections. Jason could you please file a new bug for that issue?  I don't think it's mod_ssl specific, mod_ssl appears to be doing the right thing here.			Jason Brady	Joe Orton	ducrot
32842	null	CLOSED		Chris Sorisio	1104079380000	1113583378000		FrontPage 2003 compatibility I experienced problems trying to import sites or open sites via Microsoft FrontPage 2003 from a WebDAV-enabled Apache 2.0.52 server.  I could not import or view subdirectories of any parent directory I attempted to open due to '301' errors, although my httpd.conf had the usual 'redirect-carefully' entries for Microsoft WebDAV clients.  From checking my access logfiles, it appears either:  a.  FrontPage 2003 was announced itself as a Mozilla 4.0 client. b.  Apache 2.0.52 was recognizing FrontPage 2003 as a Mozilla 4.0 client.  By adding 'BrowserMatch '^Mozilla 4.0' redirect-carefully' to my httpd.conf, I was able to correct the behavior.  I don't know if the fault here lies with Microsoft FrontPage 2003 or Apache.  Either FP2003 isn't announcing itself properly or Apache isn't properly identifying it.  Sample acccess_log entry for FrontPage 2003:  192.168.100.200 - - [26/Dec/2004:09:25:51 -0500] 'PROPFIND /webdav/images HTTP/1.1' 301 326 '-' 'Mozilla/4.0 (compatible; MS FrontPage 6.0)'	I've added:  BrowserMatch 'MS FrontPage' redirect-carefully  to the default config which should take care of this.  Thanks for the report.			Joe Orton
32848	null	RESOLVED		Tim K. Taylor	1104166620000	1105714959000		No independent control of CertificateRequest handshake message SSLv3 draft (5.6.4) and RFC2246 (7.4.4) describe the capability to provide a list a CA distinguished names for defining a desired authorization space. This is currently not possible with mod_ssl.  Even though OpenSSL SSL contexts have both a certificate store for client authentication and a stack of CA names for the CertificateRequest handshake message, they are both created from the same set of certificates. This is ok when the list of trusted roots is also the issuer of the client certificates.  PROBLEM ======= When the trusted roots issue subordinate (intermediate) CA certificates which in turn issue end entity certificates, there is the possibility that some and not all of the intermediate CA certificates are acceptable for the trusted root. However, if the trusted root is used for the CertificateRequest handshake message, all of its intermediate CA's are acceptable. Of course, if the trusted root is left out, the certificate chain cannot be verified.  FIX === Separate and independent control of the CertificateRequest handshake message. Currently, the SSLCACertificateFile and SSLCACertificatePath are used to both define the trust list for client authentication and create the list of CA distinguished names for the CertificateRequest message. By adding a new directive to mod_ssl (SSLCADNRequestPath, SSLCADNRequestFile) that, only when present, will specifically define the set of certificates to derive the client_CA distinguished names in the exact same way as SSLCACertificate*. In this case SSLCACertificate* will only define the trust list. When not present, SSLCACertificate* does double duty as normal. This makes the fix downwardly compatible with existing SSL configurations.  PATCH ===== diff -ru httpd-2.0.52-pristine/modules/ssl/mod_ssl.c httpd-2.0.52-patch3/modules/ssl/mod_ssl.c --- httpd-2.0.52-pristine/modules/ssl/mod_ssl.c\tMon Aug 23 10:18:54 2004 +++ httpd-2.0.52-patch3/modules/ssl/mod_ssl.c\tTue Dec 14 11:27:21 2004 @@ -111,10 +111,16 @@                  '("/path/to/file' - PEM encoded)')      SSL_CMD_ALL(CACertificatePath, TAKE1,                  'SSL CA Certificate path ' -                '("/path/to/dir' - contains PEM encoded files)') +                '("/path/to/dir' - contains PEM encoded files for client authentication)')      SSL_CMD_ALL(CACertificateFile, TAKE1,                  'SSL CA Certificate file ' -                '("/path/to/file' - PEM encoded)') +                '("/path/to/file' - PEM encoded for client authentication)') +    SSL_CMD_ALL(CADNRequestPath, TAKE1, +                'SSL CA Distinguished Name path ' +                '("/path/to/dir' - symlink hashes to PEM of acceptable CA names to request)') +    SSL_CMD_ALL(CADNRequestFile, TAKE1, +                'SSL CA Distinguished Name file ' +                '("/path/to/file' - PEM encoded to derive acceptable CA names to request)')      SSL_CMD_SRV(CARevocationPath, TAKE1,                  'SSL CA Certificate Revocation List (CRL) path '                  '("/path/to/dir' - contains PEM encoded files)') ================================================================================================ diff -ru httpd-2.0.52-pristine/modules/ssl/mod_ssl.h httpd-2.0.52-patch3/modules/ssl/mod_ssl.h --- httpd-2.0.52-pristine/modules/ssl/mod_ssl.h\tFri Aug 27 04:03:24 2004 +++ httpd-2.0.52-patch3/modules/ssl/mod_ssl.h\tTue Dec 14 11:27:26 2004 @@ -442,6 +442,20 @@      const char  *ca_cert_path;      const char  *ca_cert_file;   +    /* +     * Acceptable CA names for certificateRequest message. (RFC2246)  +     * These two were added to support specifying a CA name +     * list that may or may not include a self-signed root CA. +     * This allows the ability to create a limited authorization +     * space given the (possible) growth of complex trust hierarchies. +     * +     * For backward compatibility, if SSLCADNRequest* is not specified +     * the default behavior of using SSLCACertificate* for both trust +     * and certificateRequest (client_CA list) will occur. +     */ +    const char  *ca_name_path; +    const char  *ca_name_file; +      const char  *cipher_suite;        /* for client or downstream server authentication */ @@ -502,6 +516,8 @@      int           nVerifyDepth;      const char   *szCACertificatePath;      const char   *szCACertificateFile; +    const char   *szCADNRequestPath; +    const char   *szCADNRequestFile;      const char   *szUserName;  } SSLDirConfigRec;   @@ -534,6 +550,8 @@  const char  *ssl_cmd_SSLCertificateChainFile(cmd_parms *, void *, const char *);  const char  *ssl_cmd_SSLCACertificatePath(cmd_parms *, void *, const char *);  const char  *ssl_cmd_SSLCACertificateFile(cmd_parms *, void *, const char *); +const char  *ssl_cmd_SSLCADNRequestPath(cmd_parms *, void *, const char *); +const char  *ssl_cmd_SSLCADNRequestFile(cmd_parms *, void *, const char *);  const char  *ssl_cmd_SSLCARevocationPath(cmd_parms *, void *, const char *);  const char  *ssl_cmd_SSLCARevocationFile(cmd_parms *, void *, const char *);  const char  *ssl_cmd_SSLVerifyClient(cmd_parms *, void *, const char *); ================================================================================================ diff -ru httpd-2.0.52-pristine/modules/ssl/ssl_engine_config.c httpd-2.0.52-patch3/modules/ssl/ssl_engine_config.c --- httpd-2.0.52-pristine/modules/ssl/ssl_engine_config.c\tMon Aug 23 10:18:54 2004 +++ httpd-2.0.52-patch3/modules/ssl/ssl_engine_config.c\tTue Dec 14 11:27:47 2004 @@ -122,6 +122,8 @@        mctx->auth.ca_cert_path   = NULL;      mctx->auth.ca_cert_file   = NULL; +    mctx->auth.ca_name_path   = NULL; /* added to support separate control */ +    mctx->auth.ca_name_file   = NULL; /* of certificate request message.   */      mctx->auth.cipher_suite   = NULL;      mctx->auth.verify_depth   = UNSET;      mctx->auth.verify_mode    = SSL_CVERIFY_UNSET; @@ -217,6 +219,8 @@        cfgMergeString(auth.ca_cert_path);      cfgMergeString(auth.ca_cert_file); +    cfgMergeString(auth.ca_name_path); +    cfgMergeString(auth.ca_name_file);      cfgMergeString(auth.cipher_suite);      cfgMergeInt(auth.verify_depth);      cfgMerge(auth.verify_mode, SSL_CVERIFY_UNSET); @@ -286,6 +290,8 @@        dc->szCACertificatePath    = NULL;      dc->szCACertificateFile    = NULL; +    dc->szCADNRequestPath      = NULL; +    dc->szCADNRequestFile      = NULL;      dc->szUserName             = NULL;        return dc; @@ -323,6 +329,8 @@        cfgMergeString(szCACertificatePath);      cfgMergeString(szCACertificateFile); +    cfgMergeString(szCADNRequestPath); +    cfgMergeString(szCADNRequestFile);      cfgMergeString(szUserName);        return mrg; @@ -825,6 +833,32 @@      sc->server->auth.ca_cert_file = arg;        return NULL; +} + +const char *ssl_cmd_SSLCADNRequestPath(cmd_parms *cmd, void *dcfg, const char *arg) { +    SSLSrvConfigRec *sc = mySrvConfig(cmd->server); +    const char *err; + +    if ((err = ssl_cmd_check_dir(cmd, &arg))) { +        return err; +    } + +    sc->server->auth.ca_name_path = arg; + +    return NULL; +} + +const char *ssl_cmd_SSLCADNRequestFile(cmd_parms *cmd, void *dcfg, const char *arg) { +    SSLSrvConfigRec *sc = mySrvConfig(cmd->server); +    const char *err; + +    if ((err = ssl_cmd_check_file(cmd, &arg))) { +        return err; +    } + +    sc->server->auth.ca_name_file = arg; + +    return NULL;  }    const char *ssl_cmd_SSLCARevocationPath(cmd_parms *cmd, ================================================================================================ diff -ru httpd-2.0.52-pristine/modules/ssl/ssl_engine_init.c httpd-2.0.52-patch3/modules/ssl/ssl_engine_init.c --- httpd-2.0.52-pristine/modules/ssl/ssl_engine_init.c\tMon Jun  7 05:18:37 2004 +++ httpd-2.0.52-patch3/modules/ssl/ssl_engine_init.c\tThu Dec  9 19:04:04 2004 @@ -532,12 +532,20 @@              ssl_die();          }   -        ca_list = ssl_init_FindCAList(s, ptemp, +\tif (mctx->auth.ca_name_file || mctx->auth.ca_name_path) { +\t    ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, +\t\t      'Configuring certificateRequest message'); + +            ca_list = ssl_init_FindCAList(s, ptemp, +                                      mctx->auth.ca_name_file, +                                      mctx->auth.ca_name_path); +\t} else +            ca_list = ssl_init_FindCAList(s, ptemp,                                        mctx->auth.ca_cert_file,                                        mctx->auth.ca_cert_path);          if (!ca_list) {              ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, -                    'Unable to determine list of available ' +                    'Unable to determine list of acceptable '                      'CA certificates for client authentication');              ssl_die();          } @@ -556,7 +564,7 @@              ap_log_error(APLOG_MARK, APLOG_WARNING, 0, s,                           'Init: Oops, you want to request client '                           'authentication, but no CAs are known for ' -                         'verification!?  [Hint: SSLCACertificate*]'); +                         'verification!?  [Hint: SSLCACertificate*, SSLCADNRequest*]');          }      }  } @@ -1123,7 +1131,7 @@            if ((rv = apr_dir_open(&dir, ca_path, ptemp)) != APR_SUCCESS) {              ap_log_error(APLOG_MARK, APLOG_ERR, rv, s, -                    'Failed to open SSLCACertificatePath "%s'', +                    'Failed to open Certificate Path "%s'',                      ca_path);              ssl_die();          } ================================================================================================ diff -ru httpd-2.0.52-pristine/modules/ssl/ssl_engine_kernel.c httpd-2.0.52-patch3/modules/ssl/ssl_engine_kernel.c --- httpd-2.0.52-pristine/modules/ssl/ssl_engine_kernel.c\tMon Aug 23 10:18:55 2004 +++ httpd-2.0.52-patch3/modules/ssl/ssl_engine_kernel.c\tThu Dec  9 19:04:04 2004 @@ -470,11 +470,22 @@          /* SSL_free will free cert_store */          SSL_set_cert_store(ssl, cert_store);   -        if (!(ca_list = ssl_init_FindCAList(r->server, r->pool, -                                            ca_file, ca_path))) +\t/* +\t * If no per-dir CADNRequest* is defined, the per-dir +\t * CACertificate* takes on its default double-duty. +\t */ +        if (MODSSL_CFG_NE(szCADNRequestFile) || +            MODSSL_CFG_NE(szCADNRequestPath))          { +            ca_file = MODSSL_CFG_CA(szCADNRequestFile); +            ca_path = MODSSL_CFG_CA(szCADNRequestPath); +\t} + +        if (!(ca_list = ssl_init_FindCAList(r->server, r->pool,  +                                           ca_file, ca_path))) +        {              ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server, -                         'Unable to determine list of available ' +                         'Unable to determine list of acceptable '                           'CA certificates for client authentication');                return HTTP_FORBIDDEN;	Thanks for the submission. A trimmed-down version of this patch has been committed to the trunk for future httpd 2.1/2.2 releases.  http://svn.apache.org/viewcvs?view=rev&rev=125165 [viewcvs currently accessible]  Did you have a docs update for this too, BTW?  I had not done the doc but I can certainly do so. I assume that when I am done, that I should attach here as was done with the code. That or just send it to docs@httpd.apache.org; ideally as a diff against the XML source.  If it's hassle then just sending in some unformatted text would be great. Created an attachment (id=14160) documentation patch to mod_ssl.xml 			Joe Orton	Tim K. Taylor
32985	null	RESOLVED		Anthony DiSante	1105091940000	1106577600000		strange variable truncation with SSI regexes and HTTP_COOKIE For certain lengths of HTTP_COOKIE, it seems that SSI regexes (in 'expr=' statements) fail to capture the full length of the HTTP_COOKIE variable when using capturing parentheses.  Here's an example, tested on 2.0.52 on two different Linux servers:   <!--#set var='HTTP_COOKIE' value='xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx=n' -->  Your HTTP_COOKIE is:  '<!--#echo var='HTTP_COOKIE' -->'  <!--#if expr='$HTTP_COOKIE = /(.+)/' --> ...but captured from a regex using (.+), it's truncated to this:  '<!--#echo var='1' -->' <!--#endif -->   In case this form/webpage messes with that code, just visit this URL:  http://nodivisions.com/test.shtml  Note that the actual value of HTTP_COOKIE doesn't matter; I found this bug while using 3 real cookie values in it, but then replaced them with all Xes to test.  Only the length seems to matter.	Created an attachment (id=13999) proposed fix  There's an off-by-one in the handling of variables which expand to 128 characters, this is a fix, not sure if it's the *correct* fix... Created an attachment (id=14025) variable truncation fix #2  fix for variable truncation issue (now with comment) Fix committed for 2.0.53; thanks for the simple repro case! You're welcome; glad to help.  Thanks for the fix!			Anthony DiSante	Joe Orton
33112	null	RESOLVED		J	1105797360000	1188319409000		Query_string not preserved after content negotiation The query string is not preserved when returning the negotiated file causing CGI  scripts to miss all request variables. Here is a fix:  --- httpd-2.0.52/modules/mappers/mod_negotiation.c      2004-02-09 21:53:18. 000000000 +0100 +++ httpd-2.0.52j/modules/mappers/mod_negotiation.c     2005-01-15 13:47:20. 095964578 +0100 @@ -2938,7 +2938,7 @@      udir = ap_make_dirstr_parent(r->pool, r->uri);      udir = ap_escape_uri(r->pool, udir);      ap_internal_redirect(apr_pstrcat(r->pool, udir, best->file_name, -                                     r->path_info, NULL), r); +                                     r->path_info, '?', r->args, NULL), r);      return OK;  }  @@ -2991,6 +2991,7 @@              goto return_from_multi;          }      } +    if ((r->args != NULL) && ( sub_req->args == NULL)) sub_req->args =  apr_pstrdup(r->pool, r->args);    /* keep query_string */       /* now do a 'fast redirect' ... promotes the sub_req into the main req */      ap_internal_fast_redirect(sub_req, r);	Also present in 2.2.4. Fixed in trunk: http://svn.apache.org/viewvc?view=rev&revision=565671 It's probably irrelevant now, but I've applied and tested the patch in 2.2.4. Works fine. Fixed for 2.2.6.			Nick Kew	Per Jessen
33170	null	RESOLVED		Rici Lake	1106175420000	1107476362000		ProxyRemoteMatch uses remote proxy if regex does *not* match The ProxyRemoteMatch directive is supposed to use a regex to redirect certain proxy requests to a  remote proxy server (as I understand the documentation). I actually needed that for a configuration (see  below) and was puzzled to find that it doesn't work: (line numbers from APACHE_2_0_BRANCH, because  I can't find a web interface to svn.)  389 :  p2 = ap_strchr_c(ents[i].scheme, ':');  /* is it a partial URL? */ 390 :  if (strcmp(ents[i].scheme, '*') == 0 || 391 :      (ents[i].use_regex && ap_regexec(ents[i].regexp, url, 0,NULL, 0)) || 392 :      (p2 == NULL && strcasecmp(scheme, ents[i].scheme) == 0) || 393 :      (p2 != NULL && 394 :       strncasecmp(url, ents[i].scheme, strlen(ents[i].scheme)) == 0)) {  ap_regexec returns 0 on success, so the condition in line 391 matches if the regex didn't match, which  is the reverse of the expected behaviour. Changing line 391 to  391 :      (ents[i].use_regex && ap_regexec(ents[i].regexp, url, 0,NULL, 0) == 0) ||  produced the expected behaviour.  This code seems to have been unchanged since the directive was introduced in 2.0.35, almost three  years ago, and I cannot find any relevant bug reports; in fact, googling for ProxyRemoteMatch did not  yield any indication that anyone has ever tried to use the directive, much less succeeded. This would  seem to be a reasonable case for deleting the directive	Applied in r151248.  Thanks!			Justin Erenkrantz
33290	null	RESOLVED		Topia	1106933280000	1107053540000		 clause is really NOT limit _access_ mod_info documentation has this line: >You may wish to add a <Limit> clause inside the <Location>  directive to limit access to your server configuration information.  This line maybe causes misconfiguration with <Limit>. please rewrite such as 'You may wish to use <module>mod_access</module> ...'.	Thanks. Change made.			Rich Bowen
33382	null	RESOLVED		Rudolf Kutina	1107426840000	1109412497000		mod_proxy and MS streaming server memory leak ? Hello Apache developers, I try to use mod_proxy (mod_proxy_http) on APACHE 2.0.52 to proxy a Windows  Media streaming services 9 on HTTP protocol. It works OK, but when stream  duration is long (minutes) APACHE2 start to eat server memory slowly and its  unlimited process.  Memory is cleaned if I restart APACHE2.  I try to emulate more users with MS media load test software and for 100 users  its eat 100KB each 10 seconds.  I tried both patch from BUG 31952 and Chunked content encoding patch from  http://www.apache.org/~trawick page. No success.  This is the header from stream with data: -----------------------------------------  HTTP/1.1 200 OK Content-Type: application/x-mms-framed Server: Cougar/9.00.00.3380 Date: Tue, 01 Feb 2005 13:32:19 GMT Pragma: no-cache, client-id=841485782, features='broadcast', timeout=60000,  AccelBW=0, AccelDuration=0, Speed=1.000 Cache-Control: no-cache, x-wms-event-subscription='remote-log', x-wms-stream- type='broadcast' Last-Modified: Sat, 30 Dec 1899 00:00:00 GMT Transfer-Encoding: chunked Supported: com.microsoft.wm.srvppair, com.microsoft.wm.sswitch,  com.microsoft.wm.predstrm, com.microsoft.wm.fastcache  -----------------------------------------------------  If you need more info or test I can help.  Thanks for help  Rudolf	I have the same problem with trying to proxy 2 Axis webcams We can pay for patch! Are you in a position to try mod_proxy from httpd-2.1 or current CVS?  It would be useful to know whether they have a similar problem.  (In reply to comment #3) > Are you in a position to try mod_proxy from httpd-2.1 or current CVS?  > It would be useful to know whether they have a similar problem.   Current http (2005-02-16) from 2.0 branch have the same problem. Current httpd (2005-02-16) from CVS 2.1 branch tree with last APR have the same  problem. System is Gentoo with kernel 2.6.10 The same problem is on actual httpd for win32. Tested on precompiled version  2.0.53 on Widnows 2003 server. The same problem on httpd 1.3.33.  I am using Reverse Proxy configurations like:  ProxyRequests Off  <Proxy *>  Order deny,allow Allow from all  </Proxy>  ProxyPass /foo http://foo.example.com/bar ProxyPassReverse /foo http://foo.example.com/bar    Hello,  I am the director of the company trying to solve this problem.  Our client has  approved us to pay $500 to someone that can fix this memoryleak. This problem  is becoming critical and we really need to solve it.  If you would like to talk to us directly to expedite a resolution, you can call  USA 800-341-0860  Thanks  A fix for this has been commited to subversion in r154200: http://svn.apache.org/viewcvs.cgi?rev=154200&view=rev  I am going to propose a backport to the 2.0.x branch. Created an attachment (id=14308) Backport of r154200 to 2.0.x branch  Proposed backport with this patch to the 2.0.x branch. Backported to 2.0.x in r r155391.  The fix will part of 2.0.54.  Thanks for using Apache.			Nick Kew	Paul Querna	Rudolf Kutina	Terry Lewis
33438	null	CLOSED		Bojan Smojver	1107829680000	1107974592000		Incorrect function name in request.xml developer doc As per my e-mail to the devel list, a function name mentioned in this document is incorrect, which can lead to many hours of useless 'grepping' ;-)	Created an attachment (id=14203) Fix  fix committed to 2.1-dev and 2.0.next... thanks!			Bojan Smojver	Jeff Trawick
33466	null	RESOLVED		Spunkmeyer	1107960540000	1185883717000		> In the french version of the docs for httpd-1.3 the syntax for the <FilesMatch> directive is incorrect.  It reads 'Syntaxe : <FilesMatch regex> ... </Files>' It should be 'Syntaxe : <FilesMatch regex> ... </FilesMatch>'	Ok fixed a few years later. Thanks.			Joshua Slive
33508	null	RESOLVED		Mike Brown	1108081860000	1185884276000		folder images missing from small icons Symptom: broken folder image in directory index when using the small icon set. Probably affects all Apache versions (I am initially filing this report for just the version I have, though: 2.0.52).  Cause: When the small icon set was added, dir.gif was included, but its identical twin, folder.gif, was not. folder.gif is needed by the FancyIndexer, due to the presence of 'AddIcon /icons/folder.gif ^^DIRECTORY^^' in the default httpd.conf.  Reproduction: In your httpd.conf, in the 'Aliases' section, put  Alias /icons/ '/usr/local/www/icons-dist/small/' <Directory '/usr/local/www/icons-dist/small'>     Options Indexes MultiViews     AllowOverride None     Order allow,deny     Allow from all </Directory>  Elsewhere in httpd.conf, make sure the IndexOptions line has FancyIndexing, IconWidth=16, and IconHeight=16. Then do a graceful restart, and use a browser to access a directory that would be subject to indexing and that contains a subdirectory. Observe the broken image next to the subdirectory.  Solution: Either add copies of dir.gif & dir.png to the Apache distribution as folder.gif and folder.png, or do whatever is needed to ensure that copies get created at install time.  Thanks!  - Mike <mike@hyperreal.org> (original contributor of the small icon set)	Changed summary to improve searchability Several years later...  I just renamed dir to folder in trunk, since dir is never used. I don't see any urgency to backport this, since few people use the small icons and it is easy enough to fix in the config.  Thanks for the report.			Joshua Slive	Mike Brown
33615	null	RESOLVED		Wolfgang Walter	1108643040000	1109267661000		mod_proxy_http logs (70014)End of file found: proxy: error reading response Using apache 2.1.3 (http snapshot 20050215054011; apr snapshot 20050215053858)  als forwarding proxy for almost every request there is an entry in error.log:    [Thu Feb 17 11:28:12 2005] [error] [client 10.150.36.88] (70014)End of file  found: proxy: error reading response    This seems to be the case because APR_EOF is treated as error in  ap_proxy_http_process_response:                        else if (rv != APR_SUCCESS) {                          ap_log_cerror(APLOG_MARK, APLOG_ERR, rv, c,                                        'proxy: error reading response');                          break;    I changed it like this     --- httpd-2.1.3/modules/proxy/mod_proxy_http.c.orig 2005-02-17  11:55:35.786094428 +0100  +++ httpd-2.1.3/modules/proxy/mod_proxy_http.c 2005-02-17 11:26:21.437570547  +0100  @@ -1267,7 +1267,7 @@                           mode = APR_BLOCK_READ;                           continue;                       }  -                    else if (rv != APR_SUCCESS) {  +                    else if (rv != APR_SUCCESS && rv != APR_EOF) {                           ap_log_cerror(APLOG_MARK, APLOG_ERR, rv, c,                                         'proxy: error reading response');                           break;    The errors disappear and all seems still to work.	Thanks a lot!  Your patch was not quite right since it should just break out of the loop on EOF: committed for the next release:  http://svn.apache.org/viewcvs.cgi?rev=155209&view=rev			Joe Orton
33765	null	CLOSED		Christian Ullrich	1109577840000	1109604583000		htdigest creates digest files suid/sgid htdigest creates its digest files with both suid and sgid bits set. I traced its execution and noticed that it actually tries to create the file with full 07777 permissions, but the FreeBSD kernel ignores sticky, because it's a regular file.  In htdigest.c is a call to apr_file_open() for the digest file, with -1 in the perm argument.  htpasswd, which uses APR_OS_DEFAULT for the perm argument, creates its files with proper permissions.	Hmm, I'd guess your APR headers are outdated (i.e. not matching the lib version). Could this be? (In reply to comment #1) > Hmm, I'd guess your APR headers are outdated (i.e. not matching the lib > version). Could this be?  I don't think so. One, I installed the whole thing from the FreeBSD ports collection, and the APR headers are in the same package as the server, and two, the bug doesn't have anything to do with a wrong #define. In support/htdigest.c, even in HEAD, there is a call to apr_file_open() with -1 as fourth argument. Not something that's #defined to -1, but a literal -1.  APR_OS_DEFAULT (what htpasswd uses instead) is 07777, but it's special-cased in libapr to use 00666. Good catch! Committed to trunk, will propose for 2.0.x:  http://svn.apache.org/viewcvs.cgi?rev=155681&view=rev And committed for 2.0.54, revision 155762.  Thanks for the report!			Andr?? Malo	Christian Ullrich	Joe Orton
33803	null	RESOLVED		K.W.Schick	1109767800000	1198325521000		2 Minor Bugs in Apache Service Monitor 'am_DisconnectComputer()' uses wrong index-variable in loop  changes/fix see //!!!  void am_DisconnectComputer(LPSTR szComputerName) {     int i = 0, j;     while (g_stComputers[i].szComputerName != NULL) {         if (strcmp(g_stComputers[i].szComputerName, szComputerName) == 0) {             break;         }         ++i;     }     if (g_stComputers[i].szComputerName != NULL) {         free(g_stComputers[i].szComputerName);         RegCloseKey(g_stComputers[i].hRegistry);         for (j = i; j < MAX_PROVIS_COMPUTERS - 1; j++) { //!!! was: //!!!    g_stComputers[i].szComputerName= g_stComputers[i+1].szComputerName; //!!!    g_stComputers[i].hRegistry = g_stComputers[i+1].hRegistry; //!!! should read:             g_stComputers[j].szComputerName= g_stComputers[j+1].szComputerName;             g_stComputers[j].hRegistry = g_stComputers[j+1].hRegistry;         }         for (i = j; i < MAX_PROVIS_COMPUTERS; i++) {             g_stComputers[i].szComputerName = NULL;             g_stComputers[i].hRegistry = NULL;         }     }  }  2nd: GetApacheServicesStatus() shouldn't it read: ?!  \t} \t++computers; \tRegCloseKey(hKey); //!!! original position of                             //!!! RegCloseKey(hKey) causes a handle leak   }     FindRunningServices(); return TRUE;	Committed and backported for the next 2.0.62 and 2.2.7 releases.  Thanks for the patch!			Will Rowe
34209	null	CLOSED		David Arcuri	1112028600000	1123000494000		Segmentation fault in util_ldap_search_node_free Solaris 9, httpd 2.0.53, segfaults often resulting in gdb output similar to this: GNU gdb 6.0 Copyright 2003 Free Software Foundation, Inc. GDB is free software, covered by the GNU General Public License, and you are welcome to change it and/or distribute copies of it under certain conditions. Type 'show copying' to see the conditions. There is absolutely no warranty for GDB.  Type 'show warranty' for details. This GDB was configured as 'sparc-sun-solaris2.9'... Core was generated by "/usr/local/apache2/bin/httpd -f /usr/local/apache2/conf/web-mi.mgic.com.conf -k'. Program terminated with signal 11, Segmentation fault. Reading symbols from /usr/local/apache2/lib/libaprutil-0.so.0...done. Loaded symbols for /usr/local/apache2/lib/libaprutil-0.so.0 Reading symbols from /usr/local/lib/libldap-2.2.so.7...done. Loaded symbols for /usr/local/lib/libldap-2.2.so.7 Reading symbols from /usr/lib/libgen.so.1...done. Loaded symbols for /usr/lib/libgen.so.1 Reading symbols from /usr/local/ssl/lib/libssl.so.0.9.7...done. Loaded symbols for /usr/local/ssl/lib/libssl.so.0.9.7 Reading symbols from /usr/local/ssl/lib/libcrypto.so.0.9.7...done. Loaded symbols for /usr/local/ssl/lib/libcrypto.so.0.9.7 Reading symbols from /usr/local/lib/liblber-2.2.so.7...done. Loaded symbols for /usr/local/lib/liblber-2.2.so.7 Reading symbols from /usr/local/apache2/lib/libexpat.so.0...done. Loaded symbols for /usr/local/apache2/lib/libexpat.so.0 Reading symbols from /usr/local/apache2/lib/libapr-0.so.0...done. Loaded symbols for /usr/local/apache2/lib/libapr-0.so.0 Reading symbols from /usr/lib/libsendfile.so.1...done. Loaded symbols for /usr/lib/libsendfile.so.1 Reading symbols from /usr/lib/librt.so.1...done. Loaded symbols for /usr/lib/librt.so.1 Reading symbols from /usr/lib/libm.so.1...done. Loaded symbols for /usr/lib/libm.so.1 Reading symbols from /usr/lib/libsocket.so.1...done. Loaded symbols for /usr/lib/libsocket.so.1 Reading symbols from /usr/lib/libnsl.so.1...done. Loaded symbols for /usr/lib/libnsl.so.1 Reading symbols from /usr/lib/libresolv.so.2...done. Loaded symbols for /usr/lib/libresolv.so.2 Reading symbols from /usr/lib/libpthread.so.1...done. Loaded symbols for /usr/lib/libpthread.so.1 Reading symbols from /usr/lib/libdl.so.1...done. Loaded symbols for /usr/lib/libdl.so.1 Reading symbols from /usr/lib/libc.so.1...done. Loaded symbols for /usr/lib/libc.so.1 Reading symbols from /usr/local/lib/libgcc_s.so.1...done. Loaded symbols for /usr/local/lib/libgcc_s.so.1 Reading symbols from /usr/lib/libaio.so.1...done. Loaded symbols for /usr/lib/libaio.so.1 Reading symbols from /usr/lib/libmd5.so.1...done. Loaded symbols for /usr/lib/libmd5.so.1 Reading symbols from /usr/lib/libmp.so.2...done. Loaded symbols for /usr/lib/libmp.so.2 Reading symbols from /usr/platform/SUNW,Ultra-250/lib/libc_psr.so.1...done. Loaded symbols for /usr/platform/SUNW,Ultra-250/lib/libc_psr.so.1 Reading symbols from /usr/lib/libthread.so.1...done. Loaded symbols for /usr/lib/libthread.so.1 #0  util_ldap_search_node_free (cache=0xfecd0668, n=0x0) at util_ldap_cache.c:202 202     util_ldap_cache.c: No such file or directory.         in util_ldap_cache.c (gdb) bt #0  util_ldap_search_node_free (cache=0xfecd0668, n=0x0) at util_ldap_cache.c:202 #1  0x0002f7c8 in util_ald_destroy_cache (cache=0xfecd0668) at util_ldap_cache_mgr.c:344 #2  0x0002ea90 in util_ldap_url_node_free (cache=0xfecd0668, n=0xfecd63a0) at util_ldap_cache.c:77 (gdb)    Relevant section of code in util_ldap_cache.c  void util_ldap_search_node_free(util_ald_cache_t *cache, void *n) {     int i = 0;     util_search_node_t *node = (util_search_node_t *)n;     if (node->vals) {              /* CRASH HERE */         while (node->vals[i]) {             util_ald_free(cache, node->vals[i++]);         }         util_ald_free(cache, node->vals);     }     util_ald_free(cache, node->username);     util_ald_free(cache, node->dn);     util_ald_free(cache, node->bindpw);     util_ald_free(cache, node); }   And this was called from:  void util_ald_destroy_cache(util_ald_cache_t *cache) {     unsigned long i;     util_cache_node_t *p, *q;                                                                                                         if (cache == NULL)         return;                                                                                                         for (i = 0; i < cache->size; ++i) {         p = cache->nodes[i];         q = NULL;         while (p != NULL) {             q = p->next;            (*cache->free)(cache, p->payload);            util_ald_free(cache, p);            p = q;         }     }     util_ald_free(cache, cache->nodes);     util_ald_free(cache, cache); }   As you can see, p->payload is being passed as a NULL pointer to the free function, resulting in a segmentation fault.  I can add a NULL check to this code but is there something farther up the line causing this problem in the cache code?	 Further investigation reveals this condition is only reached when 'require group' directive is present:  <Directory '/mysitestuff'>     Options FollowSymLinks     AllowOverride All     AuthAuthoritative Off     AuthType Basic     AuthName 'my stuff'     AuthLDAPEnabled On     AuthLDAPURL 'ldap://ldapserver'     require group cn=blah,o=foo     Order allow,deny     Allow from all  Changing the 'require group' to 'require ldap-attribute foo=bar' does not produce the segmentation faults in the cache free or compare code.  I have backported only the 2.1 util_ldap_cache code dealing with this function, specifically the addition of numvals to the node struct and the logic to iterate based on this value.  Crashes still occur with this change.   More stack traces, crashing consistently in the same place now:    (gdb) where #0  util_ldap_search_node_compare (a=0x0, b=0xffbfd328) at util_ldap_cache.c:147 #1  0x0002f8bc in util_ald_cache_fetch (cache=0xfecd04a0, payload=0xffbfd328)     at util_ldap_cache_mgr.c:373 #2  0x0002d708 in util_ldap_cache_checkuserid (r=0x0, ldc=0xffbfd328, url=0xffbfd411 '&#65533;&#65533;t',     basedn=0xffbfd3f0 '(&(objectclass=*)(uid=test4806))', scope=916296, attrs=0xc9c00,     filter=0xff0d9ae4 '/237&#65533;/200', bindpw=0x1939c8 '/bliss_loan.cgi', binddn=0x0, retvals=0x3d)     at util_ldap.c:780 (gdb) quit   [emadea3@unixweb2 apache2]$ sudo pstack core core 'core' of 17258:   /tmp/httpd -f /usr/local/apache2/conf/qa.web-mi.mgic.com.conf -k start  0002ebc0 util_ldap_search_node_compare (0, ffbfd328, c9e9069, f0000000, ffbfd410, 0) + 4  0002f8b4 util_ald_cache_fetch (fecd04a0, ffbfd328, ffbfd411, ffbfd3f0, dfb48, c9c00) + 50  0002d700 util_ldap_cache_checkuserid (0, 13a758, 12ae48, 12ae90, 2, 0) + 98  00030784 mod_auth_ldap_check_user_id (0, ffffffff, 0, 99800, 99800, ffffdfe8) + 190  0008d128 ap_run_check_user_id (18efe0, 0, 1, 1905a0, 190528, 0) + 3c  0008da44 ap_process_request_internal (0, b5c00, 18efe0, 10, fecb0020, 1) + 210  0005c208 ap_process_request (18efe0, ce800, 4, 18efe0, ceb90, 0) + 9c  000576d8 ap_process_http_connection (186888, 1867b0, 1867b0, 4, ceb90, 138698) + f4  0008163c ap_run_process_connection (186888, 1867b0, 1867b0, 4, 1847e8, 18af98) + 3c  000746c0 child_main (184808, 1, cdc00, cf000, 18af98, 4e2e) + 3b0  00074814 make_child (73c00, 4, 3, 2, a, cdc00) + b4  00074a90 perform_idle_server_maintenance (da098, ce36c, ffbff8a0, da098, dfa28, 0) + 150  000750d4 ap_mpm_run (cdc00, cdc00, 0, ce800, cdc00, cdc00) + 594  0007adbc main     (da098, dfa28, ffbff9cc, cf094, cdc00, cdc00) + 610  0002bb2c _start   (0, 0, 0, 0, 0, 0) + 5c   There's some garbage in the arguments, stack getting corrupted?  This does not happen on every request -- I have a script running to continuously pump requests with random ID/password into the server from a pool of 5000 LDAP objects so I can fill the cache.  I can get generally 1 failure in every 100 requests until it starts purging the cache, then that number increases to approximately 1 in 10.  This is not acceptable for production website so I have eliminated the issue by using ldap-attribute instead of group for now.  I can see where there is the possibility of having a NULL payload in the cache  due to a node copy unable to succeed because of memory allocation issues, but  I am unable to duplicate this problem on either NetWare or SUSE Linux.  Adding  a NULL check in the node free routine couldn't hurt.    There are a couple of problems that I see with the example configuration.   First, are member and/or uniquemember attributes of the group object public?   If not then all of your accesses will probably fail anyway unless you  configure a username and password for util_ldap to use when accessing ldap.   Also, there isn't a base context defined in the ldap url.  Was this just a  typo?  Anyway, with or without the mis-configuration, I am still unable to  duplicate the problem.  yes, sorry, there's a base context in the 'real' LDAP URL ... Everything does work correctly -most- of the time.  The 2nd set of stack dumps (where it dumps in util_ldap_search_node_compare) is the most recent set of problems I am having.  I can replicate the intermittent crash (~ 1 out of 20) every time I use a 'require group cn=foo,o=bar' and it crashes every time in the same function (see above.)  And every time the stack trace via gdb seems to have corruption in the arguments to the util_ldap_cache_checkuserid function.  I have tested this with thousands of requests with random IDs from a pool, to stress both the cache filling and purging.  It seems to not exhibit crashy behavior until after the first purge.  If you'd like any additional information, I can replicate this easily, and would be happy to provide any other debugging information you need to examine this more fully.  Using prefork, by the way, if that matters.  (Was debugging with single thread, still got the crash.)   This is what happens when LDAPSharedCacheSize is too small and the out of memory condition is not handled well.  There's no error or anything returned by the calloc functions.  I suspect it's a problem in Solaris only, if no one can replicate this on any other OS.  From reading past bug reports it seems the shared memory code on Solaris is problematic at best, anyway.  Increasing LDAPSharedCacheSize to a reasonably high value that will not be exceeded during regular webserver activity has made this problem go away. I think this error condition should be handled. A Crash is not acceptable to me. This Problem is reproducible in Redhat AS 2.1.  It is a little bit difficult to determine 'a reasonably high value' of  LDAPSharedCacheSize. But I think the default value of  LDAPSharedCacheSize '100KB' is too small for the default of  LDAPCacheEntries '1024'.  Maybe it would be helpful if the default settings in the documentation didn't reflect a 200k cache size with 1024 entries?  I have mine set to 1024000 with 512 entries and 120 second timeouts and have just ran 40,000 test hits against the cache with no failures.   Created an attachment (id=15811) fix cache corruption with full cache  This patch fixes the cache corruption at full cache for me. Joe,  We have loaded tested with this patch applied and it appears to have fixed the cache corruption problem  for us as well. Good to hear, Ryan.  This has been committed to the trunk and submitted for backport to 2.0.x.  http://svn.apache.org/viewcvs?rev=225746&view=rev  Note that there is at least one other bug I know if in the current 2.0.x code which could cause cache corruption; the fact that the mutex protecting the shm segment is not initialized properly (see r105412).  I'll be proposing that for backport too. Committed for 2.0.55. *** Bug 35695 has been marked as a duplicate of this bug. ***			Brad Nicholes	David Arcuri	Joe Orton	Paul Querna	Ryan Morgan	Toshiya_Kobayashi
34266	null	RESOLVED		Cheenu	1112384460000	1113039668000		mod_proxy balancer omits query string ... I am trying to do a reverse proxy with load balancing across multiple backend  servers  My configuration is: <IfModule proxy_module> \tProxyRequests Off \t \t<Proxy balancer://mycluster> \t\tBalancerMember http://server1:8080 \t\tBalancerMember http://server2:9080 \t</Proxy> \t \t<Location /foo> \t\tProxyPass balancer://mycluster/foo \t</Location> </IfModule>     When I invoke proxy making a browser request to  http://main.server.com/foo/xservlet?abc=123 the query string does not appear in the request to the load balanced servers  (http://server1:8080 and http://server2:9080) I have not verified if http POST data is proxied correctly   There is a related bug http://issues.apache.org/bugzilla/show_bug.cgi?id=32459   Thanks Cheenu	Fixed in the HEAD. The reason was that only the true proxy requests pass the query string. Now we are setting this correctly by using parsed args if not present in r->uri.			Mladen Turk
34275	null	RESOLVED		Bostjan	1112479980000	1208418972000		ab very poor performance with both -k and -i cmdline options specified This works OK: ./ab -n 10000 -c 100 http://192.168.1.4:81/7kb.html  This works OK: ./ab -n 10000 -c 100 -k http://192.168.1.4:81/7kb.html  This works OK: ./ab -n 10000 -c 100 -i http://192.168.1.4:81/7kb.html  This DOES NOT work at all: ./ab -n 10000 -c 100 -k -i http://192.168.1.4:81/7kb.html  The output it produces is: apr_poll: The timeout specified has expired (70007)   regards, Bostjan	I failed to reproduce the issue. I have seen this issue in past regarding apr_timeout. But in my recent trials, I failed to reproduce the issue.  I tried to increase the concurrency to 1800 but still fails to reproduce the issuse. All of the below worked for me. ./bin/ab -n 550000 -c 2000 -k http://serverhost:1894/micro-benchmarks/snoop.jsp ./bin/ab -n 550000 -c 1500 -k http://serverhost:1894/micro-benchmarks/snoop.jsp ./bin/ab -n 550000 -c 2000 -k http://serverhost:1894/micro-benchmarks/snoop.jsp ./bin/ab -n 550000 -c 1800 -k http://serverhost:1894/micro-benchmarks/snoop.jsp ./bin/ab -n 550000 -c 1800 -k -i http://serverhost:1894/micro-benchmarks/snoop.jsp ./bin/ab -n 550000 -c 1800 -k -i http://serverhost:1894/index.html /usr/bin/ab -n 550000 -c 1800 -k -i http://serverhost:1894/index.html /usr/bin/ab -c 1800 -k -i http://serverhost:1894/index.html /usr/bin/ab -t 60 -c 1800 -k -i http://serverhost:1894/index.html /usr/bin/ab -t 60 -c 1000 -k -i http://serverhost:1894/index.html /usr/bin/ab -t 60 -c 1000 -k http://serverhost:1894/index.html  Recent build on 2.2.x branch: # ./bin/ab -V This is ApacheBench, Version 2.0.40-dev <$Revision: 1.146 $> apache-2.0 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Copyright 2006 The Apache Software Foundation, http://www.apache.org/  Fedora core 5 httpd # /usr/bin/ab -V This is ApacheBench, Version 2.0.40-dev <$Revision: 1.146 $> apache-2.0 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Copyright 1997-2005 The Apache Software Foundation, http://www.apache.org/   Bostjan, can you try with recent version of ab to confirm if it reproduces the issue?  Is server/client running on same box?  I successed to reproduce this bug with 2.2.6 (both server and ab). I'm not sure this is a issue of ab. Created an attachment (id=21402) against trunk  set c->length zero when HEAD Content-Length doesn't mean a response body size when a request method is HEAD. Thanks for the patch. Committed to trunk as r612954 (http://svn.apache.org/viewvc?rev=612954&view=rev). How about backporting? Benchmark of both HEAD and Keep Alive is not special. Proposed for backport as r631712 (http://svn.apache.org/viewvc?rev=631712&view=rev). Thanks for the reminder. backported to 2.2 <http://svn.apache.org/viewvc?rev=649115&view=rev>			Basant Kumar Kukreja	Ruediger Pluem	Takashi Sato
34452	null	CLOSED		Eirik Gjesteland	1113494520000	1114418834000		 in Internet Explorer Internet Explorer opens up to four http connections to the web server  (configured as reverse proxy). These are in ESTABLISHED state for the duration  of the keep-alive timeout period. Then they enter CLOSE_WAIT state, where they  stay for a few seconds. If the user tries to go to a new page AND 'friendly  http error messages' is enabled in Internet Explorer, the infamous 'The page  cannot be displayed' appears.  This has been reproduced with httpd 2.0.52 and 2.0.53 with OpenSSL 0.9.7b,  0.9.7d and 0.9.7g. We were not able to reproduce the bug in 2.0.40 or 2.0.47  (all config files were equal), which makes us believe some sort of bug or  incampability with Explorer is introduced some time after 2.0.47. One will have  to go via a proxy in order to reproduce it.  For performance reasons, it is not an option to disable keep-alive.  Disabling SSLv3 'fixes' the problem.	There have been a couple of reports like this recently.  Do you have a precise reproduction case with a specific version of MSIE, which only triggers in those particular httpd versions?  What's logged to the error log for the SSL vhost?  Anyway, the default SSL vhost configuration will disable keepalives for MSIE for the SSL vhost, using the SetEnvIf below; I take it you have disabled this?  SetEnvIf User-Agent '.*MSIE.*' /          nokeepalive ssl-unclean-shutdown /          downgrade-1.0 force-response-1.0  Please also include the full SSL configuration you're using, Created an attachment (id=14715) SSL configuration  For performance reasons (throughput was halfed without keep-alive) the default  SetEnvIf has been disabled. As 95% of our users use IE, it is not an option to  use this setting.  We tried to include just SetEnvIf User-Agent '.*MSIE.*' ssl-unclean-shutdown,  but it did not fix the problem.  We have also tried to run without mod_deflate, but that didn't help either.  My full IE version is 6.0.2800.1106.xpsp2_gdr.040517-1325CO with updates  Q323308, Q832894, Q837009 and Q867801. We have received error reports from  users with different versions, though.  The full SSL config file is now attached (virtual section included). Nothing is logged in the ssl logs on the server. In fact I don't think the  request reaches the server at all, as Explorer seems to try to use a connection  that is in CLOSE_WAIT state. One could argue that this seems like an Explorer  bug, but as we easily reproduce this problem in 2.0.52/53 and not in 40/47,  some unfortunate change seems to have been introduced after 47. OK, more things it would be useful to try:  1. MSIE can be sensitive to session caching; try switching to the SSLSessionCache shmcb:... line  2. it would be useful to narrow down where the regression occurs; particularly, if it works with 2.0.48 and fails with 2.0.49, that's useful; there was a significant change to the SSL connection closure handling there, but it shouldn't take effect if you have ssl-unclean-shutdown configured for *MSIE*.  3. get some useful logs; add to the SSL vhost config:  LogLevel debug ErrorLog logs/ssl_debug_log  and attach the resultant ssl_debug_log showing the reproduction of the failure (or better yet; a before-and-after with a version which works and one which doesn't) Created an attachment (id=14724) SSL debug log from 2.0.40 (no error)  Performed the following steps: 1. Navigated to https://10.110.64.26/ega/connectiontest/index.html (this page contains a lot of large images so that explorer sets up many connections 2. Waited until all connetions were in CLOSE_WAIT state (~30 secs) 3. Navigated to https://10.110.64.26/ega/  10.110.5.11 is the proxy server 10.110.64.26 is the reverse proxy server 10.110.64.6 is the web server Created an attachment (id=14725) SSL debug log from 2.0.52 (page cannot be displayed)  Performed the following steps: 1. Navigated to https://10.110.64.26/ega/connectiontest/index.html (this page contains a lot of large images so that explorer sets up many connections 2. Waited until all connetions were in CLOSE_WAIT state (~30 secs) 3. Navigated to https://10.110.64.26/ega/  10.110.5.11 is the proxy server 10.110.64.26 is the reverse proxy server 10.110.64.6 is the web server Created an attachment (id=14726) SSL debug log from 2.0.52 ssl2 (no error)  Performed the following steps: 1. Navigated to https://10.110.64.26/ega/connectiontest/index.html (this page contains a lot of large images so that explorer sets up many connections 2. Waited until all connetions were in CLOSE_WAIT state (~30 secs) 3. Navigated to https://10.110.64.26/ega/  10.110.5.11 is the proxy server 10.110.64.26 is the reverse proxy server 10.110.64.6 is the web server schmcb caching did not help.  I have uploaded some log files from 2.0.52 and 2.0.40.  If you still need more info I can try to narrow down where the problem occurs  in a few days. I have now verified that the error is reproducable in 2.0.49 but not in 2.0.48.   I looked at the code and it seems the problem is that ssl-unclean-shutdown is  ignored.  If you change the default: behaviour in the switch in ssl_filter_io_shutdown()  in ssl_engine_io.c to unclean the problem disappears.  I guess sslconn->shutdown_type should be set by ssl_configure_env in  ssl_engine_kernel.c, but it seems like this function is not run at all. I don't  know the httpd architecture well enough to find why not.  The reason it worked in 2.0.48 is that the block  else if (AP_BUCKET_IS_EOC(bucket)) {             /* The special 'EOC' bucket means a shutdown is needed;              * - turn off buffering in bio_filter_out_write              * - issue the SSL_shutdown              */             filter_ctx->nobuffer = 1;             status = ssl_filter_io_shutdown(filter_ctx, f->c, 0);             if (status != APR_SUCCESS) {                 ap_log_error(APLOG_MARK, APLOG_INFO, status, NULL,                              'SSL filter error shutting down I/O');             }             if ((status = ap_pass_brigade(f->next, bb)) != APR_SUCCESS) {                 return status;             }             break;         }  was inserted in ssl_io_filter_output in ssl_engine_io.c.  Does this make sense? That does make perfect sense, I was wondering whether that might be the issue.  But we now need to work out why the shutdown_type is not getting set; I'll try some tests here.  Thanks a lot! Ugh, yes.  ssl_configure_env is called from mod_ssl's ssl_hook_Translate, but that won't run if, e.g. mod_proxy's translate_name hook is run first and returns OK, as happens in the reverse-proxy case.  I have no idea why that section of mod_ssl code needs to be in a translate_name hook, it's probably historical.  If it can be moved somewhere more sensible this will work. Created an attachment (id=14750) proposed mod_ssl fix  Here's a patch which should fix this; it moves the ssl_configure_env call to the post_read_request hook, and runs said hook slightly later to ensure that it runs later than the mod_setenvif post_read_request hook (a quick hack for testing purposes, I'll do better when committing this).  Patch should apply against 2.0.5[34]-ish. Created an attachment (id=14804) equivalent patch for 2.0.x backport proposal  This patch is to be proposed for backport to 2.0.x and is essentially equivalent to the previous patch. Fixed on the trunk: http://svn.apache.org/viewcvs?view=rev&rev=161958 and proposed for backport to 2.0.x.  Thanks again for your help debugging this issue! Does anybody know whether or not this fix was incorporated in the 2.2 tree?     We recently upgraded from 2.0.48 to 2.2.0 and are now seeing a similiar issue  to what's reported here.   Let me know if you require additional information.   This patch is also contained in 2.2.0. *** Bug 20641 has been marked as a duplicate of this bug. ***			Davi Arnaut	Eirik Gjesteland	Joe Orton	Richard	Ruediger Pluem
34512	null	CLOSED		sean	1113878220000	1117773897000		comparison error file: proxy_ftp.c +90  static int ftp_check_globbingchars(const char *path) {     for ( ; *path; ++path) {         if (*path == '//')         ++path; /* BUG, should be *path */   !!!!  if (path != '/0' && strchr(FTP_GLOBBING_CHARS, *path) != NULL)             return TRUE;     }     return FALSE; }  should be if ( *path != '/0' ...	Fixed in r179704			Paul Querna
34520	null	CLOSED		Per Olausson	1113924600000	1120696030000		cope with OpenSSL 0.9.7g API changes Configure: ==========  CONFIGURE_OPTIONS=--prefix=$(DIR_PROD) --enable-ssl --with-ssl=$(OPENSSL_DIRECTORY)   /                   --enable-mods-shared=most --with-mpm=worker --without-berkeley-db   /                   --with-expat=$(DIR_SRC)/$(CURRENT_DISTRO)/srclib/apr-util/xml/expat /    Environment: ============  oslevel -r 5200-02  or  oslevel -r 4330-11  Both environments using Visual Age C/C++ at V6 with February 2005 PTFs applied (ie. fairly up-to-date ...). lslpp -L vac/*   Fileset                      Level  State  Type  Description (Uninstaller)   ----------------------------------------------------------------------------   vac.C                     6.0.0.11    A     F    C for AIX Compiler   vac.C.readme.ibm           6.0.0.1    A     F    C for AIX iFOR/LS Information   vac.Dt.common              6.0.0.0    C     F    C for AIX Desktop Integration                                                    Common Files   vac.Dt.help                6.0.0.0    C     F    C for AIX Help Desktop                                                    Integration   vac.html.DBCS.search       6.0.0.0    C     F    C for AIX Compiler                                                    Documentation Search Double                                                    Byte Common Files   vac.html.EN_US             6.0.0.0    C     F    C for AIX Compiler                                                    Documentation (HTML)--U.S.                                                    English UTF   vac.html.JA_JP             6.0.0.0    C     F    C for AIX Compiler                                                    Documentation (HTML)--Japanese                                                    UTF   vac.html.Ja_JP.C           6.0.0.0    C     F    C for AIX Compiler                                                    Documentation (HTML)--Japanese   vac.html.Ja_JP.search      6.0.0.0    C     F    C for AIX Compiler                                                    Documentation Search--Japanese   vac.html.SBCS.search       6.0.0.0    C     F    C for AIX Compiler                                                    Documentation Search Single                                                    Byte Common Files   vac.html.ZH_CN             6.0.0.0    C     F    C for AIX Compiler                                                    Documentation                                                    (HTML)--Simplified Chinese UTF   vac.html.common.search     6.0.0.0    C     F    C for AIX Compiler                                                    Documentation Search Common                                                    Files   vac.html.en_US.C           6.0.0.0    C     F    C for AIX Compiler                                                    Documentation (HTML)--U.S.                                                    English   vac.html.en_US.search      6.0.0.0    C     F    C for AIX Compiler                                                    Documentation Search--U.S.                                                    English   vac.html.ja_JP             6.0.0.0    C     F    C for AIX Compiler                                                    Documentation (HTML)--Japanese                                                    IBM-eucJP   vac.html.zh_CN.C           6.0.0.0    C     F    C for AIX Compiler                                                    Documentation                                                    (HTML)--Simplified Chinese   vac.html.zh_CN.search      6.0.0.0    C     F    C for AIX Compiler                                                    Documentation                                                    Search--Simplified Chinese   vac.lic                    6.0.0.0    C     F    C for AIX Licence Files   vac.msg.en_US.C            6.0.0.2    A     F    C for AIX Compiler Messages -                                                    en_US   vac.ndi                    6.0.0.7    A     F    C for AIX Non-Default                                                    Installation Script   vac.pdf.en_US.C            6.0.0.0    C     F    C for AIX Documentation                                                    (PDF)--U.S. English   vacpp.Dt.common            6.0.0.0    C     F    VisualAge C++ Desktop                                                    Integration Common Files   vacpp.Dt.help              6.0.0.0    C     F    VisualAge C++ Help Desktop                                                    Integration   vacpp.cmp.aix50.lib       6.0.0.10    A     F    VisualAge C++ Libraries for                                                    AIX 5.0   vacpp.cmp.aix50.tools      6.0.0.1    A     F    VisualAge C++ Tools for AIX                                                    5.0   vacpp.cmp.core            6.0.0.12    A     F    VisualAge C++ Compiler   vacpp.cmp.include         6.0.0.10    A     F    VisualAge C++ Compiler Include                                                    Files   vacpp.cmp.lib              6.0.0.0    C     F    VisualAge C++ Libraries   vacpp.cmp.rte              6.0.0.0    C     F    VisualAge C++ Compiler                                                    Application Runtime   vacpp.cmp.tools           6.0.0.10    A     F    VisualAge C++ Tools   vacpp.html.DBCS            6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--Double Byte Common                                                    Files   vacpp.html.EN_US           6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--U.S. English UTF   vacpp.html.JA_JP           6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--Japanese UTF   vacpp.html.Ja_JP           6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--Japanese   vacpp.html.SBCS            6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--Single Byte Common                                                    Files   vacpp.html.ZH_CN           6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--Simplified Chinese UTF   vacpp.html.common          6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--Common Files   vacpp.html.en_US           6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--U.S. English   vacpp.html.help            6.0.0.0    C     F    VisualAge C++ HTML Help Engine   vacpp.html.ja_JP           6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--Japanese IBM-eucJP   vacpp.html.zh_CN           6.0.0.0    C     F    VisualAge C++ Documentation                                                    (HTML)--Simplified Chinese   vacpp.lic                  6.0.0.0    C     F    VisualAge C++ Licence Files   vacpp.memdbg.aix50.lib     6.0.0.7    A     F    VA C++ User Heap/Memory Debug                                                    AIX 5.0 Libraries   vacpp.memdbg.aix50.rte    6.0.0.10    A     F    VA C++ User Heap/Memory Debug                                                    AIX 5.0 Runtime   vacpp.memdbg.lib           6.0.0.0    C     F    VisualAge C++ User Heap and                                                    Memory Debug Static Libraries   vacpp.memdbg.rte           6.0.0.0    C     F    VisualAge C++ User Heap and                                                    Memory Debug Runtime   vacpp.msg.en_US.cmp.core   6.0.0.7    A     F    VisualAge Compiler C++                                                    Messages--U.S. English   vacpp.msg.en_US.cmp.tools  6.0.0.0    C     F    VisualAge C++ Tools                                                    Messages--U.S. English   vacpp.msg.en_US.html.help  6.0.0.0    C     F    VisualAge C++ Help Engine                                                    Messages--U.S. English   vacpp.ndi                  6.0.0.7    A     F    VisualAge C++ Non-Default                                                    Installation Script   vacpp.pdf.Ja_JP            6.0.0.0    C     F    VisualAge C++ Documentation                                                    (PDF)--Japanese   vacpp.pdf.common           6.0.0.0    C     F    VisualAge C++ Documentation                                                    (PDF)--Common Files   vacpp.pdf.en_US            6.0.0.0    C     F    VisualAge C++ Documentation                                                    (PDF)--U.S. English   vacpp.pdf.zh_CN            6.0.0.0    C     F    VisualAge C++ Documentation                                                    (PDF)--Simplified Chinese   vacpp.samples.ansicl       6.0.0.6    A     F    ANSI CLass Library Samples  Cause: ======    Signature:    /vobs/openssl/prod/include/openssl/ssl2.h:    SSL_SESSION *d2i_SSL_SESSION(SSL_SESSION **a,const unsigned char * const *pp, \t\t\t     long length);    Code:      pSession = d2i_SSL_SESSION(NULL, &ptr, SSL_SESSION_MAX_DER);    Pre-processed:    unsigned char *ptr;   ...   pSession = d2i_SSL_SESSION(0, &ptr, 1024*10);                    CC=xlc_r  Bug: ====  gmake[4]: Entering directory "/vobs/apache/src/httpd-2.0.54/modules/ssl' /vobs/apache/src/httpd-2.0.54/srclib/apr/libtool --silent --mode=compile xlc_r  -g -qHALT=E    -U__STR__ -D_THREAD_SAFE -D_USE_IRS    -I/vobs/apache/src/httpd-2.0.54/srclib/apr/include -I/vobs/apache/src/httpd-2.0.54/srclib/apr-util/include -I/vobs/apache/src/httpd-2.0.54/srclib/apr-util/xml/expat/lib -I. -I/vobs/apache/src/httpd-2.0.54/os/unix -I/vobs/apache/src/httpd-2.0.54/server/mpm/worker -I/vobs/apache/src/httpd-2.0.54/modules/http -I/vobs/apache/src/httpd-2.0.54/modules/filters -I/vobs/apache/src/httpd-2.0.54/modules/proxy -I/vobs/apache/src/httpd-2.0.54/include -I/vobs/apache/src/httpd-2.0.54/modules/generators -I/vobs/openssl/prod/include/openssl -I/vobs/openssl/prod/include -I/vobs/apache/src/httpd-2.0.54/modules/dav/main -prefer-pic -c ssl_scache_shmcb.c && touch ssl_scache_shmcb.slo 'ssl_scache_shmcb.c', line 1248.46: 1506-280 (E) Function argument assignment between types 'const unsigned char* const*' and 'unsigned char**' is not allowed. 'ssl_scache_shmcb.c', line 1327.46: 1506-280 (E) Function argument assignment between types 'const unsigned char* const*' and 'unsigned char**' is not allowed. gmake[4]: *** [ssl_scache_shmcb.slo] Error 1 gmake[4]: Leaving directory "/vobs/apache/src/httpd-2.0.54/modules/ssl' gmake[3]: *** [shared-build-recursive] Error 1 gmake[3]: Leaving directory "/vobs/apache/src/httpd-2.0.54/modules/ssl' gmake[2]: *** [shared-build-recursive] Error 1 gmake[2]: Leaving directory "/vobs/apache/src/httpd-2.0.54/modules' gmake[1]: *** [shared-build-recursive] Error 1 gmake[1]: Leaving directory "/vobs/apache/src/httpd-2.0.54' gmake: *** [all-recursive] Error 1	Created an attachment (id=14755) libtool patch to enable different (hard-coded) deployment directory   This patch is not suitable for inclusion to apache, but just shows how/what differs from the vanilla source. We have one patch applied to libtool applied to enable us to use a dedicated build host which builds in one directory structure (/appl/cm/build/<env>/<component>/... while we deploy into an environment which expects things to reside under /appl/active/apache/... I never saw any other way of achieving this and as far as I can tell it has no bearing on this defect. The patch is listed below.  Otherwise there has been no other changes to the distro version and the configure options etc are the same as we use for a 2.0.51 build.     SSL_SESSION *d2i_SSL_SESSION(SSL_SESSION **a,const unsigned char * const *pp, \t\t\t     long length);  that's not from any OpenSSL release.  What SSL library are you using? We are using OpenSSL v0.9.7g. However this bug is in mod_ssl...  Is apache/modssl incompatible with 0.9.7g? Sorry, the signature comes from openssl/include/ssl.h...and I can't see that that has changed recently. Cripes, yes, they changed it between .7f and .7g! Very bad :( We'll have to fix this in mod_ssl with a bunch of ifdef fun, yes.  @@ -1268,17 +1268,18 @@  int    SSL_set_generate_session_id(SSL *, GEN_SESSION_CB);  int    SSL_has_matching_session_id(const SSL *ssl, const unsigned char *id,                                         unsigned int id_len); -SSL_SESSION *d2i_SSL_SESSION(SSL_SESSION **a,unsigned char **pp,long length); +SSL_SESSION *d2i_SSL_SESSION(SSL_SESSION **a,const unsigned char * const *pp, +                            long length);  Okay, so the story is that 0.9.7g isn't supported with current version of apache 2.0.54! If you edit build/config_vars.mk and remove the '-qHALT=E' from whichever CFLAGS line it ends up in, it should compile OK with warnings.   'Okay, so the story is that 0.9.7g isn't supported with current version     of apache 2.0.54!'  <rant> People quit your bitching!!!  If a library vendor screws with declarations in the midst of subversion bumps, you expect us to be psychic?!?  Someone should have mentioned this to the SSL project, but I suppose noone here bothers to test OpenSSL cvs HEAD. </rant>  In the coming 2.0/2.1-dev releases this is addressed.  It's now committed to cvs HEAD.  Thanks Joe for calling out the specific bump :) Ease up, Bill.  Per just made a semi-accurate statement of the current state of play, the fact that someone took the time to report the issue is appreciated.  Yes, the API break has been mentioned to openssl-dev, too.			Joe Orton	Per Olausson	Will Rowe
34542	null	RESOLVED		Pradeep Kumar S	1114015080000	1125353598000		echo $0 prints just the filename and not the whole path with mod_cgid When a script does an echo $0 with mod_cgid enabled then only the filename is  printed and the whole path is not printed which is not the case with mod_cgi.  By removing the following lines from cgid_handler() from mod_cgid.c the whole  path can be obtained. --------------------------      conf = ap_get_module_config(r->server->module_config, &cgid_module);     is_included = !strcmp(r->protocol, 'INCLUDED');  -    if ((argv0 = strrchr(r->filename, '/')) != NULL) -        argv0++; -    else -        argv0 = r->filename;      nph = !(strncmp(argv0, 'nph-', 4));  -    if ((argv0 = strrchr(r->filename, '/')) != NULL) -        argv0++; -    else         argv0 = r->filename;      if (!(ap_allow_options(r) & OPT_EXECCGI) && !is_scriptaliased(r))         return log_scripterror(r, conf, HTTP_FORBIDDEN, 0,                                'Options ExecCGI is off in this directory');     if (nph && is_included)         return log_scripterror(r, conf, HTTP_FORBIDDEN, 0,                                'attempt to include NPH CGI script');  ------------------- The first 4 lines are reduntant as the same 4 statements are repeated after a  harmless strncmp function call. The 3 lines removed ensure that argv0 is not  stripped of the path.   I have looked at the places where argv0 is later used and if it requires only  the path name or just the filename is sufficient but haven't found any. Just  wanted to know if there is any dependency. I have got apache to build and run  and with the fix the whole path is displayed. Haven't found any dependency till  now. Just wanted to confirm.	But that would break nph-scripts, wouldn't it? (In reply to comment #1) > But that would break nph-scripts, wouldn't it? I have just removed the second 3 lines leaving the first 4 lines intact. I have  tested that with nph scripts. It works. This ensures that nph scripts get just  the filename and the others get the whole path.  So the code is  --------------- conf = ap_get_module_config(r->server->module_config, &cgid_module);     is_included = !strcmp(r->protocol, 'INCLUDED');      if ((argv0 = strrchr(r->filename, '/')) != NULL)         argv0++;     else         argv0 = r->filename;      nph = !(strncmp(argv0, 'nph-', 4));  -    if ((argv0 = strrchr(r->filename, '/')) != NULL) -        argv0++; -    else         argv0 = r->filename;      if (!(ap_allow_options(r) & OPT_EXECCGI) && !is_scriptaliased(r))         return log_scripterror(r, conf, HTTP_FORBIDDEN, 0,                                'Options ExecCGI is off in this directory');     if (nph && is_included)         return log_scripterror(r, conf, HTTP_FORBIDDEN, 0,                                'attempt to include NPH CGI script');  ------------------------------------------------     Yes, this behavior was broken between mod_cgi and mod_cgid, because the   developer hadn't noted that we -tested- argv0 in mod_cgi, but then passed   argv[0] for the creation call, and therefore assumed the short name was   the argv[0] argument.    Fixed in SVN trunk, and proposed for backport.    			Andr?? Malo	Pradeep Kumar S	Will Rowe
34588	null	CLOSED		David Leonard	1114237200000	1114708828000		mod_userdir.c: wrong size alloc for suexec Small typo in mod_userdir.c:164327. Potentially wrong-size storage allocated.    ap_unix_identity_t *ugid = NULL;   ...   ugid = apr_palloc(r->pool, sizeof(ap_unix_identity_t *))	Good catch!  Thanks for the report.  http://svn.apache.org/viewcvs?rev=165151&view=rev Merged for 2.0.55.  http://svn.apache.org/viewcvs.cgi?rev=189561&view=rev			Joe Orton
34618	null	RESOLVED		Vincent MATHIEU	1114516320000	1124363108000		 2.2.21 Since I upgraded httpd from 2.0.53 to 2.0.54, I have frequently segmentation faults (redhat 7.3).  My httpd execute libphp4.so.  If I run this little script php, I generate the problem systematically : for($i=0;$i<1000;$i++){    $l = ldap_connect('ldap.univ.fr'); }   (ldap.univ.fr doesn't exists).  If I compile httpd-2.0.54 with util_ldap.c from httpd-2.0.53 version, the problem  disappear	*** Bug 34620 has been marked as a duplicate of this bug. *** Brad Nicholes requested that someone test this patch:  http://svn.apache.org/viewcvs/httpd/httpd/trunk/modules/ldap/util_ldap.c?rev=164919&r1=164918&r2=164919&view=diff (In reply to comment #2) > Brad Nicholes requested that someone test this patch: >  > http://svn.apache.org/viewcvs/httpd/httpd/trunk/modules/ldap/util_ldap.c?rev=164919&r1=164918&r2=164919&view=diff  I try to execute this patch (with 2.0.54 util_ldap.c). I have an error during patch executing :  File to patch: util_ldap.c patching file util_ldap.c Hunk #1 FAILED at 247. Hunk #2 succeeded at 321 (offset -9 lines). Hunk #3 FAILED at 1784. Hunk #4 FAILED at 1917. 3 out of 4 hunks FAILED -- saving rejects to file util_ldap.c.rej  Brad, can you provide a patch which applies to 2.0.x which mod_ldap users can test? Created an attachment (id=14873) switch to connection timout per ldap connection  Test the ldap connection timeout on a per connection basis rather than global (In reply to comment #5) > Created an attachment (id=14873) [edit]  Good! I compiled apache2.0.54 with your patch. I do not have any more segmentation faults  Thank's Created backport proposal in the STATUS file.  Just waiting for the three +1  votes. *** Bug 34705 has been marked as a duplicate of this bug. *** I installed the patch and compiled it, and at first it seemed to work. But I do some tests, works, and then if some time passes from the last test and I make a new one, the apache process hangs.  I think that the ldap connection pool has some issues with the connection timeouts and that makes the apache process to be unresponsive, The patch has been backported to 2.0.55-dev i tried the patch with apache 2.0.54 and recompiled. I still getseg faults in the error log  [Tue Jul 12 11:57:52 2005] [notice] child pid 24029 exit signal Aborted (6) [Tue Jul 12 11:57:54 2005] [notice] child pid 23956 exit signal Segmentation fault (11)  any ideas I tried the patch on a LDAP enabled apache-2.0.54 on SuSE Enterprise Linux 9  but get more segmentation faults afterwards. This apache was compiled against  the builtin openldap 2.2.6 in SLES9.  After installation of openldap-2.2.27 and recompilation of apache against this  version the segmentation faults are gone.  This seems to be related to the following patch in openldap 2.2.20  http://www.openldap.org/its/index.cgi/Software%20Bugs? id=3487;expression=TIMEOUT;casesensitive=1;usearchives=1;statetype=-1  We also applied the patch to 2.0.54 and the segmentation fault errors appeared  again, although less frequent. I see there was a bug fixed in openldap, we use  mod_ldap and auth_ldap, should we be using openldap? Yes, you need to update OpenLDAP  (In reply to comment #13) > We also applied the patch to 2.0.54 and the segmentation fault errors  appeared  > again, although less frequent. I see there was a bug fixed in openldap, we  use  > mod_ldap and auth_ldap, should we be using openldap?   We are having the same problem with Microsoft Active Directory Service (Windows  2000), we don't use OpenLDAP.  We did the patch on 2.0.54 but didn't help. So we're looking for a Windows 2000  bug now?  Is this bug closed because it works with OpenLDAP server? Can anyone else test  on Windows 2000?   (In reply to comment #14) > Yes, you need to update OpenLDAP > (In reply to comment #13) > > We also applied the patch to 2.0.54 and the segmentation fault errors  > appeared  > > again, although less frequent. I see there was a bug fixed in openldap, we  > use  > > mod_ldap and auth_ldap, should we be using openldap?   Broughan, this bug concerns a specific issue with OpenLDAP introduced in 2.0.54 which is now fixed for 2.0.55.  Bug 18334 seems to be a generic 'problems with Microsoft LDAP SDK' bug.			Brad Nicholes	Broughan	Joe Orton	Joshua	Justo Alonso	Markus Schuh	Vincent MATHIEU
34834	null	CLOSED		Timo Viipuri	1115720460000	1116962778000		t accept a trailing backslash in an input string The problem is that it is not possible to enter a string ending with a backslash+quoation mark as an input to function server/util.c:ap_getword_conf() (which is used to parse lines in httpd.conf). For example:  string ''c://temp//'' SHOULD be parsed as 'c://temp//' but CURRENTLY it is parsed as 'c://temp//''  The example shows that the function interprets the last quotation mark as forced (instead of as the end of the string) because of the preceding backslash. I think this behaviour would be OK if there were only one backslash at the end of the string but in the case of two backslashes the last quotation mark should NOT be forced to remain in the function result string.	Created an attachment (id=14981) Patch to modify server/util.c:ap_getword_conf() to accept a trailing backslash  Commited to trunk in revision 178209.  Thanks for writing the patch!			Paul Querna	Timo Viipuri
35081	null	CLOSED		Marc Stern	1117099260000	1117811714000		buffer overrun in ssl_callback_SSLVerify_CRL( ) (ssl_engine_kernel.c) I found a buffer overrun in ssl_callback_SSLVerify_CRL( ) - ssl_engine_kernel.c:   char buff[512]; /* should be plenty */ [...] n = BIO_read(bio, buff, sizeof(buff)); buff[n] = '/0';   If there are more than 512 bytes, n=512, thus we write in buff[512]. We should use     n = BIO_read(bio, buff, sizeof(buff) - 1);  This could lead to a system crash.	Thanks, Mark.  Committed to the trunk and proposed for backport. http://svn.apache.org/viewcvs?rev=179781&view=rev  Please note that bugs which you think may have security implications should be reported in the first place to security@apache.org address. Merged for 2.0.55.  http://svn.apache.org/viewcvs?rev=189562&view=rev			Joe Orton
35178	null	RESOLVED		Mindaugas Jackunas	1117701060000	1117773671000		 tag in documentation In the last paragraph there are lines:  <Files ~ '^/.ht'>  Order allow,deny  Deny from all  <Files>   the last line should be </Files> (closed tag)	Fixed in trunk.			Paul Querna
35211	null	RESOLVED		Paul Querna	1117830960000	1118716799000		RFE: Better support for Vary Headers in mod_cache Currently, mod_cache is RFC compliant in its handling of Vary headers, but it behaves in a less than optimal manner.  If a reply contains the vary header, it is noted.  If the varied headers match in both the stored version and the client request, the cache is used. If the varied headers are missing or do not match, the cached copy is not used.  When the cached copy is not used, a new version is fetched from the backend, and replaces the previously cached copy, that contained different values for the Varied headers.  This effectively kills the cache hit rate when using the Vary header, since anytime a header does vary the cached copy is destroyed.  The enhancement would be storing one copy of the page, for every Varied header value/combination.  One possible solution is to include the Varied headers in the Cache Hash.  This would give each combination of varied headers, values and URLs their own unique hash, and would enable the current mod_disk_cache and mod_mem_cache to operate with little or no changes.  The problem is that we do not know if a URL should be varied, until after we have already determined the Cache Hash.  If this route is taken, some method to change the cache hash at a later time might be needed.  Another possible solution, that would require changes to both mod_mem_cache, mod_disk_cache, and htcacheclean, would be to make some knid of 'index' node.  This node would contain a list of all known combinations for each varied header, and the location of the cached version of each.	Fixed in trunk.  Went with modifiying the .headers file format to include a new 'Vary Headers' format.			Paul Querna
35279	null	RESOLVED		Jean Dagenais	1118283000000	1118424115000		Reception of [RST,ACK] from IE cause Apache/OpenSSL to send subsequent SLL traffic as 4 TCP IP Segments instead of a minimum of one. We found out that starting with apache version 2.0.49, the behavior of Apache  (2.0.49 up to 2.0.54 )running with mod_ssl and OPenSSL/0.9.7g is changed after  the reception of a [RST, ACK] packet from Internet Explorer 6.0.  This problem does not happen with 2.0.47 and 2.0.48.  The impact is an increase packets transmitted and communication delays when  this behavior starts.   1. Expected Behavior. Apache/OPenSSL use as a Proxy to WebLogic  When we start Apache, and request a page (IE 6.0) using this kind of URL:  https://mvperf1/jmsproxy/1KBytesR.jsp, we can see that the response is  returned as a single SSL packet as shown here.  No.     Time        Source                Destination           Protocol Info       19 0.091816    70.81.65.10           198.252.177.204       SSLv3     Application Data       20 0.000218    198.252.177.204       198.252.177.27        HTTP      GET /jmsproxy/jmsproxy.do? event=update&userid=Int1user2&count=20&ackIdList=&lastMsgCount=0&latency=113.60 7810087752 HTTP/1.1       21 0.001157    198.252.177.27        198.252.177.204       HTTP      HTTP/1.1 200 OK       22 0.000012    198.252.177.204       198.252.177.27        TCP      43341  > 7002 [ACK] Seq=564 Ack=255 Win=16800 Len=0 TSV=478522705 TSER=171779478       23 0.000004    198.252.177.27        198.252.177.204       HTTP      Continuation or non-HTTP traffic       24 0.000005    198.252.177.204       198.252.177.27        TCP      43341  > 7002 [ACK] Seq=564 Ack=315 Win=16800 Len=0 TSV=478522705 TSER=171779478          25 0.000575    198.252.177.204       70.81.65.10           SSLv3     Application Data, Application Data, Application Data, Application Data   Data returned as 1 packet (4 SSL section in this packet)       26 0.111146    70.81.65.10           198.252.177.204       TCP      62101  > https [ACK] Seq=450 Ack=353 Win=64272 Len=0   If there is no operation witht he IE Browser for 60 seconds, it will send a  [RST, ACK] packet to Apache. After a few of these reset, then the next set of  communication (after the normal SSL handshake) will cause Apache/OPenSLL to  send the SSL information as 4 independant packets.  The problem is relatively easy to reproduce with 1 or 2 IE browsers.   No.     Time        Source                Destination           Protocol Info       19 0.091816    70.81.65.10           198.252.177.204       SSLv3     Application Data       20 0.000218    198.252.177.204       198.252.177.27        HTTP      GET /jmsproxy/jmsproxy.do? event=update&userid=Int1user2&count=20&ackIdList=&lastMsgCount=0&latency=113.60 7810087752 HTTP/1.1       21 0.001157    198.252.177.27        198.252.177.204       HTTP      HTTP/1.1 200 OK       22 0.000012    198.252.177.204       198.252.177.27        TCP      43341  > 7002 [ACK] Seq=564 Ack=255 Win=16800 Len=0 TSV=478522705 TSER=171779478       23 0.000004    198.252.177.27        198.252.177.204       HTTP      Continuation or non-HTTP traffic       24 0.000005    198.252.177.204       198.252.177.27        TCP      43341  > 7002 [ACK] Seq=564 Ack=315 Win=16800 Len=0 TSV=478522705 TSER=171779478          25 0.000575    198.252.177.204       70.81.65.10           SSLv3     Application Data       26 0.000021    198.252.177.204       70.81.65.10           SSLv3     Application Data       27 0.000039    198.252.177.204       70.81.65.10           SSLv3     Application Data       28 0.111146    70.81.65.10           198.252.177.204       TCP      62101  > https [ACK] Seq=450 Ack=353 Win=64272 Len=0       29 0.000021    198.252.177.204       70.81.65.10           SSLv3     Application Data       30 0.108034    70.81.65.10           198.252.177.204       TCP      62101  > https [ACK] Seq=450 Ack=455 Win=64170 Len=0	Created an attachment (id=15345) possible fix  Thanks for the detailed report and analysis.  Can you try this patch? This looks obviously correct, so, committed to trunk; http://svn.apache.org/viewcvs?rev=189971&view=rev and proposed for backport for 2.0.x.  Thanks again for the report and analysis. We have tested the fix and confirm that the problem is resolved. 			Jean Dagenais	Joe Orton
35292	null	RESOLVED		Gonzalo Paniagua Javier	1118338800000	1127686605000		ap_lingering_close does not linger up to MAX_SECS_TO_LINGER ap_lingering_close is supposed to read any leftover data in the connection until there's no more data or until MAX_SEC_TO_LINGER (30) seconds elapsed.  But turns out that it only performs up to 15 reads of (at most) 512 bytes.	Created an attachment (id=15353) Patch that fixes the problem.  This patch fixes the issue and 2 warnings I got with -Wall on apr_shutdown and apr_recv not being declared. apr_shutdown should be part of apr_compat.h.  The submitted patch is against the 2.0.x branch, not trunk. This was mentioned on http-wg a while ago, indeed.  Does the current behaviour actually cause practical problems?  The change introduces an extra gettimeofday() call into the normal processing of every request so it needs good justification. I found this out because I was sending a POST of a few MB to a web service, but I got the url wrong and saw that there were 15 small reads when closing before i got the RST when trying to read from the socket. OK, there are a few alternatives here:  - take the hit on the uncommon path where the read() doesn't get EOF first time through, and keep calling read()/apr_time_now() until 30 seconds have *really* passed  pro: equally as safe as 1.3 code con: more overhead  - bump the tmp buffer size to 8K and lower the read() timeout to 1 second.  this way the server could eat 30*8K=245K bytes without additional overhead, giving a significantly better chance of getting the response to the client than just 15*512=~7K  pro: little more overhead than current 2.0 code con: still less safe than 1.3 If there's anything I can say, I'd go for the first alternative and linger for at most ~32s, while not incurring in any additional penalty for the common path. The reason that such code isn't in there now is to avoid all the syscalls (retrieving the time).  Some cleverness may allow an implementation that is willing to wait longer (close to MAX_SECS_TO_LINGER) without retrieving the time so much. Created an attachment (id=15375) Second attempt. Patch against http-2.0.x  How about this? There are no calls to time() involved. The first read polls for up to 30s and subsequent ones only for 0.5s, with a limit on the maximum number of reads that doubles the maximum read length existing now. Oops. Forgot to increment nread_ops in the loop. I don't see how that implementation actually fixes the problem.  Or am I missing something fundamental?  The *problem* is that the server is not reading enough bytes from the socket to eat up the TCP window and prevent an RST from allowing the client to see the response.  Just changing the timeouts makes no difference, the solution needs to actually increase the number of read() calls made (and/or increase the buffer size passed to read).  In the situation which lingering close is helping, the first read call is *not* going to time out; the TCP receive buffer for this socket on the server will already be non-empty so it will necessarily return data immediately.  Changing that first timeout just introduces a new problem; if the client disappears completely after reading the response, the server will now hang around for thirty seconds waiting for a FIN that will never arrive, rather than just for two seconds.  Fixed on trunk and back-ported for 2.1.8 and later.  http://svn.apache.org/viewcvs?rev=291452&view=rev *** Bug 17722 has been marked as a duplicate of this bug. ***			Gonzalo Paniagua Javier	Jeff Trawick	Joe Orton	Paul Querna
35330	null	RESOLVED		kabe	1118535180000	1127492986000		[PATCH] AllowOverride Options does not allow Options in .htaccess When allowing Options in <Directory>, and setting Options in the .htaccess, server complains that Options isn't allowed.  This bug seems to be around since the AllowOverrideOpt patch BugID#29310: http://issues.apache.org/bugzilla/show_bug.cgi?id=29310  Following patch fixes the problem, but AllowOverride concerns security; through audit around handling of opts->override, opts->override_opts is requested.  ==== Example:   httpd.conf: <Directory /usr/local/www> \tAllowOverride All </Directory>  /usr/local/www/.htaccess: Options +ExecCGI  error_log output: [Sun Jun 12 03:38:23 2005] [alert] [client ::1] /usr/local/www/.htaccess: Option ExecCGI not allowed here   ==== PATCH: diff -aru httpd-2.1.3-beta.orig/server/request.c httpd-2.1.3-beta/server/request.c --- httpd-2.1.3-beta.orig/server/request.c\tFri Feb 11 21:00:41 2005 +++ httpd-2.1.3-beta/server/request.c\tSun Jun 12 06:10:35 2005 @@ -443,10 +443,26 @@          opts->remove = this_dir->opts_remove;      }   +#if 0      if (!(this_dir->override & OR_UNSET)) {          opts->override = this_dir->override;      }      if (!(this_dir->override_opts & OR_UNSET)) { +/* this is wrong; + * 1) ->override_opts will take OPT_* masks, not OR_* + * 2) Resetting current ->override_opts (effective AllowOverride Options=....) + *    should occur when AllowOveride (both w or w/o Options) was specified  + *    for this dir. + *    Not saying Options in AllowOverride shouldn't mean to  + *    preserve and propagate the Options= setting. + * Because of this, '<Directory>AllowOverride All' still says + * Options in .htaccess not allowed. + */ +        opts->override_opts = this_dir->override_opts; +    } +#endif +    if (!(this_dir->override & OR_UNSET)) { +        opts->override = this_dir->override;          opts->override_opts = this_dir->override_opts;      }  }	*** Bug 35329 has been marked as a duplicate of this bug. *** We now have a 'regression' severity in Bugzilla. Removed the keyword.  Thanks a lot for the patch (attaching it might have avoided the line-wrapping ;). This has been applied for 2.1.8.  http://svn.apache.org/viewcvs?rev=291125&view=rev			Joe Orton	Sander Temme	kabe
35343	null	RESOLVED		eddie	1118683440000	1198338126000		[PatchAvailable] Add MSI logging to ResolveServerName in Real_Features.dll There are a number of bugs and issues where people are trying to install  apache on windows and they get an 'Installation Interupted' error message, for  some reason ResolveServerName has failed calling gethostbyname.   ResolveServerName exits and there is no indication of why it fails.  I have added logging of WSAGetLastError when gethostbyname fails (I also added  it for WSAStartup for good measure) so when users try to install using the MSI  and it fails, by enabling msi logging they will at least have an indication of  why it failed, instead of just that it failed.      Index: real_features.c =================================================================== --- real_features.c     (revision 190008) +++ real_features.c     (working copy) @@ -65,6 +65,45 @@   #define MAXHOSTNAMELEN 255  +#define MAXSTRINGLEN 2048 + + +UINT __stdcall LogMsiError( MSIHANDLE hInstall, char* szFunction,int   dwError ) +{ + + +       char szBuf[MAXSTRINGLEN]; +    LPVOID lpMsgBuf; +       MSIHANDLE hRecord; + + +    FormatMessage( +        FORMAT_MESSAGE_ALLOCATE_BUFFER | +        FORMAT_MESSAGE_FROM_SYSTEM, +        NULL, +        dwError, +        MAKELANGID(LANG_NEUTRAL, SUBLANG_DEFAULT), +        (LPTSTR) &lpMsgBuf, +        0, NULL ); + +    wsprintf(szBuf, +        '%s failed with error: %s', +        szFunction, lpMsgBuf); + + +    LocalFree(lpMsgBuf); + + + +       hRecord = MsiCreateRecord( 1 ); +       MsiRecordSetString( hRecord, 0, szBuf ); +       MsiProcessMessage(hInstall,INSTALLMESSAGE_INFO,hRecord); +    MsiCloseHandle(hRecord); + +       return ERROR_SUCCESS; + +} +  UINT __declspec(dllexport) __stdcall ResolveServerName(MSIHANDLE hInstall)  {      char str[MAXHOSTNAMELEN + 7]; /* Allow for admin@ */ @@ -72,23 +111,27 @@      struct hostent *p;      WSADATA ver;      int x, y; - +      if (WSAStartup(MAKEWORD(2, 0), &ver)) {          MsiSetPropertyA(hInstall, 'RESOLVED_WINSOCK2', '0'); +               LogMsiError( hInstall, 'Real_Features_Dll:ResolveServerName  WSAStartup', WSAGetLastError() );          return ERROR_SUCCESS;      }       if (ver.wVersion < 2) {          WSACleanup();          MsiSetPropertyA(hInstall, 'RESOLVED_WINSOCK2', '0'); -        return ERROR_SUCCESS; +               return ERROR_SUCCESS;      }       MsiSetPropertyA(hInstall, 'RESOLVED_WINSOCK2', '1');  +      if ((gethostname(str, MAXHOSTNAMELEN) != 0)) { -        WSACleanup(); -        return ERROR_SUCCESS; +       //We failed to get the hostname so log the actual winsock error +               LogMsiError( hInstall, 'Real_Features_Dll:ResolveServerName  gethostname', WSAGetLastError() ); +               WSACleanup(); +               return ERROR_SUCCESS;      }       if (strchr(str, '.'))	Fantastic suggestion, thank you!  Adopted a similar patch for the  next 2.0.62/2.2.7 releases, along with quite a bit of additional vetting of the results, resolution of a possible segfault, and also caught the possibility of winsock2 linkages not working.			Will Rowe
35469	null	CLOSED		Nick Grynkewich	1119463140000	1123250676000		fails to decrypt PKCS#8 keyfile This might be related to Bug# 34520 I was able to build Apache 2.0.54 with mod_ssl on Solais 9 using OpenSSL 0.9.7g. HTTPD will start with any clear text key created using:  openssl genrsa -out clr.rsa 1024  or openssl pkcs8 -nocrypt -topk8 -in clr.rsa -out clr.pkcs8  Also starts fine, prompting for pass phrase, if key was created with:  openssl rsa -in clr.rsa -des -out enc.rsa  However, it will not accept the pass phrase for any key created using:  openssl pkcs8 -v1 PBE-MD5-DES -in clr.rsa -topk8 -out enc.des.v1.pkcs8  or openssl pkcs8 -v2 des -in clr.rsa -topk8 -out enc.des.v2.pkcs8  or openssl pkcs8 -v2 des3 -in clr.rsa -topk8 -out enc.des3.v2.pkcs8  All of the created keys are readable and results identical when the command:  openssl rsa -in <keyfile> -noout -text  is issued against them.  One of the core OpenSSL developers suggests that:  'They may be missing some calls to add the PBE algorithms. This is automatic if you call OpenSSL_add_all_algorithms() but needs to be handled if algorithms are being added manually.'  Additional information: mod_jk and mpm_worker are also built-in. When started with a clear text key or a encrypted key in the 'old' format, the server runs flawlessly.	Created an attachment (id=15793) possible fix  Looks like the right solution.\tCan you try this patch? Apologies for the delay; I was unable to install your patch, per se. However, I made this change:  $ diff -u modules/ssl/ssl_engine_init.orig modules/ssl/ssl_engine_init.c    --- modules/ssl/ssl_engine_init.orig    Fri Jul 29 12:17:39 2005 +++ modules/ssl/ssl_engine_init.c       Fri Jul 29 12:17:56 2005 @@ -83,6 +83,7 @@        SSL_load_error_strings();      SSL_library_init(); +    OpenSSL_add_all_algorithms();  }    /*  And that fixes the problem. So, assuming that my inability to apply the patch is strictly user error (most likely case). Then I would consider this resolved. OK thanks, applied on the trunk. 			Joe Orton	Nick Grynkewich
35550	null	RESOLVED		Bj	1120076220000	1188213262000		mime.types entry for .es extension The current mime.types configuration file does not have an entry for the .es  file extension. It should be associated with the IESG-approved media type  application/ecmascript (see https://datatracker.ietf.org/public/pidtracker.cgi? command=view_id&dTag=7686 for details).	Added .ecma to trunk in rev 570206.  The .es extension is already used by languages (Spanish). 			Roy T. Fielding
36090	null	RESOLVED		Chris Darroch	1123557420000	1134133220000		CGI Status: header triggers recursive ErrorDocument handling If a CGI script outputs a Status: header with a value other than 200, and then generates malformed headers, the message that is returned to the client includes the bogus statement that 'Additionally, a 500 Internal Server Error error was encountered while trying to use an ErrorDocument to handle the request' even if no ErrorDocument directives are present in the server configuration files.  For example, with no ErrorDocuments defined, the following Perl CGI script:  #!/usr/bin/perl print 'Status: 404/n'; print 'FOO/n/n';  produces this HTML output:  Internal Server Error The server encountered an internal error or misconfiguration and was unable to complete your request. ... Additionally, a 500 Internal Server Error error was encountered while trying to use an ErrorDocument to handle the request.  This bug occurs with both Apache 1.3 and 2.x (it was tested using 1.3.33 and 2.1.6-alpha).  The source of the problem appears to be in ap_process_request() in modules/http/http_request.c.  I will follow up this bug report with a proposed patch which addresses the issue described below.  The ap_process_request() function is used by the main 'process_connection' hook functions in modules/http/http_core.c.  The ap_process_request() function calls ap_invoke_handler(), which calls ap_run_handler(), which invokes the correct 'handler' hook function for a given request.  In the case of a request that maps to a CGI script, this is either cgi_handler() or cgid_handler() in modules/generators/mod_cgi.c or mod_cgid.c, respectively.  Those 'handler' hook functions both use ap_scan_script_header_err_brigade() to parse the HTTP headers output by a CGI script.  That function is a wrapper around ap_scan_script_header_err_core() in server/util_script.c, which does the actual parsing.  If ap_scan_script_header_err_core() sees a valid Status: header line in the script's output, it sets r->status accordingly.  However, it may then encounter an error, for example, if it finds a malformed HTTP header.  In the case of the sample CGI script shown above, the 'FOO' header line causes cgi_handler() or cgid_handler() to receive back an HTTP_INTERNAL_SERVER_ERROR return code from ap_scan_script_header_err_brigade().  They pass that back through their local log_script() function (in mod_cgi.c or mod_cgid.c) to ap_run_handler(), which passes it back through ap_invoke_handler() to ap_process_request().  When ap_process_request() does not receive OK or DONE fro ap_invoke_handler() it calls ap_die(), also in modules/http/http_request.c. The ap_die() function is called from various places, mostly in the modules/http/* and modules/proxy/* code, in order to terminate the current request.  It determines whether an ErrorDocument directive exists for a given error code; if one does and it maps to a local URL (beginning with a leading / character), then it performs an internal redirection using ap_internal_redirect() in the same file. If the sub-request that is generated causes another error, then ap_die() will be called recursively.  When this occurs, ap_internal_redirect() needs to back out of the situation, use the default error message for the original error code, and amend it with a note about the secondary error code from the internal redirection.  To do this, it examines r->status for a value other than HTTP_OK; if another value is found, then ap_die() assumes that it has been called from within a failing internal redirection for an ErrorDocument directive with a local URL.  It then recovers the initial request data, prevents any handling of customized error messages with ErrorDocument directives, and calls ap_send_error_response() in modules/http/http_protocol.c with its recursive_error parameter set. This function is responsible for sending back the appropriate error message to the client, along with the additional information about the recursive_error parameter.  The problem described in this bug report occurs because if r->status has been set to a value other than HTTP_OK by ap_scan_script_header_err_core() -- or any other function invoked during request handling -- then ap_die() treats that as a signal that a recursive error is in progress, although this is not true.  The proposed patch amends the ap_process_request() function by resetting r->status to HTTP_OK just before calling ap_die().  No changes are made to ap_internal_redirect() or ap_internal_redirect_handler() in the same modules/http/http_request.c file, although they have similar blocks of code.  This is because these functions are used in various places to perform internal redirections, copying most of the original request's data, including its r->status value.  This includes ap_die() itself, which uses ap_internal_redirect() to handle local URLs in ErrorDocument directives.  The assumption is therefore made that any caller of these two internal redirection functions knows that the r->status value of the initial request has an appropriate value (i.e., HTTP_OK) before invoking them. If this is not true, then other similar bugs may exist elsewhere in the code; however, a quick scan suggests that some users of these functions do this.  For example, asis_handler() in modules/generators/mod_asis.c resets r->status to HTTP_OK before calling ap_internal_redirect_handler().  The mod_cgi and mod_cgid modules seem to perform explicit checks for r->status == HTTP_OK before using these functions.  The modules/arch/win32/mod_isapi.c file along with mod_rewrite.c, mod_actions.c, and mod_negotiation.c in modules/mappers might all be examined to determine if r->status could be a value other than HTTP_OK prior to their use of these functions, since if these functions detect an error and call ap_die(), then ap_die() will think it is handling a recursive error, as is the case with this particular bug.	Created an attachment (id=15973) suggested patch to ap_process_request()  Created an attachment (id=17122) for 2.2.0  updated for 2.2.0 Fixed for 2.2.1 in Revision 355454. 			Chris Darroch	Nick Kew
36166	null	RESOLVED		Ryan Schmidt	1123874820000	1125086102000		' The documentation of the Redirect and RedirectMatch directives [1] reads, in part, like this:  Syntax:\tRedirect [status] URL-path URL  URL-path must be a fully qualified URL, not a relative path, even when used with .htaccess files or  inside of <Directory> sections.  I believe this should read 'URL must be a fully qualified URL' since URL-path is certainly supposed to be  a path, and not fully-qualified, and none of the examples show URL-path to be fully-qualified. This  error appears in the 1.3, 2.0, and 2.1 documentation pages.  [1] http://httpd.apache.org/docs/2.1/mod/mod_alias.html#redirectmatch	It does actually refer to the URL-Path, although the term 'fully qualified' is probably misleading.  It means that the path must start with a slash, and cannot be relative to the directory containing the .htaccess file. Ah, I see... And what of 'URL'? Must it be a full URL with protocol, or can it be a 'fully-qualified URL' (i.e.  starting with a slash)? Could it be a relative URL? The examples only show full URLs with protocol, but the  documentation does not seem to specify whether other forms are also permissible. It is best practice to use a full URL starting with a scheme, although I believe that recent versions will also take a URL-path and tag on the current server name.  But you are right that this all should be clarified.  Something along the lines <usage> <p>The Redirect directive maps an old URL into a new one by asking the client to refetch the resource at the new location.</p>  <p>The old <em>URL-path</em> is a (%-decoded) path beginning with a slash.  A relative path is not allowed.  The new <em>URL</em> should be an absolute URL beginning with a scheme, but a URL-path beginning with a slash may also be used, in which case the scheme and hostname of the current server will be added.</p>  <p>Then any request beginning with <em>URL-Path</em> will return a redirect request to the client at the location of the target <em>URL</em>.  Additional path information beyond the matched <em>URL-Path</em> will be appended to the target URL.</p>  ... Fixed in 2.1.			Joshua Slive	Ryan Schmidt
36410	null	RESOLVED		Fabian Fagerholm	1125343680000	1125409058000		Problem with cgid when module other than mod_suexec is providing uid/gid When trying mod_vhost_ldap (http://alioth.debian.org/projects/modvhostldap/) I discovered that cgid segfaults when trying to run a simple cgi script. This is documented in the Debian BTS (http://bugs.debian.org) as bug #323785 (http://bugs.debian.org/323785).  The issue was discussed in the #apache channel on IRC, and it was concluded that the reason for the segfault is that cgid is unable to access the memory region where mod_vhost_ldap keeps its module_config structure -- or any other module_config structure for that matter. For suExec, there is special magic in mod_cgid that allows its configuration to be passed through the unix socket so that cgid can use it. However, adding such special cases for every module that needs them is not really a good way to solve the problem.  So a more generic way of letting mod_cgid access is needed. When discussing the issue on IRC, colmmacc suggested that there is a more correct way implemented in os/unix/unixd.c.	Not quite on the unixd.c, but there is a more correct way of doing this within cgid, working on it now. This bug has been fixed in trunk, see;  http://svn.apache.org/viewcvs?rev=264759&view=rev A patch for the 2.2.x branch is now available at;  http://people.apache.org/~colm/2.2.x-suexec-cgid.patch Apologies, I meant the 2.0.x branch;  http://people.apache.org/~colm/2.0.x-suexec-cgid.patch			Colm MacCarthaigh
36438	null	RESOLVED		St	1125489900000	1125583597000		Problem with CRL file loading in mod_ssl When you use 'SSLCARevocationFile' directive to launch a Certificate Revocation  List, if the CRL file is not in PEM format (DER for example), no warning or  error message is written in logs file, so that you don't detect that something  goes wrong... In this case, when a revoked client certificate is submitted to  Apache during SSL negociation, the verification doesn't work well (e.g. nothing  happen !). I think that it's a major problem because this bug concerns security aspects of  Apache. I detetected this situation on Apache 2.0.50 with openssl 0.9.7-8 Sincerely,	Thanks for the report.  This is fixed on the trunk:  http://svn.apache.org/viewcvs.cgi?rev=265702&view=rev			Joe Orton
36506	null	RESOLVED		Matthijs Kooijman	1125941880000	1185885280000		' Documentation for mod_rewrite lists the following line for 'RewriteEngine': 'Note that, by default, rewrite configurations are not inherited. This means that you need to have a RewriteEngine on directive for each virtual host in which you wish to use it.' This ('by default') implies that the 'RewriteEngine' can be made inheritable.  Furthermore, the documentation lists the following for 'RewriteOptions': 'inherit     This forces the current configuration to inherit the configuration of the parent. In per-virtual-server context this means that the maps, conditions and rules of the main server are inherited. In per-directory context this means that conditions and rules of the parent directory's .htaccess configuration are inherited.'  This says that the 'configuration' is inherited, which seems to mean only a 'RewriteOptions inherit' is needed in each vhost to inherit all settings.  In practice, you also need a 'RewriteEngine On' for each vhost. This should be mentioned somewhere.  Additionally one could wonder if a 'RewriteEngine On' would be neccesary at all in each vhost, but that is beside the point here :-)	Several years later... Thanks, I've improved the documentation on this point by adding a separate section discussing it.			Joshua Slive
36507	null	RESOLVED		Christoph Bachhuber-Haller	1125942060000	1128640485000		mod_proxy_balancer does not handle sticky sessions with tomcat correctly Apache Tomcat uses JSESSIONID values like 95C5BB2B084DB06938BF798FCF3B3994.tomcat2 for sticky sessions. 'tomcat2' is the route set in jvmRoute in the Engine element in server.xml.   I expected that mod_proxy_balancer would match its path argument against the part after the . from JSESSIONID, but it tries to match against the whole cookie and fails obviousely. (in httpd-2.1.6-alpha/modules/proxy/mod_proxy_balancer.c, find_route_worker function)  That way, balancer is useless as a replacement for mod_jk load balancing with sticky sessions.	Created an attachment (id=16546) Patch against trunk  I can confirm this problem. The attached patch should fix this. Can you please give it a try? Hi Ruediger,  (In reply to comment #1) > Created an attachment (id=16546) [edit] > Patch against trunk >  > I can confirm this problem. > The attached patch should fix this. Can you please give it a try?  I can confirm that this patch fixes my problem. Thank you very much! I wonder though whether the tomcat session id format is any standard or if apache should support sticky sessions for load balancing in a more generic way.   Bye, Christoph Committed to trunk (r295013) http://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/modules/proxy/mod_proxy_balancer.c?rev=295013&r1=279973&r2=295013 Committed and backported to 2.2.x branch (r306888). > though whether the tomcat session id format is any standard or if apache should > support sticky sessions for load balancing in a more generic way.   It does. As you can choose the name of the cookie you can make any application where you can set a cookie work with that. Just set cookie BLAH=a.route in your application. Of course it is more convenient if the application container is able to do this (like Tomcat). BTW: I know no standard for coding such routing information inside a cookie. But if you know one I would be interested to get it known.			Christoph Bachhuber-Haller	R??diger Pl??m	Ruediger Pluem
36563	null	RESOLVED		Ondrej Sury	1126216080000	1127492867000		mod_ldap caching breaks when value is NULL I am author of mod_vhost_ldap (second module based on mod_ldap :-) and I found some rather nasty bug in mod_ldap caching.  There is error in caching, when any attribute returned from LDAP is null, then mod_ldap caches only attributes fetched before this null attribute.  Example from logs: (first run) [Thu Sep 08 21:30:13 2005] [debug] mod_vhost_ldap.c(383): [client 172.16.21.2] [mod_vhost_ldap.c]: dn: apacheServerName=000001.tld,ou=VHosts,ou=web,dc=active24,dc=com [Thu Sep 08 21:30:13 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheServerName: 000001.tld [Thu Sep 08 21:30:13 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheServerAdmin: (null) [Thu Sep 08 21:30:13 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheDocumentRoot: /var/www/00/10/04/000001.tld/www/ [Thu Sep 08 21:30:13 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheScriptAlias: /var/www/00/10/04/000001.tld/cgi-bin [Thu Sep 08 21:30:13 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheSuexecUid: 1004 [Thu Sep 08 21:30:13 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheSuexecGid: 1004  (second run -> results from cache) [Thu Sep 08 21:30:18 2005] [debug] mod_vhost_ldap.c(383): [client 172.16.21.2] [mod_vhost_ldap.c]: dn: apacheServerName=000001.tld,ou=VHosts,ou=web,dc=active24,dc=com [Thu Sep 08 21:30:18 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheServerName: 000001.tld [Thu Sep 08 21:30:18 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheServerAdmin: (null) [Thu Sep 08 21:30:18 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheDocumentRoot: (null) [Thu Sep 08 21:30:18 2005] [debug] mod_vhost_ldap.c(395): [client 172.16.21.2] [mod_vhost_ldap.c]: processing apacheScriptAlias: (null) [Thu Sep 08 21:30:19 2005] [notice] child pid 3379 exit signal Segmentation fault (11)  Quick workaround is to move attributes which can be NULL to end or to define _all_ attributes in LDAP.  Corect way is to fix this bug in mod_ldap.  Since structure is returned ok on first run I think that there is a way how to fix it.  I will look on this when I have some time.  Ondrej. P.S.: Tested on 2.0.53, but I have checked 2.0.54 ChangeLog and diffs and it includes only addition of LDAPConnectionTimeout.	  This has been fixed in Apache 2.1 rev. 156587 but never backported to Apache  2.0.  *** This bug has been marked as a duplicate of 33901 *** Will you accept backported patch if I prepare it?  Ondrej   Sure.  It will have to be proposed for backport, reviewed and accepted by a  vote before it actually makes it into the code.  But it can certainly be done. Created an attachment (id=16429) Backported patch to fix invalid cache content handling  Hi, I have created backport of fix for correct cache items handling if they include NULL values, thus reopening bug and changing severity to wishlist.  Ondrej. P.S.: If this is not correct way how to propose backport then bang me :-) Proposed for backport to 2.0.  Waiting for votes. Changing severity to Major, since this bug is not as harmless as I thought to be. There is memory leak in util_ldap_search_node_free().  Only items before first item with NULL value are freed, and rest of items are left in cache. Backported to 2.0.55			Brad Nicholes	Ondrej Sury
36883	null	RESOLVED		Noel J. Bergman	1128153120000	1128727063000		mod_proxy_ajp and tomcat issues I don't know whether this is on the mod_proxy_ajp side or the tomcat side,  so ...  host: \tlinux (CentOS, aka RHEL, 4 with all current updates) browser:\tfirefox 1.0.7 httpd:\t2.1.7, built from source tomcat:\t5.0.28, binary distribution  append to /etc/hosts: \t127.0.0.1\tlocalhost tomcat  append to httpd.conf:   <VirtualHost *>  ServerName tomcat  #ProxyPass        / ajp://localhost:8009/  ProxyPass        / http://localhost:8080/  #ProxyPassReverse / ajp://localhost:8009/  ProxyPassReverse / http://localhost:8080/  </VirtualHost>  No other changes from a default installation of the two servers.  The first problem is that if you simply browse to http://tomcat and click on  admin, it works with HTTP, but not with AJP.  To illustrate, let's compare the  differences with wget:  AJP:  $ wget http://tomcat/admin  --01:06:56--  http://tomcat/admin             => "admin'  Resolving tomcat... 127.0.0.1  Connecting to tomcat|127.0.0.1|:80... connected.  HTTP request sent, awaiting response... 302 Moved Temporarily  Location: https://tomcat/admin/ [following]  --01:06:56--  https://tomcat/admin/             => "index.html'  Connecting to tomcat|127.0.0.1|:443... failed: Connection refused.  Resolving tomcat... 127.0.0.1  Connecting to tomcat|127.0.0.1|:443... failed: Connection refused.  HTTP:  $ wget http://tomcat/admin  --01:09:20--  http://tomcat/admin             => "admin'  Resolving tomcat... 127.0.0.1  Connecting to tomcat|127.0.0.1|:80... connected.  HTTP request sent, awaiting response... 302 Moved Temporarily  Location: http://tomcat/admin/ [following]  --01:09:20--  http://tomcat/admin/             => "index.html'  Connecting to tomcat|127.0.0.1|:80... connected.  HTTP request sent, awaiting response... 200 OK  Length: 2,622 (2.6K) [text/html]    100%[====================================>] 2,622         --.--K/s    01:09:20 (53.20 MB/s) - "index.html' saved [2622/2622]  Note that the 302 redirects from HTTP to HTTPS in the AJP case, but not in the  HTTP case.  OK, so let's bypass the 302 and go directly to http://tomcat/admin/.  The  initial GET works with either protocol, e.g., with AJP:   # wget http://tomcat/admin/  --01:10:06--  http://tomcat/admin/             => "index.html.1'  Resolving tomcat... 127.0.0.1  Connecting to tomcat|127.0.0.1|:80... connected.  HTTP request sent, awaiting response... 200 OK  Length: 2,615 (2.6K) [text/html    100%[====================================>] 2,615         --.--K/s    01:10:06 (95.92 MB/s) - "index.html.1' saved [2615/2615]  However, the resources referenced on the page are only fetched when using  HTTP, not AJP.  The difference is readily apparent.  The images, stylesheets,  etc., are served up with HTTP, but not with AJP.	If you bring up the same stock configurations described above, you can also  reproduce the redirect to HTTPS problem by accessing http://tomcat/tomcat-docs. I can reproduce the problem with 5.5.12 (and httpd 2.0.8) as well, so since  from the lack of response no one in tomcat-dev appears to care about problems  with 5.0.x, I'm modifying the record to show that it effects the current  development branch, too. (In reply to comment #2) > ... httpd 2.0.8 ...  Er, make that 2.1.8, i.e., the latest available code. (In reply to comment #2) > I can reproduce the problem with 5.5.12 (and httpd 2.0.8) as well, so since  > from the lack of response no one in tomcat-dev appears to care about  problems  > with 5.0.x, I'm modifying the record to show that it effects the current  > development branch, too.  It seems that the problem is that mod_proxy_ajp isn't playing nice with  mod_ssl (so that this is really a Httpd bug).  Even when the connection isn't  HTTPS, mod_proxy_ajp is sending (empty) SSL attributes like cipher, client- cert, session-id.  This causes Tomcat to believe that the request was recieved  on HTTPS, so it redirects accordingly.  Below is a dump of the Request message  that Tomcat recieves from Httpd:  FINE: 12 34 00 6b 02 02 00 08 48 54 54 50 2f 31 2e 31  | .4.k....HTTP/1.1 FINE: 00 00 0c 2f 74 6f 6d 63 61 74 2d 64 6f 63 73 00  | .../tomcat-docs. FINE: 00 09 31 32 37 2e 30 2e 30 2e 31 00 ff ff 00 07  | ..127.0.0.1.??.. FINE: 68 6f 75 73 74 6f 6e 00 22 b8 00 00 02 a0 0b 00  | houston.'?...?.. FINE: 0c 68 6f 75 73 74 6f 6e 3a 38 38 38 38 00 00 0c  | .houston:8888... FINE: 4d 61 78 2d 46 6f 72 77 61 72 64 73 00 00 02 31  | Max-Forwards...1 FINE: 30 00 07 00 00 00 08 00 00 00 09 00 00 00 ff     | 0.............?  Now that William Barker has assessed the defect locale, try reassigning to  Apache httpd-2.0 product. Created an attachment (id=16617) Patch against trunk  Thanks to all for the analysis data. The attached patch against trunk should fix this. Can you please give it a try and give feedback. Created an attachment (id=16619) Patch against Tomcat 5.5.9  After doing some further tests and further analysis I must revert my earlier assumption that this is a httpd bug. It rather seems that org.apache.ajp.RequestHandler does not honour the isSSL bit inside an ajp message correctly. Attached is a patch against Tomcat 5.5.9 that should fix this. Hi,  I must dissagree with you. The bug has nothing to do with Tomcat. Tomcat works pretty well with mod_jk w or w/o SSL.  The error is obviously in mod_proxy_ajp. Mladen is insisting that the problem is with mod_proxy_ajp, so he'll veto the patch. Unfortunately, he's quite busy right now, so more comments later.  It also seems to me that it is a mod_proxy_ajp bug if it sends bogus HTTPS related headers if this isn't actually using HTTPS. (In reply to comment #7) > Created an attachment (id=16619) [edit] > Patch against Tomcat 5.5.9 > After doing some further tests and further analysis I must revert my earlier > assumption that this is a httpd bug. It rather seems that > org.apache.ajp.RequestHandler does not honour the isSSL bit inside an ajp > message correctly. Attached is a patch against Tomcat 5.5.9 that should fix > this.  The first patch of mod_proxy_ajp is sub-optimal, but will work.  It would be  better if mod_proxy_ajp honored the is_ssl flag and didn't bother to check the  SSL attributes unless it was set.  Your patch of Tomcat isn't even worth vetoing, since the patched class doesn't  exist in 5.5.x, and is deprecated in 4.1.x.  Play watch the bouncing bug ;-). Created an attachment (id=16620) Fix for mod_proxy_ajp's SSL attributes  This fixes mod_proxy_ajp handling of SSL attributes.  Not only does it stop it from sending garbage to Tomcat, but it doesn't even bother with the lookup unless the request came in on SSL.  And, as a bonus feature, it even gets the key-size working again.  Someday, mod_proxy_ajp may be almost as good as mod_jk ;-). Apart from a few minor style issues the patch looks good to me. Thanks. It removes the problem I saw with my first version of the patch which did not fix it correctly. What still worries me a little bit is the comment above the key_size block, which says 'added support only in ajp14 mode'. Maybe I am just misreading this comment, but could someone of the AJP gurus confirm that this attribute is also valid in AJP13? (In reply to comment #13) > misreading this comment, but could someone of the AJP gurus confirm that this > attribute is also valid in AJP13?  All current release versions of Tomcat support it, and any older ones will  ignore an attribute that they don't recognize.     Committed a style adjusted variant to trunk (r307195) http://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/modules/proxy/ajp_header.c?rev=307195&r1=232247&r2=307195  and to 2.2.x branch (r307196) http://svn.apache.org/viewcvs.cgi/httpd/httpd/branches/2.2.x/modules/proxy/ajp_header.c?rev=307196&r1=234103&r2=307196  (In reply to comment #8) > Hi, >  > I must dissagree with you. > The bug has nothing to do with Tomcat. > Tomcat works pretty well with mod_jk w or w/o SSL. >  > The error is obviously in mod_proxy_ajp.  Agreed, but I am not sure if the AJP connector on Tomcat side should set isSSL to true once it finds some of the SSL variables in the AJP message. From my point of view it should also ignore all SSL variables in the message if isSSL is set to false in the message.			Mladen Turk	Noel J. Bergman	Remy Maucherat	Ruediger Pluem	william.barker@wilshire.com
36906	null	RESOLVED		Heiko Jansen	1128419760000	1130274934000		balancer seems to rewrite the URL before it is proxied Given this config   <Proxy balancer://mycluster>     BalancerMember 'http://10.1.2.10:4321/Test' retry=10 loadfactor=1     BalancerMember 'http://10.1.2.11:4321/Test' retry=10 loadfactor=1   </Proxy>   ProxyPass /Test balancer://mycluster lbmethod=byrequests on host mybalancer.local.org With /Test on the internal servers (_not_ Apache) being a stub wich is a case sensitive starting point for requests (either POST or GET with QUERY_STRING) on an special application.  When trying to access http://mybalancer.local.org/Test the internal servers are balanced/proxied but the request arriving at them has been rewritten to '/test/'!!	Created an attachment (id=16777) Patch against trunk  Could you please give the attached patch a try? It should fix your problem. Nope, only partially: The case of the leading 'T' is no longer changed to lower case, but the trailing slash is still appended. The internal application does not handle that. It expects to see '/Test', not '/Test/'. This problem is caused by a configuration flaw on your side. Please use the following configuration instead:  <Proxy balancer://mycluster>     BalancerMember 'http://10.1.2.10:4321' retry=10 loadfactor=1     BalancerMember 'http://10.1.2.11:4321' retry=10 loadfactor=1 </Proxy> ProxyPass /Test balancer://mycluster/Test lbmethod=byrequests That does not seem sensible to me - and it also does not work. Using your config my backend servers see only '/' as URL.  And if you were right I believe I could not do sth. like this - which would be a major drawback in my eyes:  <Proxy balancer://mycluster>     BalancerMember 'http://10.1.2.10:4321/Test1' retry=10 loadfactor=1     BalancerMember 'http://10.1.2.11:4321/Path/to/Test2' retry=10 loadfactor=1 </Proxy> ProxyPass /MyTest balancer://mycluster/Test lbmethod=byrequests  Correct me if I??m wrong... Have to correct myself: the config you proposed _does_ work. Should??ve been more accurate when testing it....  The second part of my comment, however, still applies: if things work like you say one cannot have different paths on the backend servers. Sometimes this would come in very handy.  On the other hand: if things work like you say, the majority of cases should be covered.  Perhaps the docs could be enhanced to better describe the way the configuration works. Adding the path to the BalancerMember parameter seemed quite natural to me since the port to be used on the respective backend is given there - so why not the path also?!  Anyway: thanks for your effort and thanks for mod_proxy_balancer: it is a powerfull enrichment for the httpd!  Ok, you got me :-). Of course your second comment is completely valid and it does not seem to be logical why your configuration does not work, but mine does. So I try to explain what happens:  The right side of a ProxyPass side will be normalized. Your configuration contains the URL balancer://mycluster. This gets normalized to balancer://mycluster/ which is correct, as the URL should consist of <scheme>://<host><uri>. If uri is empty it is assumed to be '/'. On the other hand when creating the final proxy URL from a balancer member the approach is:  <balancer member><uri of right side of ProxyPass><path after left side of ProxyPass in request>  In your case this means e.g.  http://10.1.2.11:4321/Test (balancer member) + '/' (uri of right side of ProxyPass) + '' (path after left side of ProxyPass in request) = http://10.1.2.11:4321/Test/.  In general this approach is fine and correct. But it makes the following configurations impossible in cases where Test1 and Test2 cannot handle the trailing /:    <Proxy balancer://mycluster>     BalancerMember 'http://10.1.2.10:4321/Test1' retry=10 loadfactor=1     BalancerMember 'http://10.1.2.11:4321/Test2' retry=10 loadfactor=1   </Proxy>   ProxyPass /Test balancer://mycluster lbmethod=byrequests  But after a first glance to the code make this work and keep all other cases working seem to get complicated. So I will  - Mark this bug as fixed close (as your problem is fixed with the patch and the adjusted configuration) - Try to get the patch in 2.1.9 - Keep this in mind and have a look when I have time. I will update this PR once I find a solution for this. Committed to trunk (r328463): http://svn.apache.org/viewcvs?rev=328463&view=rev  Committed to 2.2.x branch (r328465): http://svn.apache.org/viewcvs?rev=328465&view=rev			Heiko Jansen	Ruediger Pluem
36917	null	RESOLVED		Mike McCartney	1128464340000	1185251302000		[DOC] mod_dumpio requires LogLevel debug I am playing around with mod_dumpio.  I think it's a great idea and I hope it sticks.  One thing I would like to see added to the documentation is a note stating that mod_dumpio sends its output to the ErrorLog using LogLevel debug. If you have configured your server for LogLevel warn (the default), then DumpIOInput On and DumpIOOutput On will have no effect.  After discovering this, it makes sense but it's not intuitive from the documentation (or by the name of the directives) that this is how it works.  thanks, mike	Does this ring true?  A quick scan over mod_dumpio.c seems to say yes.  If so, I'll hack mod_dumpio.xml a bit. Fixed in 2.0, 2.2 & trunk.  http://svn.apache.org/viewvc?view=rev&rev=559006 http://svn.apache.org/viewvc?view=rev&rev=559008 http://svn.apache.org/viewvc?view=rev&rev=559009  Thanks.			Jason Lingohr	Vincent Bray
36951	null	RESOLVED		Rocky Seelbach	1128616140000	1128639912000		Proxy httpd runs away with cpu on broken CONNECT client I don't think this is a dupe of 29744.    Apache 2.1.8 (also checked 2.1.7 and 2.1.6, same prob) Occurs on UnixWare 7.1.3 MP2, unable to demonstrate on Linux.  I realize most folks don't have a UnixWare box to abuse.  I'd like to help  isolate this.  Please let me know what I can do.    Using Apache as a caching-proxy.  When the browser attempts to make a secure  CONNECT through the proxy, and the browser side of the connection terminates  ungracefully, the related httpd processes run away with the processor.    Configuration: CC=cc CFLAGS='-KPIC,thread' ./configure / --prefix=/usr/local/apache2 / --enable-cache / --enable-disk-cache / --enable-proxy / --enable-proxy-connect / --enable-proxy-http / --disable-ipv6 / --disable-autoindex / --disable-userdir / --with-mpm=prefork  I've tried to build with the worker MPM, no joy.  Output from make and  httpd.conf available as;  http://citiperk.net/make_out.txt http://citiperk.net/make_err.txt http://citiperk.net/httpd.conf.txt  This problem came up while we were adding people to the proxy for the first  time, trying to see how it would perform with more than just me.  It worked  fine, but I would occasionally find a runaway process after a day or two of it  being up.    I can now reliably reproduce the problem by requesting a secure page and  closing the browser before the page can complete. I am not able to break it by  requesting non-secure pages.   With the processes spun up I looked at netstat.  There appeared to be three  connections from the proxy to the content still open.  Proto Recv-Q Send-Q  Local Address   Foreign Address        (state) tcp        0      0  proxy.51767     content.443   ESTABLISHED tcp        0      0  proxy.51766     content.443   ESTABLISHED tcp        0      0  proxy.51765     content.443   ESTABLISHED  These close after a few minutes, but the runaway httpd processes are still  consuming all the available cpu time.  With the Apache log running at debug  level the only relevant entries indicates a CONNECT has been established  [Wed Oct 05 03:05:20 2005] [debug] proxy_util.c(1428): proxy: CONNECT: fam 2  socket created to connect to content.company.net [Wed Oct 05 03:05:20 2005] [debug] mod_proxy_connect.c(231): proxy: CONNECT:  Returning 200 OK Status [Wed Oct 05 03:05:20 2005] [debug] mod_proxy_connect.c(252): proxy: CONNECT:  setting up poll()  Running 'truss -f -n -rall -mall -tall -p <runaway pid>' shows similar for each  runaway, and they each stream to the screen as fast as the window will paint.  28750:  poll(0x081C8820, 2, -1)         = 1  Would appreciate any ideas on how to help debug.	I guess http://httpd.apache.org/dev/debugging.html#gdb could be useful for you to further debug the problem. It would be nice to have stacktrace of the runaway process to get an idea what goes wrong. I wonder if this is it?  Streams-based TCP surfacing EOF situation in different manner?  Index: modules/proxy/mod_proxy_connect.c =================================================================== --- modules/proxy/mod_proxy_connect.c   (revision 292899) +++ modules/proxy/mod_proxy_connect.c   (working copy) @@ -358,6 +358,7 @@                          break;                  }                  else if ((pollevent & APR_POLLERR) || (pollevent & APR_POLLHUP)) +                    rv = APR_EOF;                      break;              }              else  The break in that scenario just gets us out of the loop for checking events which were notified.  It doesn't get us out of the while (1).  There are other paths to consider in that loop as well.  This was just a quick theory. UnixWare debug stack trace follows.  I'm currently stepping through and  printing the stack.  If I get it to loop I'll put the whole trace up.  New program httpd (process p1) grabbed Created 1 thread(s) for process p1 HALTED p1.1 [_poll]         0xbffc3b3c (_poll+12:)          jb     0x1 <bffc3b3f> Error: Could not grab /usr/local/apache2/bin/httpd debug> stack Stack Trace for p1.1, Program httpd *[0] _poll(0x81bdac8, 0x2, 0xffffffff)  [0xbffc3b3c]  [1] apr_pollset_poll(0x81bdab0, 0xffffffff, 0xffffffff, 0x8045558, 0x804555c)   [0xbfc7a4a9]  [2] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@284]  [3] proxy_run_scheme_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyhost=NULL, proxyport=0)      [mod_proxy.c@1928]  [4] proxy_handler(r=0x81bc498) [mod_proxy.c@725]  [5] ap_run_handler(r=0x81bc498)        [config.c@158]  [6] ap_invoke_handler(r=0x81bc498)     [config.c@371]  [7] ap_process_request(r=0x81bc498)    [http_request.c@258]  [8] ap_process_http_connection(c=0x81b6538)    [http_core.c@172]  [9] ap_run_process_connection(c=0x81b6538)     [connection.c@43]  [10] ap_process_connection(c=0x81b6538, csd=0x81b6480) [connection.c@178]  [11] child_main(child_num_arg=5)       [prefork.c@640]  [12] make_child(s=0x80f3120, slot=5)   [prefork.c@736]  [13] perform_idle_server_maintenance(p=0x80ed3c0)      [prefork.c@871]  [14] ap_mpm_run(_pconf=0x80ed3c0, plog=0x81334d8, s=0x80f3120) [prefork.c@1075]  [15] main(argc=3, argv=0x804790c, 0x804791c)   [main.c@710]  [16] _start()  [0x8053650]  Here's the loop.   [2] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@284]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@294]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@295]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@297]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@331]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@332]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@333]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@360]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@361]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@366]  *[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8,  url='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@284]  Thanks for the data. It is very helpful. The loop seems to confirm Jeffs theory. But I guess the patch should look like  Index: mod_proxy_connect.c =================================================================== --- mod_proxy_connect.c (Revision 295013) +++ mod_proxy_connect.c (Arbeitskopie) @@ -357,8 +357,11 @@                      else                          break;                  } -                else if ((pollevent & APR_POLLERR) || (pollevent & APR_POLLHUP)) +                else if ((pollevent & APR_POLLERR) +                         || (pollevent & APR_POLLHUP)) { +                    rv = APR_EOF;                      break; +                }              }              else                  break;  because I guess we need to set rv to APR_EOF *and* do a break. Ruediger, that appears to correct the bug.  With the change you describe  compiled in I am no longer able to reproduce the problem.  Ausgezeichnete  Arbeit. The credits belong to Jeff who had the correct theory just from the start. I only tweaked his patch. Jeff I am not quite sure by your comments if you fear bad sideeffects of this patch. So I would like to leave the commit decision to you. Thanks for the follow-up fix, Reudiger!  That was the intended execution but I am too old and blind to see properly and too lazy to test for myself.  Thanks for the quick feedback, Rocky!  Now committed to 2.2 branch and trunk.			Jeff Trawick	Rocky Seelbach	Ruediger Pluem
36966	null	RESOLVED		Watson	1128703260000	1129122454000		ab makes more download requests than asked to 100 requests for the index file:  ab -c 1 -n 100 http://localhost/ Resulting number of requests: 100. Good.  100 requests for the index file. Concurrency 5:  ab -c 5 -n 100 http://localhost/ Resulting number of requests: 104. Ack.  The number of actual requests, according to the apache log file, is always:  number of requests + (concurrency - 1) for c > 1.	Sounds like an off-by-one error.  The culprit? 1672        for (i = 0; i < n; i++) { 1673            const apr_pollfd_t *next_fd = &(pollresults[i]); 1674            struct connection *c = next_fd->client_data; Fixed on trunk, thanks for the report.  http://svn.apache.org/viewcvs?rev=314844&view=rev Thanks for the speedy response :)			Joe Orton	Sander Temme	Watson
37051	null	CLOSED		Graham Coker	1129138500000	1129221633000		Mod_SSL warning Init: SSL server IP/port conflict. I am building 64bit Apache 2.0.54, with shared libraries, and SSL enabled, the  application builds without any problems, but when running the server the  following errors appear in the error log.  My OpenSSL is 0.9.8, but I have applied the patch to Mod_SSL which allows this  version of OpenSSL to work.  [Wed Oct 12 16:24:19 2005] [warn] Init: SSL server IP/port conflict:  www.philipm orris.uk.com:443 (/etc/httpd/conf/ssl.conf:280) vs. www.queenswood.co.uk:443  (/e tc/httpd/conf/ssl.conf:306) [Wed Oct 12 16:24:19 2005] [warn] Init: SSL server IP/port conflict:  www.crowsfe et.net:443 (/etc/httpd/conf/ssl.conf:254) vs. www.queenswood.co.uk:443  (/etc/htt pd/conf/ssl.conf:306) [Wed Oct 12 16:24:19 2005] [warn] Init: You should not use name-based virtual  ho sts in conjunction with SSL!! [Wed Oct 12 16:24:19 2005] [notice] Apache/2.0.54 (Unix) PHP/5.0.5  mod_ssl/2.0.5 4 OpenSSL/0.9.8 DAV/2 configured -- resuming normal operations  I have compiled Apache under Solaris 9, with GCC 3.4.2, and also in Solaris 10  with GCC 3.4.2, and with Sun Studio 10, and in every instance I've had the  errors in the log. (System is a Netra T1/AC200 with a 500mhz Ultrasparc IIi  CPU)  It's a minor problem, as the server continues, and it correctly links my IP  Virtual SSL sites to their correct certificates without any problems, it  appears to just be a logging issue.  If I switch to a 32bit build, then there is no problem, the SSL warning is  gone, and everything works fine, but I wish to use the 64bit build to get  around the STDIO limit of 255 open files that Solaris has.	It would be helpful if you can post your ssl and virtual host configuration here. Thanks, here is the ssl.conf file I am using to test the 64bit build, its a  copy from our of our 'production' servers which are currently on a 32bit build  of Apache 2.0.54, I've xxx'ed out part of the pathnames as they appear on the  production server, but apart from that the config file is 'as is'  Building the same source tree in 32 bit resolves the warning, but as soon as I  compile into 64bit I have the problem.   My configure is / ./configure --enable-modules=most --enable-mods-shared=all --enable-so -- enable-ssl=/usr/local/ssl --enable-ssl=shared --enable-suexec --with-suexec- caller=xxx --with-suexec-docroot=/xxx/xxx --with-suexec- logfile=/var/log/suexec.cgi.log  When compiling with GCC, in 64bit, im using CFLAGS=-mcpu=ultrasparc -m64 -O3,  and with Sun Studio im using CFLAGS=-Xa -xtarget=ultra2 -xarch=v9a -xvis -xO4 - xspace -xdepend  Both compilers successfully build both the 32bit, and 64bit versions, both the  GCC and Sun CC 32 bit builds have no errors in the error_log, but the GCC and  Sun CC 64bit builds both exhibit the same warnings in the error_log.  As I reported initialy the server continues to startup after the warning, and  the SSL sites are functioning 100%, with the correct certificate attached to  the sites as I would expect.  Apart from this one warning in the error_log, the 64bit build is performing  spectacularly well, on identical 500mhz Netra AC200 servers the 32bit build is  pumping out 350 requests per second according to an AB test on a very simple  static html file, the same test on the 64bit build is giving 400  requests/second.  I initially tested the 64bit build using a production httpd.conf with 200  virtual *:80 NameVirtual hosts, but to simplify testing I replaced it with the  default httpd.conf that is installed after the initial make install, so the  only 'modified' config file is ssl.conf which I have added below.     #    CustomLog logs/dummy-host.example.com-access_log common  ## ##  SSL Global Context ## ##  All SSL configuration in this context applies both to ##  the main server and all SSL-enabled virtual hosts. ##  # #   Some MIME-types for downloading Certificates and CRLs # AddType application/x-x509-ca-cert .crt AddType application/x-pkcs7-crl    .crl  #   Pass Phrase Dialog: #   Configure the pass phrase gathering process. #   The filtering dialog program ("builtin' is a internal #   terminal dialog) has to provide the pass phrase on stdout. SSLPassPhraseDialog  builtin  #   Inter-Process Session Cache: #   Configure the SSL Session Cache: First the mechanism #   to use and second the expiring timeout (in seconds). #SSLSessionCache        none #SSLSessionCache        shmht:logs/ssl_scache(512000) #SSLSessionCache        shmcb:logs/ssl_scache(512000) SSLSessionCache         dbm:logs/ssl_scache SSLSessionCacheTimeout  300  #   Semaphore: #   Configure the path to the mutual exclusion semaphore the #   SSL engine uses internally for inter-process synchronization. SSLMutex  file:logs/ssl_mutex  #   Pseudo Random Number Generator (PRNG): #   Configure one or more sources to seed the PRNG of the #   SSL library. The seed data should be of good random quality. #   WARNING! On some platforms /dev/random blocks if not enough entropy #   is available. This means you then cannot use the /dev/random device #   because it would lead to very long connection times (as long as #   it requires to make more entropy available). But usually those #   platforms additionally provide a /dev/urandom device which doesn't #   block. So, if available, use this one instead. Read the mod_ssl User #   Manual for more details. SSLRandomSeed startup builtin SSLRandomSeed connect builtin #SSLRandomSeed startup file:/dev/random  512 #SSLRandomSeed startup file:/dev/urandom 512 #SSLRandomSeed connect file:/dev/random  512 #SSLRandomSeed connect file:/dev/urandom 512  ## ## SSL Virtual Host Context ##  #<VirtualHost 212.46.140.6:443>  #  General setup for the virtual host #DocumentRoot '/xxx/xxx/wyenetco' #ServerName www.wyenet.co.uk #ServerAdmin webmaster@wyenet.net #ScriptAlias /cgi-bin/ '/xxx/xxx/wyenetco/cgi-bin/' #ErrorLog /xxx/xxx/wyenetco/logs/error_log #TransferLog /xxx/xxx/wyenetco/logs/access_log   #   SSL Engine Switch: #   Enable/Disable SSL for this virtual host. #SSLEngine on  #   SSL Cipher Suite: #   List the ciphers that the client is permitted to negotiate. #   See the mod_ssl documentation for a complete list. #SSLCipherSuite ALL:!ADH:! EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL  #   Server Certificate: #   Point SSLCertificateFile at a PEM encoded certificate.  If #   the certificate is encrypted, then you will be prompted for a #   pass phrase.  Note that a kill -HUP will prompt again.  Keep #   in mind that if you have both an RSA and a DSA certificate you #   can configure both in parallel (to also allow the use of DSA #   ciphers, etc.) #SSLCertificateFile /xxx/xxx/conf/ssl.crt/www.wyenet.co.uk.crt #SSLCertificateFile /xxx/xxx/conf/ssl.crt/server-dsa.crt  #   Server Private Key: #   If the key is not combined with the certificate, use this #   directive to point at the key file.  Keep in mind that if #   you've both a RSA and a DSA private key you can configure #   both in parallel (to also allow the use of DSA ciphers, etc.) #SSLCertificateKeyFile /xxx/xxx/conf/ssl.key/www.wyenet.co.uk.key #SSLCertificateKeyFile /xxx/xxx/conf/ssl.key/server-dsa.key  #   Server Certificate Chain: #   Point SSLCertificateChainFile at a file containing the #   concatenation of PEM encoded CA certificates which form the #   certificate chain for the server certificate. Alternatively #   the referenced file can be the same as SSLCertificateFile #   when the CA certificates are directly appended to the server #   certificate for convinience. #SSLCertificateChainFile /xxx/xxx/conf/ssl.crt/ca.crt  #   Certificate Authority (CA): #   Set the CA certificate verification path where to find CA #   certificates for client authentication or alternatively one #   huge file containing all of them (file must be PEM encoded) #   Note: Inside SSLCACertificatePath you need hash symlinks #         to point to the certificate files. Use the provided #         Makefile to update the hash symlinks after changes. #SSLCACertificatePath /xxx/xxx/conf/ssl.crt #SSLCACertificateFile /xxx/xxx/conf/ssl.crt/ca-bundle.crt  #   Certificate Revocation Lists (CRL): #   Set the CA revocation path where to find CA CRLs for client #   authentication or alternatively one huge file containing all #   of them (file must be PEM encoded) #   Note: Inside SSLCARevocationPath you need hash symlinks #         to point to the certificate files. Use the provided #         Makefile to update the hash symlinks after changes. #SSLCARevocationPath /xxx/xxx/conf/ssl.crl #SSLCARevocationFile /xxx/xxx/conf/ssl.crl/ca-bundle.crl  #   Client Authentication (Type): #   Client certificate verification type and depth.  Types are #   none, optional, require and optional_no_ca.  Depth is a #   number which specifies how deeply to verify the certificate #   issuer chain before deciding the certificate is not valid. #SSLVerifyClient require #SSLVerifyDepth  10  #   Access Control: #   With SSLRequire you can do per-directory access control based #   on arbitrary complex boolean expressions containing server #   variable checks and other lookup directives.  The syntax is a #   mixture between C and Perl.  See the mod_ssl documentation #   for more details. #<Location /> #SSLRequire (    %{SSL_CIPHER} !~ m/^(EXP|NULL)/ / #            and %{SSL_CLIENT_S_DN_O} eq 'Snake Oil, Ltd.' / #            and %{SSL_CLIENT_S_DN_OU} in {'Staff', 'CA', 'Dev'} / #            and %{TIME_WDAY} >= 1 and %{TIME_WDAY} <= 5 / #            and %{TIME_HOUR} >= 8 and %{TIME_HOUR} <= 20       ) / #           or %{REMOTE_ADDR} =~ m/^192/.76/.162/.[0-9]+$/ #</Location>  #   SSL Engine Options: #   Set various options for the SSL engine. #   o FakeBasicAuth: #     Translate the client X.509 into a Basic Authorisation.  This means that #     the standard Auth/DBMAuth methods can be used for access control.  The #     user name is the "one line' version of the client's X.509 certificate. #     Note that no password is obtained from the user. Every entry in the user #     file needs this password: "xxj31ZMTZzkVA'. #   o ExportCertData: #     This exports two additional environment variables: SSL_CLIENT_CERT and #     SSL_SERVER_CERT. These contain the PEM-encoded certificates of the #     server (always existing) and the client (only existing when client #     authentication is used). This can be used to import the certificates #     into CGI scripts. #   o StdEnvVars: #     This exports the standard SSL/TLS related "SSL_*' environment variables. #     Per default this exportation is switched off for performance reasons, #     because the extraction step is an expensive operation and is usually #     useless for serving static content. So one usually enables the #     exportation for CGI and SSI requests only. #   o CompatEnvVars: #     This exports obsolete environment variables for backward compatibility #     to Apache-SSL 1.x, mod_ssl 2.0.x, Sioux 1.0 and Stronghold 2.x. Use this #     to provide compatibility to existing CGI scripts. #   o StrictRequire: #     This denies access when 'SSLRequireSSL' or 'SSLRequire' applied even #     under a 'Satisfy any' situation, i.e. when it applies access is denied #     and no other module can change it. #   o OptRenegotiate: #     This enables optimized SSL connection renegotiation handling when SSL #     directives are used in per-directory context. #SSLOptions +FakeBasicAuth +ExportCertData +CompatEnvVars +StrictRequire #<Files ~ '/.(cgi|shtml|phtml|php3?)$'> #    SSLOptions +StdEnvVars #</Files> #<Directory '/usr/local/apache2/cgi-bin'> #    SSLOptions +StdEnvVars #</Directory>  #   SSL Protocol Adjustments: #   The safe and default but still SSL/TLS standard compliant shutdown #   approach is that mod_ssl sends the close notify alert but doesn't wait for #   the close notify alert from client. When you need a different shutdown #   approach you can use one of the following variables: #   o ssl-unclean-shutdown: #     This forces an unclean shutdown when the connection is closed, i.e. no #     SSL close notify alert is send or allowed to received.  This violates #     the SSL/TLS standard but is needed for some brain-dead browsers. Use #     this when you receive I/O errors because of the standard approach where #     mod_ssl sends the close notify alert. #   o ssl-accurate-shutdown: #     This forces an accurate shutdown when the connection is closed, i.e. a #     SSL close notify alert is send and mod_ssl waits for the close notify #     alert of the client. This is 100% SSL/TLS standard compliant, but in #     practice often causes hanging connections with brain-dead browsers. Use #     this only for browsers where you know that their SSL implementation #     works correctly. #   Notice: Most problems of broken clients are also related to the HTTP #   keep-alive facility, so you usually additionally want to disable #   keep-alive for those clients, too. Use variable 'nokeepalive' for this. #   Similarly, one has to force some clients to use HTTP/1.0 to workaround #   their broken HTTP/1.1 implementation. Use variables 'downgrade-1.0' and #   'force-response-1.0' for this. #SetEnvIf User-Agent '.*MSIE.*' / #         nokeepalive ssl-unclean-shutdown / #         downgrade-1.0 force-response-1.0 # #   Per-Server Logging: #   The home of a custom SSL log file. Use this when you want a #   compact non-error SSL logfile on a virtual host basis. #CustomLog logs/ssl_request_log / #          '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b' # #</VirtualHost>  <VirtualHost 212.46.140.76:443> SuexecUserGroup crowsfeet nobody ServerAdmin webmaster@blackhillcomputersoftware.co.uk DocumentRoot /xxx/xxx/crowsfeet/docs-ssl ScriptAlias /cgi-bin/ '/xxx/xxx/crowsfeet/cgi-bin-ssl/' #Alias /images/ '/xxx/xxx/crowsfeet/docs/images/' ServerName www.crowsfeet.net ErrorLog /xxx/xxx/crowsfeet/logs/error_log CustomLog /xxx/xxx/crowsfeet/logs/access_log combined SSLEngine on SSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL SSLCertificateFile /xxx/xxx/conf/ssl.crt/www.crowsfeet.net.crt SSLCertificateKeyFile /xxx/xxx/conf/ssl.key/www.crowsfeet.net.key <Files ~ '/.(cgi|shtml|phtml|php3?)$'>     SSLOptions +StdEnvVars </Files> <Directory '/xxx/xxx/apache/cgi-bin-ssl'>     SSLOptions +StdEnvVars </Directory> SetEnvIf User-Agent '.*MSIE.*' /          nokeepalive ssl-unclean-shutdown /          downgrade-1.0 force-response-1.0 CustomLog /xxx/xxx/crowsfeet/logs/ssl_request_log /           '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b' </VirtualHost>  <VirtualHost 212.46.140.73:443> SuexecUserGroup pmorris nobody ServerAdmin webmaster@philipmorris.uk.com DocumentRoot /xxx/xxx/philipmorris/docs-ssl ScriptAlias /cgi-bin/ '/xxx/xxx/philipmorris/cgi-bin-ssl/' Alias /images/ '/xxx/xxx/philipmorris/docs/images/' ServerName www.philipmorris.uk.com ErrorLog /xxx/xxx/philipmorris/logs/error_log CustomLog /xxx/xxx/philipmorris/logs/access_log combined SSLEngine on SSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL SSLCertificateFile /xxx/xxx/conf/ssl.crt/www.philipmorris.uk.com.crt SSLCertificateKeyFile /xxx/xxx/conf/ssl.key/www.philipmorris.uk.com.key <Files ~ '/.(cgi|shtml|phtml|php3?)$'>     SSLOptions +StdEnvVars </Files> <Directory '/usr/local/apache/cgi-bin-ssl'>     SSLOptions +StdEnvVars </Directory> SetEnvIf User-Agent '.*MSIE.*' /          nokeepalive ssl-unclean-shutdown /          downgrade-1.0 force-response-1.0 CustomLog /wyenet/web/philipmorris/logs/ssl_request_log /           '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b' </VirtualHost>  <VirtualHost 212.46.140.64:443> SuexecUserGroup queenswd nobody ServerAdmin webmaster@queenswood.co.uk DocumentRoot /xxx/xxx/queenswood/ ScriptAlias /cgi-bin/ '/xxx/xxx/queenswood/cgi-bin/' ServerName www.queenswood.co.uk ErrorLog /wyenet/web/queenswood/logs/error_log CustomLog /xxx/xxx/queenswood/logs/access_log combined SSLEngine on SSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL SSLCertificateFile /xxx/xxx/conf/ssl.crt/www.queenswood.co.uk.crt SSLCertificateKeyFile /xxx/xxx/conf/ssl.key/www.queenswood.co.uk.key <Files ~ '/.(cgi|shtml|phtml|php3?)$'>     SSLOptions +StdEnvVars </Files> <Directory '/usr/local/apache/cgi-bin'>     SSLOptions +StdEnvVars </Directory> SetEnvIf User-Agent '.*MSIE.*' /          nokeepalive ssl-unclean-shutdown /          downgrade-1.0 force-response-1.0 #CustomLog /xxx/xxx/queenswood/logs/ssl_request_log / #          '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b' </VirtualHost>  </IfDefine> # I think I need some debugging information from you since I do not have a 64 Bit system at hand. For debugging httpd with gdb please have a look at  http://httpd.apache.org/dev/debugging.html  Please keep in mind to recompile your httpd with gcc and -O2 -g instead of -O3 in this case. You should set a breakpoint at ssl_engine_init.c:1039 via break ssl_engine_init.c:1039 After httpd stopped at this point please issue print key  Background: I think that          key = apr_psprintf(p, '%pA:%u',                            &s->addrs->host_addr, s->addrs->host_port);  in line 1037-1038 of ssl_engine_init.c do not deliver different results for the different virtual host, because apr_psprintf might not correctly format 64 Bit pointers. BTW: Some APR guys listening? Could you guys give a hint on that theory? Nice! You found the buggy code ;) but the reason why is:  %pA takes a 'struct in_addr *' argument, but that's being passed an 'apr_sockaddr_t *' argument.  ...it should be %pI instead. Created an attachment (id=16684) Patch against trunk  Graham could you please give this patch a try and see if this removes your problem? It does what Joe proposed. That isn't quite right, since %pI prints 'address:port' using the port out of the apr_sockaddr_t structure.   I'm not sure even whether that port will be the same as s->addr->host_port - probably not.  If it is, that's OK; need to test that.  There's a further problem that %pI is liable to print corrupt strings with apr_psprintf due to an APR bug (only fixed on the trunk). Created an attachment (id=16685) patch against 2.0.x   Here's an alternative patch which should be slightly safer. Applied Joe's second patch to my 2.0.54 code, and compiled, so far so good, no  errors reported in the error_log now.  Excellent, with my normal config file the error_log is now clean, and just  shows the server starting up. I also ran a test with an invalid SSL  configuration with NameVirtual hosts, and it correctly identified the problem,  and logged it to error_log.    Thanks for the update Graham. Joe, sorry for the misunderstanding and thanks for the update. As far as I can see the problem is also on the trunk and given the apr problem I think we should not rely on apr_psprintf in this point on the trunk too. Do you commit or should I do? Thanks for testing the patch out.  Committed to trunk and 2.2.x; this is probably not worth a backport to 2.0.x since it's only a warning.  http://svn.apache.org/viewcvs?rev=320796&view=rev			Graham Coker	Joe Orton	Ruediger Pluem
37074	null	CLOSED		Karel Rambousek	1129219800000	1130310347000		Enable/Disable mistakes in documentation Location: http://httpd.apache.org/docs/2.0/programs/configure.html  --disable-env     Enable setting and clearing of environment variables, which is provided by mod_env.  SHOULD BE:  --disable-env     Disable setting and clearing of environment variables, which is provided by mod_env.   --disable-status     Enable the process/thread monitoring, which is provided by mod_status.  SHOULD BE:  --disable-status     Disable the process/thread monitoring, which is provided by mod_status.	Thanks for your submission on this -- changes committed.  Doh! Jason, please don't reassign bugs to yourself. Assign back to bugs@httpd.apache.org. And fixed again.			Andr?? Malo	Jason Lingohr
37288	null	RESOLVED		Julian Reschke	1130501340000	1130682389000		t a current lock A PUT request with the following 'If' request header:    If: (<DAV:no-lock>)  is supposed to fail with status 412, but executes the PUT.	Created an attachment (id=16828) proposed fix for handling of unknown state tokens in mod_dav  The current behaviour is caused by the fix for bug 16452; attached patch improves handling of unknown state tokens in mod_dav so that they are evaluated to false at the right time. Fixed on the trunk, thanks for the report.  http://svn.apache.org/viewcvs.cgi?view=rev&rev=329562			Joe Orton
37347	null	RESOLVED		John Stefani	1131032100000	1195962874000		mod_disk_cache replaces HTTP Status 301 with 200 this is the same as 23550 except it applies to mod_disk_cache and does not occur in mod_mem_cache (so excuse the copying of the well stated report)  When apache is configured as a reverse proxy with mod_disk_cache enabled (or both mod_disk_cache and mod_mem_cache but not with mod_mem_cache alone), it will cache 301 responses from the backend.   Now, when we hit the memory-cached object, mod_disk_cache returns the original 301 response with a replaced HTTP status of 200. This causes clients to not follow the redirect.  I will try to illustrate this:  request:     GET /foo HTTP/1.1     Host: www.foo.tld  1st response, before caching:     HTTP/1.1 301 Moved Permanently     Location: http://www.foo.tld/foo/  subsequent response, on same request:     HTTP/1.1 200 OK     Location: http://www.foo.tld/foo/  => Client ignores Location: header	Created an attachment (id=16870) Patch against 2.0.x branch  This has been fixed in trunk and 2.2.x a while ago (r220038). Can you please give the attached patch a try? It should fix the problem for mod_disk_cache and for mod_mem_cache  Thank You,  the patch you supplied fixed the issue.  Are there any plans to merge it into the 2.0.x code?   Thanks for testing. I proposed it for backport to 2.0.x by adding it to the STATUS file: http://svn.apache.org/viewcvs.cgi/httpd/httpd/branches/2.0.x/STATUS?p2=%2Fhttpd%2Fhttpd%2Fbranches%2F2.0.x%2FSTATUS&p1=httpd%2Fhttpd%2Fbranches%2F2.0.x%2FSTATUS&r1=330635&r2=330634&rev=330635&view=diff&makepatch=1&diff_format=u  I reopen the bug and will close it again once the patch has been backported. fixed as r372047 http://svn.apache.org/viewvc?view=rev&revision=372047			John Stefani	Ruediger Pluem	Takashi Sato
37357	null	RESOLVED		Albert Jin	1131119760000	1133891242000		 linkage specification in unixd.h is required for C++ An apache httpd module implemented with C++ cannot be loaded if call a  function from unixd.h (built with g++/libtool).  Why not add extern 'C'  linkage specification inside this header?  This looks not consistent with  other header include style,    extern 'C' {   #include 'unixd.h'   }   // ...   unixd_set_global_mutex_perms(...);   // ...	Thanks for the report.  Fixed on the trunk:   http://svn.apache.org/viewcvs?rev=354389&view=rev			Joe Orton
37559	null	RESOLVED		Marc Guardiola	1132336680000	1132574418000		mod_deflate + mod_proxy overwrite the Vary: header Hi,   mod_deflate seems to overwrite Vary headers set by applications (or  mod_headers) when serving proxied content.   Below my virtualhost configuration and the test data.   _____________ # cat /usr/local/apache/conf/deflate.conf <Virtualhost *>   ServerName            direct.test.nl   DocumentRoot          /var/www/html   AddOutputFilterByType DEFLATE text/html text/plain text/css </VirtualHost>  <Virtualhost *>   ServerName            proxy.test.nl   ProxyPass             /       http://backend.test.nl/   ProxyPassReverse      /       http://backend.test.nl/   AddOutputFilterByType DEFLATE text/html text/plain text/css </VirtualHost>  <Virtualhost *>   ServerName            backend.test.nl   DocumentRoot          /var/www/html </VirtualHost> _________________  # cat test.cgi #!/bin/sh  echo 'Content-type: text/html' echo 'Vary: Accept' echo '' echo ''  echo    ' <!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 4.01 Transitional//EN'><html> <head> <title>Test</title> </head> </body> </html>         ' ______________  # wget --header='Accept-Encoding: compress, gzip' -SO backendhtml  backend.test.nl/cgi-bin/test.cgi 2>&1 | grep Vary  4 Vary: Accept  # wget --header='Accept-Encoding: compress, gzip' -SO directhtml   direct.test.nl/cgi-bin/test.cgi 2>&1 | grep Vary  4 Vary: Accept,Accept-Encoding  # wget --header='Accept-Encoding: compress, gzip' -SO proxyhtml    proxy.test.nl/cgi-bin/test.cgi 2>&1 | grep Vary  4 Vary: Accept-Encoding  ______________ The last request should generate the same Vary header as the second one..   Kind regards,   Marc Guardiola	Forgot to mention that mod_proxy is not the cause, without mod_deflate it works  fine (The Vary header is not deleted by mod_proxy):  # cat /usr/local/apache/conf/deflate.conf <Virtualhost *>   ServerName            backend.test.nl   DocumentRoot          /var/www/html </VirtualHost>  <Virtualhost *>   ServerName            proxynodeflate.test.nl   ProxyPass             /       http://backend.test.nl/   ProxyPassReverse      /       http://backend.test.nl/ </VirtualHost>  __________________  # wget --header='Accept-Encoding: compress, gzip' -SO proxynodeflate       proxynodeflate.test.nl/cgi-bin/test.cgi 2>&1 | grep Vary  4 Vary: Accept  Regards,   Marc Created an attachment (id=16995) Patch against 2.0.x (merge Vary instead of setting it)  I think you hit the problem that has been fixed on the trunk in r161691 (http://svn.apache.org/viewcvs.cgi?rev=161691&view=rev). Please try if the attached patch fixes your problem. It works! Vary headers set by applications and/or by mod_headers are merged now.  Thanks!  Marc Proposed for backport to 2.0.x: (http://svn.apache.org/viewcvs.cgi?rev=347969&view=rev)			Marc Guardiola	Ruediger Pluem
37566	null	RESOLVED		Ruediger Pluem	1132436940000	1141684028000		Write message to error log if AuthGroupFile cannot be opened. Today I hunted 20 minutes for a typo in the filename of an AuthGroupFile setting, because I got only an Internal Server Error when accesing the protected location, but no message in the error log. Having a look in the code I detected that  1. There is an commented call to aplog_error in groups_for_user of    mod_auth.  2. groups_for_user in mod_auth_digest prints a message to the error log    if the group file cannot be opened.  I see no reason, why this is not done for groups_for_user in mod_auth. The attached patch fixes this.	Created an attachment (id=16998) Patch against 2.0.55  Proposed patch for backport (http://svn.apache.org/viewcvs.cgi?rev=345685&view=rev). The patch will be part of 2.0.56.			Ruediger Pluem
37753	null	RESOLVED		Kazuhiro Osawa	1133526360000	1133645025000		t move It doesn't move in stickysession when not Cookie but URL is used when  stickysession of the ProxyPass directive is specified when mod_proxy_balancer  is used.   Patch that enables operation is put up to the following.  Please apply it to mod_proxy_bakancer.c.   --- mod_proxy_balancer-old.c    2005-12-02 20:04:48.000000000 +0900 +++ mod_proxy_balancer.c        2005-12-02 20:05:51.000000000 +0900 @@ -113,7 +113,7 @@      char *path = NULL;       for (path = strstr(url, name); path; path = strstr(path + 1, name)) { -        path += (strlen(name) + 1); +        path += strlen(name);          if (*path == '=') {              /*               * Session path was found, get it's value	Created an attachment (id=17119) patch to mod_proxe_balancer URL stickysession bug.  It doesn't move in stickysession when not Cookie but URL is used when  stickysession of the ProxyPass directive is specified when mod_proxy_balancer  is used.   Thanks for submiting the patch. Fixed in trunk as r352010 (http://svn.apache.org/viewcvs.cgi?rev=352010&view=rev) and proposed for backport in r352011 (http://svn.apache.org/viewcvs.cgi?rev=352010&view=rev).  Backported r356764 			Kazuhiro Osawa	Nick Kew	Ruediger Pluem
37790	null	RESOLVED		Nick Kew	1133799900000	1134558477000		server blocks on error return from POST_READ_REQUEST The following code was sent to me as a test case.  It blocks for a long time!      int test(request_rec *r) {           ap_log_error(APLOG_MARK, APLOG_NOTICE | APLOG_NOERRNO, 0, r->server,   'Return an error');           return HTTP_FORBIDDEN;   }   static void register_hooks(apr_pool_t *p)   {       ap_hook_post_read_request(test, NULL, NULL, APR_HOOK_MIDDLE);   }     When run, it blocks in ap_discard_request_body, called from ap_die.    The bug seems to be that it's trying to read input before attaching the  HTTP_IN filter.  The patch attached fixes it, though I'm not sure it's  optimal.	Created an attachment (id=17151) Patch  Attach HTTP input filter before discarding request body. Fixed  r356764 			Nick Kew
37791	null	RESOLVED		keilh	1133802240000	1138536739000		SEGV if the client is connection plain to a SSL enabled port Consider the following configuration:   ErrorDocument 400 /server_error.html  Listen  some.server.com:443  <VirtualHost some.server.com:443>  ServerName   some.server.com:443  SSLEngine               On SSLProtocol             +TLSv1 +SSLv3 SSLCipherSuite          !EXPORT56:RC4-MD5:DES-CBC3-SHA:EXP-RC4-MD5 SSLOptions              +OptRenegotiate +StdEnvVars SSLCertificateFile      server-cert.pem  <Location / > SSLCipherSuite DES-CBC3-SHA </Location>  </VirtualHost>    If a client is connection plain to the SSL port, the server cores with the following stack: (debug build on solaris)  dummy_worker(opaque = 0x156088) worker_thread(thd = 0x156088, dummy = 0x22b020) process_socket(p = 0x23a4a8, sock = 0x23a4e0, my_child_num = 0, my_thread_num = 9, bucket_alloc = 0x23c4b0) ap_process_connection(c = 0x23a5d0, csd = 0x23a4e0) ap_run_process_connection(0x23a5d0, 0x23a4e0, 0x23a4e0, 0x9, 0x23a5c8, 0x23c4b0) ap_process_http_connection(c = 0x23a5d0) ap_read_request(conn = 0x23a5d0) ap_die(type = 400, r = 0x244500) ap_internal_redirect(new_uri = 0x150410 '/server_error.html', r = 0x244500) ap_process_request_internal(r = 0x245388) ap_run_access_checker(0x245388, 0xfee9630c, 0x245c92, 0xffffffff, 0xfffffff8, 0x245510) ssl_hook_Access(r = 0x245388) SSL_get_current_cipher(s = (nil))  The problems is that by ap_internal_redirect the ssl_hook_Access(..) will now be called, and that method does not handle the case ssl == NULL.  Fix: do not run the access-checker-hooks for the error handling  Config workaround: Configure also 'SSSLRequire' if you configure 'SSLSLCipherSuite' for any location.  We tested the described behaviour with apache/2.0.53 and apache/2.1.9	Thanks for the report, this has been fixed on the trunk:  http://svn.apache.org/viewcvs.cgi?rev=354394&view=rev Created an attachment (id=17393) Patch against 2.0.x  Proposed for backport to 2.2.x as r355720 (http://svn.apache.org/viewcvs.cgi?rev=355720&view=rev) and proposed for backport to 2.0.x as r368152 (http://svn.apache.org/viewcvs.cgi?rev=368152&view=rev). There is also a CVEID for this bug: CAN-2005-3357 Doesn't the same problem also appear at the very beginning of in ssl_hook_Fixup() ?  if (!(sc->enabled && sslconn && (ssl = sslconn->ssl)))    should become if ( !sc->enabled || !sslconn || (ssl != sslconn->ssl) )  Right ? (In reply to comment #4) >  > if (!(sc->enabled && sslconn && (ssl = sslconn->ssl))) >    should become > if ( !sc->enabled || !sslconn || (ssl != sslconn->ssl) ) >  > Right ?  No.  1. Your version is nearly the same as above because  !(sc->enabled && sslconn && (ssl = sslconn->ssl))  is equal to  !sc->enabled || !sslconn || !(ssl == sslconn->ssl)  keep in mind that   ssl = sslconn->ssl  and  ssl == sslconn->ssl  are different things. So the original condition becomes true if sslconn->ssl is equal to NULL which is only checked if sslconn is different from NULL. But I need to check on the trunk where the current condition is somewhat different and maybe also wrong. So thanks for the pointer.  Meanwhile I checked the slightly different condition on trunk and 2.2.x and they are also correct. I read too fast, sorry :-(			Joe Orton	Marc Stern	Ruediger Pluem
37798	null	RESOLVED		techie	1133815320000	1188213358000		Add quite popular CHM extension to mime.types application/mshelp \thlp chm  Without this string apache gives out file with text/plain content-type resulting in garbage on a user screen instead of prompt to download the file.  If you'll decide to add some more mime types, here is a list http://www.free-solutions.de/w3/domains_MIMETypes.html	As stated in the docs, we only add types on request if they are registered at IANA but I can't find 'mshelp' here: <http://www.iana.org/assignments/media-types/application/>.  Thanks anyway. Done. Now you can add application/vnd.ms-htmlhelp to mime.types  http://www.iana.org/assignments/media-types/application/vnd.ms-htmlhelp Added     application/vnd.ms-htmlhelp   chm  to trunk in rev 570206.			Andr?? Malo	Roy T. Fielding	techie
37840	null	RESOLVED		Per Olausson	1134051540000	1134065833000		2.2.0 does not build with VAC/VACPP V6 on AIX 5.2 There are several programming errors in the 2.2.0 code that prevent this from building on AIX 5.2 with the IBM native Visual Age C/C++ compilers (V6+).  On a sidenote, the duplication of multiple configure points take forever to run.  Details:  AIX oslevel -r:  5200-05 vac.C:           6.0.0.11 vacpp.cmp.core:  6.0.0.12  Patches that fix these defects:  *** apr_dbd.c   Thu Aug 11 15:06:26 2005 --- apr_dbd.c.new       Wed Dec  7 12:17:37 2005 *************** *** 160,166 ****   {       int ret = driver->start_transaction(pool, handle, trans);       if (*trans) { !         apr_pool_cleanup_register(pool, *trans, (void*)driver->end_transaction,                                     apr_pool_cleanup_null);       }       return ret; --- 160,166 ----   {       int ret = driver->start_transaction(pool, handle, trans);       if (*trans) { !         apr_pool_cleanup_register(pool, *trans, driver->end_transaction,                                     apr_pool_cleanup_null);       }       return ret; *************** *** 169,175 ****                                            apr_pool_t *pool,                                            apr_dbd_transaction_t *trans)   { !     apr_pool_cleanup_kill(pool, trans, (void*)driver->end_transaction);       return driver->end_transaction(trans);   }  --- 169,175 ----                                            apr_pool_t *pool,                                            apr_dbd_transaction_t *trans)   { !     apr_pool_cleanup_kill(pool, trans, driver->end_transaction);       return driver->end_transaction(trans);   }  *** apr_dbd_internal.h  Mon Aug 22 01:24:11 2005 --- apr_dbd_internal.h.new      Wed Dec  7 12:16:38 2005 *************** *** 97,103 ****        *  @param transaction - the transaction.        *  @return 0 for success or error code        */ !     int (*end_transaction)(apr_dbd_transaction_t *trans);        /** query: execute an SQL query that doesn't return a result set        * --- 97,103 ----        *  @param transaction - the transaction.        *  @return 0 for success or error code        */ !     int (*end_transaction)(void *trans);        /** query: execute an SQL query that doesn't return a result set        * *** bio.h       Tue May 17 01:08:27 2005 --- bio.h.new   Wed Dec  7 12:38:09 2005 *************** *** 676,682 ****    /*long BIO_ghbn_ctrl(int cmd,int iarg,char *parg);*/  ! #ifndef __GNUC__   #define __attribute__(x)   #endif   int BIO_printf(BIO *bio, const char *format, ...) --- 676,682 ----    /*long BIO_ghbn_ctrl(int cmd,int iarg,char *parg);*/  ! #ifndef __attribute__   #define __attribute__(x)   #endif   int BIO_printf(BIO *bio, const char *format, ...) *** httpd.h     Thu Sep 29 21:44:53 2005 --- httpd.h.new Wed Dec  7 12:24:16 2005 *************** *** 1074,1080 ****   typedef enum  {       CONN_STATE_CHECK_REQUEST_LINE_READABLE,       CONN_STATE_READ_REQUEST_LINE, !     CONN_STATE_LINGER,   } conn_state_e;    /** --- 1074,1080 ----   typedef enum  {       CONN_STATE_CHECK_REQUEST_LINE_READABLE,       CONN_STATE_READ_REQUEST_LINE, !     CONN_STATE_LINGER   } conn_state_e;    /** *** sockets.c   Fri Sep  9 09:21:17 2005 --- sockets.c.new       Wed Dec  7 12:05:15 2005 *************** *** 422,428 ****       return APR_SUCCESS;   }  ! APR_POOL_IMPLEMENT_ACCESSOR(socket);    APR_IMPLEMENT_INHERIT_SET(socket, inherit, pool, socket_cleanup)  --- 422,428 ----       return APR_SUCCESS;   }  ! APR_POOL_IMPLEMENT_ACCESSOR(socket)    APR_IMPLEMENT_INHERIT_SET(socket, inherit, pool, socket_cleanup)	BIO.h is for OpenSSL and not apache, this incompatibility is seen with 0.9.8a OpenSSL. Thanks for the report and patches.  Have you passed on the bio.h problem to the OpenSSL developers?  The apr_dbd.c thing was already fixed on the trunk, I've committed the sockets.c and httpd.h fixes too and proposed the latter for inclusion in the next 2.2.x release.  http://svn.apache.org/viewcvs?rev=355141&view=rev http://svn.apache.org/viewcvs?rev=355143&view=rev  Yes I emailed in a bug to the openssl guys.  openssl.org #1252			Joe Orton	Per Olausson
37874	null	RESOLVED		Mark Cox	1134408180000	1144762153000		CVE-2005-3352 mod_imap cross-site scripting flaw Summary:  A flaw in the imagemap processing module, mod_imap, in versions of Apache httpd 1.3, 2.0 and 2.2 can in some circumstances cause the referer header to be output without being escaped in HTML.  This could allow an attacker who is able to influence the referer header the ability to do cross-site scripting attacks against sites using mod_imap in a vulnerable configuration.  Impact:   moderate (http://httpd.apache.org/security/impact_levels.html)  Mitigation:  This flaw only affects sites using mod_imap with a map file that contains the 'referer' directive.  In order to exploit this flaw the attacker would need to control the  referer header and therefore would need to entice a victim to visit a URL under the attackers control.  A sucessful cross-site scripting attack using this flaw would be limited to certain browsers.  Firefox and Mozilla browsers for example already escape suspect characters in a URL which blocks this from being exploited.  Solution:  The attached patch ensures that the referer header in mod_imap is escaped and therefore cannot be used as part of a cross-site scripting attack.  Where this patch cannot be used, a temporary solution is to remove the 'referer' directive from any map files.  Verification:  I was able to verify this by constructing a victim site with a vulnerable mod_imap configuration and by constructing a set of scripts on the attacker site.  When the attackers site was visited using the Internet Explorer browser it was able to steal the users private cookies from the victim site.  Timeline:  20051101 CERT notification of flaw to security@apache.org 20051102 ASF verification of flaw 20051103 Assigned CVE-2005-3352 with proposed patches 20051104 Contacted CERT asking for co-ordinated release and reporter info 20051114 No response from CERT, contacted them again suggesting 20051118 20051114 CERT said they would contact reporter 20051212 No further response from CERT or reporter, made public	Created an attachment (id=17199) Patch for apache-1.3 tree (ack fielding, jorton)  Created an attachment (id=17200) Patch for apache-2.0 tree (ack fielding, jorton)  VU#299838 JPCERT#94453446 JVN#06045169 The fixes for this were committed a while back:  http://svn.apache.org/viewcvs?rev=357161&view=rev (trunk) http://svn.apache.org/viewcvs?rev=356291&view=rev (2.2.x) http://svn.apache.org/viewcvs?rev=356278&view=rev (1.3.x) http://svn.apache.org/viewcvs?rev=356279&view=rev (2.0.x) 			Joe Orton	Mark Cox
37905	null	RESOLVED		Mark	1134570360000	1134577197000		Background for 2.2 docs has extra greater-than symbol There is an extra greater-than symbol in the FAQ->Background documentation, which turns up next to the question 'May I use the Apache logo on my product or Web site?'.   Affected page is:  http://httpd.apache.org/docs/2.2/faq/background.html  Search for 'background.logo' in the source to find it.	Whatever you saw isn't there now, and the document was last modified well over  a week ago.  Beg pardon, I was looking at the first instance of 'background.logo'.  You  meant the second!  I've just fixed it in svn, so it should show up soon on the  site. 			Nick Kew
37911	null	RESOLVED		Nick Burch	1134588900000	1181347277000		' The logic for deciding if a warning about the certificate CN not matching the server name is incorrect for the case of wilcard certificates. (It incorrectly drops into the normal test for a valid wildcard certificate)  The fix is:  --- ssl_engine_init.c.sav       2005-12-09 16:36:21.000000000 +0000 +++ ssl_engine_init.c   2005-12-14 18:23:01.360818339 +0000 @@ -834,14 +836,16 @@      if (SSL_X509_getCN(ptemp, cert, &cn)) {          int fnm_flags = FNM_PERIOD|FNM_CASE_BLIND;   -        if (apr_fnmatch_test(cn) && -            (apr_fnmatch(cn, s->server_hostname, -                         fnm_flags) == FNM_NOMATCH)) -        { -            ap_log_error(APLOG_MARK, APLOG_WARNING, 0, s, +        if (apr_fnmatch_test(cn)) +               { +                       if (apr_fnmatch(cn, s->server_hostname, +                         fnm_flags) == FNM_NOMATCH) +                       { +                               ap_log_error(APLOG_MARK, APLOG_WARNING, 0, s,                           '%s server certificate wildcard CommonName (CN) "%s' '                           'does NOT match server name!?',                           ssl_asn1_keystr(type), cn); +                       }          }          else if (strNE(s->server_hostname, cn)) {              ap_log_error(APLOG_MARK, APLOG_WARNING, 0, s,	Thanks for the report and the patch.  This is checked in to the trunk:  http://svn.apache.org/viewcvs.cgi?rev=378487&view=rev I'm still getting this with the Apache provided 2.0.59 binary build for win32 when using a wildcard certificate. The fix has not been been proposed for backport. If you feel this is important, try bringing it up on dev@httpd.apache.org Proposed for backport as r571936 (http://svn.apache.org/viewvc?rev=571936&view=rev). Backported to 2.2.x as r572630 (http://svn.apache.org/viewvc?rev=572630&view=rev) *** Bug 43278 has been marked as a duplicate of this bug. ***			Dale	Davi Arnaut	Joe Orton	Ruediger Pluem
37968	null	RESOLVED		Lo	1135080720000	1150880401000		missing BuildPrereq: zlib-devel in httpd.spec The pre-compilation fails at mod_deflate when zlib-devel is not installed (httpd-2.2.0/prefork/config.log) A building dependency on zlib-devel should be added in httpd.spec	'httpd.spec' and 'zlib-devel' come from your distro's package manager, not  from Apache.      A build bug in Apache itself would appear totally differently.  httpd.spec is included in httpd-2.2.0.tar.gz which I downloaded from apache.org today. So it is not provided by RedHat. What was really missing on my system was /usr/include/zlib.h (which is provided by zlib-devel on RedHat systems, but exists on other systems). Oops, sorry, httpd.spec does appear in the package.  zlib-devel (indeed  anything-devel) is still a package-manager thing.    What did you say fails?  Is it in configure (in which case that's expected  behaviour) or in make (in which case it's a bug if your configure was  successful)?  When configure came to mod_deflate, it stopped whit this message 'error: mod_deflate has been requested but can not be built due to prerequisite failures' Just before, the check for zlib.h ('checking for zlib library') had failed.  On RedHat systems, this file is provided by the RPM zlib-devel. Since httpd.spec is provided for building on RPM-friendly systems (whether or not RedHat), it should include a BuildPrereq: on zlib-devel Fixed in r415945 in trunk: http://svn.apache.org/viewvc?view=rev&revision=415945  Thanks for reporting the problem!			Lo	Nick Kew	Paul Querna
38017	null	RESOLVED		Dick Snippe	1135289340000	1151573072000		mod_cache not working in reverse proxy setup? mod_cache does not serve cached content. We'd like to use mod_cache + mod_disk_cache + mod_proxy + mod_proxy_ajp as a reverse caching proxy. The backend server (tomcat) sets all the right http headers (Expires, Last-Modified) but apache refuses to serve cached content. The same problem also shows up with mod_mem_cache and/or mod_proxy_http Examination shows that entries are inserted into the cache using the hostname '_default_'. I assume this is because of the logic in cache_generate_key_default in modules/cache/cache_storage.c  However, cache lookups are done with the actual hostname. So, apache cannot find the data it inserted on earlier requests.  Our setup is as follows: ./configure --prefix=/software/apache-2.2.0-cache --with-mpm=worker --enable-cache --enable-mem-cache --enable-disk-cache --enable-proxy --enable-proxy-http --enable-proxy-ajp --enable-proxy-balancer --enable-rewrite --enable-mods-shared=all  The relevant bits in the config file are: ProxyPreserveHost       On CacheDefaultExpire      60 CacheMaxExpire          3600 CacheIgnoreCacheControl On CacheIgnoreNoLastMod    On CacheEnable             disk    / CacheRoot               /e/fp/shrd02/tmp/cache ProxyPass               /       ajp://shrd01as:8009/ ProxyPassReverse        /       ajp://shrd01as:8009/  BTW: we use apache-2.0.X mod_mem_cache extensively. In the 2.0.X instances caching works, so I'm quite surprised to encounter problems in 2.2. I assume I must be doing something wrong, but can't figure out what.	Created an attachment (id=17342) Patch proposal against trunk  I can confirm that this is a regression. Could you please give the attached patch a try and let me know the results? Oh I forgot: Thanks for the good analysis of the problem. That eased my search for the cause very much. (In reply to comment #2) > I can confirm that this is a regression. Could you please give the attached > patch a try and let me know the results?  the patch works! I tested all comninations of mod_mem_cache, mod_disk_cache and mod_proxy_http, mod_proxy_ajp and it appears to work in all cases Thanks for testing. The patch has been commited to trunk as r367798 (http://svn.apache.org/viewcvs.cgi?rev=367798&view=rev) and been proposed for backport to 2.2.x as r367800 (http://svn.apache.org/viewcvs.cgi?rev=367800&view=rev). The patch has been backported to 2.2.x as r374931 (http://svn.apache.org/viewcvs.cgi?rev=374931&view=rev) and will be part of 2.2.1 I am still seeing these errors on 2.0.58 & 2.2.2 using mod_proxy for a reverse proxy for RPC over HTTP and Exchange.  Downgrading to 2.0.54 fixes the problem, maybe there are still some other occurences besides the ones patched here that have not been fixed?  I also tried this on 2.2.2 and it didn't work either.  [Tue Jun 27 18:08:08 2006] [error] (70014)End of file found: proxy: prefetch request body failed to 10.2.181.53 from 15.235.153.107 () [Tue Jun 27 19:07:46 2006] [error] (104)Connection reset by peer: proxy: prefetch request body failed to 10.2.181.53 from 10.2.181.18 () Sorry, but your problem is completely unrelated to this bug.			Alex Georgopoulos	Dick Snippe	Ruediger Pluem
38034	null	RESOLVED		Julian Reschke	1135422720000	1200743289000		 failures PUT to an unmapped URL (DELETEd before) with    If-None-Match: *  currently fails with 412, but should succeed (see <http://greenbytes.de/tech/webdav/rfc2616.html#rfc.section.14.26.p.8>).	It seems that If-Match and If-None-Match in general aren't evaluated properly when the target does not exist.  For instance:  LOCK /unmapped If-Match: '*'  should fail with 412, but creates the lock.  Or  LOCK /unmapped If-None-Match: '*'  should succeed, but fails with 412.  Created an attachment (id=19658) test cases for LOCK request with if-* headers  Isn't there any programmer somewhere to help fix this bug. It is a *severe* bug in mod_dav and it is open for at least four years, while IIS does it right.  Created an attachment (id=20552) Fixes If-Match: * and If-None-Match: * bug for mod_dav  The bug is in function ap_meets_conditions() in modules/http/http_protocol.c: it always evaluates 'If-Match: *' to TRUE (is FALSE, if resource does not exist) and 'If-None-Match: *' to FALSE (is TRUE, if the resource does not exist). This function is called by mod_dav, function dav_validate_request(). In this case, ap_meets_conditions() seems not able to get etag reliably (probably a bug in mod_dav). Fix: A new function dav_meets_conditions() is created in modules/dav/main/util.c. It is mostly a copy of ap_meets_conditions(), but fixes the mentioned errors. dav_validate_request() calls dav_meets_conditions() instead of ap_meets_conditions(). ToDo: it would be better to fix this in ap_meets_conditions(). But to do this, this functions must know, whether the resource exists, and it must be able to reliably get the etag of the resource. But as I am not familiar with Apache-programming, I can't do this. I even doubt that it is possible without changes in other Apache modules besides mod_dav.  Created an attachment (id=20553) Test results for conditional LOCK-requests  HTTP-body and irrelevant headers are removed. Clients should remove 'W/' from weak Etags. Apache always creates weak Etags, when a request is sent within less than 1 second after the last modification. So clients that use HEAD to get the Etag immediately after PUT will be fooled when they use this Etag some seconds later. Why would a client remove the weakness indicator?  If the server wants to make x and W/x match, it needs to implement Etag matching that way. But clients should treat etags as opaque strings. IMHO.  > Why would a client remove the weakness indicator? Because the weakness indicator sent by Apache is nonsense.  When I send a PUT request and immediately thereafter send a HEAD request, I always get a weak Etag from Apache, say W/'19e60b-20-279033c0'. If I do the HEAD request some seconds later, I get the strong Etag '19e60b-20-279033c0'. Neither Apache nor somebody else changed the content, it is just what I sent in the PUT request. And this makes no sense to the client.  The reason is in modules/http/http_etag.c, ap_make_etag():       * If the request was made within a second of the last-modified date,      * we send a weak tag instead of a strong one, since it could      * be modified again later in the second, and the validation      * would be incorrect.  What should be the sense of this (would be nice if you could explain it to me)?  - changes may happen at any time. Why are young files bad and old ones good?  - are there race conditions within in Apache, so the Etag will not match the body of the response (mtime and etag are evaluated at one time, the response-body some time later)? In this case a weak Etag is just as wrong as strong one. Why should this race condition occur only within 1 second after the file has been modified? If this realy is the case, it needs debugging.  - when the Etag matches the body of the response, it is completely ok to change the content on the server 0.1 microsecond later (because this will change Etag).  As long as Apache (or some module) does not distinguish between 'semantically significant changes' and changing some byte, there is no reason for weak Etags (see RFC 2616, 13.3.3 Weak and Strong Validators).  For any caching WebDAV-client, it is essential to get the Etag of files uploaded to the server. If this is impossible, the client has to throw away the local copy and download it from the server again -- but only after waiting at least one second.  Real world: As long as one uses only standard WebDAV (RFC 4918) with Apache mod_dav (I don't know about extension like versioning), or any other WebDAV-server, removing the weakness indicator is no problem at all. davfs2 does it, and I never heard of any problem that might be related to this.  P.S.: Servers, that don't edit the body of a PUT, should send a strong Etag and Last-Modiefied in the PUT-response, allthough the WebDAV Working Group was not able to address this problem. It would avoid race conditions.  (In reply to comment #7) > > Why would a client remove the weakness indicator? > Because the weakness indicator sent by Apache is nonsense.  But that doesn't mean that people should apply hacks to their clients.  > When I send a PUT request and immediately thereafter send a HEAD request, I > always get a weak Etag from Apache, say W/'19e60b-20-279033c0'. If I do the HEAD > request some seconds later, I get the strong Etag '19e60b-20-279033c0'. Neither > Apache nor somebody else changed the content, it is just what I sent in the PUT > request. And this makes no sense to the client.  It makes perfect sense for clients that just need a weak etag, such as for making GET in the browser conditional.   > The reason is in modules/http/http_etag.c, ap_make_etag(): >  >      * If the request was made within a second of the last-modified date, >      * we send a weak tag instead of a strong one, since it could >      * be modified again later in the second, and the validation >      * would be incorrect. >  > What should be the sense of this (would be nice if you could explain it to me)? >  > - changes may happen at any time. Why are young files bad and old ones good?  As long as the timestamp of the file equals the system time, it can't be used to compute a strong etag (because the file can change again in the same interval). Once it's not the same anymore, it can be used to compute a strong etag.  > - are there race conditions within in Apache, so the Etag will not match the > body of the response (mtime and etag are evaluated at one time, the > response-body some time later)? In this case a weak Etag is just as wrong as > strong one. Why should this race condition occur only within 1 second after the > file has been modified? If this realy is the case, it needs debugging. >  > - when the Etag matches the body of the response, it is completely ok to change > the content on the server 0.1 microsecond later (because this will change Etag).  That depends on the resolution of the system clock.  > As long as Apache (or some module) does not distinguish between 'semantically > significant changes' and changing some byte, there is no reason for weak Etags > (see RFC 2616, 13.3.3 Weak and Strong Validators). >  > For any caching WebDAV-client, it is essential to get the Etag of files uploaded > to the server. If this is impossible, the client has to throw away the local > copy and download it from the server again -- but only after waiting at least > one second.  Yes, that's a problem. But putting hacks into the clients (removing the weakness indicator) is the wrong way to handle this.  > Real world: As long as one uses only standard WebDAV (RFC 4918) with Apache > mod_dav (I don't know about extension like versioning), or any other > WebDAV-server, removing the weakness indicator is no problem at all. davfs2 does > it, and I never heard of any problem that might be related to this.  That's because nobody has tested with other WebDAV servers that may assign weak etags for other reasons than the one you see in Apache/moddav.  > P.S.: Servers, that don't edit the body of a PUT, should send a strong Etag and > Last-Modiefied in the PUT-response, allthough the WebDAV Working Group was not > able to address this problem. It would avoid race conditions.  Actually, servers should send the ETag always, no matter whether the body was changed (IMHO). See proposal in http://greenbytes.de/tech/webdav/draft-reschke-http-etag-on-write-latest.html (follow ups with respect to this on the http-wg mailing list, please).   Looks like this is the wrong place for our discussion. So I created a new bug report. (#42987 Weak Etags in Apache are useless and violate RFC 2616, 13.3.3) Please have a look at the test cases for the 'perfect sense' of apache-style weak etags in a conditional GET.  This bug is not specific to WebDAV! If-None-Match is a pure HTTP construct and as such fixing this bug should not touch mod_dav.  I'll post a patch shortly. Created an attachment (id=21295) Clean fix  This patch comes from mod_dav_acl-0.1.2 and was written by Jari Urpalainen.  Please consider applying and closing this bug. RFC 2616 says '...or if '*' is given and any current entity exists for that resource, then the server MUST NOT perform the requested method.'  Therefore, this patch assumes that the absence of an etag implies the absence of the entity.  Is this an assumption we want to make?  also see the discussion at:  http://mail-archives.apache.org/mod_mbox/httpd-dev/200710.mbox/%3c470E9A9F.8020202@pearsoncmg.com%3e  http://mail-archives.apache.org/mod_mbox/httpd-dev/200711.mbox/%3c1b4c87db0711190838v69dd7593l15c0ceb4e4755b01@mail.gmail.com%3e (In reply to comment #12) > Is this an assumption we want to make?  I'm not qualified to provide advice on that question. But please note that the patch can easily be modified if this assumption turns out not to be valid. So the only thing preventing this bug from being closed is making this decision. (In reply to comment #13) > http://mail-archives.apache.org/mod_mbox/httpd-dev/200710.mbox/%3c470E9A9F.8020202@pearsoncmg.com%3e > http://mail-archives.apache.org/mod_mbox/httpd-dev/200711.mbox/%3c1b4c87db0711190838v69dd7593l15c0ceb4e4755b01@mail.gmail.com%3e  I didn't read everything slowly, but isn't all this related to a different bug? I mean, the problem in #38034 is fixed in a correct way easily enough, without refactoring. > I'm not qualified to provide advice on that question. But please note that the > patch can easily be modified if this assumption turns out not to be valid. So > the only thing preventing this bug from being closed is making this decision.  The main thing preventing this bug from being closed is an actual commit to the source code.  This bug  has been opened for almost 2 years (16593 has been open for over 4.5 years!) and has seen 3 or 4  proposed patches.  When a bug sees this many patches and no action, then there is a scaling problem somewhere in the  development process.  Adoption of the litmus webdav test suite would also be good to prevent regressions.  I spoke to Greg  Stein at ApacheCon last month about this bug and he mentioned that he had tested If-Match / If- None-Match behavior when he originally wrote mod_dav.  Unfortunately, mod_dav has regressed in  that regard.  An automated test would have caught the regression. (In reply to comment #14)  > I'm not qualified to provide advice on that question. But please note that the > patch can easily be modified if this assumption turns out not to be valid. So > the only thing preventing this bug from being closed is making this decision.  (Ok, my last reply was me venting.  Here is my more productive response ;-)  The patch may be easily modified to any particular state, but deciding on that state is the hard part ;-)   In this case, if the assumption is not valid (which I do not believe it is), then we must decide on how we  signify that a resource does not exist (i.e. is null).  The email thread I pointed you to discusses that  issue somewhat.  Chris Darroch proposed NON_EXTANT_RESOURCE or NO_RESOURCE.  Paritosh had  already submitted a patch with 'resource-exists' but then later agreed with Chris on using  NO_RESOURCE (a trivial change to the patch).   Then in the next month, after discussing this bug with  Paul Querna at ApacheCon, Paritosh attempted to revive the thread and proposed another possible  approach endorsed by Paul.  No one replied to Paritosh's email.  At that point, Paritosh and I decided not to invest more time in creating and testing yet another patch  which may not make it into Apache.   We're not opposed to doing so in the future, but we'd like to get  our own automated testing infrastructure setup specifically for our patches to Apache (there are more  to come).  Testing that mod_dav_fs still works by hand for every patch (and every time a patch needs to  be changed) is time consuming.    Right now, we are under increasing pressure to tend more to our non-open-source-community tasks  at our company.  We hope to devote more time to pushing fixes for bugs such as this one in the near  future.  Hopefully, your and our efforts will not be in vain.  btw, please vote for this bug if you haven't done so already.   The patch proposed by Simon Perreault only treats the bug in 'If-None-Match: *', but the same bug is in 'If-Match: *' and must be fixed too.  >> Is this an assumption we want to make? >I'm not qualified to provide advice on that question. But please note that the >patch can easily be modified if this assumption turns out not to be valid. So >the only thing preventing this bug from being closed is making this decision.  Evaluation of 'If-Match: *' and 'If-None-Match: *' depends on whether the resources does *exist*. I do not know, whether checking for the existence of an Etag is equivalent to checking for the existence of the resource. But if you want to do it this way, you must *know*. I am worrying about the idea of making a decision about making an *assumption*.  >This bug is not specific to WebDAV! If-None-Match is a pure HTTP construct and >as such fixing this bug should not touch mod_dav.  This is true, and it is wrong. Most applications seem not to use 'If-None-Match: *' and 'If-Match: *' and will therefore not be affected by this bug. But these conditionals are essential for WebDAV. So - it would be *nice* to have a clean and general solution - it is *necessary* to fix that bug for WebDAV.  As it is, a WebDAV-client can either work reliable or work with Apache. These two options are exclusive.  Cheers Werner  Additional remark an equivalence of 'check for existence' and 'check for Etag':  I am not familiar with apache programming, so this is based on one assumption. - Apache modules can register their own, specialised ap_make_etag-function, overriding apaches generic ap_make_etag-function.  If this assumption is true, it would be perfectly reasonable for a module, to return an etag only if the resource is cacheable, and to return NULL if the resource is not cacheable. So checking for the existance of an etag can not replace the check for existance of the resource.  I think a clean, general solution should be in the line of the patch provided by Paritosh Shah. There must also be a clean solution for the potential problems considerd by Paritosh Shah and Chris Darroch.  As I understand, a clean solution might possibly change some internal interface and possibly affect other modules. I fully understand that this needs serious consideration and might take some time.  If it is therefore not possible to fix this bug in a clean, general way for the next release, I suggest that the next release should fix the bug for mod_dav only (so it will not affect other modules). You might use that ugly, code dublicating monster from me. As soon as a better solution is found, this mod_dav-only patch can be removed without side effects.  Werner  Created an attachment (id=21343) Fix against 2.2.x  Werner, can you please confirm that the attached patch against 2.2.x solves your problem? This is the version of the patch that should be backported. Referring to comment #20: I applied the patch to the Debian/Etch-version of Apache 2.2.3 and only exchanged mod_dav.so in the installed binary version.  All my tests succeeded (no errors).  The tests included (with response code):  LOCK If-None-Match: *, file does not exist 200 OK  PUT If-None-Match: *, file does not exist 201 Created  PUT If-None-Match: *, file does exist 412 Precondition Failed  PUT If-Match: *, file does exist 204 No Content  PUT If-Match: 'af508-2c-69e15c40', etag matches existing file 204 No Content  PUT If-Match: 'quatsch', etag seems to not exactly match existing file 412 Precondition Failed  Thanks Werner  Just to be crystal clear: Everything is now as you expect, right? Yes!  Your patch fixes bug 38034.  Werner  Thanks for confirmation. I am sorry to say that it is likely that the patch missed the boat for 2.2.7, but it is highly likely that it will be part of 2.2.8 as it already has two votes for backport and only misses one:  http://svn.apache.org/viewvc?view=rev&revision=609024 http://svn.apache.org/viewvc/httpd/httpd/branches/2.2.x/STATUS?view=markup&pathrev=609024  But at least a accepted patch that is already in trunk is now available. Thanks for being persistent. Just a question related to this issue - not sure if I'm 100% correct in my thinking yet...  Did ap_meet_condition fail because the ETag for the non-existant file is constantly changing (mtime only ETag from http_etag.c) as there is no finfo (as a by product of it not existing)?  locks on non-existent files create a .DAV/.locknull so a resource does actually exist (a lock-null resource)? is this correct?  I'm happy with the present work-around but if what i'm thinking is the case then a cleaner fix in the future could be having mod_dav always providing its ETags (overriding http_etag for DAV directories) and as it knows about lock-null resources it could use the .locknull file for a constant inode-size-mtime Etag instead of just mtime, making ap_meets_condition happy?  That's if my assumptions are correct. In reply to comment #25:  Lock-null resources do *not* exist. Only the name is locked to prevent other clients from creating a resource with that name.  Lock-null resources have no etag and no mtime associated.  GET requests on lock-null resources will fail with 404 NOT FOUND.  An LOCK If-None-Match: * must fail with '423 LOCKED' (not 412 PRECONDITION FAILED).  Finally: Locked-null resources are deprecated by RFC 4918 in favour of locked-empty resources, which do exist. They will probably disappear in an overhaul of mod_dav.  Etags in mod_dav and mod_dav_fs should be handled separately from the Apache core. This is an open issue which cannot be solved that easy. Please see Bug report #42987 as well as the discussion thread starting at http://mail-archives.apache.org/mod_mbox/httpd-dev/200710.mbox/%3c470E9A9F.8020202@pearsoncmg.com%3e  Werner  Sorry, it's me again.  There seems to be a related bug in the way apache/mod_dav handles conditional PUT with header If-Unmodified-Since. It will always fail because ap_meets_conditions does not know the mtime of the resource. This bug will not show up most of the time as etag is checked first. I only noticed it, because a bug in davfs2 caused a PUT-request without If-Match-header and with If-Unmodified-Since-header.  As the interface documentation of ap_meets_conditions in include/http_protocal.h says, ap_meets_conditions is only ment for GET requests. It can't work with PUT. So a future revision should either change ap_meets_conditions, as proposed by Paritosh, or mod_dav should handle conditionals all of it's own (taking into account that the requirements of WebDAV are quite different in this respect).  Werner  > So a future revision should either change ap_meets_conditions, as proposed by > Paritosh, or mod_dav should handle conditionals all of it's own (taking into > account that the requirements of WebDAV are quite different in this respect).  The requirements fot WebDAV are exactly the same as for plain HTTP, except for the addition of the 'If' header.  Or am I missing something?  In reply to comment #28:  Yes, you missed the point.  Apache core does not handle PUT-requests and ap_meets_conditions is designed for GET/HEAD-requests only (this is documented behaviour). This is perfectly OK for the vast majority of Web-servers (they don't need and don't want PUT). WebDAV is about authoring and PUT is essential.  Why ap_meets_conditions cannot work with PUT: ap_meets_conditions compares the validators from the request with the validators from the response. This is OK for GET. With PUT-requests, the validators from the request have to be compared to the validators associated with the stored entity before the PUT-body is stored. The validators in the response will be different.  It is up to the decision by Apache developers, whether they want to - change ap_meets_conditions (this will change the interface), or - leave it to modules like mod_dav to check the conditions according to their needs.  Werner  What you're describing are the differences between Apache httpd and moddav, not between RFC2616 and RFC4918.  PUT is part of RFC2616, so are all conditional headers (except 'If'). Maybe an HTTP server implementation that does not support PUT can get away with a simpler *implementation*, but that doesn't really change the required semantics.  Hello Julian,  the header ot this page says 'ASF Bugzilla'. I assume 'A' stands for Apache, not for Anything.  Werner  (In reply to comment #29) > the vast majority of Web-servers (they don't need and don't want PUT). WebDAV is  If Apache just wants to keep the status quo, then yes.  But PUT is showing up in REST-style applications  (although disguised as a POST) and in XForms.  Core Apache may eventually want to care about PUT    Fixed in 2.2.8.			Julian Reschke	Michael Clark	Ruediger Pluem	Simon Perreault	Tim Olsen	Werner
38070	null	RESOLVED		Masanari Iida	1135845720000	1139079009000		httpd returns status code 200 instead 304, but logged 304 in log. Version httpd-2.2.0 Use mod_cgi  This symptom has been reported against older apaches before. apache 1.3 http://archive.apache.org/gnats/5640 apache 2.0 http://issues.apache.org/bugzilla/show_bug.cgi?id=37166 But the solution is not included in current 1.3 and 2.0 sources. And this time,Ireport it against apache 2.2.0.  Symptom: Browser access cgi program multiple times. 1st time, httpd returns status code 200 packet and logged status 200 in accesslog. Correct screen is display. 2nd time, httpd returns status code 200 without BODY and logged  status 304 in accesslog.  Blank screen is display.  Sample script: http://issues.apache.org/bugzilla/attachment.cgi?id=16757  Fix patchlet: http://archive.apache.org/gnats/5640  I hope apache developer will include the patch into all 3 version of httpd souce trees.  Regards, Masanari Iida	I have posted this symptom to apache users mailing list. Nick Kew reply to the question.  From: Nick Kew <>\tMailed-By: httpd.apache.org Reply-To: users httpd apache org To: users@httpd apache org Date: Jan 15, 2006 4:26 AM Subject: Re: [users@httpd] Bug or feature?  On Saturday 14 January 2006 18:04, Masanari Iida wrote: > Hi, > > I would like to ask the list members if following are > bug or feature of apache. > > Use following sample script, > Apache version: ANY  (1.3, 2.0 and 2.2) > > #!/bin/sh > cat <<EOT > Status: 200 OK > Last-Modified: Tue, 15 Feb 2005 15:00:00 GMT > Content-Type: text/html > > Hello world > EOT  Interesting.  I can confirm that your CGI script with an If-Modified-Since header later than the Last-Modified date supplied by the script does indeed return 200 with no body.  That's broken, but is it Apache or the script that's at fault[1]?  RFC2616 says of If-Modified-Since:       c) If the variant has not been modified since a valid If-^M         Modified-Since date, the server SHOULD return a 304 (Not^M         Modified) response.^M  That makes sense: the script is stupid but technically within its rights to send the 200 unconditionally.  So Apache should presumably accommodate it by ignoring the If-Modified-Since header and returning 200 with the full body.  If that's not already in bugzilla, you might consider entering it there.  [1] It's both, of course.  -- Nick Kew Fixed in trunk:  r370692  Are you sure you don't want to convert a CGI-generated 200 to a 304 when the HTTP conditions fail?  ap_scan_script_header_err is also called by mod_asis .  I use mod_asis extensively, with files which include Last-Modified: and ETag: headers, and it would be disastrous to return 200 when 304 would be appropriate.  Admittedly, I've had to patch both mod_asis.c and util_script.c to get the right results, but my server seems to return the responses I expect. (In reply to comment #3)  > Are you sure you don't want to convert a CGI-generated 200 to a 304 when the  > HTTP conditions fail?    There are two cases.  If the CGI *explicitly* generates a Status: header, we  should honour it.  If not, then we just need to generate whatever is  appropriate - usually 200, or 302 if the CGI emitted a Location header.    >   ap_scan_script_header_err is also called by mod_asis .  I    The crucial difference thare is that mod_asis isn't documented as having a  Status header (though I guess it might, if it goes through the same parsing as  CGI).    > use mod_asis extensively, with files which include Last-Modified: and ETag:  > headers, and it would be disastrous to return 200 when 304 would be  appropriate.    Your asis doesn't say 'Status: foo'?  Then the patch won't affect it.  >   > Admittedly, I've had to patch both mod_asis.c and util_script.c to get the  right  > results, but my server seems to return the responses I expect.    If you're saying we've got something wrong in the patch, please explain.  Fixed in:    trunk: http://svn.apache.org/viewcvs?rev=370692&view=rev    2.0:   http://svn.apache.org/viewcvs?rev=374894&view=rev   2.2:   http://svn.apache.org/viewcvs?rev=374895&view=rev  I have opened Red Hat's bugzilla case and ask RH to back port your patch into RH's.   https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=176663  Then RH's engineer wrote in comment #5.  >Comment #5 From Joe Orton (jorton@redhat.com)  \t on 2006-02-20 10:49 EST   [reply]  \t   \t  > >The fix committed upstream prevents handling of conditional requests with a CGI >script which outputs an explicit (albeit redundant) 'Status: 200' header.  This >would count as a regression so we would not include that patch as-is in a RHEL >update. > >I've prepared a (simpler) alternative patch, which fixes the real issue and will >make packages available for testing. >  --- httpd-2.0.52/server/util_script.c.cgistatus +++ httpd-2.0.52/server/util_script.c @@ -462,6 +462,13 @@              if ((cgi_status == HTTP_OK) && (r->method_number == M_GET)) {                 cond_status = ap_meets_conditions(r); + +                /* In case an explicit Status: header had set +                 * r->status_line, then unset it here, so that the +                 * actual handler return value will be honoured. */ +                if (cond_status != OK) { +                    r->status_line = NULL; +                }             }             apr_table_overlap(r->err_headers_out, merge,                 APR_OVERLAP_TABLES_MERGE);  With Red Hat's fix, apache with sample cgi return 200,304,304,304. With Nick's fix, apache with sample cgi return 200,200,200,200. Both cases, no more white (empty) display. But,which one is better solution?  The CGI spec. is quite explicit on this:    7.2.1.3. Status     The 'Status' header field is used to indicate to the server what status code   the server MUST use in the response message.    so a patch that causes it to change that breaks CGI.    Having said that, for the particular example reported in this bug, Joe's fix  is better in practical terms.  That's because the CGI script itself misused  'status'.  See todays thread on dev@httpd.  Notwithstanding a semantically flawed sentence in a draft which expired over six years ago, a CGI script which includes cache validation headers in its response cannot rely on a status code of 200 being returned to the client.  An HTTP/1.1 proxy may return a 304 response without troubling the server; or if it has to transmit the request via an HTTP/1.0 proxy it may convert a conditional GET to a HEAD whose 200 response may be converted to a 304 if the conditions are satisfied.  Insisting that a 200 response with cache validation headers be transmitted unchanged is futile.  The draft supposedly encodes current CGI practice, but I suspect that in the area of cache validation headers in CGI-generated responses there is no current practice to encode.  The documentation for mod_asis says 'A Status: header is also required', where 'required' implies that it can never be omitted.  Since the header handling is common with mod_cgi the documentation is plainly wrong.  I have removed the Status line from my 802 .asis files with no ill effects.  Whatever the outcome of the argument about 'Status: 200' with a 'Last-Modified:' which satisfies a conditional request, I'm going to have to continue to patch ap_scan_script_header_err to include my 'ETag:' headers in the check. (In response to Dave Sparks)    1. What a proxy can do with a response is totally independent of CGI rules.   They operate at different levels, and affect different agents.    2. Thanks for the headsup re: mod_asis documentation.  I've just fixed  the .xml source, so that should propagate through to the live docs in due  course.    3. You keep telling us you had to patch a problem, but I still can't see a  problem description.  If we had one, maybe we could fix it, as we have done  the bug that was clearly and accurately described in this bug report. 			Dave Sparks	Masanari Iida	Nick Kew
38084	null	RESOLVED		inoue	1136050440000	1184333510000		s document has a wrong Configuration Example about postgresql http://httpd.apache.org/docs/2.2/en/mod/mod_authn_dbd.html contains the following example:  > #Use the PostgreSQL driver > DBDriver pgsql > #Connection string: database name and login credentials > DBDParams 'dbname=htpasswd user=apache pass=xxxxxx'  Unfortunately, this doesn't work properly. We should write 'password' instead of 'pass' in this case.  The DBDParams depend on the postgresql API. The API is described in the following site: http://www.postgresql.org/docs/7.4/static/libpq.html#LIBPQ-CONNECT http://www.postgresql.org/docs/8.1/static/libpq.html#LIBPQ-CONNECT  I think these references are necessary in addition to fixing 'pass'.	Fixed in the documentation source (SVN r360505).  Will percolate through to  the online HTML docs in due course.  (In reply to comment #1) > Fixed in the documentation source (SVN r360505).  Will percolate through to  > the online HTML docs in due course.   Additional comment regarding this case:  While that documentation fix was definitly correct for the postgresql case, it cost me more than an hour of debugging as I simply changed the driver from psql to mysql and expected the params line to have the same syntax.  Yes, that is documented somewhere else, but it would be nice to add a remark to the mod_authn_dbd page noting that other drivers need 'pass=' and not 'password='.   That subtile difference is otherwise easily overlooked. Otmar,  I'm not sure that adding arbitrary comments to one modules documentation will help someone looking for help with a different module.  However I will add a disclaimer to the docs, that states that 'pass' or 'password' are usually reserved words in rdbms'  -- Tony 			Nick Kew	Otmar Lendl	Tony Stevenson
38108	null	RESOLVED		Scott Fletcher	1136316300000	1143645238000		s parse error in build/instdso.sh When compiling and installing PHP with the Apache's DSO module, I ran into compile failure when using 'make install'.  After some troubleshooting, it all boiled down to this apache's instdso.sh file.  So, I simplify this testcase here...  --snip-- #!/bin/sh  #DLNAME="sed -n '/^dlname=/{s/.*='/([^']*/)'//1/;p}' $TARGETDIR/$DSOARCHIVE_BASENAME" DLNAME="sed -n '/^dlname=/{s/.*='/([^']*/)'//1/;p}' /usr/local/apache2/modules/libphp5.la" #LIBRARY_NAMES="sed -n '/^library_names/{s/library_names='/([^']*/)'//1/;p}' $TARGETDIR/$DSOARCHIVE_BASENAME" LIBRARY_NAMES="sed -n '/^library_names/{s/library_names='/([^']*/)'//1/;p}' /usr/local/apache2/modules/libphp5.la" LIBRARY_NAMES="echo $LIBRARY_NAMES | sed -e 's/ *$DLNAME//g'"   if test -z '$DLNAME' then #  echo 'Warning!  dlname not found in $TARGETDIR/$DSOARCHIVE_BASENAME.'   echo 'Warning!  dlname not found in /usr/local/apache2/modules/libphp5.la.'   echo 'Assuming installing a .so rather than a libtool archive.'   exit 0 fi --snip--  where I get this error...  --snip-- sed: 0602-404 Function /^dlname=/{s/.*='/([^']*/)'//1/;p} cannot be parsed. sed: 0602-404 Function /^library_names/{s/library_names='/([^']*/)'//1/;p} cannot be parsed. Warning!  dlname not found in /usr/local/apache2/modules/libphp5.la. Assuming installing a .so rather than a libtool archive. --snip--  The original result when trying to install PHP source code was...  --snip-- -=[root@netgate] -=[/usr/local/src/php-5.1.1]==>make install         echo '/ / Installing PHP SAPI module:       apache2handler /usr/local/apache2/build/instdso.sh SH_LIBTOOL='/usr/local/apache2/build/libtool' libphp5.la /usr/local/apache2/modules rm -f /usr/local/apache2/modules/libphp5.so /usr/local/apache2/build/libtool --mode=install cp libphp5.la /usr/local/apache2/modules/ cp .libs/libphp5.a /usr/local/apache2/modules/libphp5.a cp .libs/libphp5.lai /usr/local/apache2/modules/libphp5.la libtool: install: warning: remember to run "libtool --finish /usr/local/src/php-5.1.1/libs' sed: 0602-404 Function /^dlname=/{s/.*='/([^']*/)'//1/;p} cannot be parsed. sed: 0602-404 Function /^library_names/{s/library_names='/([^']*/)'//1/;p} cannot be parsed. Warning!  dlname not found in /usr/local/apache2/modules/libphp5.la. Assuming installing a .so rather than a libtool archive. chmod 755 /usr/local/apache2/modules/libphp5.so chmod: /usr/local/apache2/modules/libphp5.so: A file or directory in the path name does not exist. apxs:Error: Command failed with rc=65536 . make: 1254-004 The error code from the last command is 1.  Stop. -=[root@netgate] -=[/usr/local/src/php-5.1.1]==> --snip--  I don't see any existing bug in this Apache's bugzilla but I did see one bug that is unrelated to this one...  Bug #29599  Whatever happen, I'm unable to install PHP.  However, back then, Apache was configured, compiled and installed without a problem...	Do you have LANG set?  Google says this can happen because of an AIX bug with LANG set. *** Bug 38111 has been marked as a duplicate of this bug. *** *** Bug 38112 has been marked as a duplicate of this bug. *** *** Bug 38110 has been marked as a duplicate of this bug. *** That's interesting.  I don't get it on why does the LANGUAGE have to do with this.  I did 'echo $LANG' and got the 'en_US' response so I did this, 'export LANG=''' and did the 'echo $LANG' and got the blank response.  So, tried running this command manually, '/usr/local/apache2/build/instdso.sh SH_LIBTOOL='/usr/local/apache2/build/libtool' libphp5.la /usr/local/apache2/modules' and still get this sed error message.  The same thing for 'make install' in the /usr/local/src/php5.1.1 directory.  I did the make clean  and double check to make sure. The output of the cat command of the libphp5.la in the /usr/local/apache/modules/libphp5.la result in ..  --snip-- # libphp5.la - a libtool library file # Generated by ltmain.sh - GNU libtool 1.5.18 (1.1220.2.245 2005/05/16 08:55:27) # # Please DO NOT delete this file! # It is necessary for linking the library.  # The name that we can dlopen(3). dlname='libphp5.so'  # Names of this library. library_names='libphp5.a libphp5.a'  # The name of the static archive. old_library=''  # Libraries that this one depends upon. dependency_libs=' -lssl -lcrypto -lssl -lcrypto -lssl -lcrypto -L/usr/local/ssl/lib -L/usr/local/lib -lssl -lcrypto -lssl -lcrypto -lm /usr/local/lib/libcurl.la -lssl -lcrypto -lssl -lcrypto /usr/local/lib/libodbc.la -ldl -liconv -lthread'  # Version information for libphp5. current=0 age=0 revision=0  # Is this an already installed library? installed=yes  # Should we warn about portability when linking against -modules? shouldnotlink=yes  # Files to dlopen/dlpreopen dlopen='' dlpreopen=''  # Directory that this library needs to be installed in: libdir='/usr/local/src/php-5.1.1/libs' --snip--  if that can be of a further help here.. Can you try adding at the top of build/instdso.sh:  LANG=C LC_ALL=C LANGUAGE=C export LANG LC_ALL LANGUAGE  (and then 'make install' from httpd, then try installing PHP again) Still get the same error but it look a little better...  The old error was   --snip-- sed: 0602-404 Function /^dlname=/{s/.*='/([^']*/)'//1/;p} cannot be parsed. sed: 0602-404 Function /^library_names/{s/library_names='/([^']*/)'//1/;p} cannot be parsed. Warning!  dlname not found in /usr/local/apache2/modules/libphp5.la. Assuming installing a .so rather than a libtool archive. --snip--  while the new error is  --snip-- sed: Function /^dlname=/{s/.*='/([^']*/)'//1/;p} cannot be parsed. sed: Function /^library_names/{s/library_names='/([^']*/)'//1/;p} cannot be parsed. Warning!  dlname not found in /usr/local/apache2/modules/libphp5.la. Assuming installing a .so rather than a libtool archive. --snip--  Noticed that the '0602-404' is no longer there in the new error message.  I'm not sure if the AIX's native sed is that compatible with that sed script or not. Created an attachment (id=17816) Patch file to avoid sed errors on installing apache 2.2  I believe the patch file I attached will eliminate sed error. It has been affected to all environments so that the ${prefix}/modules  directory contains '.a' and '.la' files because of this error. >LANG=C >LC_ALL=C >LANGUAGE=C >export LANG LC_ALL LANGUAGE  The sed error you were referring to, I found out it only apply to AIX 4.3, not AIX 5.2.  Trying your patch that eliminate the sed error and it seem to work pretty well with no sed error but I get further compile error.  Here's what I got...  --snip-- Installing PHP SAPI module:       apache2handler /usr/local/apache2/build/instdso.sh SH_LIBTOOL='/usr/local/apache2/build/libtool' libphp5.la /usr/local/apache2/modules rm -f /usr/local/apache2/modules/libphp5.so /usr/local/apache2/build/libtool --mode=install cp libphp5.la /usr/local/apache2/modules/ cp .libs/libphp5.a /usr/local/apache2/modules/libphp5.a cp .libs/libphp5.lai /usr/local/apache2/modules/libphp5.la libtool: install: warning: remember to run "libtool --finish /usr/local/src/php-5.1.2/libs' chmod 755 /usr/local/apache2/modules/libphp5.so chmod: /usr/local/apache2/modules/libphp5.so: A file or directory in the path name does not exist. apxs:Error: Command failed with rc=65536 --snip--  So, I check the /usr/local/apache2/module directory and found there is no libphp5.so file.  So, with further studying and tracing to the instdso.sh script I noticed that   --snip-- rm -f /usr/local/apache2/modules/libphp5.so --snip--   is removed first as to remove the older or obselote file.  Then the next part get executed..  --snip-- /usr/local/apache2/build/libtool --mode=install cp libphp5.la /usr/local/apache2/modules/ --snip--  which does in fact copy both files, libphp5.a and libphp5.la files, not the libphp5.so file.  So, hte next few part of the script which use sed.  With some tracing and execution of a shell script.  I get  --snip-- libphp5.so   libphp5.a libphp5.a   libphp5.a libphp5.a --snip--  and no sed error.  So, we the patch is working as it fix this bug.  Then further below in the script is a 'rm -f ....' script that remove those libphp5.a files so it explained why there's no libphp5.* files in that directory.  Which lead us to the next part of the script that caused the   --snip-- Warning!  dlname not found in /usr/local/apache2/modules/libphp5.la. --snip--  to appear.  Then the next part of the script here  --snip-- if test '$DLNAME' != '$TARGET_NAME' then     mv $TARGETDIR/$DLNAME $TARGETDIR/$TARGET_NAME fi --snip--  where the 'if test' script produced a result..  --snip-- if test 'libphp5.so' != 'libphp5.so' then      mv /usr/local/apache2/modules/libphp5.so /usr/local/apache2/modules/ fi --snip--  So, this part of the script is correct and there's still no libphp5.so in that directory at all.  The next part of the script just removed everything.  So, no wonder why I get the apxs errors and chmod error.  The libphp5.so is never copied over in the first place.  I'm looking forward to a further patch fix that would allow the libphp5.so to be put into the /usr/local/apache2/module directory...  It is just a bad script.  So, go ahead and check in that patch fix as it fix this AIX sed problem.... Nice work Masaoki, was that patch to fix the issue with the AIX sed too?  We've had a report of a similar error on Solaris too (bug 38696) so I've asked whether this fix works there too. this time, adding CC:  Nice work Masaoki, was that patch to fix the issue with the AIX sed too?  We've had a report of a similar error on Solaris too (bug 38696) so I've asked whether this fix works there too. > was that patch to fix the issue with the AIX sed too? Yea, for the AIX sed? Actually I don't have AIX environment.  This was not the right place to post the patch.  However, I guess, this should be common problem as just sed script string was wrong.  I confirmed my pacth works on RedHat 7.3 x86 and Solaris 10 x86. *** Bug 38696 has been marked as a duplicate of this bug. *** I meant to say this patch fix for AIX's sed now work without a problem.  So,  it's a good thing you posted here.  Since you mentioned Red Hat too.  (Along  with Sun)  OS --> All  Let us know the patch had been check into the branch.  The newer problem I have is not a sed bug (with the patch fix) so I'll file a  new bug later (cleaner bug report) on this week or next week as soon as I  finish rebuilting AIX from scratch.  (Well PHP folks said I need GNU Linker  which doesn't solve the problem.  Also later learned that GNU Linker doesn't  work too well with AIX as it's incompactible with AIX and IBM's web site said  we only need to use the AIX's native sed instead of the GNU linker.  A sign of  further messed up.) The original sed script works fine on GNU sed 4.1.2, while it does not on GNU  sed 3.1 or Solaris sed. The patched script works fine on all of above. Filed bug #39099 for the php module that doesn't work in Apache 2.2.0.  Any chance of anyone testing this patch any further or checking it in to the branch without breaking it before the next Apache release?  I thought I did see somewhere in the Apache file that specify the minimum GNU Sed version somewhere but I couldn't find it.  Is the reason for this bug being unchanged due to not assigning the bug to bugs@httpd.apache.org instead of leaving it as new?  This bugzilla is a little confusing as I'm so used to the Mozilla's bugzilla.  Sorry for the spam if I misunderstood. No, just lazy engineers lacking round tuits.  This is now committed to the trunk, and proposed for inclusion in 2.2.x.  http://svn.apache.org/viewcvs?rev=389797&view=rev  Thanks again for the patch, Masaoki.			Joe Orton	Masaoki Kobayashi	Ruediger Pluem	Scott Fletcher
38123	null	RESOLVED		Daniel Andersson	1136398380000	1143844500000		Invalid Expect header not immediately rejected When Apache was sent the following lines using telnet:  GET / HTTP/1.1 Host: whatever.hostname.com Expect: %8p   It 'hangs' for some period of time, and if this is automated in a script the server stops accepting new connections for the period of time it takes to 'process' the requests.  As of now I have tested it with version 2.0.54-r31 of Gentoo with the hardened USE flag turned on and on OpenBSD 3.8 (don't remember the version here though).	This is because httpd is waiting for more header data. Please lower the value of TimeOut (default 300 seconds) to mitigate this problem. In general this can happen with lots of other incompletely sent header situations. Not a security bug because the request does timeout.  But not a proper response to the request either.  httpd should give an immediate error rather than waiting. A patch was checked into trunk as r370172 (http://svn.apache.org/viewcvs.cgi?rev=370172&view=rev). Patch: http://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/server/protocol.c?p2=%2Fhttpd%2Fhttpd%2Ftrunk%2Fserver%2Fprotocol.c&p1=httpd%2Fhttpd%2Ftrunk%2Fserver%2Fprotocol.c&r1=370172&r2=370171&rev=370172&view=diff&makepatch=1&diff_format=u Created an attachment (id=17481) Improved patch against 2.2.x  Backported to 2.2.1 as r390503 (http://svn.apache.org/viewcvs?rev=390503&view=rev).			Joshua Slive	Ruediger Pluem
38177	null	RESOLVED		Wilson Cheung	1136709840000	1136957122000		apache-1.3.33/34: mod_log_forensic module use of assert() vs. ap_assert() introduces __eprintf() gcc-ism? 1) On 11/13/04, per the recommendation on the Apache website, I submitted    the following question/bug report/patch regarding a possible problem    with the mod_log_forensic module's use of assert() vs. ap_assert()    under Solaris to the 'apache-httpd-users' mailing list (it causes    a 'mod_log_forensic.so: symbol __eprintf: referenced symbol not found'    error when attempting to run 'httpd'):     http://marc.theaimsgroup.com/?l=apache-httpd-users&m=110039542317294&w=2      On 11/14/04, Joshua Slive recommended I instead submit this report to    'apache-httpd-dev' mailing list or the Apache bugs database:     http://marc.theaimsgroup.com/?l=apache-httpd-users&m=110045679622830&w=2   2) On 11/14/04, Jim Jagielski replied to this issue on the apache-httpd-dev    mailing list and also proposed a more formal patch for the problem:     http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=110045758526041&w=2    http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=110045807628303&w=2   3) Jeff Trawick submitted a '+1' reply to Jim Jagielski's proposed patch    on 11/14/04 and so did Andre Malo on 11/15/04:     http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=110045945314944&w=2    http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=110051618628764&w=2      Since I did not see any follow-up negative responses to Jim Jagielski's    proposed patch, I had assumed that discussing this problem on the    developer's mailing list meant it would be included in the next    apache-1.3.x release?   4) On 01/08/06, I compiled the latest apache-1.3.34 version (released on    10/18/05) and I see that this issue with the mod_log_forensic.c file    still exists so apparently this minor patch from almost a year ago    apparently did not make it into the apache-1.3.x release cycle.     I'm now submitting this bug report to request that it be committed    for inclusion in the next apache-1.3.x release (whenever that occurs).   Thank you!	Committed to the 1.3.x branch in r367914.  Thanks for the reminder!			Garrett Rooney
38227	null	RESOLVED		Brad Boyer	1137012240000	1145719595000		AJP proxy not thread-safe? I had to change from using worker MPM to prefork to avoid connection loss with the AJP proxy code. I'm using httpd 2.2.0 and tomcat 5.5.12. I get these errors in the apache httpd error log:  [Wed Jan 11 11:20:33 2006] [error] (70007)The timeout specified has expired: ajp_ilink_receive() can't receive header [Wed Jan 11 11:20:33 2006] [error] ajp_read_header: ajp_ilink_receive failed [Wed Jan 11 11:20:33 2006] [error] (120006)APR does not understand this error code: proxy: read response failed from (null) (127.0.0.1)  These 3 lines repeat numerous times, and it does not seem to reconnect to tomcat until reloaded. Changing to prefork appears to eliminate these errors.  This situation occurs after less than an hour of load testing, and is fairly consistent. With the MPM changed over to prefork, the error has not been seen over much longer test periods under the same load.  The configuration is an apache httpd doing a ProxyPass to a tomcat running on the same box. If it matters, the httpd is also using mod_ssl and these requests are coming in over https.  This is a locally compiled build of 2.2.0, with the only changed code being the patch that can be found in bug 29744.	In order to make it reconnect please add retry=1 to your ProxyPass directive (see also parameter retry at http://httpd.apache.org/docs/2.2/mod/mod_proxy.html#proxypass) Have you checked for the Tomcat logs? The first error seems to indicate that Tomcat is not responding any longer  I have experienced the same bug, the problem also seem to cause the tomcat server (5.0.28) to run out of threads, I assume the problem is also causing the ajp threads not to be closed, so I assume using a retry will not help. Yet to confirm whether using prefork instead of worker fixes the problem, but I'll try this and add this to the bug report.  ajp_read_header: ajp_ilink_receive failed (120006)APR does not understand this error code: proxy: read response failed from (null) (<ip_addr_here>) Then later  proxy: AJP: failed to make connection to backend: <ip_addr_here> (110)Connection timed out: proxy: AJP: attempt to connect to <ip_addr_here>:8009 (<ip_addr_here>) failed  It looks like tomcat can recover if it is under light load and the threads timeout, but when the load increases tomcat dies as all the threads get used up   Maybe PR#36495 is a similar bug. Could you please provide your proxy config? The config in bug 36495 is very similar to my original situation. Apache httpd 2.2 and tomcat runnnig together on a single Linux box with the config on httpd using ProxyPass to redirect to 127.0.0.1:8009. The messages once the poster moved to 2.2 are basically the same.  Here's the proxy config I have (with some URL segments changed to xxx):      ProxyRequests off     <Proxy *>         Order allow,deny         Deny from all     </Proxy>     <Proxy ajp://127.0.0.1:8009/*>         Order deny,allow         Allow from all     </Proxy>     ProxyPass /xxx ajp://127.0.0.1:8009/xxx After further testing this appears to be a problem with a misconfigured tomcat, the ajp connector behaves differently in worker mode than prefork and requires a larger number of tomcat ajp threads. Tested this under extreemly heavy load and all seems to work ok with no problems. This is all documented in the connector docs, I guess I should have picked this up earlier. Thanks for feedback. Could you please add the link to the connector docs where you found the information that solved your problem? Fixing the tomcat configuration did help, but it still appears that we are having the same problem where tomcat will run out of threads using ajp mod_proxy in worker mode. We cannot reproduce this problem in testing, only on the live systems. No real errors from apache except this, by which point tomcat has run out of threads, which I assume why this error appears. [error] (70007)The timeout specified has expired: ajp_ilink_receive() can't receive header  We also get this error in prefork mode, but it does not seem to cause tomcat to die I'm seeing similar errors.   The setup is Apache 2.2.0 with mod_proxy_ajp and Tomcat 5.0.27. I tried RewriteRules with [P] first, then switched to ProxyPass - same result.  This is the log of the virtual host: (Servernames replaced by $MYSERVER, IPs replaced by $LOCALIP) ==> httpd_error_log <== [Thu Mar 23 16:23:09 2006] [error] ajp_read_header: ajp_ilink_receive failed [Thu Mar 23 16:23:09 2006] [error] (120006)APR does not understand this error code: proxy: read response failed from (null) (localhost)                                                                                                                                                                                      This is the global apache log: ==> /opt/httpd/logs/error_log <== [Thu Mar 23 16:23:09 2006] [error] [client $LOCALIP] proxy: error reading status line from remote server $MYSERVER referer: $REFERER [Thu Mar 23 16:23:09 2006] [error] [client $LOCALIP] proxy: Error reading from remote server returned by $URL, referer: $REFERER [Thu Mar 23 16:23:09 2006] [error] (70007)The timeout specified has expired: ajp_ilink_receive() can't receive header   Nothing fancy shows up in catalina.out or Tomcat logs, just a lot of  Mar 23, 2006 4:24:40 PM org.apache.jk.common.ChannelSocket processConnection INFO: connection timeout reached  but they seem normal and occur all the time.  I do _not_ see this behaviour under heavy load, I see it almost instantly.  Things get worse: Connections from Apache to Tomcat stay open:  [root@server root]# netstat -tn|sed -n -e '1,2p;/8059/p' Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address           Foreign Address         State tcp        1      0 127.0.0.1:46802         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46814         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46790         127.0.0.1:8059          CLOSE_WAIT tcp        0      0 127.0.0.1:46826         127.0.0.1:8059          ESTABLISHED tcp        1      0 127.0.0.1:46729         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46777         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46753         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46765         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46697         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46604         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46636         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46544         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46551         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46518         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46505         127.0.0.1:8059          CLOSE_WAIT tcp        1      0 127.0.0.1:46414         127.0.0.1:8059          CLOSE_WAIT tcp      794      0 127.0.0.1:8059          127.0.0.1:46328         CLOSE_WAIT tcp        0      0 127.0.0.1:8059          127.0.0.1:46826         ESTABLISHED  There are times when no ESTABLISHED connection is available - it seems to take quite long for tomcat to recover. Not that the Recv-Q has data in it!  server.xml snippet:      <Connector protocol='AJP/1.3'                address='127.0.0.1'                port='8059'                minProcessors='10'                maxProcessors='250'                maxPostSize='0'                enableLookups='false'                useBodyEncodingForURI='true'                acceptCount='25'                debug='0'                redirectPort=''                connectionTimeout='60000'     />  (Yes, there are probably some superfluous settings there).  I do not see an increase in thread count or apache child count (using prefork MPM). Created an attachment (id=18031) Debugging output patch referenced in my comment.  I believe I'm seeing the same problem with my build of Apache 2.2.0 connecting to an instance of Tomcat 5.5.10.  THE SETUP  I'm running this on a dual cpu (Intel(R) Xeon(TM) CPU 2.80GHz) machine running Linux 2.4.21-15.ELsmp.\tApache server-info reveals:    -D APACHE_MPM_DIR='server/mpm/worker'   -D APR_HAS_SENDFILE -D APR_HAS_MMAP   -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)   -D APR_USE_SYSVSEM_SERIALIZE   -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT   -D APR_HAS_OTHER_CHILD   -D AP_HAVE_RELIABLE_PIPED_LOGS   -D HTTPD_ROOT='/usr/local/apache/2.2.0'   -D SUEXEC_BIN='/usr/local/apache/2.2.0/bin/suexec'   -D DEFAULT_ERRORLOG='logs/error_log'   -D AP_TYPES_CONFIG_FILE='conf/mime.types'   -D SERVER_CONFIG_FILE='conf/httpd.conf'  I'm using mod_proxy to balance incoming requests to an Apache VirtualHost to a mounted Tomcat service via AJP.  I think I've included the important Apache configuration below:    <Proxy balancer://tomcat>     BalancerMember ajp://server.mydomain.org:8009 route=server.mydomain.org   </Proxy>    <VirtualHost vhost.mydomain.org:80>     RewriteEngine on     RewriteCond %{ENV:HTTPD_BASE}/logs/myapp.pause -f     RewriteRule .* - [forbidden,last]     RewriteRule ^(/+test(?:/.*)?)$ /myapp$1 [env=internal:yes]     RewriteCond %{ENV:internal} =yes     RewriteRule ^(/+myapp/.*) $1 [passthrough,last]     RewriteRule ^/+myapp/(.*) /$1 [redirect=permanent,last]      ProxyPass /myapp balancer://tomcat/myapp stickysession=JSESSIONID nofailover=on     ProxyPassReverse / http://vhost.mydomain.org/myapp/     ProxyPassReverseCookiePath /myapp/ /   </VirtualHost>  My Tomcat Connector in server.xml is straightforward:      <Connector \t     protocol='AJP/1.3' \t      address='${catalina.hostname}' \t\t port='8009' \tenableLookups='false'\t\t     />  So a user connects to    http://vhost.mydomain.org/test  and then mod_proxy will forward the request via AJP to    http://server.mydomain.org:8009/myapp/test  The 'test' servlet is a simple one.  It computes a random number been 0 and 1000, and sleeps for that many milliseconds, before printing a one line response to the client.   THE PROBLEM  Using this stripped down configuration, what I see when I use ab(1) to load test the service, is that Tomcat is forced to keep creating new threads to service incoming connections, and it leaves them in the Keepalive state after ab(1) has finished.  Tomcat also indicates it is *using* those threads (perhaps polling on them?)  Every time I make a new request via mod_proxy, a new Thread is started in Tomcat.  However, when I query Tomcat directly, I see a thread get created, the request gets serviced, and the thread is switch to the Ready steady, indicating it is now able to to accept new requests.  If I run    netstat -t | egrep '^tcp.*:8009'  on the server, I see a constantly growing number of connections between Apache and Tomcat.  When I query Tomcat directly, I do not see this growing pool of connections.  This lead me to believe the problem was mod_proxy keeping connections open (perhaps the backend pooling code), but failing to either reuse them, or perhaps failing to properly close them on cleanup.   THE DEBUGGING   First, I added some debugging to proxy_util.c.\tI've attached it to this comment.  Basically all I did was print out a stupid log message when it first initializes, and then each time a connections is acquired.  Now, starting up Apache I see this in the log:  [Wed Apr 05 21:09:35 2006] [error] 0: worker->hmax: 25, worker->cp->res: not null [Wed Apr 05 21:09:35 2006] [debug] proxy_util.c(1666): proxy: initialized worker 0 in child 16610 for (server.mydomain.org) min=0 max=25 smax=25 [Wed Apr 05 21:09:35 2006] [error] 0: worker->hmax: 25, worker->cp->res: not null [Wed Apr 05 21:09:35 2006] [debug] proxy_util.c(1666): proxy: initialized worker 2 in child 16610 for (*) min=0 max=25 smax=25  For my test I first see if any connections exist to Tomcat (there should not be any):   ; netstat -t | egrep '^tcp.*:8009' | tr -s ' '  As I expect, no connections exist.  Next, on a different machine, I make a single request to my virtual host:    ab -n 1  http://vhost.mydomain.org/test  It completes, and tells me it was successful.  I see a bunch of debugging in the log indicating mod_proxy is working.  In the chatter, I see my own debugging lines:  [Wed Apr 05 21:09:43 2006] [error] 1: worker->hmax: 0, worker->cp->res: not null [Wed Apr 05 21:09:43 2006] [error] 2: called connection_constructor  This surprises me for two reasons.  First of all, I was expecting worker->hmax to be 25, not 0.  The second reason is that I expected to see that worker->cp->res have a value, not to be null.  [As an aside, subsequent testing showed that if I added 'max=25' to the BalanceMember configuration directive, worker->hmax would be 25 in requests; the null value for worker->cp->res did not change.]  Now, I check on my server to see if any connections exist (I expect a connection, due to the connection pooling):  ; netstat -t | egrep '^tcp.*:8009' | tr -s ' ' tcp 0 0 server.mydomain.org:8009 server.mydomain.org:39642 ESTABLISHED tcp 0 0 server.mydomain.org:39642 server.mydomain.org:8009 ESTABLISHED   Now, if I run a second request, I would have expected mod_proxy_ajp to reuse the existing connection.\tBut look what happens after I ran my ab command a second time:  [Wed Apr 05 21:09:46 2006] [error] 1: worker->hmax: 0, worker->cp->res: null [Wed Apr 05 21:09:46 2006] [error] 2: called connection_constructor  And netstat shows two *new* connections, for a total of four:    ; netstat -t | egrep '^tcp.*:8009' | tr -s ' '   tcp 0 0 server.mydomain.org:8009 server.mydomain.org:39753 ESTABLISHED   tcp 0 0 server.mydomain.org:8009 server.mydomain.org:39642 ESTABLISHED   tcp 0 0 server.mydomain.org:39753 server.mydomain.org:8009 ESTABLISHED   tcp 0 0 server.mydomain.org:39642 server.mydomain.org:8009 ESTABLISHED  I tried making a number of connections, and watched the connections grow until it filled all available threads on my Tomcat container (which was set to the default maxThreads of 200).  First, I reset everything:    ; apachectl stop   ; catalina.sh stop    ; apachectl start   ; catalina.sh start    ; netstat -t | egrep '^tcp.*:8009' | tr -s ' '|wc -l \t0  And then on my test client I make 200 connections:     ab -n 200 http://vhost.mydomain.org/test  and then my server shows over 400 established connections:    ; netstat -t | egrep '^tcp.*:8009' | tr -s ' '|grep -c ESTABLISHED   466  Ack!  If I tweak the proxy code, setting one of these the 'close' flags to true:    conn->close_on_recycle = 1;   conn->close = 1;  Then Apache cleans itself up, and Tomcat does not get overwhelmed.  What I'm unable to determine so far is if this is a problem with mod_proxy(_(balance|ajp))?.c, a problem with Tomcat + Apache, a problem with the APR utilities, etc.  :(  Any insights from folks would be much appreciated!  Apologies for the long post...   Jim  Thank you very much for your detailed post. I suspect a thing that has been fixed meanwhile. Could you please give http://httpd.apache.org/dev/dist/httpd-2.2.1.tar.gz a try? Keep in mind that this is NO official release of httpd-2.2.1, but one that the developers are currently deciding on whether to release it or not. It is known that this tarball currently contains a bug that prevents using SSL backends with the proxy, but this does not harm your current problem. It would be very nice if you could give it a try and let me know the results.  Another thing regarding your astonishments regarding the reusing of connections. Keep in mind that the pool limit is PER httpd process. So the maximum number of connections is not what you set via max, but <max> * <maximum number of httpd processes>. You have not posted your MPM settings here, so if you allow httpd to create 8 processes, 200 connections to the backend are ok.  > And netstat shows two *new* connections, for a total of four: >  >  ; netstat -t | egrep '^tcp.*:8009' | tr -s ' ' >  tcp 0 0 server.mydomain.org:8009 server.mydomain.org:39753 ESTABLISHED >  tcp 0 0 server.mydomain.org:8009 server.mydomain.org:39642 ESTABLISHED >  tcp 0 0 server.mydomain.org:39753 server.mydomain.org:8009 ESTABLISHED >  tcp 0 0 server.mydomain.org:39642 server.mydomain.org:8009 ESTABLISHED  Actually there is only *one* more connection, but as httpd and Tomcat are running on the same server you see *both* ends of the tcp connection in netstat. If you are running httpd and tomcat on the same server you have to divide your netstat results by 2. (In reply to comment #10) > Thank you very much for your detailed post. I suspect a thing that has been > fixed meanwhile. Could you please give > http://httpd.apache.org/dev/dist/httpd-2.2.1.tar.gz a try?  I certainly would be happy to!  I was about to post that I had added some more debugging and discovered that mod_proxy was emitting info that it had initialized worker->id 0 and worked->id 2, but not worker->id 1, and that mod_proxy_ajp was being handed worker->id 1. Dunno if that was the problem being resolved in the fix.   I will try 2.2.1 right now.  It'll take me a few minutes to compile and test, but I'll post back here within the hour.  > Actually there is only *one* more connection, but as httpd and Tomcat are > running on the same server you see *both* ends of the tcp connection in  Sorry, reading my original post shows I put too much stress on the high number of connections.  I was in fact realizing the two lines were from the same connection, I was just surprised that new sockets kept getting added instead of old ones being reused. (In reply to comment #10) > I suspect a thing that has been fixed meanwhile. Could you please give > http://httpd.apache.org/dev/dist/httpd-2.2.1.tar.gz a try? Keep in mind that > this is NO official release of httpd-2.2.1, but one that the developers are > currently deciding on whether to release it or not. It is known that this > tarball currently contains a bug that prevents using SSL backends with the > proxy, but this does not harm your current problem. It would be very nice if  > you could give it a try and let me know the results.  Hi,  I tried out 2.2.1, and I'm now seeing the kind of connection growth I expected.  I slowly increased the concurrent requests (from the original *1* thread I was using in the tests I originally posted about), to tens of threads, without seeing an undue increase in the number of used connections.  I note that Tomcat does still eventually reach 200 active threads when I hit it Apache with many requests, but it appears as though Apache is now reusing existing connections.  From this first pass, it looks to me like 2.2.1 fixes the problem I was having. Thank you very much for your help!  (In reply to comment #12)  >  > I note that Tomcat does still eventually reach 200 active threads when > I hit it Apache with many requests, but it appears as though Apache is  As mentioned, this possibly works as designed. This depends on your MPM settings.  >  > From this first pass, it looks to me like 2.2.1 fixes the problem I was  Sounds good. Please let me know the results if you do more intense tests.   Created an attachment (id=18055) make mod_proxy_balancer init_balancer_member call ap_proxy_initialize_worker  (In reply to comment #13) > > As mentioned, this possibly works as designed. This depends on your MPM settings. >  > >  > > From this first pass, it looks to me like 2.2.1 fixes the problem I was >  > Sounds good. Please let me know the results if you do more intense tests.  Hi,  I've done some more testing, and I *think* I may have found a bug with the load balancer.  I am running httpd 2.2.1, with server/thread limits of    StartServers 8   ServerLimit 16   ThreadsPerChild 64  I allowed for 1024 threads on the Tomcat side.\tThe proxy setup is the same as I mention in comment #9.  When I was initially load testing the 2.2.1 server, I happened to be setting the max attributes on the balancer:    <Proxy balancer://tomcat>     BalancerMember ajp://server.mydomain.org:8009 route=server.mydomain.org max=64   </Proxy>  This seemed rock solid, I threw batches of 500+ concurrent requests from our Sun Fire T2000 to this linux server, and it dealt with the load.  However, I then tried removing the 'max' attribute, and ran into some problem.  I found that, without the hard-coded the max attribute, I could reliably lock the system up when throwing 500 concurrent requests at it.  My understanding from previous comments and the notes is that, if one does not specify additional attributes, the defaults should be to use the ThreadsPerChild to set s/max:    smin=0  smax=64 max=64  Setting LogLevel to debug I saw that mod_proxy code says  [debug] proxy_util.c(1690): proxy: initialized worker 0 in child 15926 for (argo02.highwire.org) min=0 max=64 smax=64 [debug] proxy_util.c(1690): proxy: initialized worker 2 in child 15926 for (*) min=0 max=64 smax=64  But that it never said it had initialized worker 1.  Adding my own debugging, I can see that 'worker 1' is the one which is being used by the balancer, and that the 'worker 1' hmax was always 0 *if I did not set the 'max=64' attribute.*  In other words, it was never inheriting the 'default' hmax.  Delving into the mod_balancer code, I found that    mod_proxy_balancer.c:77   init_balancer_member(proxy_server_conf *, server_rec *, proxy_balancer *)  was running    ap_proxy_initialize_worker_share(conf, workers, s);  but was not running, as far as I could tell, anything which might initialize all the other fields for the worker.  Is this a bug?  I noted that mod_proxy.c:1867 and mod_proxy.c:1868 performs a two-step initialization, where it calls ap_proxy_initialize_worker_share and then it calls   ap_proxy_initialize_worker(workers, s);  Now, I don't know if this lack of a two-step initialization in mod_proxy_balancer is a problem (or if it just a lack of understanding of the code on my part), but I am finding that adding the second initialization call to init_balancer_member seemed to fix the problem for me (the default, ThreadsPerChild based, hmax was picked up for worker 1).  Any thoughts?  Thank you for your time,  Jim  Folks,  I don't know if my previous followup on this bug was read or not, or if people are already looking at it.  Without feedback, I can't tell if I should keep pursuing this, follow up with more details, etc.  I can understand somebody telling me 'No, we know this isn't the problem' but I'm not hearing anything.  Without feedback I'm stuck not knowing if this is a bug or a fatal misunderstanding on my part.  Given httpd 2.2.1 and the following settings:    Server Version: Apache/2.2.1 (Unix) DAV/2 mod_ssl/2.2.1 OpenSSL/0.9.7a   Server Built: Apr 6 2006 00:22:26   Module Magic Number: 20051115:1   Hostname/port: server.mydomain.org:80   Timeouts: connection: 300    keep-alive: 300   MPM Name: Worker   MPM Information: Max Daemons: 2 Threaded: yes Forked: yes   Server Architecture: 32-bit   Server Root: /highwire/server/apache   Config File: -c/-C directives   Server Built With:     -D APACHE_MPM_DIR='server/mpm/worker'     -D APR_HAS_SENDFILE     -D APR_HAS_MMAP     -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)     -D APR_USE_SYSVSEM_SERIALIZE     -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT     -D APR_HAS_OTHER_CHILD     -D AP_HAVE_RELIABLE_PIPED_LOGS     -D HTTPD_ROOT='/usr/local/apache/2.2.1'     -D SUEXEC_BIN='/usr/local/apache/2.2.1/bin/suexec'     -D DEFAULT_ERRORLOG='logs/error_log'     -D AP_TYPES_CONFIG_FILE='conf/mime.types'     -D SERVER_CONFIG_FILE='conf/httpd.conf'  It appears as though the mod_proxy pool of connections is not being consistently reused when the balancer is used.  Given the configuration:    ServerLimit 2   ThreadsPerChild 10    <Proxy balancer://tomcat>     BalancerMember ajp://server.mydomain.org:8009 route=server.mydomain.org   </Proxy>    <VirtualHost  vhost.mydomain.org:80>     ServerName  vhost.mydomain.org      RewriteEngine on      RewriteCond %{ENV:HTTPD_BASE}/logs/myapp.pause -f     RewriteRule .* - [forbidden,last]      DocumentRoot vhosts/myapp/htdocs      RewriteRule ^(/+test(?:/.*)?)$ /myapp$1 [env=internal:yes]      RewriteCond %{ENV:internal} =yes     RewriteRule ^(/+myapp/.*)  $1 [passthrough,last]     RewriteRule ^/+myapp/(.*) /$1 [redirect=permanent,last]      ProxyPass /myapp balancer://tomcat/myapp stickysession=JSESSIONID nofailover=on     ProxyPassReverse / http://vhost.mydomain.org/myapp/     ProxyPassReverseCookiePath /myapp/ /   </VirtualHost>  My understanding of the documentation    http://httpd.apache.org/docs/2.2/mod/mod_proxy.html#proxypass  is that, with the above ServerLimit and ThreadPerChild limit, we should never see more than 20 connections form between Apache and any one BalancerMember target (2 servers x 10 threads = 20 total threads).  On startup, we see zero connections between Apache and Tomcat:    ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'   ;  I make one request, and see one connection form:    ; ab -n 1 http://vhost.mydomain.org/test   ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'   tcp 0 0 server.mydomain.org:59165 server.mydomain.org:8009 ESTABLISHED  Now what happens if I make 20 concurrent requests? What I would expect to see is up to 20 connections established, and no more.    ; ab -c 20 -n 20 http://vhost.mydomain.org/test   ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l        21  If I make another 20 connections, I see the connections more than double:    ; ab -c 20 -n 20 http://vhost.mydomain.org/test   ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l        44  Now look what happens when I plug in min/smax/max settings into the BalancerMember directive.  These are settings which I think the documentation indicates are the defaults, given my configuration above:    <Proxy balancer://tomcat>     BalancerMember ajp://server.mydomain.org:8009 route=server.mydomain.org min=0 smax=10 max=10   </Proxy>  After an apache restart, we have no connections, I make a bunch of requests, and see 20 connections, and never more than that.  Even when I make 50 concurrent requests, Apache simply queues and processes as it should:    ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l         0    ; ab -c 20 -n 20 http://vhost.mydomain.org/test   ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l        20    ; ab -c 50 -n 50 http://vhost.mydomain.org/test   ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l        20  If we activate the balancer, and the balancer has only one Tomcat target as in this case, shouldn't it should still be obeying the same limits as defined in the configuration.  Otherwise we have a situation where the number of proxy connections is unbounded, right?  Say Apache is configured to serve no more than 1024 requests at any one moment in time, and we wanted to balance load between two Tomcat servers.  What we'd probably do is set up two Tomcat servers which are each configured to accept 1024 requests, but we would expect to see apache balancer send ~512 requests to each Tomcat server.  What we would *not* expect to see is Apache opening more connections to a Tomcat server than Apache itself is configured to serve at any one time.  In summary, it appears to be a bug to have to declare min/smax/max values which are the same as the defaults per the documentation, without which the number of connections opened appears to be unbounded.  My examination of the code led me to believe that the source of the problem is that the BalancerMember worker is not getting its hmax value properly initialized, and that it is therefore bypassing the pool of reusable connections when it is acquiring connections (proxy_util.c:1758, in ap_proxy_acquire_connection).  If I add the patch I submitted in comment #14 and remove the min/smax/max directives, I see the behavior I am expecting -- Apache never opens more than 20 connections in all to its Tomcat server.  Looking at svn.apache.org, I see that initialization was actually removed in a previous version, though the comments do not explain why it is not appropriate to initialize the balancer worker:    http://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/modules/proxy/proxy_balancer.c?rev=105347&r1=105320&r2=105347  The only reason I can think of to have the current behavior is that somehow the dynamic of balancing between multiple backend servers is expected to be able to handle more connections -- but it just doesn't make sense to me that it would ever be normal for Apache to open more connections to any one backend server than Apache can serve itself.  If this isn't considered a bug, I'd very much appreciate it if someone would point out the reason.  Thank you for your time,   Jim  You are correct this is a bug. I checked your patch and it looks fine. I have not committed it yet, because I want to find out the reason, why we are making a copy of each worker we add to a balancer (see http://mail-archives.apache.org/mod_mbox/httpd-dev/200604.mbox/%3c443F81D8.3030401@apache.org%3e). If we would not make a copy of each worker there would be no need for additional initialization. Thank you for the details. My impression has been that the additional worker copies are somehow meant to be virtual, and the intent was to have them resolve to the actual workers.  I wasn't actually seeing where that occured in the code though.  I'll watch the email thread you refer to with interest! Please let me know if you need any further debugging/testing done.  If it turns out that copying the worker is not really the correct thing to do it would require several changes to the code to do this differently. These changes will take some time. As your patch does not run in a wrong direction and we actually have the bug now I committed your patch to the trunk as r394446 (http://svn.apache.org/viewcvs?rev=394446&view=rev). Proposed for backport to 2.2.x as r394653 (http://svn.apache.org/viewcvs?rev=394653&view=rev). Backported to 2.2.x as r396050 (http://svn.apache.org/viewcvs?rev=396050&view=rev). *** Bug 39267 has been marked as a duplicate of this bug. ***			Brad Boyer	James A. Robinson	Malcolm Amir Hussain-Gambles	Ruediger Pluem	Tino Schwarze
38277	null	RESOLVED		Lee Thompson	1137280140000	1140174744000		openssl link options When you compile apache to use a version of openssl in /opt/ssl, it will pick up the link options from the openssl version installed in /usr.      ./configure --enable-so --enable-ssl --with-ssl=/opt/ssl  I'll attatch a proposed fix for this issue	Created an attachment (id=17423) pkg-config for openssl  Think this fixes the issue That's not correct; what needs to be done to fix this is to set the PKG_CONFIG_PATH environment variable at the same time that CPPFLAGS is set when an  argument is passed to --with-ssl Fixed on the trunk:  http://svn.apache.org/viewcvs.cgi?rev=378473&view=rev  Thanks for the report. I like your patch better than mine.  Yours is compliant with the documentation of pkgconfig.			Joe Orton	Lee Thompson
38301	null	RESOLVED		Alex Hudson	1137502200000	1188473369000		Consider adding OpenDocument mime types Hi.  Please consider adding the following OpenDocument mime types to the default apache configuration. The OpenDocument format is the OASIS standard for writing documents, and is supported by a number of applications including OpenOffice.org, KOffice, Abiword, and many more are developing support (e.g., Apache Lenya).      http://opendocumentfellowship.org/Resources/ForWebmasters  I attach a patch to add these types.  The mime types are in the process of being formally registered:    http://lists.oasis-open.org/archives/office/200505/msg00002.html  This is related to bug #37185, I think that bug should possibly depend on this one. Also, would it be worth entering an equivalent bug against apache 1.3?	Created an attachment (id=17443) Proposed patch to add the necessary mime types.  Just to update this bug, the MIME types mentioned have now been registered with IANA; see vnd.oasis.opendocument.*  It would be good to see future versions of Apache deliver these files correctly out-of-the-box. The full list can be found at IANA:    http://www.iana.org/assignments/media-types/application/ Committed to trunk in rev 571267. 			Alex Hudson	Lars Nood	Roy T. Fielding
38340	null	RESOLVED		Aleksey Pesternikov	1137806460000	1137847790000		mod_proxy_ajp does not support support common headers (0xA0??) mod_proxy_ajp does not support support common header codes (0xA0??) described  in http://httpd.apache.org/docs/2.2/mod/mod_proxy_ajp.html.en#resppacketstruct    HOW TO REPEAT:  use with tomcat 4.0:  [Fri Jan 20 14:07:48 2006] [debug] mod_proxy_ajp.c(195): proxy:  APR_BUCKET_IS_EOS  [Fri Jan 20 14:07:48 2006] [debug] mod_proxy_ajp.c(200): proxy: data to read  (max 8186 at 4)  [Fri Jan 20 14:07:48 2006] [debug] mod_proxy_ajp.c(215): proxy: got 0 bytes of  data  [Fri Jan 20 14:07:51 2006] [debug] ajp_header.c(643): ajp_read_header:  ajp_ilink_received 04  [Fri Jan 20 14:07:51 2006] [debug] ajp_header.c(653): ajp_parse_type: got 04  [Fri Jan 20 14:07:51 2006] [debug] ajp_header.c(484): ajp_unmarshal_response:  status = 200  [Fri Jan 20 14:07:51 2006] [debug] ajp_header.c(495): ajp_unmarshal_response:  Number of headers is = 2  [Fri Jan 20 14:07:51 2006] [error] ajp_msg_get_string():  BufferOverflowException 16 55  [Fri Jan 20 14:07:51 2006] [error] ajp_unmarshal_response: Null header value  [Fri Jan 20 14:07:51 2006] [error] (120001)APR does not understand this error  code: proxy: send body failed to (null) (localhost)  [Fri Jan 20 14:07:51 2006] [debug] proxy_util.c(1769): proxy: AJP: has  released connection for (localhost)    The problem is in responce packet parsing code.    HOW TO FIX:  Apply patch:  --- ajp_header.c.ORIG   Fri Jan 20 15:15:58 2006  +++ ajp_header.c        Fri Jan 20 15:39:33 2006  @@ -506,7 +506,7 @@           }             if ((name & 0XFF00) == 0XA000) {  -            ajp_msg_peek_uint16(msg, &name);  +            ajp_msg_get_uint16(msg, &name);               stringname = long_res_header_for_sc(name);               if (stringname == NULL) {                   ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server,	Created an attachment (id=17470) Patch against 2.2  Created an attachment (id=17471) Patch against trunk  The trunk version is got ahead so patch is different Thanks for the patch. From the first glance it seems to do the correct thing. Could you please attach a testcase (e.g. a jsp) such that I can doublecheck the patch? Forget about the example. I was not able to reproduce the problem, because I used Tomcat 5 to test which does not sent the headers back as integers any longer but as strings. BTW: Your trunk version of the patch is wrong as we need to peek at this position of the code. Nevertheless the 2.2.x version looks good and I will take care of it. Committed to trunk as r371013  (http://svn.apache.org/viewcvs.cgi?rev=371013&view=rev) and proposed for  backport as r371014 (http://svn.apache.org/viewcvs.cgi?rev=&view=rev).  (In reply to comment #5)  > Committed to trunk as r371013   > (http://svn.apache.org/viewcvs.cgi?rev=371013&view=rev) and proposed for   > backport as r371014 (http://svn.apache.org/viewcvs.cgi?rev=&view=rev).     Thank you, Ruediger!    I have a small comment on reproducing the problem.  default connector in Tomcat 4.1 is org.apache.coyote.tomcat4.CoyoteConnector  which works ok.  To reproduce the problem you have to use  org.apache.ajp.tomcat4.Ajp13Connector.  This is a part of server.xml as of jakarta-tomcat-4.1.31-src.tar.gz:        <!-- Define a Coyote/JK2 AJP 1.3 Connector on port 8009 -->      <Connector className='org.apache.coyote.tomcat4.CoyoteConnector'                 port='8009' minProcessors='5' maxProcessors='75'                 enableLookups='true' redirectPort='8443'                 acceptCount='10' debug='0' connectionTimeout='0'                 useURIValidationHack='false'                  protocolHandlerClassName='org.apache.jk.server.JkCoyoteHandler'/>        <!-- Define an AJP 1.3 Connector on port 8009 -->      <!--      <Connector className='org.apache.ajp.tomcat4.Ajp13Connector'                 port='8009' minProcessors='5' maxProcessors='75'                 acceptCount='10' debug='0'/>      -->    So you need to comment out the first connector and uncomment the second one.  After that any access (even 404) will cause the problem.    (In reply to comment #6)  > To reproduce the problem you have to use  > org.apache.ajp.tomcat4.Ajp13Connector.  This is the one that had been marked deprecated some time ago :-).  (In reply to comment #7)  > > To reproduce the problem you have to use   > > org.apache.ajp.tomcat4.Ajp13Connector.  >   > This is the one that had been marked deprecated some time ago :-).    Not a good reason to break own specs  http://httpd.apache.org/docs/2.2/mod/mod_proxy_ajp.html.en#resppacketstruct   			Aleksey Pesternikov	Ruediger Pluem
38403	null	RESOLVED		matthias	1138303320000	1143929758000		Child-Thread uses 100%CPU usage, mod_proxy ? This bug is probably related to #36951, however the offered solution was for 2.1.8 and not merged into 2.2.0.  Setup: Apache 2.2.0 is used as a reverse proxy for accelerating an apache1.3+php on the same host. we are using worker mdm and mod_proxy is configured to use a pool. Apache is build from current source.  Problem: At least once a day 1 or 2 threads consume 100% of their cpu (dual+ht, so system remains responsive). strace says that the process is waiting for the child  futex(0xb2b10bf8, FUTEX_WAIT, 1847, NULL <unfinished ...>  while the child (1847) is in a loop of:   close(-1)                               = -1 EBADF (Bad file descriptor)  (the other thread did the same)  the worker-thread and its parent process remain up, even if all other worker threads of this process have been shutdown and apache already uses other processes to service requests.  ps -L -e -F UID        PID  PPID   LWP  C NLWP    SZ  RSS PSR STIME TTY          TIME CMD ... nobody    1839 19001  1839  0    3 693301 235192 3 Jan25 ?       00:00:00 /home/apache22/bin/httpd -k start nobody    1839 19001  1847 99    3 693301 235192 1 Jan25 ?       1-03:37:44 /home/apache22/bin/httpd -k start nobody    1839 19001  1928 99    3 693301 235192 2 Jan25 ?       1-03:37:54 /home/apache22/bin/httpd -k start ... (these are all threads of PID 1839)  I could not get a backtrace of the crazy thread, gdb hangs after this:  gdb httpd 1928 ... [Thread debugging using libthread_db enabled] [New Thread -1209694528 (LWP 1839)]  the threads show up in extended server status: Srv\tPID\tAcc\tM\tCPU \tSS\tReq\tConn\tChild\tSlot\tClient\tVHost\tRequest 0-0\t1839\t8/32/6705\tW \t13.39\t101250\t0\t19.5\t0.14\t40.40\tx.x.x.x\tfrontservername\tGET /proxied/url/... 0-0\t1839\t30/117/6898\tR \t13.59\t101250\t0\t307.9\t0.60\t42.39 \t?\t? ...  they survive gracefull restarts and apache restart kills them with SIGKILL  I have the feeling that this bug is triggered by timeouts or partial responses of the accelerated server. (We had database problems with the backend server, so a lot of proxy requests failed, see error_log, however there was no error message associated with the requested ressource, remote_addr or processids from the extend status (probably because the threads did not yet get to log anything)  proxy: error reading status line from remote server 127.0.0.1 proxy: Error reading from remote server returned by proxy: error reading status line from remote server (null) (70007)The timeout specified has expired: proxy: prefetch request body failed to 127.0.0.1:8081 (127.0.0.1) from   We log the x-forwarded-for header on the backend, and the ip from the server status does not show up, so the request headers were never received by the backend server.	> This bug is probably related to #36951, however the offered solution was for > 2.1.8 and not merged into 2.2.0. sorry wrong guess, ' rv=APR_EOF; ' is in 2.2.0, it's probably a similar thing on another line  (In reply to comment #1) > sorry wrong guess, ' rv=APR_EOF; ' is in 2.2.0, it's probably a similar thing on > another line  YES, about 35 lines above is the same situation as in #36951 only for the another socket (i guess the one to the remote server). (this makes sense, as I had a 'buggy' backend server, while the other bug hat 'buggy' client.  I'm trying the patched version and get the info back here.  If this sounds like a good thing, can someone provide a patch and get this into CVS ? Sorry I'm not that good with this Could you please let me know where in the code (filename, line) you suppose the error? PR #36951 is about mod_proxy_connect. I doubt that it is used in your reverse proxy configuration. Regarding the problem getting a backtrace: You called gdb with the LWP id:  gdb httpd 1928  Try to call it with the PID of the LWP. That would be  gdb httpd -p 1839  Hope that helps. Further debugging tips can be found at: http://httpd.apache.org/dev/debugging.html Forgot one thing: Debugging can be problematic if you compiled your httpd with --enable-pie on Linux. its build without pie, however i tried to build everything static .  thx for the gdb hint, heres the output  (gdb) info threads   3 Thread -1884591184 (LWP 8768)  0xb7e7f308 in allocator_free () from /home/apache22/lib/libapr-1.so.0   2 Thread -2052428880 (LWP 8785)  0x0807b039 in ap_core_input_filter ()   1 Thread -1209833792 (LWP 8702)  0xb7f89402 in ?? () (gdb) thread 3 [Switching to thread 3 (Thread -1884591184 (LWP 8768))]#0  0xb7e7f308 in allocator_free () from /home/apache22/lib/libapr-1.so.0 (gdb) bt #0  0xb7e7f308 in allocator_free () from /home/apache22/lib/libapr-1.so.0 #1  0xb7e7f224 in apr_allocator_free () from /home/apache22/lib/libapr-1.so.0 #2  0xb7f6a81f in apr_bucket_free () from /home/apache22/lib/libaprutil-1.so.0 #3  0xb7f6b146 in heap_bucket_destroy () from /home/apache22/lib/libaprutil-1.so.0 #4  0xb7f6b35c in apr_brigade_cleanup () from /home/apache22/lib/libaprutil-1.so.0 #5  0xb7f6b3b1 in apr_brigade_destroy () from /home/apache22/lib/libaprutil-1.so.0 #6  0x0806e810 in ap_getline () #7  0x0809b7a0 in ap_proxy_http_process_response () #8  0x0809c878 in proxy_http_handler () #9  0x08095249 in proxy_run_scheme_handler () #10 0x08092ab1 in proxy_handler () #11 0x0807ce41 in ap_run_handler () #12 0x0807d581 in ap_invoke_handler () #13 0x080b4a66 in ap_process_request () #14 0x080b1f7c in ap_process_http_connection () #15 0x080842d8 in ap_run_process_connection () #16 0x08084707 in ap_process_connection () #17 0x080c2ecb in process_socket () #18 0x080c36d4 in worker_thread () #19 0xb7e8b868 in dummy_worker () from /home/apache22/lib/libapr-1.so.0 #20 0x00bfb341 in start_thread () from /lib/tls/libpthread.so.0 #21 0x00b136fe in clone () from /lib/tls/libc.so.6 (gdb) thread 2 [Switching to thread 2 (Thread -2052428880 (LWP 8785))]#0  0x0807b039 in ap_core_input_filter () (gdb) bt #0  0x0807b039 in ap_core_input_filter () #1  0x08087957 in ap_get_brigade () #2  0x0806e3c8 in ap_rgetline_core () #3  0x0806e7ff in ap_getline () #4  0x0809b4f9 in ap_proxy_read_headers () #5  0x0809ba00 in ap_proxy_http_process_response () #6  0x0809c878 in proxy_http_handler () #7  0x08095249 in proxy_run_scheme_handler () #8  0x08092ab1 in proxy_handler () #9  0x0807ce41 in ap_run_handler () #10 0x0807d581 in ap_invoke_handler () #11 0x080b4a66 in ap_process_request () #12 0x080b1f7c in ap_process_http_connection () #13 0x080842d8 in ap_run_process_connection () #14 0x08084707 in ap_process_connection () #15 0x080c2ecb in process_socket () #16 0x080c36d4 in worker_thread () #17 0xb7e8b868 in dummy_worker () from /home/apache22/lib/libapr-1.so.0 #18 0x00bfb341 in start_thread () from /lib/tls/libpthread.so.0 #19 0x00b136fe in clone () from /lib/tls/libc.so.6 (gdb) thread 1 [Switching to thread 1 (Thread -1209833792 (LWP 8702))]#0  0xb7f89402 in ?? () (gdb) bt #0  0xb7f89402 in ?? () #1  0x00bfc06d in pthread_join () from /lib/tls/libpthread.so.0 #2  0xb7e8ba3b in apr_thread_join () from /home/apache22/lib/libapr-1.so.0 #3  0x080c3c89 in join_workers () #4  0x080c4090 in child_main () #5  0x080c419d in make_child () #6  0x080c46c3 in perform_idle_server_maintenance () #7  0x080c48e4 in server_main_loop () #8  0x080c4bb8 in ap_mpm_run () #9  0x080683aa in main ()   I reattached the process a few times, the threads seem to do not leave their functions.  stepi circles around this:  0xb7e7f277 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f27a in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f27c in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f27f in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f282 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f285 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f288 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f28c in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2a6 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2aa in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2ac in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2af in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2b2 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2b5 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2b9 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2bb in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2bd in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2cd in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2d0 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2d3 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2d6 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2da in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2dd in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2e0 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f2e2 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f300 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f303 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f306 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f308 in allocator_free () from /home/apache22/lib/libapr-1.so.0 0xb7e7f30a in allocator_free () from /home/apache22/lib/libapr-1.so.0 This was the proposed patch, but i guess you're right and this is not used in my setup.   *** mod_proxy_connect.c.myversion 2006-01-26 18:32:12.000000000 +0000 --- mod_proxy_connect.c.orig    2006-01-27 11:32:08.000000000 +0000 *************** static int proxy_connect_handler(request *** 325,334 ****                       else                           break;                   } !                 else if ((pollevent & APR_POLLERR) || (pollevent & APR_POLLHUP)) { !                   rv = APR_EOF;                       break; -               }               }               else if (cur->desc.s == client_socket) {                   pollevent = cur->rtnevents; --- 325,332 ----                       else                           break;                   } !                 else if ((pollevent & APR_POLLERR) || (pollevent & APR_POLLHUP))                       break;               }               else if (cur->desc.s == client_socket) {                   pollevent = cur->rtnevents;     Another interesting point:   I configured the server to use a pool for to the backend server:   it limits the maximal connections to the backend server. this works normal, but if i have this amok threads it stops working. could be related to the behaviour of a graceful restart ..  > it limits the maximal connections to the backend server. this works normal, but > if i have this amok threads it stops working. could be related to the behaviour > of a graceful restart .. >   to clarify this is the pool: ProxyPass           / http://127.0.0.1:8081/ min=1 smax=10 max=14 ttl=120 acquire=10000 timeout=5 retry=2  wenn starting multiple clients against a sleep.php there are no more than 14 conenctions on the backend. with a amok-thread + possibly after a graceful restart. there's no limit on the connections to the backend anymore.   this could be intended behaviour of graceful restart or it is related to the loop above which prevents apache from counting.   I know that the limit is per process, so i double checked that there's only one process with 250 threads running in apache2.  Please do not change the assignments of bugs. (In reply to comment #8) > Please do not change the assignments of bugs. I'm sorry, this info on the status link encouraged me: 'Once you provide this information, please reassign thebug back to the person that placed it in the NEEDINFO status.' http://issues.apache.org/bugzilla/page.cgi?id=fields.html#status To be sure that the thread is really looping in allocator_free, could you please run ltrace against the process to see which library calls it does? we were unable to ltrace the processes (ltrace returns without error, and sometimes kills the amok process). we found out from looking at /proc, that it is not the allocator_free thread which consumes the cpu, but the core_input_filter thread (telling from the SleepAVG in /proc/PID/status).  we recompiled with -ggdb and obtained more infos at the next occurence of the phenomenon.   (gdb) info threads   3 Thread -2063254608 (LWP 9309)  allocator_free (allocator=0x195737d0, node=0xa52eec0) at memory/unix/apr_pools.c:332   2 Thread 1801628592 (LWP 9350)  0x0807af5b in ap_core_input_filter (f=0x195740b8, b=0x9feddc8, mode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)     at core_filters.c:141   1 Thread -1210169664 (LWP 9228)  0xb7f09402 in __kernel_vsyscall ()  I attach a complete backtrace to this bug. Bottom line is, that we are stuck on this line:   ap_core_input_filter (f=0x195740b8, b=0x9feddc8, mode=AP_MODE_GETLINE,     block=APR_BLOCK_READ, readbytes=0) at core_filters.c:141 141         BRIGADE_NORMALIZE(ctx->b);   code says this:      /* ### This is bad. */     BRIGADE_NORMALIZE(ctx->b);   but I'm not sure whether 'this is bad' refers to a possible bug or just a performance issue.   Is there a simple way to inspect the BRIGADE in gdb ? I guess there's a special situation with the brigade or its buckets, that arives from the fact that we run the http-backend on localhost (probably caused by unusual/local tcp behaviour ?) Created an attachment (id=17584) full gdb backtrace, (copied from shell)  (In reply to comment #11) Thanks for the update.  >  > ap_core_input_filter (f=0x195740b8, b=0x9feddc8, mode=AP_MODE_GETLINE, >     block=APR_BLOCK_READ, readbytes=0) at core_filters.c:141 > 141         BRIGADE_NORMALIZE(ctx->b); >  >  > code says this: >  >     /* ### This is bad. */ >     BRIGADE_NORMALIZE(ctx->b); >  >  > but I'm not sure whether 'this is bad' refers to a possible bug or just a > performance issue.  >  > Is there a simple way to inspect the BRIGADE in gdb ? I guess there's a special  Yes, there is a helpful macro to inspect a brigade in gdb (dump_brigade). Please have a look at the end of the section of http://httpd.apache.org/dev/debugging.html#gdb  BRIGADE_NORMALIZE is a macro that does a loop. May it would be helpful to replace  BRIGADE_NORMALIZE(ctx->b);  with the expanded macro to see if the loop is never left.  do {      apr_bucket *e = APR_BRIGADE_FIRST(ctx->b);      do {           if (e->length == 0 && !APR_BUCKET_IS_METADATA(e)) {              apr_bucket *d;              d = APR_BUCKET_NEXT(e);              apr_bucket_delete(e);              e = d;          }          else {              e = APR_BUCKET_NEXT(e);          }      } while (!APR_BRIGADE_EMPTY(ctx->b) && (e != APR_BRIGADE_SENTINEL(ctx->b)));  } while (0)  Furthermore it would be better to use step / next instead of stepi to check where the code circles. stepi only executes one assembler instruction, whereas step executes one line of C code.  In your initial comment to this bug you mentioned that a thread is looping with close(-1). Would it be possible to get a backtrace of this thread?  So I would recommend the following next steps:  1. Expand the BRIGADE_NORMALIZE macro and recompile. 2. If the error occurs again do a dump_brigade ctx->b and attach the output 3. Check with if the BRIGADE_NORMALIZE loop is left. For this set a breakpoint after the loop and cont. If you reach it the loop is left if not we circle in the loop. 4. Try to get a backtrace of the thread that loops with close(-1) short update: I'm still trying to hunt it down. here's a short summary:  Currently not reproducable at will, but steadily recurring about once a day.   As long as I did close looks at it, there are always 2 threads with similar stack trace ( ap_proxy_http_process_response, one ap_proxy_read_headers, the other just ap_getline ). While one is cleaning up, the other is probably stuck in BRIGADE_NORMALIZE (which also does some cleanup). Sounds like a race condition where 2 threads are cleaning up the same brigade. (I will try to get some info on the brigade that the other thread tries to cleanup, next time).   step/next did not return the last time, so the MACRO line was never left.   the strace close(-1) threads does only show up 1 in 10 times. Either its a different bug or it is about the repeated cleanup/normalization of a socket-bucket. Most of the times the threads produce no system/library calls, so I guess they are caught in a very small loop. We probably found the root of evil:  a graceful restart does destroy but not reinitialize the resource list that keeps the pooled connections. this is due to a early return in ap_proxy_initialize_worker (proxy_util.c) when called again. Our patch is not nice, but worked for us. (restart instead of graceful did it also as workaround)   --- proxy_util.c        2006-02-06 13:59:35.000000000 +0000 +++ proxy_util.c.orig   2006-02-06 17:48:39.000000000 +0000 @@ -1629,7 +1630,7 @@      int mpm_threads;  #endif  -    if (worker->s->status & PROXY_WORKER_INITIALIZED && worker->cp->res) { +    if (worker->s->status & PROXY_WORKER_INITIALIZED) {          /* The worker is already initialized */          return APR_SUCCESS;      }   We noticed this when we tried to force the 99% cpu threads by stressing the webserver with ab ( -k -c 20 ). after a graceful restart the server was likely to coredump at   proxy_util.c:1758 (*conn)->worker = worker;  because conn was null. it seems that conn is deleted be another thread. conditional breakpoints above proxy_util.c:1745 (rv = APR_SUCCESS;) never spotted a conn = 0.  before the graceful we run through this condition (no problems) but after gracefull res is null.      if (worker->hmax && worker->cp->res) {         rv = apr_reslist_acquire(worker->cp->res, (void **)conn);     }  this change in flow introduces the concurrency problems. is the else branch without the pool threadsafe or only intended for prefork ?   Some facts that would speek for the graceful theory: a) 99% threads only appeared on servers in the farm that used graceful and not restart b) they only appeared after a graceful, never directly after startup c) after a graceful, there was no limit on the number of backend connections   on the setup: We use Dual Xeons with Hyperthreading (so there might be higher concurrency) and we compiled with --enable-nonportable-atomics Thanks for the update and the in depth analysis. From my first brief into this I agree that the resource list needs to be initialized in these cases. But it seems also that your patch as you assumed isn't complete. From a first brief view I think more fixes are required. As I am still wondering whether the problem that is fixed by your patch is really the root cause of the problem you reported I would like you to keep me updated if the problem is gone with your patched httpd's. Anyway: Good work. Feedback: we are running almost a week now with the patched version. So far this server remains free of problems, except for 2 seg faults in 5 days. (so there's more to do as you said)  On the other servers in the farm I got one 99% percent process in the last 5 days and a whole bunch of segfaults.   They are all running non-patched non-debug httpds and are running on same hardware, kernel, config etc. except that they do a restart instead of graceful, which has helped so far (i thought). So if 'restart' always runs the if-branch that creates the pool, than you're right and it was not the root of OUR evil).  I also have to modify my statement that 99er only appear on graceful restarting apaches, they are just more likely to be seen there and to survive long enough to be analyzed.  We will do more testing with patched versions next week and see if we can get more insight. I'll keep you updated. Meanwhile patches have been created on trunk that are proposed for backport:  http://svn.apache.org/viewcvs?rev=377738&view=rev http://svn.apache.org/viewcvs?rev=377780&view=rev  Backported to 2.2.1.			Ruediger Pluem	matthias
38448	null	RESOLVED		Stijn Hoop	1138638420000	1188541710000		mod_proxy encodes ~ to %7E in Reverse Proxy mode In a reverse proxy setup I encountered a problem with user directories; it seemed like every now and then users got redirected to http://host/%7Euser instead of the correct http://host/~user. After some debugging I figured out that the frontend mod_proxy was 'canonicalizing' URLs, thereby encoding ~ as %7E. This would not be an issue but for lots of backend server software that relied on the URL passed to the backend server to be the same as the one the user saw in their browsers. Now, this is of course a bad assumption *but* I don't really know why the canonicalization happens in the first place, or even why ~ is not considered a safe character.  I have attached a patch that simply adds '~' to the set of 'reserved' characters for modules/proxy/proxy_util.c:ap_proxy_canonenc. It does the job on my site. Is there any reason not to apply it?  Note: I tried to subscribe to apache-users@ to ask around for other people experiencing this bug bug the list never confirmed my emails...	Created an attachment (id=17536) patch to reserve ~ character in mod_proxy  Here is the trivial patch. well.. guess nobody's interested either way? (In reply to comment #2) > well.. guess nobody's interested either way?  ~ may or may not be a reserved character according to which edition of the RFC  you read.  Encoding it as %7E is a safe option.  I don't see any strong reason to apply your patch (but feel free to try and  convince me).  Neither do I see any reason to close this report - it's marked  as PatchAvailable for the benefit of anyone who wants it. I changed my mind since my previous comment, and I've committed this  to /trunk/.  Thanks:-) Many thanks! That's one less customized package to maintain! Fixed in 2.2 branch (r571456).  Closing.			Nick Kew	Stijn Hoop
38449	null	RESOLVED		Bjoern Voigt	1138638660000	1138658679000		CacheSize is documented but not available in Apache 2.2 There is a link to 'CacheSize' in the documentation of Apache 2.2 mod_cache:    http://httpd.apache.org/docs/2.2/mod/mod_cache.html  The link points to     http://httpd.apache.org/docs/2.2/mod/mod_disk_cache.html#cacheroot  But since, 'CacheSize' is not available any more the 'CacheSize' link should be removed. The cache size could now be limited with htcacheclean:    http://httpd.apache.org/docs/2.2/programs/htcacheclean.html	Thanks for the fix. Committed as r373585 (http://svn.apache.org/viewcvs.cgi?rev=373585&view=rev) to the trunk and as r373588 (http://svn.apache.org/viewcvs.cgi?rev=373588&view=rev) to 2.2.x			Ruediger Pluem
38521	null	RESOLVED		Ole Kv	1139169360000	1139171569000		 404 URL bug in 'Background - Frequently Asked Questions' (http://httpd.apache.org/docs/2.2/faq/background.html) The link ''Powered by Apache' graphic' (http://httpd.apache.org/docs/apache_pb.gif) routes to a non-existing document (=> 404 Not Found).	Actually a 301 redirect, which then returns 404.    Now fixed in svn, so that'll percolate through to the site soon - thanks. 			Nick Kew
38524	null	RESOLVED		matthias	1139191920000	1139696413000		mod_proxy(_http) does not send keep-alive headers The headers of a proxied page do not contain a keep-alive or connection headers, but the server acts according to its local keepalive timeout and max count, but the client-browser needs to guess, wether the server supports keep-alive.   Setup: ./configure --enable-proxy --enable-proxy-http  Config: ProxyPass /proxy/ http://httpd.apache.org/  Testcase: #telnet localhost 80 GET /proxy/robots.txt HTTP/1.1 Host: httpd.apache.org Connection: keep-alive User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1;)   The response neither contains a Connection: nor a Keep-alive: header. However the connection remains open for 5 seconds and is then 'closed by the foreign host'. A 'GET / HTTP/1.1' returns:  Keep-Alive: timeout=5, max=100 Connection: Keep-Alive  talking directly to the remote server also returns these values, they only get lost passing the proxy. (this also happens when configured as forward proxy)  BTW: a 'connection: close' request header makes its way through to the backend server, which causes the connection between front and backend server to be dropped. When used to accelerate a backend server this prevents the connection from being reused for another client or the next request.	Created an attachment (id=17619) Patch against trunk  I had a look in this issue and have an idea why this happens. I still need some discussion for this patch on the dev list, but I would like to know if it fixes your problem. So could you please try the attached patch and check if it solves the problem? thanks for the quick patch, it works for me. However you also need to get rid of line 616 which already clears the connection header from the headers_in. (In reply to comment #2) > thanks for the quick patch, it works for me. However you also need to get rid of > line 616 which already clears the connection header from the headers_in.  Thanks for the quick test. I think you mean line 620, don't you? Alas! Stupid copy and paste error. Thanks for pointing it out. I will discuss the patch on the dev list and keep you in the loop.   Next stupid thing of mine: Of course its 616 in the patched version, but 620 in the unpatched one :-). I really should RTFM of patch and diff, so line numbers and order of fileargs  wouldn't be a problem ...  2 things I'm wondering as code novice about: does the copied table get freed and wouldn't it be better to just save the removed headers ? (P.S: patch isnt't in productive environment yet, so we don't know of possible side-effects) (In reply to comment #5) > I really should RTFM of patch and diff, so line numbers and order of fileargs  > wouldn't be a problem ...  I should have looked at the patched version :-).  >  > 2 things I'm wondering as code novice about: does the copied table get freed and  Yes, because the space is allocated from a memory pool and this pool is cleaned after the end of the request.  > wouldn't it be better to just save the removed headers ? (P.S: patch isnt't in > productive environment yet, so we don't know of possible side-effects)  In principle yes, especially if the other headers are large. I have to take a look into it whether the extra effort of doing so is justified, because several headers are removed by ap_proxy_clear_connection and it adds some work to save them and merge them back in. The full copy approach has a simpler logic and if possible I like to keep things simple :-) (In reply to comment #6)  >  > > wouldn't it be better to just save the removed headers ? (P.S: patch isnt't in > > productive environment yet, so we don't know of possible side-effects)  Meanwhile I had a closer look into this and as apr_table_copy only copies the pointers to the key / value pairs of the headers I guess we neither gain much speed (actually I think we will loose speed for a small number of headers) nor save a reasonable amount of memory (also guess that we waste memory for a low number of headers) by only saving the removed headers and merg??ng them back in later on. I keep you updated.   I committed two patches to the trunk (r377053 and r377057, http://svn.apache.org/viewcvs.cgi?rev=377053&view=rev, http://svn.apache.org/viewcvs.cgi?rev=377057&view=rev). r377053 fixes the problem with the missing keepalive headers in the response, wheras r377055 prevents the closing of the backend connection if the client send Connection: close. http://svn.apache.org/viewcvs.cgi?rev=377053&view=rev introduced a pool memory problem since I used the wrong pool for apr_table_copy. http://svn.apache.org/viewcvs.cgi?rev=377525&view=rev should fix this, but I am waiting for confirmation by other developers. I keep you updated.   It has been confirmed that http://svn.apache.org/viewcvs.cgi?rev=377525&view=rev fixes the pool memory problem. So could you please test with both patches applied and let me know the results? Many thanks. we are running the patches productive, keepalive headers are correctly exchanged between browser and frontend apache (mod_proxy). Backend Connections remain open as far as the backends keep alive settings permits it. No memory problems noticed. Good work. Thanks. We were experiencing the same problem for our reverse proxy (v2.0) and therefore updated to version 2.2.2 that included this patch. For testing and debugging purposes we used HTTP connections to our backend (a webdispatcher). Client <--https--> Apache2.2.2 as Reverse Proxy <--http--> Dispatcher <--http--> App Server  For production we need a HTTPS connection to this webdispatcher. Client <--https--> Apache2.2.2 as Reverse Proxy <--httpS--> Dispatcher <--http--> App Server  When using this setup (mod_proxy + mod_ssl), we're experiencing a lot more connections in contrast to the setup without mod_ssl. Since I cannot sniff on these HTTPS connections, I cannot provide you with any logs.  Has anyone experienced the same problem? Any suggestions?  From mod_proxy_http.c Apache 2.2.2    /*      * TODO: Currently we cannot handle persistent SSL backend connections,      * because we recreate backend->connection for each request and thus      * try to initialize an already existing SSL connection. This does      * not work.      */     if (is_ssl)         backend->close_on_recycle = 1;  (In reply to comment #12) > We were experiencing the same problem for our reverse proxy (v2.0) and therefore > updated to version 2.2.2 that included this patch. > For testing and debugging purposes we used HTTP connections to our backend (a > webdispatcher). > Client <--https--> Apache2.2.2 as Reverse Proxy <--http--> Dispatcher <--http--> > App Server >  > For production we need a HTTPS connection to this webdispatcher. > Client <--https--> Apache2.2.2 as Reverse Proxy <--httpS--> Dispatcher > <--http--> App Server >  > When using this setup (mod_proxy + mod_ssl), we're experiencing a lot more > connections in contrast to the setup without mod_ssl. > Since I cannot sniff on these HTTPS connections, I cannot provide you with any logs. >  > Has anyone experienced the same problem? Any suggestions?   (In reply to comment #12) > We were experiencing the same problem for our reverse proxy (v2.0) and therefore > updated to version 2.2.2 that included this patch. > For testing and debugging purposes we used HTTP connections to our backend (a > webdispatcher). > Client <--https--> Apache2.2.2 as Reverse Proxy <--http--> Dispatcher <--http--> > App Server >  > For production we need a HTTPS connection to this webdispatcher. > Client <--https--> Apache2.2.2 as Reverse Proxy <--httpS--> Dispatcher > <--http--> App Server >  > When using this setup (mod_proxy + mod_ssl), we're experiencing a lot more > connections in contrast to the setup without mod_ssl. > Since I cannot sniff on these HTTPS connections, I cannot provide you with any logs. >  > Has anyone experienced the same problem? Any suggestions?   (In reply to comment #12) > We were experiencing the same problem for our reverse proxy (v2.0) and therefore > updated to version 2.2.2 that included this patch. > For testing and debugging purposes we used HTTP connections to our backend (a > webdispatcher). > Client <--https--> Apache2.2.2 as Reverse Proxy <--http--> Dispatcher <--http--> > App Server >  > For production we need a HTTPS connection to this webdispatcher. > Client <--https--> Apache2.2.2 as Reverse Proxy <--httpS--> Dispatcher > <--http--> App Server >  > When using this setup (mod_proxy + mod_ssl), we're experiencing a lot more > connections in contrast to the setup without mod_ssl. > Since I cannot sniff on these HTTPS connections, I cannot provide you with any logs. >  > Has anyone experienced the same problem? Any suggestions?   			James	Philip Brusten	Ruediger Pluem	matthias
38602	null	RESOLVED		Jean Dagenais	1139546160000	1141763753000		Keep Alive not workwing with mod_proxy (New socket created for every request proxied) We are testing Apache 2.2 before migrating to this new release, and we found  out that Apache does not keep sockets open with or other server (JBoss 3.2).  The same configuration is working fine on Apache 2.0.55.  We tried with both worker and prefork MPM, and this is the same behavior.  Apache is runing on Red Hat AS 4.0, Update2, 64 Bit, on a Dell Dual Core 1850.   The Keep-Alive connection between the IE Brower and Apache works OK, and no  socket is created between multiple requests, but every requests sent(proxied)  between Apache and JBoss cause a new socket to be created.  IE includes the HTTP header: Connection: Keep-Alive, but Apache does not send  it to JBosss.  This is an example of the message received from IE, and then sent to JBOSS  HTTP Request #1 IE Browser -> Apache  Referer:  http://mvperf21/application/company/navigation/fx/app/applicationStatusBar.jsp If-Modified-Since: Wed, 01 Jan 2003 18:23:51 GMT Accept-Encoding: gzip, deflate User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR  1.1.4322) Host: mvperf21 Connection: Keep-Alive           *************Keep Alive Header ********** Cookie: JSESSIONID=83A9AE074F3F79CF0F7D24D88EE02167; OrganizationId=AA5000;  uid=KsXw/VpMpxQPpqeqxomCRnH515Hx9LID9MpiUAvkw9c=;  __JPW_SID__=83A9AE074F3F79CF0F7D24D88EE02167   HTTP/1.1 200 OK Date: Fri, 10 Feb 2006 02:31:45 GMT Cache-Control: no-cache Pragma: No-cache Expires: Thu, 01 Jan 1970 00:00:00 GMT Content-Type: text/xml;charset=ISO-8859-1 Content-Length: 54  <OK ts='1139538705730' pt='101'> </OK>     HTTP Request #2 Apache -> JBoss (No Keep-Aliver HTTP Header ????)   GET /proxy/company/proxy/u.jsp? diagnum=220&userid=82955&count=20&wait=100&priority=1&ackIdList=&latency=176.49 542718129723&realLatency=230&MsgInterval=331&MsgProcTime=70&lastMsgCount=0&QTPr ocTime=20&IRProcTime=10&sts=200 HTTP/1.1 Host: 198.252.177.19:8080 Accept: */* Accept-Language: en-us Referer:  http://mvperf21/application/company/navigation/fx/app/applicationStatusBar.jsp If-Modified-Since: Wed, 01 Jan 2003 18:23:51 GMT Accept-Encoding: gzip, deflate User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR  1.1.4322) Cookie: JSESSIONID=83A9AE074F3F79CF0F7D24D88EE02167; OrganizationId=AA5000;  uid=KsXw/VpMpxQPpqeqxomCRnH515Hx9LID9MpiUAvkw9c=;  __JPW_SID__=83A9AE074F3F79CF0F7D24D88EE02167 Max-Forwards: 10 X-Forwarded-For: 198.252.177.123 X-Forwarded-Host: mvperf21 X-Forwarded-Server: mvperf21.company.com  HTTP/1.1 200 OK Cache-Control: no-cache Pragma: No-cache Expires: Thu, 01 Jan 1970 00:00:00 GMT Content-Type: text/xml;charset=ISO-8859-1 Content-Length: 54 Date: Fri, 10 Feb 2006 02:31:45 GMT    This is the content of the httpd-vhosts.conf   <VirtualHost 198.252.177.38:80> ServerAdmin admin@company.com DocumentRoot '/company/opt/apache2/htdocs/' ServerName mvperf21.integral.com:80 ErrorLog logs/error_log  Timeout 300 KeepAlive On MaxKeepAliveRequests 1000 KeepAliveTimeout 100  ProxyRequests Off \t ProxyPass        /proxy/ http://198.252.177.19:8080/proxy/ smax=5 max=20  ttl=120 retry=300 ProxyPassReverse /proxy/ http://198.252.177.19:8080/proxy/       \t </VirtualHost>	In HTTP/1.1 the _default_ behaviour is to use persistent connections. To quote the spec:  'A significant difference between HTTP/1.1 and earlier versions of HTTP is that persistent connections are the default behavior of any HTTP connection. That is, unless otherwise indicated, the client SHOULD assume that the server will maintain a persistent connection, even after error responses from the server.'  So in this case IE is sending a Keep-Alive header to try to get persistent connections even if it's talking to an HTTP/1.0 server that supports them. It's not needed for HTTP/1.1 servers.  Anyway, it looks to me like you probably are getting persistent connections between Apache and JBoss, which I infer from the HTTP/1.1 in the request and response headers and more specifically from the lack of a 'Connection: close' header from JBoss. ('Connection: close' is how an HTTP/1.1 server says it wants to close the TCP connection)  This is not conclusive, though. The Ultimate Test, of course - and what I recommend - is to look at the TCP conversation between your hosts (e.g. with Ethereal or Tethereal) to see whether TCP connections really are being closed after each request. I did a trace with Ethereal, and the socket connection between IE and Apache  is kept open, but a new socket is used between Apache and JBoss for each  exchange.  IE Is running on 198.252.177.123 Apache is running on 198.252.177.38 JBOss is running on 198.252.177.19  No.     Time        Source                Destination           Protocol Info      16 0.250856    198.252.177.123       198.252.177.38        HTTP      GET /jmsproxy/company/jmsproxy/u.jsp?diagnum=221      17 0.000203    198.252.177.38        198.252.177.19        TCP      11970  > 8080 [SYN] Seq=0 Ack=0 Win=5840 Len=0 MSS=1460 TSV=8098330 TSER=0 WS=9      18 0.000053    198.252.177.19        198.252.177.38        TCP      8080  > 11970 [SYN, ACK] Seq=0 Ack=1 Win=5792 Len=0 MSS=1460 TSV=30418315  TSER=8098330 WS=9      19 0.000022    198.252.177.38        198.252.177.19        TCP      11970  > 8080 [ACK] Seq=1 Ack=1 Win=6144 Len=0 TSV=8098330 TSER=30418315      20 0.000066    198.252.177.38        198.252.177.19        HTTP      GET /jmsproxy/company/jmsproxy/u.jsp?diagnum=221      21 0.000156    198.252.177.19        198.252.177.38        TCP      8080  > 11970 [ACK] Seq=1 Ack=858 Win=7680 Len=0 TSV=30418316 TSER=8098330      22 0.102066    198.252.177.19        198.252.177.38        HTTP      HTTP/1.1 200 OK      23 0.000011    198.252.177.38        198.252.177.19        TCP      11970  > 8080 [ACK] Seq=858 Ack=257 Win=7168 Len=0 TSV=8098432 TSER=30418418      24 0.000086    198.252.177.38        198.252.177.19        TCP      11970  > 8080 [FIN, ACK] Seq=858 Ack=257 Win=7168 Len=0 TSV=8098432 TSER=30418418      25 0.000041    198.252.177.38        198.252.177.123       HTTP      HTTP/1.1 200 OK      26 0.000114    198.252.177.19        198.252.177.38        TCP      8080  > 11970 [FIN, ACK] Seq=257 Ack=859 Win=7680 Len=0 TSV=30418418 TSER=8098432      27 0.000010    198.252.177.38        198.252.177.19        TCP      11970  > 8080 [ACK] Seq=859 Ack=258 Win=7168 Len=0 TSV=8098432 TSER=30418418      28 0.217864    198.252.177.123       198.252.177.38        TCP      1578  > http [ACK] Seq=1493 Ack=512 Win=16656 Len=0        29 0.091197    198.252.177.123       198.252.177.38        HTTP      GET /jmsproxy/company/jmsproxy/u.jsp?diagnum=222      30 0.000145    198.252.177.38        198.252.177.19        TCP      11971  > 8080 [SYN] Seq=0 Ack=0 Win=5840 Len=0 MSS=1460 TSV=8098741 TSER=0 WS=9      31 0.000107    198.252.177.19        198.252.177.38        TCP      8080  > 11971 [SYN, ACK] Seq=0 Ack=1 Win=5792 Len=0 MSS=1460 TSV=30418727  TSER=8098741 WS=9      32 0.000014    198.252.177.38        198.252.177.19        TCP      11971  > 8080 [ACK] Seq=1 Ack=1 Win=6144 Len=0 TSV=8098742 TSER=30418727      33 0.000064    198.252.177.38        198.252.177.19        HTTP      GET /jmsproxy/company/jmsproxy/u.jsp?diagnum=222      34 0.000170    198.252.177.19        198.252.177.38        TCP      8080  > 11971 [ACK] Seq=1 Ack=857 Win=7680 Len=0 TSV=30418728 TSER=8098742      35 0.102191    198.252.177.19        198.252.177.38        HTTP      HTTP/1.1 200 OK      36 0.000009    198.252.177.38        198.252.177.19        TCP      11971  > 8080 [ACK] Seq=857 Ack=257 Win=7168 Len=0 TSV=8098844 TSER=30418830      37 0.000079    198.252.177.38        198.252.177.19        TCP      11971  > 8080 [FIN, ACK] Seq=857 Ack=257 Win=7168 Len=0 TSV=8098844 TSER=30418830      38 0.000041    198.252.177.38        198.252.177.123       HTTP      HTTP/1.1 200 OK      39 0.000122    198.252.177.19        198.252.177.38        TCP      8080  > 11971 [FIN, ACK] Seq=257 Ack=858 Win=7680 Len=0 TSV=30418830 TSER=8098844      40 0.000009    198.252.177.38        198.252.177.19        TCP      11971  > 8080 [ACK] Seq=858 Ack=258 Win=7168 Len=0 TSV=8098844 TSER=30418830   I am also trying to used pooled connection to the backend,   e.g. ProxyPass /example http://backend.example.com min=20 max=50   and I was wondering why I do not see these 20 connections created when I start  the Apache server? Does it require a Proxy message do be received before  creating these connections? A patch against trunk has been created (r378032, http://svn.apache.org/viewcvs?rev=378032&view=rev). Could you please give it a try? Please keep in mind that there is a further keepalive bug with mod_proxy on the client side of the connection (#38524). I verified the patch, and it solve the issues with Keep Alive connections.  The connections are kept open, and the Keep-Alive header is passed to the  JBoss server.  Thanks a lot! Proposed for backport as r383321 (http://svn.apache.org/viewcvs?rev=383321&view=rev) *** Bug 39258 has been marked as a duplicate of this bug. *** *** Bug 39258 has been marked as a duplicate of this bug. *** *** Bug 43238 has been marked as a duplicate of this bug. ***			Axel-Stephane Smorgrav	Doug Dixon	Jean Dagenais	Ruediger Pluem
38699	null	RESOLVED		Christophe JAILLET	1140215460000	1184870611000		Code clean up (apr_pstrdup) Remove a apr_palloc / strcpy construction by a single apr_pstrdup to improve  readability.	Created an attachment (id=17732) Patch for the proposed clean-up  Created an attachment (id=19852) Updated patch  The patch has been updated to be synchronized with the current SVN HEAD. http://svn.apache.org/viewvc?view=rev&revision=557837 			Christophe JAILLET	Nick Kew
38701	null	CLOSED		Christophe JAILLET	1140216060000	1142538021000		Code clean up Change a apr_palloc / strcpy / strcat sequence into a single apr_pstrcat call  wich :    * is more readable and reduce source code size    * is faster    * use less memory	Created an attachment (id=17733) proposed patch for the clean up  Thanks for the patch!  It has now been committed to trunk.			Christophe JAILLET	Jeff Trawick
38737	null	RESOLVED		Chris Darroch	1140542820000	1148668547000		keepalives may cause worker MPM on linux to stall during shutdown I covered much of the background on this in the following mailing list thread:  http://marc.theaimsgroup.com/?l=apache-httpd-dev&m=113986864730305&w=2  The usual firestorm of discussion broke out ... anyway, as I noted, it's important to me that even if I issue an ungraceful restart or shutdown that the MPM manages, if at all possible, to call apr_pool_destroy(pchild).  Otherwise, important cleanup functions that are registered against the pool don't get invoked; in my case, that's the DB disconnection cleanups in mod_dbd/apr_dbd.  To summarize, on Linux, poll() doesn't immediately return with EBADF if another thread closes the socket descriptor, as described here:  http://bugme.osdl.org/show_bug.cgi?id=546  When a worker thread is running process_socket(), after handling the request it then waits for the specified Keep-Alive period.  This is actually done inside the apr_bucket_read() in ap_rgetline_core(); the apr_socket_recv() function runs apr_wait_for_io_or_timeout(), which performs a poll() for the Keep-Alive period.   When an ungraceful restart or shutdown message is received by the worker MPM, it uses close_worker_sockets() to close all the sockets the worker threads might be polling on.  On Solaris, for example, that has the side-effect of immediately causing apr_wait_for_io_or_timeout() to return EBADF, which curtails all the calling functions until process_socket() returns and the worker thread notices the workers_may_exit flag and exits.  That in turn allows join_workers() to run to completion, after which clean_child_exit() can run the cleanups on the pchild pool and all child memory pools.  But on Linux, the worker child process is stuck waiting for the Keep-Alive period for the polling to timeout, and during this period, the main httpd process often decides the child process is non-responsive, and sends SIGKILL.  For me, that means my important cleanup functions never run.  The attached patch is the simplest fix I've found; it turns out that by simply signalling the worker threads with any signal is sufficient, because then poll() wakes up and returns EBADF (because the socket descriptor has been closed).  At first I assumed poll() would return EINTR, but luckily, that's not the case, so the fix gets that much simpler.	Created an attachment (id=17761) signals worker threads after closing their sockets  Created an attachment (id=17762) same again for event MPM  (From update of attachment 17762) Actually, this isn't needed because of the asynchronous polling on Keep-Alives.  Committed to 2.3 HEAD:  http://svn.apache.org/viewvc?view=rev&revision=409715 Created an attachment (id=18355) patch for current 2.2.x branch 			Chris Darroch
38793	null	RESOLVED		matthias	1141061460000	1145719710000		Segfault when backend failes, threading issue We run apache22 as reverse proxy to a backend application server (apache1.3). When we put apache22 under load ( ab -k -c 200 ) and restart the backend server, there's a good chance of a segmentation fault.   We've done multiple runs and all Segfault backtraces shared the  proxy_http_handler in mod_proxy_http.c with calls between the comments 'Step One' and 'Step Six'. The attached backtrace is the most common one.   My guess is, that when the first connection fails, it clears pooled connections/ressources currently being used by other threads that are already in the code between 'Step One' and 'Step Six', so their backend->connection gets nulled in the middle of doing something. In my opinion backend->connection should never be 0 in this part of the code, since all failed functions would goto cleanup. However backtrace shows them 0 as well as some cond breakpoints. (Although sometimes breakpoints get passed, but thread segfaults anyway).     #0  0x08095f79 in ap_proxy_make_fake_req (c=0x0, r=0x19520540) at proxy_util.c:351         rp = (request_rec *) 0x94d53f0 #1  0x0809b6ca in ap_proxy_http_process_response (p=0x94d42f8, r=0x19520540, backend=0x917c0e0, origin=0x0, conf=0x91069d8,     server_portstr=0xaef82190 '') at mod_proxy_http.c:1206         c = (conn_rec *) 0x94d44e8         buffer = '/0' <repeats 3420 times>, '/211/003_/000/211/003_/000H/037/uffff/uffff/uffffG]/000/000/000/000/000/uffff)"/000/023/000/000/000/uffff/016/uffff/uffff/000/000/000/000/000/000/000/000/uffff/036/uffff/uffff/f/000/000/000/024/000/000/000/uffff!/003D/uffff/016/uffff/uffff/uffff/016/uffff/uffff/uffff/036/uffff/uffff/n/000/000/000/003/000/000/001/207F/000/000/023/000/000/000/uffff/016/uffff/uffff/000/020/000/000/f/000/000/000/uffff/036/uffff/uffff/f/000/000/000/uffff/016/uffff/uffff/001', '/0' <repeats 19 times>, '/024/000/000/000/003/000/002/000/uffff!/003D/207F/000/000/000/000/000/000/001/000/000/000/024/000/001', '/0' <repeats 16 times>, '/001/024/000/006/000/uffff/uffff/uffff/uffff/uffff/uffff/uffff/uffffd/r/000/000d/r/000/000@/000/000/000/024/000/002/000/uffff!/003D/207'...         buf = 0xa <Address 0xa out of bounds>         keepchar = 100 'd'         rp = (request_rec *) 0x95037d8         e = (apr_bucket *) 0x312e302e         bb = (apr_bucket_brigade *) 0x94d53f0         len = -1         backasswards = 774909495         interim_response = 842082336         pread_len = 0         save_table = (apr_table_t *) 0x72656b72 #2  0x0809c7e2 in proxy_http_handler (r=0x19520540, worker=0x9106db0, conf=0x91069d8, url=0x94d4ff0 '/test/output.php?delay=10',     proxyname=0x0, proxyport=0) at mod_proxy_http.c:1712         status = 0         server_portstr = '/000N/r/b]/005/000/000/a/000/000/000/000/000/000/000 e/030/t/uffffDM/t@/005R/031/000/000/000'         scheme = 0x94d4f90 'http'         proxy_function = 0x80d5ff9 'HTTP'         u = 0x195217fa '://127.0.0.1:8081/test/output.php?delay=10'         backend = (proxy_conn_rec *) 0x917c0e0         is_ssl = 0         p = (apr_pool_t *) 0x94d42f8         c = (conn_rec *) 0x94d44e8         uri = (apr_uri_t *) 0x94d4f60 #3  0x080951d5 in proxy_run_scheme_handler (r=0x19520540, worker=0x9106db0, conf=0x91069d8,     url=0x195217f6 'http://127.0.0.1:8081/test/output.php?delay=10', proxyhost=0x0, proxyport=0) at mod_proxy.c:1936         pHook = (proxy_LINK_scheme_handler_t *) 0x91dd358         n = 0         rv = 424810486 #4  0x08092a3d in proxy_handler (r=0x19520540) at mod_proxy.c:739 #5  0x0807cdcd in ap_run_handler (r=0x19520540) at config.c:157 #6  0x0807d50d in ap_invoke_handler (r=0x19520540) at config.c:371 #7  0x080b49d2 in ap_process_request (r=0x19520540) at http_request.c:258 #8  0x080b1ee8 in ap_process_http_connection (c=0x94d44e8) at http_core.c:171 #9  0x08084264 in ap_run_process_connection (c=0x94d44e8) at connection.c:43 #10 0x08084693 in ap_process_connection (c=0x94d44e8, csd=0x94d4338) at connection.c:178 #11 0x080bddcb in process_socket (p=0x94d42f8, sock=0x94d4338, my_child_num=0, my_thread_num=12, bucket_alloc=0x1951c4f8)     at worker.c:531 #12 0x080be5d4 in worker_thread (thd=0x91a05c0, dummy=0x91dddc8) at worker.c:876 #13 0xb7ef7868 in dummy_worker (opaque=0x91a05c0) at threadproc/unix/thread.c:138 #14 0x006bb341 in start_thread () from /lib/tls/libpthread.so.0 #15 0x005e36fe in clone () from /lib/tls/libc.so.6   as mentioned this is the most common one but we even got segfaults here:  #0  0xb7ed2246 in allocator_free (allocator=0x0, node=0x9b15110) at memory/unix/apr_pools.c:319 #1  0xb7ed2224 in apr_allocator_free (allocator=0x0, node=0x9b15110) at memory/unix/apr_pools.c:384 #2  0xb7fbd81f in apr_bucket_free (mem=0x9b15138) at buckets/apr_buckets_alloc.c:182 #3  0xb7fbda6a in socket_bucket_read (a=0x9b011c8, str=0xb6a47f40, len=0xb6a47f3c, block=APR_BLOCK_READ)     at buckets/apr_buckets_socket.c:71 #4  0xb7fbe933 in apr_brigade_split_line (bbOut=0x9af8180, bbIn=0x9af81a8, block=APR_BLOCK_READ, maxbytes=8192)     at buckets/apr_brigade.c:292 #5  0x0807b024 in ap_core_input_filter (f=0x9af71d0, b=0x9af8180, mode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)     at core_filters.c:171 #6  0x080878e3 in ap_get_brigade (next=0x9af71d0, bb=0x9af8180, mode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)     at util_filter.c:489 #7  0x0806e358 in ap_rgetline_core (s=0xb6a480a4, n=8192, read=0xb6a4809c, r=0x9af7400, fold=0, bb=0x9af8180) at protocol.c:222 #8  0x0806e78f in ap_getline (s=0xb6a48120 '', n=8192, r=0x9af7400, fold=0) at protocol.c:463 #9  0x0809b70a in ap_proxy_http_process_response (p=0x9b04a98, r=0x9b11150, backend=0x9a94e80, origin=0x9af6f90, conf=0x9a1f9d8,     server_portstr=0xb6a4a190 '') at mod_proxy_http.c:1214 #10 0x0809c7e2 in proxy_http_handler (r=0x9b11150, worker=0x9a1fdb0, conf=0x9a1f9d8, url=0x9b05018 '/test/output.php?delay=1',     proxyname=0x0, proxyport=0) at mod_proxy_http.c:1712 #11 0x080951d5 in proxy_run_scheme_handler (r=0x9b11150, worker=0x9a1fdb0, conf=0x9a1f9d8,     url=0x9b123fe 'http://127.0.0.1:8081/test/output.php?delay=1', proxyhost=0x0, proxyport=0) at mod_proxy.c:1936 #12 0x08092a3d in proxy_handler (r=0x9b11150) at mod_proxy.c:739 #13 0x0807cdcd in ap_run_handler (r=0x9b11150) at config.c:157 #14 0x0807d50d in ap_invoke_handler (r=0x9b11150) at config.c:371 #15 0x080b49d2 in ap_process_request (r=0x9b11150) at http_request.c:258 #16 0x080b1ee8 in ap_process_http_connection (c=0x9b04c88) at http_core.c:171 #17 0x08084264 in ap_run_process_connection (c=0x9b04c88) at connection.c:43 #18 0x08084693 in ap_process_connection (c=0x9b04c88, csd=0x9b04ad8) at connection.c:178 #19 0x080bddcb in process_socket (p=0x9b04a98, sock=0x9b04ad8, my_child_num=0, my_thread_num=1, bucket_alloc=0x9b06aa0)     at worker.c:531 #20 0x080be5d4 in worker_thread (thd=0x9ab88c0, dummy=0x9aa8a38) at worker.c:876 #21 0xb7ede868 in dummy_worker (opaque=0x9ab88c0) at threadproc/unix/thread.c:138 #22 0x006bb341 in start_thread () from /lib/tls/libpthread.so.0 #23 0x005e36fe in clone () from /lib/tls/libc.so.6	I did some more debugging and found a strange behaviour in ap_proxy_connect_backend  #0  ap_proxy_connect_backend (proxy_function=0x80d5ff9 'HTTP', conn=0x9d0cfd8, worker=0x9c95db0, s=0x9d154c8) at proxy_util.c:2045         rv = 164679640         connected = 1         loglevel = 164190680         backend_addr = (apr_sockaddr_t *) 0x9d60a00         newsock = (apr_socket_t *) 0x9d8fa28 #1  0x0809c748 in proxy_http_handler (r=0x9d99af8, worker=0x9c95db0, conf=0x9c959d8, url=0x9d91268 '/test/output.php?delay=0', proxyname=0x0, proxyport=0)     at mod_proxy_http.c:1691  I put a breakpoint on the return statement in case that conn->sock is null, however the function will return true, because its internal newsock is valid and its connected counter is 1. (see stacktrace above). conn looks magically empty:  (gdb) inspect conn->hostname $4 = 0x0 (gdb) inspect conn->port $5 = 0 (gdb) inspect conn->pool $6 = (apr_pool_t *) 0x9d60768 (gdb) inspect conn->is_ssl $7 = 0 (gdb) inspect conn->sock $8 = (apr_socket_t *) 0x0 (gdb) inspect conn->addr $9 = (apr_sockaddr_t *) 0x0 (gdb) inspect conn->flags $10 = 0 (gdb) inspect conn->close $11 = 0 (gdb) inspect conn->close_on_recycle $12 = 0 (gdb) inspect conn->worker $13 = (proxy_worker *) 0x9c95db0  connected is only set right after conn->sock = newsock , both vars are never touched until return then. How does conn become so empty ? I also do not have any of the error messages from ap_proxy_connect_backend in the error_log, so I assume the bad boy might be another thread.  I get the following error messages from other threads and they are already int the logfile when the above breakpoint is hit, so chances are that things get messed up here.  [Sat Mar 04 18:12:48 2006] [error] [client 127.0.0.1] proxy: error reading status line from remote server (null) [Sat Mar 04 18:12:48 2006] [error] [client 127.0.0.1] proxy: Error reading from remote server returned by /test/output.php  above this errormessage is  ap_proxy_http_cleanup(NULL, r, backend); which i think is redundant as proxy_http_handler runs cleanup: anyway. removing did not fix the problem.   Let me know if this looks like something to go into deeper. (PS. We are running mod_worker)  Created an attachment (id=17836) Temporary debug patch to narrow down the problem.  Could you please apply the attached patch temporarily and set the LogLevel to debug? A conn data structure should be only leased to one thread at the same time from the connection pool. So in theory different threads should not have access to the same data structure at the same time. The patch logs the aquire and release operations and hopefully helps to see if this is not the case. switch loglevel to debug eliminates problem ( probably because of a change in timing because of the additional overhead).  I changed the patch to log as ERROR. I grepped the logfile for the segfaulting backend and all non 'backend' messages:  [Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Aquired backend 0x987bff8 for request 0xa9e20540, connection 0xaa01ab08, pid 13549, tid 0xb4184bb0 [Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for request 0xa9e20540, connection 0xaa01ab08, pid 13549, tid 0xb4184bb0 [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading status line from remote server (null) [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from remote server returned by /test/output.php [Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for request 0xa9e20540, connection 0xaa01ab08, pid 13549, tid 0xb4184bb0 [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading status line from remote server (null) [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from remote server returned by /test/output.php [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading status line from remote server (null) [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from remote server returned by /test/output.php [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading status line from remote server (null) [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from remote server returned by /test/output.php [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading status line from remote server (null) [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from remote server returned by /test/output.php [Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Aquired backend 0x987bff8 for request 0xaa034be8, connection 0xaa030d90, pid 13549, tid 0xadd7abb0 [Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Aquired backend 0x987bff8 for request 0xa9e2a568, connection 0xaa018a90, pid 13549, tid 0xaf17cbb0 [Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for request 0xa9e2a568, connection 0xaa018a90, pid 13549, tid 0xaf17cbb0 [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading status line from remote server (null) [Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from remote server returned by /test/output.php [Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for request 0xa9e2a568, connection 0xaa018a90, pid 13549, tid 0xaf17cbb0  The backend gets released, 'error reading status line' gets logged, and the same backend gets released again. Afterwards it gets acquired by 2 different threads.  One thread fails with same error (0xaf17cbb0) releasing the backend, the other thread gets the segfault (0xadd7abb0) while in ap_proxy_connection_create. (gdb bt).  I suspect   ap_proxy_http_cleanup(NULL, r, backend)   in line 1220 ( and 1246, numbers my vary because of your patch ) of mod_proxy_http.c to be the problem, as mentioned in previous comment, it gets called there and again in line 1741, after the cleanup:-goto.  I don't know what the proxy_function argument means in line 1741, because the other cleanups are called with NULL ?    Removing line 1220 eliminates the Segfaults. But I get these lines after some time running ab:  (99)Cannot assign requested address: proxy: HTTP: attempt to connect to 127.0.0.1:8081 (127.0.0.1) failed  I guess this could be related to a temporary shortage of tcp-ip source ports (I'm running ab from the same machine and it never happens for the first 20000 requests) BTW: this also fixes the ' remote server (null) ' thing of the error line. see also: http://issues.apache.org/bugzilla/show_bug.cgi?id=37770#c2   Many thanks for the update. It was very helpful. The problem seems to be caused by the fact that apr_reslist_release does not notice 'double releases' (see also http://marc.theaimsgroup.com/?l=apr-dev&m=114168465029319&w=2). I am checking now if this is a bug inside apr-util or inside the proxy code. If it is a bug inside the proxy code, I need to implement additional measures to prevent such 'double releases' (apart from removing the unnecessary double calls to ap_proxy_http_cleanup which you already mentioned). These additional measures should help track down such issues faster in the future and prevent the server from segfaulting in such situations. I'll keep you updated. Created an attachment (id=17874) Patch against trunk to fix double return of connections to pool  I created a patch that removes the double calls to ap_proxy_http_cleanup and adds a check if a connection has been already returned to the connection pool before. Could you please give the patch a try and let me know if this fixes your problem and if you do not see any error messages of 'proxy: Pooled connection 0x%pp for worker %s has been already returned to the connection pool.'. Thanks.  We applied the patch about 10 days ago, no double-free warnings so far. Crash is no longer reproducable with ab in test environment.   However we are still seeing segfaults in our logfiles in production use. I have the suspect it might be related to mod_ssl, but I did not have time to look into this so far.   So this patch is probably ready to roll, although there's more to do ... Committed patch to trunk as r394088 (http://svn.apache.org/viewcvs?rev=394088&view=rev). Proposed for backport to 2.2.x as r394653 (http://svn.apache.org/viewcvs?rev=394653&view=rev). Backported to 2.2.x as r396049 ( http://svn.apache.org/viewcvs?rev=396049&view=rev).			Ruediger Pluem	matthias
38819	null	RESOLVED		Bob Ionescu	1141228140000	1185885619000		mod_headers compatibility about RequestHeader 'Compatibility of RequestHeader' might be missunderstandable as someone might think RequestHeader is only available in 2.0 but not in 2.2.	Created an attachment (id=17814) proposed patch  I just removed the compatibility line entirely, since we don't track whether 2.2+ is compatible with 1.3. Please backport  http://httpd.apache.org/docs/2.0/en/mod/mod_headers.html http://httpd.apache.org/docs/2.2/en/mod/mod_headers.html			Bob Ionescu	Joshua Slive	Takashi Sato
38838	null	RESOLVED		Alex Deiter	1141390320000	1143648566000		Apache 64-bit permanent got a Signal 10, Bus error with mod_ssl Hi,  I'm build Apache 2.2.0 on Solaris 9. Apache 64-bit permanent got a Signal 10, Bus error with mod_ssl:  [Fri Mar 03 14:45:25 2006] [notice] child pid 14003 exit signal Bus error (10), possible coredump in /usr/local  gdb say me: Reading symbols from /usr/lib/sparcv9/nss_files.so.1...done. Loaded symbols for /usr/lib/64/nss_files.so.1 #0  ssl_scache_shmcb_store (s=0x1001efc90, id=<value optimized out>, idlen=<value optimized out>,     timeout=1141386623, pSession=<value optimized out>) at ssl_scache_shmcb.c:241 241             memset(ptr, 0, size); (gdb) bt #0  ssl_scache_shmcb_store (s=0x1001efc90, id=<value optimized out>, idlen=<value optimized out>,     timeout=1141386623, pSession=<value optimized out>) at ssl_scache_shmcb.c:241 #1  0xffffffff7b1166b4 in ssl_callback_NewSessionCacheEntry (ssl=<value optimized out>,     session=0xffffffff7bf00008) at ssl_engine_kernel.c:1635 #2  0xffffffff7af31480 in ssl_update_cache () from /usr/local/lib/libssl.so.3 #3  0xffffffff7af1c10c in ssl3_accept () from /usr/local/lib/libssl.so.3 #4  0xffffffff7af31b60 in SSL_accept () from /usr/local/lib/libssl.so.3 #5  0xffffffff7af24ce8 in ssl23_get_client_hello () from /usr/local/lib/libssl.so.3 #6  0xffffffff7af2544c in ssl23_accept () from /usr/local/lib/libssl.so.3 #7  0xffffffff7af31b84 in SSL_accept () from /usr/local/lib/libssl.so.3 #8  0xffffffff7b112af8 in ssl_io_filter_connect (filter_ctx=0x1002534f8) at ssl_engine_io.c:1047 #9  0xffffffff7b113104 in ssl_io_filter_input (f=0x10025d478, bb=0x10025f968, mode=AP_MODE_GETLINE,     block=APR_BLOCK_READ, readbytes=4297403752) at ssl_engine_io.c:1292 #10 0x000000010003c9bc in ap_get_brigade (next=0x10025d478, bb=0x10025f968, mode=AP_MODE_GETLINE,     block=APR_BLOCK_READ, readbytes=0) at util_filter.c:489 #11 0x000000010002471c in ap_rgetline_core (s=0x10025e4d8, n=8192, read=0xffffffff7ffff2e0, r=0x10025e4a8,     fold=0, bb=0x10025f968) at protocol.c:222 #12 0x0000000100025424 in ap_read_request (conn=0x100252d68) at protocol.c:587 #13 0x000000010003cf98 in ap_process_http_connection (c=0x100252d68) at http_core.c:164 #14 0x0000000100039180 in ap_run_process_connection (c=0x100252d68) at connection.c:43 #15 0x0000000100044060 in child_main (child_num_arg=<value optimized out>) at prefork.c:640 #16 0x0000000100044374 in make_child (s=0x100172e38, slot=0) at prefork.c:736 #17 0x000000010004447c in startup_children (number_to_start=4) at prefork.c:757 #18 0x0000000100045120 in ap_mpm_run (_pconf=0x10016daf8, plog=<value optimized out>, s=<value optimized out>)     at prefork.c:975 #19 0x000000010001d7e0 in main (argc=1, argv=0xffffffff7ffffb18) at main.c:712  # /usr/local/sbin/apachectl -v Server version: Apache/2.2.0 Server built:   Mar  3 2006 14:17:26 # /usr/local/sbin/apachectl -V Server version: Apache/2.2.0 Server built:   Mar  3 2006 14:17:26 Server's Module Magic Number: 20051115:0 Architecture:   64-bit Server MPM:     Prefork   threaded:     no     forked:     yes (variable process count) Server compiled with....  -D APACHE_MPM_DIR='server/mpm/prefork'  -D APR_HAS_SENDFILE  -D APR_HAS_MMAP  -D APR_USE_FCNTL_SERIALIZE  -D APR_USE_PTHREAD_SERIALIZE  -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT  -D APR_HAS_OTHER_CHILD  -D AP_HAVE_RELIABLE_PIPED_LOGS  -D DYNAMIC_MODULE_LIMIT=128  -D HTTPD_ROOT='/usr/local'  -D SUEXEC_BIN='/usr/local/bin/suexec'  -D DEFAULT_PIDLOG='/var/run/httpd.pid'  -D DEFAULT_SCOREBOARD='logs/apache_runtime_status'  -D DEFAULT_LOCKFILE='/var/run/accept.lock'  -D DEFAULT_ERRORLOG='logs/error_log'  -D AP_TYPES_CONFIG_FILE='etc/apache/mime.types'  -D SERVER_CONFIG_FILE='etc/apache/httpd.conf'  Apache build with openssl 0.9.8a:  # ldd /usr/local/sbin/httpd         libm.so.1 =>     /usr/lib/64/libm.so.1         libpcre.so.0 =>  /usr/local/lib/libpcre.so.0         libaprutil.so.0 =>       /usr/local/lib/libaprutil.so.0         libldap.so.5 =>  /usr/lib/64/libldap.so.5         libdb.so.4 =>    /usr/local/lib/libdb.so.4         libexpat.so.1 =>         /usr/local/lib/libexpat.so.1         libiconv.so.2 =>         /usr/local/lib/libiconv.so.2         libapr.so.0 =>   /usr/local/lib/libapr.so.0         libresolv.so.2 =>        /usr/lib/64/libresolv.so.2         libuuid.so.1 =>  /usr/lib/64/libuuid.so.1         libsendfile.so.1 =>      /usr/lib/64/libsendfile.so.1         librt.so.1 =>    /usr/lib/64/librt.so.1         libsocket.so.1 =>        /usr/lib/64/libsocket.so.1         libnsl.so.1 =>   /usr/lib/64/libnsl.so.1         libpthread.so.1 =>       /usr/lib/64/libpthread.so.1         libdl.so.1 =>    /usr/lib/64/libdl.so.1         libc.so.1 =>     /usr/lib/64/libc.so.1         libmd5.so.1 =>   /usr/lib/64/libmd5.so.1         libaio.so.1 =>   /usr/lib/64/libaio.so.1         libmp.so.2 =>    /usr/lib/64/libmp.so.2         libthread.so.1 =>        /usr/lib/64/libthread.so.1         /usr/platform/SUNW,Sun-Fire-V210/lib/sparcv9/libc_psr.so.1         /usr/platform/SUNW,Sun-Fire-V210/lib/sparcv9/libmd5_psr.so.1  my httpd.conf:  ServerRoot '/usr/local' Listen 80  LoadModule authz_host_module lib/apache/mod_authz_host.so #LoadModule include_module lib/apache/mod_include.so LoadModule log_config_module lib/apache/mod_log_config.so LoadModule logio_module lib/apache/mod_logio.so LoadModule env_module lib/apache/mod_env.so LoadModule setenvif_module lib/apache/mod_setenvif.so LoadModule ssl_module lib/apache/mod_ssl.so LoadModule mime_module lib/apache/mod_mime.so LoadModule dir_module lib/apache/mod_dir.so #LoadModule alias_module lib/apache/mod_alias.so  User apache Group apache ServerAdmin root@komi.mts.ru DocumentRoot '/var/apache/data'  <Directory />         Options FollowSymLinks         AllowOverride None         Order deny,allow         Deny from all </Directory>  <Directory '/var/apache/data'>         Options Indexes FollowSymLinks         AllowOverride None         Order allow,deny         Allow from all </Directory>  <IfModule dir_module>         DirectoryIndex index.html </IfModule>  <FilesMatch '^/.ht'>         Order allow,deny         Deny from all </FilesMatch>  ErrorLog /var/log/apache/error.log LogLevel warn  <IfModule log_config_module>         LogFormat '%h %l %u %t /'%r/' %>s %b /'%{Referer}i/' /'%{User-Agent}i/'' combined         LogFormat '%h %l %u %t /'%r/' %>s %b' common    <IfModule logio_module>         LogFormat '%h %l %u %t /'%r/' %>s %b /'%{Referer}i/' /'%{User-Agent}i/' %I %O' combinedio    </IfModule>         CustomLog /var/log/apache/access.log common </IfModule>  DefaultType text/plain  <IfModule mime_module>         TypesConfig etc/apache/mime.types         AddType application/x-compress .Z         AddType application/x-gzip .gz .tgz </IfModule>  <IfModule ssl_module>         SSLRandomSeed startup builtin         SSLRandomSeed connect builtin         Include etc/apache/ssl.conf </IfModule>  ServerTokens Prod  my ssl.conf:  Listen 443 AddType application/x-x509-ca-cert .crt AddType application/x-pkcs7-crl    .crl SSLPassPhraseDialog  builtin SSLSessionCache        shmcb:/var/run/ssl_scache(512000) SSLSessionCacheTimeout  300 SSLMutex  file:/var/run/ssl_mutex  <VirtualHost _default_:443>  DocumentRoot '/var/apache/data' ServerName www.example.com:443 ServerAdmin you@example.com ErrorLog /var/log/apache/error.log TransferLog /var/log/apache/access.log SSLEngine on SSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL SSLCertificateFile /usr/local/etc/ssl/server.crt SSLCertificateKeyFile /usr/local/etc/ssl/server.key SSLCACertificateFile /usr/local/etc/ssl/ca.crt  <FilesMatch '/.(cgi|shtml|phtml|php)$'>     SSLOptions +StdEnvVars </FilesMatch> <Directory '/var/apache/cgi-bin'>     SSLOptions +StdEnvVars </Directory>  BrowserMatch '.*MSIE.*' /          nokeepalive ssl-unclean-shutdown /          downgrade-1.0 force-response-1.0  CustomLog /var/log/apache/ssl.log /           '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b'  </VirtualHost>  Other programms, which build with openssl works fine for me: samba, sendmail, cyrus-imap, cups, etc...  Thanks!	Created an attachment (id=17823) shmcb inline-beats-alignment-workaround fix  Gosh, haven't had to fix one of these for ages.  Are you using gcc?  If so, what version?  Can you try the attached patch?  # /usr/local/bin/gcc -v Using built-in specs. Target: sparc64-sun-solaris2.9 Configured with: ../configure --prefix=/usr/local --libexecdir=/usr/local/lib --enable-threads=solaris --enable-languages=c,c++ --enable-shared=libstdc++ --disable-multilib --disable-nls --disable-libstdcxx-pch sparc64-sun-solaris2.9 Thread model: solaris gcc version 4.0.2  > Can you try the attached patch?  Patch work fine for me. Thanks for a fast reply!  Thanks a lot! Fixed on trunk and proposed for inclusion in 2.2.x: thanks for the report.  http://svn.apache.org/viewcvs?rev=382799&view=rev			Alex Deiter	Joe Orton
38848	null	RESOLVED		Ronnie Brunner	1141430640000	1192085840000		httpd -X option broken If httpd is running in single process debug mode (-X commandline option), it does not properly respond to stop (SIGTERM), graceful (SIGUSR1), graceful-stop (SIGWINCH) and probably other signals.  Except for a kill -9, the process cannot be terminated anymore and there is no way to properly shutdown the process.  (BTW: I guess it's on newer versions as well but I didn't know hoe to cekc out working head version of either 2.2 or 2.3)	FWIW I'm seeing the same thing on Darwin on my Powerbook.   Control-C (which I think sends a SIGINT) also doesn't give me a reaction. It's as if we go through the  trouble of ignoring the signals (default for most signals is to terminate the program), but don't register  handlers when in -X mode.   Interestingly, httpd reacts to ^C when run under -X. Maybe gdb plants its own handler?   Trunk is also affected.   Some notes on checking out the development trunk at http://httpd.apache.org/dev/devnotes.html .   In short, you get the latest and greatest as follows:   $ svn co http://svn.apache.org/repos/asf/httpd/httpd/trunk httpd-trunk  $ cd httpd-trunk/srclib/apr $ svn co http://svn.apache.org/repos/asf/apr/apr/trunk apr $ svn co http://svn.apache.org/repos/asf/apr/apr-util/trunk apr-util I was playing around with this, and I can 'fix' the problem with the following change:  Index: server/mpm/prefork/prefork.c =================================================================== --- server/mpm/prefork/prefork.c        (revision 383230) +++ server/mpm/prefork/prefork.c        (working copy) @@ -536,7 +536,7 @@       bucket_alloc = apr_bucket_alloc_create(pchild);  -    while (!die_now) { +    while (!die_now && !shutdown_pending) {          conn_rec *current_conn;          void *csd;   I'm not sure if this is correct though, and I'm not sure when this problem started.  svn blame and poking around areas of the code related to die_now and shutdown_pending didn't show any particularly promising changes, mostly stuff from way the hell back in the day.  Didn't try to fix the problem on non-prefork MPMs, but I do recall noticing it with worker a while back. I tried your patch and it did allow me to terminate httpd with Ctrl-C. However semaphores don't get released (the real problem IMHO), thus I still have to run ipcrm every once in a while.  Btw, you can kill httpd without patching by hitting Ctrl-/ (SIGQUIT). This was committed as: http://svn.apache.org/viewvc?view=rev&rev=552029			Garrett Rooney	Joe Orton	Sander Temme	becarre@free.fr
38910	null	RESOLVED		Robby Griffin	1141922520000	1147876818000		mod_autoindex prints unescaped filenames In the default configuration of Apache httpd-2.2.0, filenames printed by mod_autoindex are not properly html-escaped. This can inject arbitrary html directly in the autoindex output, potentially making it unusable for navigation purposes. For example:  [build, install, and run httpd-2.2.0] cd $PREFIX/htdocs mkdir foo touch 'foo/<body onload=alert(1)>' [visit /foo/ in a browser (tested with Firefox)] [an alert dialog appears]  Earlier versions of Apache httpd do contain this bug, but are not affected in their default configurations. The difference is that versions prior to 2.2.0 have 'IndexOptions FancyIndexing' enabled in the default httpd.conf, so a different code path is used to display the filenames.  Here's a patch against 2.2.0 (and probably applicable to earlier versions) which adds the necessary escaping to the displayed filename in non-fancy, non-table autoindex output. I'll include it inline because I don't see how to attach a file in Bugzilla.  --- httpd-2.2.0/modules/generators/mod_autoindex.c.orig\tThu Nov 10 09:20:05 2005 +++ httpd-2.2.0/modules/generators/mod_autoindex.c\tThu Mar  9 02:42:54 2006 @@ -1819,8 +1819,9 @@              ap_rputc('/n', r);          }          else { -            ap_rvputs(r, '<li><a href=/'', anchor, '/'> ', t2, -                         '</a></li>/n', NULL); +            ap_rvputs(r, '<li><a href=/'', anchor, '/'> ', +                      ap_escape_html(scratch, t2), +                      '</a></li>/n', NULL);          }      }      if (autoindex_opts & TABLE_INDEXING) {	Created an attachment (id=17857) adds proper html escaping  Ok, fine, so I can add an attachment after first creating the bug report. Thank you for your patch; it appears this affects 2.0 and 1.3 httpd as well?  We very rarely patch httpd 1.3, but this looks like one of those rare examples of a very clean change affecting all versions. (In reply to comment #2) > Thank you for your patch; it appears this affects 2.0 and 1.3 httpd as well?  Yes, that's correct. Thanks a lot for the patch.  Committed to trunk:    http://svn.apache.org/viewcvs.cgi?rev=407265&view=rev  and proposed for 2.2.x.			Joe Orton	Robby Griffin	Will Rowe
38966	null	RESOLVED		David Gersic	1142368860000	1151691476000		Introduction on Stopping and Restarting page should have WINCH signal listed The introduction on this page says:  ------------------------------------------------------------------------------ There are three signals that you can send the parent: TERM, HUP, and USR1, which  will be described in a moment. ------------------------------------------------------------------------------  The page then goes on to describe TERM, HUP, USR1, and WINCH. Seems like WINCH  should be added to the list in the introduction. I searched the 'open' and  'closed' bug reports, and I don't see this listed.	Thanks.  This was in trunk but not 2.2.  It should get in the next release.			Joshua Slive
39133	null	RESOLVED		Dave Dewey	1143567600000	1143578735000		Uses real domain name in example configuration On the above-referenced page, 'cyberthugs.com' is used in the example 'deny' directive.  I have owned cyberthugs.com for 10 years and use it as my primary mail domain as well as for many other activities (such as running httpd).  I would prefer to not have it referenced here.  Can this please be changed?	Fixed in trunk and in the 2.0 and 2.2 branches.  Should percolate through to  the online documentation in the next couple of days, as well as future  releases. 			Nick Kew
39203	null	RESOLVED		Che Wang	1144174320000	1156294238000		mod_proxy_balancer does not treat trailing slash like Proxypass directive Running httpd-2.2.0-1 on CentOS 4.3 (rebuilt source rpm package).  Found a bug with mod_proxy_balancer module where it does not treat a URL the same as mod_proxy module would.  Using Apache as a reverse proxy with mod_proxy module passing this directive to a single backend server works just fine:  ProxyPass /KenwoodAccess/ http://172.20.111.33:80/KenwoodAccess/  This next example is a WORKING configuration for mod_proxy_balancer. No errors are generated in Apache and passes to the backend servers:  ProxyPass /KenwoodAccess balancer://KWA_cluster lbmethod=byrequests stickysession=JSESSIONID nofailover=off <Proxy balancer://KWA_cluster>         BalancerMember http://172.20.111.33:80/KenwoodAccess smax=15 loadfactor=1         BalancerMember http://172.20.111.34:80/KenwoodAccess smax=15 loadfactor=1         #BalancerMember http://test.kenwoodaccess.com/noworkers.html smax=15 loadfactor=80 </Proxy>  Where the bug happens:  ProxyPass /KenwoodAccess/ balancer://KWA_cluster lbmethod=byrequests *NOTE: The trailing slash in the first option.  This will generate an error message in Apache logs:  [Mon Apr 03 17:04:55 2006] [warn] proxy: No protocol handler was valid for the URL /site/images/buts/forgotpassword.gif. If you are using a DSO version of mod_proxy, make sure the proxy submodules are included in the configuration using LoadModule.  This error message seems to be misleading when passing options using the trailing slash.  How I am interpreting it is mod_proxy_balancer doesn't want to call on other mod_proxy submodules properly.  Googling shows that people resolved this Apache error message by adding 'LoadModule' for the submodules of mod_proxy (ie: mod_proxy_connect, mod_proxy_http, etc.).  This is not the case with me, since Apache shows these submodules as loaded:  httpd -M  proxy_module (shared)  proxy_connect_module (shared)  proxy_ftp_module (shared)  proxy_http_module (shared)  proxy_ajp_module (shared)  proxy_balancer_module (shared)  This has been troubleshooted down to trailing slashes as the culprit for mod_proxy_balancer and mod_proxy Proxypass directive works just fine with trailing slashes.	  > ProxyPass /KenwoodAccess/ http://172.20.111.33:80/KenwoodAccess/  and  > ProxyPass /KenwoodAccess/ balancer://KWA_cluster lbmethod=byrequests  are different cases. In the first case you have a trailing slash at both ends in the second case you do not have this.   > This will generate an error message in Apache logs: >  > [Mon Apr 03 17:04:55 2006] [warn] proxy: No protocol handler was valid for the > URL /site/images/buts/forgotpassword.gif. If you are using a DSO version of > mod_proxy, make sure the proxy submodules are included in the configuration > using LoadModule.  Please specify the request that leads to this error message.  Please set also the LogLevel to debug and attach the output of your error_log file. *** Bug 39206 has been marked as a duplicate of this bug. *** I had the same issue, and this does not necessarily mean that is not a bug but I have at least discovered a workaround.  In my case, within a certain Virtual Host I pass all requests to the Load Balancer. This received the same errors when configured as follows:  ProxyPass / balancer://cluster nofailover=On ProxyPassReverse / balancer://cluster <Proxy balancer://cluster>   BalancerMember ajp://10.0.1.102:8009   BalancerMember ajp://10.0.1.103:8009 </Proxy>  But works if the configuration is changed to this:  ProxyPass / balancer://cluster/ nofailover=On ProxyPassReverse / balancer://cluster/ <Proxy balancer://cluster/>   BalancerMember ajp://10.0.1.102:8009/   BalancerMember ajp://10.0.1.103:8009/ </Proxy>  I agree that the error message is misleading, but this problem is not limited to mod_proxy_balancer and the balancer scheme but also occurs with  ProxyPass / http://www.somewhere.com  (it must be ProxyPass / http://www.somewhere.com/)  So the problem is really a misconfiguration on the user side that I mark as a WONTFIX. (In reply to comment #4) > ProxyPass / http://www.somewhere.com >  > (it must be ProxyPass / http://www.somewhere.com/) >  > So the problem is really a misconfiguration on the user side that I mark as a > WONTFIX.  May be the manual should be updated, too, because three or four examples provided under the ProxyPass directive are using such invalid syntax. (In reply to comment #5) >  > May be the manual should be updated, too, because three or four examples > provided under the ProxyPass directive are using such invalid syntax.  Ok, agreed, but strictly speaking only the balancer example is wrong.   ProxyPass /example http://backend.example.com  is correct again. The basic rule for this is:  If the left side of ProxyPass ends with a / the right side must also end with a /. If the right side of ProxyPass ends with a / but the left side does not this will cause // in the URL send to the backend which usually does not harm, but to play safe both sides really should end in the same manner. Maybe an idea for a sanity check that issues a warning to the error log during the configuration parsing of the ProxyPass directives if this is not the case. I have added a note to the documentation regarding trailing slashes: r409455 (http://svn.apache.org/viewvc?rev=409455&view=rev)			Bob Ionescu	Noah Schoenholtz	Ruediger Pluem
39245	null	RESOLVED		Jeff Tharp	1144442160000	1176365922000		Mod_proxy_http ProxyErrorOverride eating cookies From a post on the Apache httpd-dev mailing list: Hi,  The 'ProxyErrorOverride On' setting is correctly catching the errors from the (reverse) proxied server. Only, it overrides too much IMHO. Right now it overrides anything that's not in the 2xx range, but I think it should allow also the 3xx range for redirects etc.  A commonly used 'trick' is to set a cookie with a 302 header so the browser gets redirected to the page which 'needs' the cookie. When using ProxyErrorOverride, mod_proxy_http sets its own headers and the cookie is lost.  The attached patch check not only for ap_is_HTTP_SUCCESS but also for ap_is_HTTP_REDIRECT which should solve the problem.  Thanks, Bart van der Schans  I can second this claim, as we also see it with our applications, most notably when attempting to reverse proxy the login process of SAP E-Recruiting, IBM WebSphere Portal Server, and Roller (http://rollerweblogger.org/page/project).  I have attached the patch proposed by the original poster.  Please see the list thread for some further discussion of this patch	Created an attachment (id=18043) Bart's proposed patch  Here are some comments made on this patch on the httpd-dev list by Ruediger Pluem along with Bart's replies: Pl&#65533;m wrote: >  >> -----Urspr&#65533;ngliche Nachricht----- >> Von: Bart van der Schans >> >> Hi, >> >> The 'ProxyErrorOverride On' setting is correctly catching the errors >> from the (reverse) proxied server. Only, it overrides too much IMHO. >> Right now it overrides anything that's not in the 2xx range,  >> but I think >> it should allow also the 3xx range for redirects etc. >  > I had a quick look into this and noticed the following: >  > 1. It may make sense to add ap_is_HTTP_INFO to this also. Yes, that shounds like a good idea.  > 2. ProxyErrorOverride is currently only honoured by mod_proxy_http, >    mod_proxy_ajp ignores it. Is this intended? I don't have much experience with ajp, but being able to set a custom error is a good idea I think.  > 3. This is a change in behaviour for people who use customized redirect >    pages for browsers that do not support redirects (are there any?) Wouldn't that change from currently broken to working?  > 4. 304 not modified responses from the backend are currently not supported >    without this patch. I didn't actually tested that.  Regards, Bart Have you tried to set a custom error document? Can you check if  ErrorDocument 301 /dummy.html ErrorDocument 302 /dummy.html ErrorDocument 303 /dummy.html  fixes your problem? Of course dummy.html must be a file in your document root. Finally able to work on this bug again.  Tested this behavior using version 2.2.3 and it looks like the issue is now resolved.  Cookies are correctly set on 302 redirect requests with ProxyErrorOverride On.  I suspect changes elsewhere cleaned up this issue since the bug was first reported. NOT FIXED in vanilla 2.2.3.   I'm using mod_proxy_http to reverse proxy a resin application server. Cookies and most headers set by resin in a 302 response are dropped by 2.2.3 when proxyerroroverride is on.   What follows are transcripts with our internal 2.2.3 server; the first transcript is with proxyerroroverride on in the specified virtual host config; the second with proxyerroroverride off.   Transcript #1, proxyerroroverride on  [user@HOST ~]$ telnet HOST 80 Trying 172.20.17.48... Connected to HOST (172.20.17.48). Escape character is '^]'. POST /ec/login.htm HTTP/1.1 Host: HOST Cookie: JSESSIONID=A6534nqtHTaUTMwp-q Content-Type: application/x-www-form-urlencoded Content-Length: 33  userName=z10000&password=password HTTP/1.1 302 Found Date: Fri, 29 Dec 2006 17:56:23 GMT Location: http://HOST/ec/postLogin.htm Content-Length: 234 Content-Type: text/html; charset=iso-8859-1  <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>302 Found</title> </head><body> <h1>Found</h1> <p>The document has moved <a href='http://HOST/ec/postLogin.htm'>here</a>.</p> </body></html> Connection closed by foreign host.    Transcript #2, proxyerroroverride off  [user@HOST ~]$ telnet HOST 80 Trying 172.20.17.48... Connected to HOST (172.20.17.48). Escape character is '^]'. POST /ec/login.htm HTTP/1.1 Host: HOST Cookie: JSESSIONID=A6534nqtHTaUTMwp-q Content-Type: application/x-www-form-urlencoded Content-Length: 33  userName=z10000&password=password HTTP/1.1 302 Found Date: Fri, 29 Dec 2006 17:57:44 GMT Server: Resin/3.0.14 Pragma: No-cache Expires: Thu, 01 Jan 1970 00:00:00 GMT Cache-Control: no-cache Cache-Control: no-store Content-Language: en-US Location: http://HOST/ec/postLogin.htm Content-Length: 88 Set-Cookie: userInfo=VARIOUSSTUFF; domain=HOST; path=/ Set-Cookie: XXXX=w0NIFrSTDuo250TP4oXq13pk9C1Rlt9Q; domain=HOST; path=/ Content-Type: text/html; charset=UTF-8  The URL has moved <a href='http://HOST/ec/postLogin.htm'>here</a>  Connection closed by foreign host.   Update: we applied Bart's proposed patch, with line numbers modified to suit 2.2.3, and it solved the problem for us.   So with proxyerroroverride On and patched 2.2.3, we are able to pass cookies back from a resin app server serving 302 responses over http.  Very good!  *** Bug 41601 has been marked as a duplicate of this bug. *** I can confirm this is indeed NOT FIXED in httpd 2.2.4.  I had thought it was based on some tests I did earlier, but today we had application who displayed the exact same symptoms as others have reported...when issuing a 302 redirect with ProxyErrorOverride On, the Set-Cookie header was lost.  I used the patch from Bug ID 41601 submitted by Stuart Children as this was updated for 2.2.4.  I can confirm that applying this patch fixed my problem...could this patch please be applied to both trunk and/or 2.2? I don't think this can reasonably be described as a bug: rather it's documented behaviour of ProxyErrorOverride.  We can't apply the suggested patch, because it breaks that.  *You* can of course apply the patch yourself, since it's the behaviour you want.  However, it's a reasonable enhancement request, to provide an option to preserve *headers* from the backend while substituting a local response *body*.  Simple solution: if you want your cookies from the backend, don't override them.  (In reply to comment #8) > I don't think this can reasonably be described as a bug: rather it's > documented behaviour of ProxyErrorOverride.  Huh? http://httpd.apache.org/docs/2.2/mod/mod_proxy.html#proxyerroroverride  [quote] This directive is useful for reverse-proxy setups, where you want to have a common look and feel on the error pages seen by the end user. This also allows for included files (via mod_include's SSI) to get the error code and act accordingly (default behavior would display the error page of the proxied server, turning this on shows the SSI Error message). [/quote]  Since when are redirects considered errors?  This bug is a *regression* in behaviour from 2.0.x.  > However, it's a reasonable enhancement request, to provide an option to > preserve *headers* from the backend while substituting a local response > *body*.  We (well, I) don't want that. We want the entire proxied request to be left alone, because there's nothing wrong with it! Don't replace the body with the ErrorDocument, don't remove the headers.  > Simple solution: if you want your cookies from the backend, don't override > them.  I'm not... Clearly the documentation is not explicit enough here to define how the implementation should act; I'd certainly agree that not treating 3xx response as 'errors' for the purposes of ProxyErrorOverride would be the obvious default.  Are you sure this is a regression since vanilla 2.0.x Stuart?  AFAICT the 2.0.x code will override errors for any non-2xx response too. (In reply to comment #10) > Clearly the documentation is not explicit enough here to define how the > implementation should act; I'd certainly agree that not treating 3xx response > as 'errors' for the purposes of ProxyErrorOverride would be the obvious > default.  Yes, granted it does give a definition of 'error pages' - but as you seem to agree, most people would not take that to include redirects (or 304 responses come to that).  > Are you sure this is a regression since vanilla 2.0.x Stuart?  AFAICT the > 2.0.x code will override errors for any non-2xx response too.  Granted we do apply patches and our own modules to the server I saw this on (when just upgrading the httpd version and looking for broken things), but I'm pretty sure none of those would affect this area of behaviour. However, I have confirmed that (see below).  The 2.0.x code is actually pretty confused, and potentially broken in other ways. Within ap_proxy_http_process_response  we see:      * if we are overriding the errors, we can't put the content     * of the page into the brigade     */     if ( (conf->error_override ==0) || r->status < 400 ) {  Which would be correct in my book (though better expressed using the macros). But then later:      if ( conf->error_override ) {         /* the code above this checks for 'OK' which is what the hook expects */         if ( r->status == HTTP_OK )             return OK;         else  {             int status = r->status;             r->status = HTTP_OK;             /* Discard body, if one is expected */             if ((status > 199) && /* not any 1xx response */                 (status != HTTP_NO_CONTENT) && /* not 204 */                 (status != HTTP_RESET_CONTENT) && /* not 205 */                 (status != HTTP_NOT_MODIFIED)) { /* not 304 */                ap_discard_request_body(rp);            }             return status;         }     } else          return OK;  which would seem to indicate that only 200 would ever be considered a non-error response (even more wrong I hope you'll agree)!  However, there is something more going on - which I've not had time to follow through/debug as yet. Proof is in what an actual vanilla server does, so here goes:  Built Apache (2.2.4 and 2.0.58) with: ./configure --prefix=/tmp/httpd-X.X.X --with-mpm=prefork --enable-so --enable-mods-shared='rewrite expires info deflate speling headers unique-id proxy asis'  with: gcc (GCC) 4.1.1 20070105 (Red Hat 4.1.1-51) on: Linux gnl05024.int.gnl 2.6.19-1.2895.fc6 #1 SMP Wed Jan 10 19:28:18 EST 2007 i686 i686 i386 GNU/Linux  On one server (I guess being fair you'd put this somewhere independent - but I tried it both way rounds), create a CGI which does this:  $ curl --get --verbose http://localhost:2058/cgi-bin/redirect * About to connect() to localhost port 2058 *   Trying 127.0.0.1... connected * Connected to localhost (127.0.0.1) port 2058 > GET /cgi-bin/redirect HTTP/1.1 > User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5 > Host: localhost:2058 > Accept: */* >  < HTTP/1.1 302 Found < Date: Thu, 15 Feb 2007 18:07:36 GMT < Server: Apache/2.0.58 (Unix) < X-My-Secret-Header: moo < Location: http://httpd.apache.org/ < Content-Length: 283 < Content-Type: text/html; charset=iso-8859-1 <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>302 Found</title> </head><body> <h1>Found</h1> <p>The document has moved <a href='http://httpd.apache.org/'>here</a>.</p> <hr> <address>Apache/2.0.58 (Unix) Server at localhost Port 2058</address> </body></html> * Connection #0 to host localhost left intact * Closing connection #0  OK, so we've got a 302 response, with a custom header in there.  Now take both our 2.2 and 2.0 servers with respective vanilla configs and add:  ProxyPass /rproxy http://localhost:2058/cgi-bin ProxyPassReverse /rproxy http://localhost:2058/cgi-bin ProxyErrorOverride On  and restart. Now we can make the request to the CGI above but going through each reverse proxy. Firstly, on the 2.0.58 server:  $ curl --get --verbose http://localhost:2058/rproxy/redirect * About to connect() to localhost port 2058 *   Trying 127.0.0.1... connected * Connected to localhost (127.0.0.1) port 2058 > GET /rproxy/redirect HTTP/1.1 > User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5 > Host: localhost:2058 > Accept: */* >  < HTTP/1.1 302 Found < Date: Thu, 15 Feb 2007 18:16:54 GMT < Server: Apache/2.2.4 (Unix) < X-My-Secret-Header: moo < Location: http://httpd.apache.org/ < Content-Length: 208 < Content-Type: text/html; charset=iso-8859-1 <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>302 Found</title> </head><body> <h1>Found</h1> <p>The document has moved <a href='http://httpd.apache.org/'>here</a>.</p> </body></html> * Connection #0 to host localhost left intact * Closing connection #0  Correct HTTP status and custom header is present. Now on the 2.2.4 server:  $ curl --get --verbose http://localhost:2204/rproxy/redirect * About to connect() to localhost port 2204 *   Trying 127.0.0.1... connected * Connected to localhost (127.0.0.1) port 2204 > GET /rproxy/redirect HTTP/1.1 > User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5 > Host: localhost:2204 > Accept: */* >  < HTTP/1.1 302 Found < Date: Thu, 15 Feb 2007 18:17:40 GMT < Location: http://httpd.apache.org/ < Content-Length: 208 < Content-Type: text/html; charset=iso-8859-1 <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>302 Found</title> </head><body> <h1>Found</h1> <p>The document has moved <a href='http://httpd.apache.org/'>here</a>.</p> </body></html> * Connection #0 to host localhost left intact * Closing connection #0  We've lost the headers. QED.   Interestingly, making HEAD requests we see behaviour the other way around:  $ curl --head --verbose http://localhost:2058/rproxy/redirect * About to connect() to localhost port 2058 *   Trying 127.0.0.1... connected * Connected to localhost (127.0.0.1) port 2058 > HEAD /rproxy/redirect HTTP/1.1 > User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5 > Host: localhost:2058 > Accept: */* >  < HTTP/1.1 302 Found HTTP/1.1 302 Found < Date: Thu, 15 Feb 2007 18:18:11 GMT Date: Thu, 15 Feb 2007 18:18:11 GMT < Location: http://httpd.apache.org/ Location: http://httpd.apache.org/ < Content-Type: text/html; charset=iso-8859-1 Content-Type: text/html; charset=iso-8859-1  * Connection #0 to host localhost left intact * Closing connection #0  $ curl --head --verbose http://localhost:2204/rproxy/redirect * About to connect() to localhost port 2204 *   Trying 127.0.0.1... connected * Connected to localhost (127.0.0.1) port 2204 > HEAD /rproxy/redirect HTTP/1.1 > User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5 > Host: localhost:2204 > Accept: */* >  < HTTP/1.1 302 Found HTTP/1.1 302 Found < Date: Thu, 15 Feb 2007 18:18:52 GMT Date: Thu, 15 Feb 2007 18:18:52 GMT < Server: Apache/2.2.4 (Unix) Server: Apache/2.2.4 (Unix) < X-My-Secret-Header: moo X-My-Secret-Header: moo < Location: http://httpd.apache.org/ Location: http://httpd.apache.org/ < Content-Type: text/html; charset=iso-8859-1 Content-Type: text/html; charset=iso-8859-1  * Connection #0 to host localhost left intact * Closing connection #0  Also note that *both* servers 'pause' for ~5s between receiving the request and responding. I think that this is caused by the backend server trying to stream its body out, and the frontend server not consuming it - possibly a seperate issue. Why the custom header comes through in 2.2.4 and not in 2.0.5 I haven't looked into - but the fact that GET and HEAD give you different headers would seem to be a bug with each version yes?  Anyway, applying my patch to 2.2.4:  $ curl --get --verbose http://localhost:2204/rproxy/redirect * About to connect() to localhost port 2204 *   Trying 127.0.0.1... connected * Connected to localhost (127.0.0.1) port 2204 > GET /rproxy/redirect HTTP/1.1 > User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5 > Host: localhost:2204 > Accept: */* >  < HTTP/1.1 302 Found < Date: Thu, 15 Feb 2007 18:30:59 GMT < Server: Apache/2.2.4 (Unix) < X-My-Secret-Header: moo < Location: http://httpd.apache.org/ < Content-Length: 208 < Content-Type: text/html; charset=iso-8859-1 <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>302 Found</title> </head><body> <h1>Found</h1> <p>The document has moved <a href='http://httpd.apache.org/'>here</a>.</p> </body></html> * Connection #0 to host localhost left intact * Closing connection #0  So it now passes the header through correctly. Also, the HEAD is now the same:  $ curl --head --verbose http://localhost:2204/rproxy/redirect * About to connect() to localhost port 2204 *   Trying 127.0.0.1... connected * Connected to localhost (127.0.0.1) port 2204 > HEAD /rproxy/redirect HTTP/1.1 > User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5 > Host: localhost:2204 > Accept: */* >  < HTTP/1.1 302 Found HTTP/1.1 302 Found < Date: Thu, 15 Feb 2007 18:31:37 GMT Date: Thu, 15 Feb 2007 18:31:37 GMT < Server: Apache/2.2.4 (Unix) Server: Apache/2.2.4 (Unix) < X-My-Secret-Header: moo X-My-Secret-Header: moo < Location: http://httpd.apache.org/ Location: http://httpd.apache.org/ < Content-Type: text/html; charset=iso-8859-1 Content-Type: text/html; charset=iso-8859-1  * Connection #0 to host localhost left intact * Closing connection #0  And the 'pause' has gone - hence my theory.  I think the above all indicates:  1) 2.2.x has different behaviour from 2.0.x (as myself - and others it would seem - were expecting/relying on that, I call it a regression) in how they treat 3xx response when erroroveride is on. 2) Both branches may have a bug with HEAD not being the same as GET. 3) There's a potential issue left with bodies not being consumed (?)   I'll look further into 2) and 3) tomorrow, if time allows. Have been stuck in meetings most of this afternoon, it's past home time, and I've looked at this enough already for one day. :) (In reply to comment #11) > Yes, granted it does give a definition of 'error pages' - but as you seem to > agree, most people would not take that to include redirects (or 304 responses > come to that).  Sigh, see what happens when you're tired. That should obviously read:  it does *not* give a definition of 'error pages' (In reply to comment #11) > 2) Both branches may have a bug with HEAD not being the same as GET.  This one is slightly complex. See bug #41646  > 3) There's a potential issue left with bodies not being consumed (?)   Relatively straight-forward. See bug #41644  I think these are all independent issues (well, they are related in the block of code the affect which makes for confusion testing when you start discovering them, but they can be resolved on their own). Created an attachment (id=19915) extend directive based on Nick's comments  see http://mail-archives.apache.org/mod_mbox/httpd-dev/200704.mbox/%3c20070404163031.71e4da7b@grimnir%3e simple fix to skip override processing for 1xx and 3xx (in addition to 2xx) responses committed to trunk and proposed for backport to 2.2.x For posterity; references to the fixes committed:  trunk: http://svn.apache.org/viewvc?view=rev&rev=527969 2.2.x: http://svn.apache.org/viewvc?view=rev&rev=534068 			Eric Covener	Jeff Tharp	Jeff Trawick	Joe Orton	Nick Kew	Ruediger Pluem	Stuart Children	jonah benton
39253	null	RESOLVED		Bjorn Stabell	1144501740000	1144528969000		Rewrite proxy requests being handled by wrong proxy In Apache 2.2.1 (the release candidate) either mod_proxy or mod_rewrite is breaking badly.  Here's  what the trimmed down config file looks like (it still exhibits the same problem):  \tListen 192.168.100.22:80 \t<VirtualHost 192.168.100.22:80> \t        ServerName www.domain.com  \t        RewriteEngine On \t        RewriteRule ^/external/(.*)\t\thttp://192.168.100.66:8099/$1 [P] \t        RewriteRule  ^/(.*)\t\t\thttp://127.0.0.1:8080/$1 [P] \t</VirtualHost>   Steps to reproduce the problem:  SCENARIO 1:  1. Restart Apache  2. Access http://www.domain.com/ -> is proxied to 127.0.0.1:8080 as expected  3. Access http://www.domain.com/external/ (and all subsequent requests) -> is still proxied to 127.0.0.1:8080, although rewrite_log shows it matches the /external rule   SCENARIO 2:  1. Restart Apache  2. Access http://www.domain.com/external/ -> is proxied to 192.168.100.66:8099 as expected  3. Access http://www.domain.com/external/ (and all subsequent requests) -> is still proxied to 192.168.100.66:8099, although rewrite_log shows it matches the / rule  Btw, I don't have mod_proxy_balancer loaded.	Created an attachment (id=18045) Patch against trunk  Could you please give the attached patch a try and have a look if it fixes your problem? Yes, great!  With the patch applied I can no longer reproduce the problem.  Thanks a bunch!  What great service, on a Saturday! :) Patch committed to trunk as r392613 (http://svn.apache.org/viewcvs?rev=392613&view=rev) and proposed for backport 2.2.x as r392700 (http://svn.apache.org/viewcvs?rev=392700&view=rev) Backported to 2.2.x as r393047 (http://svn.apache.org/viewcvs?rev=393047&view=rev). *** Bug 39763 has been marked as a duplicate of this bug. ***			Bjorn Stabell	Nick Kew	Ruediger Pluem
39266	null	RESOLVED		James Pfaff	1144722780000	1146775152000		After enabling mod_cache via the mod_memory_cache storage engine MIME types revert to the DefaultType directive... After enabling mod_cache via the mod_mem_cache storage engine MIME types for  html files revert to the DefaultType directive even if a force type directive  has been placed in the http.conf file. The only file type I actually tested  this on was a .css file in which the mime types file had a definition, there  was an AddType declaration%, and a ForceType declaration on ALL CSS files. I  had to improvise and disable caching on all files that this bug could  interfere with.  Note: Only tested on CSS files Only tested with the mod_mem_cache cache storage engine The original response with a clear cache was not documented so it is possible  this is a bug with some sort of module that has impact on MIME types sent to  the client	Created an attachment (id=18097) Patch against trunk  I can confirm this bug. Can you please check if the attached patch fixes your problem? (In reply to comment #2) > I can confirm this bug. Can you please check if the attached patch fixes your > problem?  I would like to, but if I am correct I can't just add that to the module  seeing as it is already pre-compiled and I am on a Windows system. I  appologize, but I don't have much proficiency with C/C++ programming. If you  could give me the mod_mem_cache.so module for Windows with that patch applied  I would be happy to give it a try. Ok, scratch that. I downloaded the source and applied the patch to the proper  section of the file, now the only problem is how exactly do I go about  compiling the updated file? You need to recompile the whole server, but you do not need to exchange anything more then the mod_mem_cache file within your installed server with the one that came out of your compilation. I am not a Windows guy so I cannot provide any help about how to compile httpd on Windows, but I guess the following links will provide valuable help:  http://httpd.apache.org/docs/trunk/platform/win_compiling.html http://httpd.apache.org/docs/trunk/platform/windows.html Hmmm... I just found this bug report. I'm going to give the attached patch a try and let you know what happens. (In reply to comment #6) > Hmmm... I just found this bug report. I'm going to give the attached patch a try > and let you know what happens.  After some limited testing this patch appears to fix the problem (applied it to apache-2.2.0) (In reply to comment #7) > After some limited testing this patch appears to fix the problem (applied it to > apache-2.2.0)  Also applied it to apache-2.2.2 and it appears to fix the problem in 2.2.2 as well.  Thanks for test. Committed to trunk as r399388 (http://svn.apache.org/viewcvs?rev=399388&view=rev). *** Bug 39124 has been marked as a duplicate of this bug. *** Proposed for backport to 2.2.x as r399856 (http://svn.apache.org/viewcvs?rev=399856&view=rev). *** Bug 39539 has been marked as a duplicate of this bug. *** Backported to 2.2.x as r410932 (http://svn.apache.org/viewvc?rev=410932&view=rev).			Dick Snippe	James Pfaff	Ruediger Pluem
39282	null	CLOSED		Davi Arnaut	1144852800000	1145228233000		read of unitialized memory In ap_rgetline_core() if the brigade (ctx->bb) contais only an EOS bucket after the ap_get_brigade() call, the for loop will stop and last_char will be read without being properly itialized.	Created an attachment (id=18083) initialize last_char with zero  Committed to trunk as r394070 (http://svn.apache.org/viewcvs?rev=394070&view=rev). Thanks. Proposed for backport to 2.2.x as r394653 (http://svn.apache.org/viewcvs?rev=394653&view=rev). Created an attachment (id=18112) 2.0.x version of the patch  Proposed for backport to 2.0.x as r394654 (http://svn.apache.org/viewcvs?rev=394654&view=rev).  Backported to 2.2.x as r395985 (http://svn.apache.org/viewcvs?rev=395985&view=rev).			Davi Arnaut	Ruediger Pluem
39317	null	RESOLVED		Lucas Gonze	1145059860000	1188213172000		add mapping from .xspf extension to application/xspf+xml The XSPF playlist format uses the extension .xspf and content type application/xspf.xml.	Your URL points to a draft that claims to expire in 2005.  Google fails to  find any reference to the type being registered, or even in process of  registration, at IANA.  Please clarify.  Added to trunk in rev 570206 			Nick Kew	Roy T. Fielding
39321	null	RESOLVED		Nick	1145132580000	1145221415000		ProxyPass causes segfaults When specifying something like:  ProxyPass / test5 ProxyPassReverse / test5  httpd will segfault on startup.  If I change to:  ProxyPass / http://test5 ProxyPassReverse / http://test5  then it will startup just fine.  Not that I can think of a need to go without the http:// at the moment, but nevertheless it should not segfault.  More details below.  Using apache httpd 2.2.0  configure options: --includedir=/usr/apache-include /         --prefix=/usr --sysconfdir=/etc/httpd --localstatedir=/var /         --enable-so /         --enable-mime-magic /         --enable-headers /         --enable-proxy /         --enable-rewrite /         --enable-proxy-http /         --enable-ssl /         --enable-cgid /         --disable-userdir /         --with-mpm=worker /         --enable-suexec /         --with-suexec-caller=apache /         --with-suexec-docroot=/home /         --with-suexec-logfile=/var/log/httpd/suexec.log   small httpd.conf that can be used to reproduce the error:  ServerRoot '/' PidFile /var/run/httpd.pid User apache Group apache Listen 80 ErrorLog /var/log/httpd/error/apache.log CustomLog /var/log/httpd/access/apache.log combined Scriptsock /usr/www/apachecgi/cgid-sock  NameVirtualHost *:80  <VirtualHost *:80> ProxyPass / test5 ProxyPassReverse / test5 </VirtualHost>    output of httpd -l:  Compiled in modules:   core.c   mod_authn_file.c   mod_authn_default.c   mod_authz_host.c   mod_authz_groupfile.c   mod_authz_user.c   mod_authz_default.c   mod_auth_basic.c   mod_include.c   mod_filter.c   mod_log_config.c   mod_env.c   mod_mime_magic.c   mod_headers.c   mod_setenvif.c   mod_proxy.c   mod_proxy_connect.c   mod_proxy_ftp.c   mod_proxy_http.c   mod_proxy_ajp.c   mod_proxy_balancer.c   mod_ssl.c   worker.c   http_core.c   mod_mime.c   mod_status.c   mod_autoindex.c   mod_asis.c   mod_suexec.c   mod_cgid.c   mod_negotiation.c   mod_dir.c   mod_actions.c   mod_alias.c   mod_rewrite.c   mod_so.c	Fixed in trunk: http://svn.apache.org/viewcvs?rev=394390&view=rev  Backport to 2.2 proposed.    Fixed - http://svn.apache.org/viewcvs?rev=394557&view=rev 			Nick Kew
39386	null	RESOLVED		Brian J. France	1145821920000	1155074036000		mod_dbd merge function needs to merge prepared mod_dbd dbd_merge function needs to merge prepared:  Something like:    cfg->prepared = (add->prepared != NULL) ? add->prepared : base->prepared;	Fixed in 2.2.3			Nick Kew
39420	null	RESOLVED		Eric	1146103260000	1166189706000		FilterProvider ignores resp prefix. There is a bug in FilterProvider directive of mod_filter.  It will not work properly if 'resp' is specified. It will match everything instead of only the header specified.  eg. FilterProvider COMPRESS DEFLATE resp=Content-Type $text/html  will cause the deflate filter to be applied to everything, regardless of if  the content-type matched or not.  It works properly only if 'resp=' is omitted.  eg. the following will only apply the filter to text/html FilterProvider COMPRESS DEFLATE Content-Type $text/html	It seems that the code path that handles the 'resp=' case (around line 640) in 2.2.2 does not invoke ap_str_tolower(str). If you add this line, then things start to work a lot better. However, I am not sure whether this should be added for all cases, or only for the resp= case. Hence I am not proposing a patch. The documentation (mod/mod_filter.html) gives the following example  FilterDeclare SSI FilterProvider SSI INCLUDES resp=Content-Type $text/html FilterChain SSI  as despatch is currently case sensitive and needs to be lower case to work, changing the documentation to the following could help  FilterDeclare SSI FilterProvider SSI INCLUDES resp=content-type $text/html FilterChain SSI Fixed in /trunk/ and 2.2.4.  Thanks for the report. 			Alan Hicks	Nick Kew	Philip Gladstone
39487	null	RESOLVED		Andrew Smith	1146779520000	1164167373000		 error message i have this in my httpd.conf:  CustomLog '|/usr/sbin/rotatelogs /var/log/httpd/access_log.%Y-%m-%d 86400' combined  every time someone loads a page on my site i now get the following lines in my error log:  1 Previous file handle doesn't exists /var/log/httpd/access_log.2006-05-04 piped log program '/usr/sbin/rotatelogs /var/log/httpd/access_log.%Y-%m-%d 86400' failed unexpectedly	This is an unnecessarily confusing error message, it means simply that rotatelogs could not open the log file - perhaps an SELinux error, check for audit errors in dmesg. Fixed on trunk, http://svn.apache.org/viewvc?view=rev&revision=478135			Joe Orton
39518	null	RESOLVED		Christophe JAILLET	1147120860000	1184870655000		 to apr_pmemdup Patchlet to clean up some code.  It change some 'apr_palloc / memcpy' construction into a single apr_pmemdup  which is more easy to read.	Created an attachment (id=18247) Patch for the proposed clean-up  http://svn.apache.org/viewvc?view=rev&revision=557837 			Christophe JAILLET	Nick Kew
39529	null	RESOLVED		Ray Price	1147171800000	1153923883000		No Authentication dialog thrown once valid username (but incorrect password) is entered My Config:  LoadModule authz_user_module modules/mod_authz_user.so LoadModule ldap_module modules/mod_ldap.so LoadModule authnz_ldap_module modules/mod_authnz_ldap.so  <Location /ldap2> AuthBasicProvider ldap AuthType Basic AuthName 'LDAP secure2' AuthLDAPBindDN 'testdomain2//Administrator' AuthLDAPBindPassword password AuthLDAPUrl 'ldap://server:389/OU=Test Users,DC=testdomain2,DC=local?sAMAccountName' AuthzLDAPAuthoritative  off require valid-user  </Location>  I'm authenticating against an Active Directory. I observe that if I enter a correct user name but incorrect password I am not asked to reauthenticate, I just get an internal server error.  This is due to this piece of code:  mod_authnz_ldap.c  static authn_status authn_ldap_check_password(request_rec *r, const char *user,                                               const char *password) { ...         return (LDAP_NO_SUCH_OBJECT == result) ? AUTH_USER_NOT_FOUND #ifdef LDAP_SECURITY_ERROR                  : (LDAP_SECURITY_ERROR(result)) ? AUTH_DENIED #endif                  : AUTH_GENERAL_ERROR; ... }  LDAP_SECURITY_ERROR is not defined in the winldap SDK (nor the Sun ONE sdk) - I presume it is an OpenLDAP addition. This results in any error other than an invalid object being treated as an internal server error.  This can be corrected by modifying to:  #ifdef LDAP_SECURITY_ERROR                  : (LDAP_SECURITY_ERROR(result)) ? AUTH_DENIED #else \t\t\t\t : LDAP_INAPPROPRIATE_AUTH == result ? AUTH_DENIED \t\t\t\t : LDAP_INVALID_CREDENTIALS == result ? AUTH_DENIED \t\t\t\t : LDAP_INSUFFICIENT_RIGHTS == result ? AUTH_DENIED #endif	Fixed in trunk and proposed for backport Bug observed as well on Sun Solaris 5.8. Apparently, LDAP_INSUFFICIENT_RIGHTS isn't defined neither in Sun sdk. LDAP_INSUFFICIENT_ACCESS may be used instead. The abstraction of this error message in APR-util in apr_ldap_init.h   needs to be fixed, mod_authnz_ldap shouldn't be including toolkit specific #defines anywhere. The abstraction has been added to apr-util.  It is called  APU_LDAP_INSUFFICIENT_ACCESS.  But we can't use it in mod_authnz_ldap.c until  a suitable libaprutil has been released.  So for now, mod_authnz_ldap.c has to  include #defines. Backported to 2.2.x as r425731 (http://svn.apache.org/viewvc?rev=425731&view=rev).			Brad Nicholes	Damien Lachuer	Graham Leggett	Ruediger Pluem
39593	null	RESOLVED		Michael Han	1147813680000	1153749688000		mod_cache always misses mod_proxy_http files over SSL I have Apache 2.2.2 with mod_ssl, mod_proxy (and mod_proxy_http) and mod_cache (both mem & disk) on a RedHat EL4 U3 box. I have SSL termination enabled on my _default_:443 vhost and proxypass to HTTP on a backend Apache server. Files retrieved from the proxy endpoint are 100% cache miss in mod_cache. Relevant vhost configuration stanza looks like:  SSLProxyEngine On ProxyRequests Off ProxyPass /s5/ http://rcdev1ws14/ CacheEnable disk / CacheEnable disk http://rcdev1ws14/ CacheEnable mem / CacheEnable mem http://rcdev1ws14/ CacheRoot /var/run/httpd/cache CacheDirLength 1 CacheDirLevels 1 MCacheSize 20480 # The following are me getting increasingly desparate to make mod_cache hit CacheIgnoreCacheControl On CacheStorePrivate On CacheStoreNoStore On CacheIgnoreHeaders User-Agent Accept Max-Forwards X-Forwarded-For X-Forwarded-Host X-Forwarded-Server Cookie Vary  What's interesting is that the same configuration directives on my _default_:80 vhost works properly. The cache hits.  I added additional debugging statements to mod_cache (inline diff included below). Requesting the same file twice in a row, I grabbed the debug logs and have included them below (removed ssl_engine_io and ssl_engine_shmcb class messages, as they appear to be useless for current purposes). Notice that URL canonicalisation is occurring AFTER mod_disk_cache attempts to look up the file in cache, but then stores the file using a key generated from the canonicalised URL. Clearly this must be the problem's root cause. I'm unclear about what needs to be changed, though.  <<EndOfLogOutput [Tue May 16 14:07:20 2006] [info] [client 172.16.0.44] Connection to child 2 established (server rcdev1ws18:443) [Tue May 16 14:07:20 2006] [info] Seeding PRNG with 648 bytes of entropy [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1752): OpenSSL: Handshake: start [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: before/accept initialization [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 read client hello A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write server hello A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write certificate A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write server done A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 flush data [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 read client key exchange A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 read finished A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write change cipher spec A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write finished A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 flush data [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1598): Inter-Process Session Cache: request=SET status=OK id=150FA988C7DB59F6F35666ECF91FD055478CC00399AEA87E4E6E803D8A275A10 timeout=300s (session caching) [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1756): OpenSSL: Handshake: done [Tue May 16 14:07:20 2006] [info] Connection: Client IP: 172.16.0.44, Protocol: TLSv1, Cipher: RC4-SHA (128/128 bits) [Tue May 16 14:07:20 2006] [info] Initial (No.1) HTTPS request received for child 2 (server rcdev1ws18:443) [Tue May 16 14:07:20 2006] [error] disk_cache: Failed to open file /var/run/httpd/cache/b/DgKJmDvOggzqD69@NEvzQ.header. [Tue May 16 14:07:20 2006] [debug] cache_storage.c(311): cache_select(): Decline to serve from provider (null). [Tue May 16 14:07:20 2006] [debug] cache_storage.c(311): cache_select(): Decline to serve from provider (null). [Tue May 16 14:07:20 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /s5/images/login.gif [Tue May 16 14:07:20 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /s5/images/login.gif [Tue May 16 14:07:20 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //rcdev1ws14/images/login.gif [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1378): [client 172.16.0.44] proxy: http: found worker http://rcdev1ws14/ for http://rcdev1ws14/images/login.gif [Tue May 16 14:07:20 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Tue May 16 14:07:20 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://rcdev1ws14/images/login.gif [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (rcdev1ws14) [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1858): proxy: connecting http://rcdev1ws14/images/login.gif to rcdev1ws14:80 [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1951): proxy: connected /images/login.gif to rcdev1ws14:80 [Tue May 16 14:07:20 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 172.16.100.164:80 (rcdev1ws14) [Tue May 16 14:07:20 2006] [debug] mod_proxy_http.c(1448): proxy: start body send [Tue May 16 14:07:20 2006] [debug] mod_cache.c(602): cache: Caching url: /s5/images/login.gif [Tue May 16 14:07:20 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Tue May 16 14:07:20 2006] [debug] mod_disk_cache.c(959): disk_cache: Stored headers for URL http://rcdev1ws18:80/s5/images/login.gif? [Tue May 16 14:07:20 2006] [debug] mod_disk_cache.c(1048): disk_cache: Body for URL http://rcdev1ws18:80/s5/images/login.gif? cached. [Tue May 16 14:07:20 2006] [debug] mod_proxy_http.c(1537): proxy: end body send [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (rcdev1ws14) [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1770): OpenSSL: Write: SSL negotiation finished successfully [Tue May 16 14:07:20 2006] [info] [client 172.16.0.44] Connection closed to child 2 with standard shutdown (server rcdev1ws18:443) [Tue May 16 14:07:20 2006] [info] [client 172.16.0.44] Connection to child 4 established (server rcdev1ws18:443) [Tue May 16 14:07:20 2006] [info] Seeding PRNG with 648 bytes of entropy [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1752): OpenSSL: Handshake: start [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: before/accept initialization [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 read client hello A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write server hello A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write certificate A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write server done A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 flush data [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 read client key exchange A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 read finished A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write change cipher spec A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 write finished A [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1760): OpenSSL: Loop: SSLv3 flush data [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1598): Inter-Process Session Cache: request=SET status=OK id=E086C9A9C157DF5AC6383786D1E5D270DA92C697B085ACBE65F239390CED592E timeout=300s (session caching) [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1756): OpenSSL: Handshake: done [Tue May 16 14:07:20 2006] [info] Connection: Client IP: 172.16.0.44, Protocol: TLSv1, Cipher: RC4-SHA (128/128 bits) [Tue May 16 14:07:20 2006] [info] Initial (No.1) HTTPS request received for child 4 (server rcdev1ws18:443) [Tue May 16 14:07:20 2006] [error] disk_cache: Failed to open file /var/run/httpd/cache/b/DgKJmDvOggzqD69@NEvzQ.header. [Tue May 16 14:07:20 2006] [debug] cache_storage.c(311): cache_select(): Decline to serve from provider (null). [Tue May 16 14:07:20 2006] [debug] cache_storage.c(311): cache_select(): Decline to serve from provider (null). [Tue May 16 14:07:20 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /s5/images/login.gif [Tue May 16 14:07:20 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /s5/images/login.gif [Tue May 16 14:07:20 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //rcdev1ws14/images/login.gif [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1378): [client 172.16.0.44] proxy: http: found worker http://rcdev1ws14/ for http://rcdev1ws14/images/login.gif [Tue May 16 14:07:20 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Tue May 16 14:07:20 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://rcdev1ws14/images/login.gif [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (rcdev1ws14) [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1858): proxy: connecting http://rcdev1ws14/images/login.gif to rcdev1ws14:80 [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1951): proxy: connected /images/login.gif to rcdev1ws14:80 [Tue May 16 14:07:20 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 172.16.100.164:80 (rcdev1ws14) [Tue May 16 14:07:20 2006] [debug] mod_proxy_http.c(1448): proxy: start body send [Tue May 16 14:07:20 2006] [debug] mod_cache.c(602): cache: Caching url: /s5/images/login.gif [Tue May 16 14:07:20 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Tue May 16 14:07:20 2006] [debug] mod_disk_cache.c(959): disk_cache: Stored headers for URL http://rcdev1ws18:80/s5/images/login.gif? [Tue May 16 14:07:20 2006] [debug] mod_disk_cache.c(1048): disk_cache: Body for URL http://rcdev1ws18:80/s5/images/login.gif? cached. [Tue May 16 14:07:20 2006] [debug] mod_proxy_http.c(1537): proxy: end body send [Tue May 16 14:07:20 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (rcdev1ws14) [Tue May 16 14:07:20 2006] [debug] ssl_engine_kernel.c(1770): OpenSSL: Write: SSL negotiation finished successfully [Tue May 16 14:07:20 2006] [info] [client 172.16.0.44] Connection closed to child 4 with standard shutdown (server rcdev1ws18:443) EndOfLogOutput  --- mod_disk_cache.c 2006-04-21 18:53:06.000000000 -0700 +++ mod_disk_cache.c.new        2006-05-16 13:32:12.000000000 -0700 @@ -389,6 +389,7 @@      flags = APR_READ|APR_BINARY|APR_BUFFERED;      rc = apr_file_open(&dobj->hfd, dobj->hdrsfile, flags, 0, r->pool);      if (rc != APR_SUCCESS) { +        ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server, 'disk_cache: Failed t o open file %s.', dobj->hdrsfile);          return DECLINED;      }     @@ -404,6 +405,7 @@          apr_file_read_full(dobj->hfd, &expire, len, &len);           if (expire < r->request_time) { +            ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server, 'disk_cache: File  %s in cache has expired.', dobj->hdrsfile);              return DECLINED;          }     @@ -426,6 +428,7 @@          flags = APR_READ|APR_BINARY|APR_BUFFERED;          rc = apr_file_open(&dobj->hfd, dobj->hdrsfile, flags, 0, r->pool);          if (rc != APR_SUCCESS) { +            ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server, 'disk_cache: Fail ed to open file %s.', dobj->hdrsfile);              return DECLINED;          }         }    @@ -457,6 +460,7 @@  #endif      rc = apr_file_open(&dobj->fd, dobj->datafile, flags, 0, r->pool);      if (rc != APR_SUCCESS) { +        ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server, 'disk_cache: Failed to open file %s.', dobj->datafile);          /* XXX: Log message */          return DECLINED;      } @@ -470,6 +474,7 @@      rc = file_cache_recall_mydata(dobj->hfd, info, dobj, r);      if (rc != APR_SUCCESS) {          /* XXX log message */ +        ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server, 'disk_cache: Failed to retrieve file %s bytes.', dobj->hdrsfile);          return DECLINED;      }  --- cache_storage.c  2006-04-21 18:53:06.000000000 -0700 +++ cache_storage.c.new 2006-05-16 13:32:28.000000000 -0700 @@ -195,6 +195,9 @@                            if (list->provider->recall_headers(h, r) != APR_SUCCESS) {                  /* TODO: Handle this error */ +                ap_log_error(APLOG_MARK, APLOG_DEBUG, APR_SUCCESS, +                             r->server, +                             'cache_select(): Failed to recall_headers for provider %s.', list->provider_name);                  return DECLINED;              }  @@ -305,6 +308,9 @@          }          case DECLINED: {              /* try again with next cache type */ +            ap_log_error(APLOG_MARK, APLOG_DEBUG, APR_SUCCESS, r->server, +                  'cache_select(): Decline to serve from provider %s.', +                  cache->provider_name);              list = list->next;              continue;          }	This bug is somewhat similar to #38017. I can confirm it. Could you please give the attached patch a try? It is against trunk, but also works against httpd 2.2.2. Created an attachment (id=18296) Patch against trunk  I saw that bug and even tried backing out the patch from the 2.2.2 code. But the patch you provided seems to work fine. Thanks! Commited to trunk as r407357 (http://svn.apache.org/viewcvs?rev=407268&view=rev). Thanks for testing. Proposed for backport to 2.2.x as r409425 (http://svn.apache.org/viewcvs?rev=409425&view=rev). Backported to 2.2.x as r425035 (http://svn.apache.org/viewvc?rev=425035&view=rev).			Michael Han	Ruediger Pluem
39613	null	RESOLVED		Olaf van der Spek	1147975980000	1189690119000		httpd-default.conf contains non-default ServerSignature This conf file contains 'ServerSignature On' but the default appears to be off.  So including the default conf in httpd.conf results in changes to the  behaviour, something that's not expected.	Fixed in trunk. Thanks.			Joshua Slive
39647	null	RESOLVED		Christopher Shumway	1148416260000	1171036521000		mod_cache sets incorrect Content-type headers for cached context with backend httpd 1.3.33 and mod_jk 1.2.15 This is similar, but does not appear to be the same as bug 39266.  I've applied the patch to mod_mem_cache.c and it makes no diffrence.  It also does not matter if the storage for mod_cache is disk or memory cache.  Here's the configuration:  Frontend reverse caching proxy server running httpd 2.2.2, prefork mpm.  The backend web server is httpd 1.3.36 with mod_jk 1.2.15.  Mod_jk connects to Tomcat 5.0.30 via an ajp 1.3 connector. The namespace /res/* is mounted into Tomcat via mod_jk's JKMount directive.  The first time content is accessed via the front end proxy, it sends the approperate content-type header, e.g. 'image/jpeg'.  Further attempts to get the same image usually return a content-type header of 'text/html'.  Here's the correct headers from the client and server:  GET /res/img/content/liferaft.jpg HTTP/1.1 Host: nuked.greatschools.net User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3) Gecko/20060426 Firefox/1.5.0.3 Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5 Accept-Language: en-us,en;q=0.5 Accept-Encoding: gzip,deflate Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7 Keep-Alive: 300 Connection: keep-alive Cookie: TRNO=1127250133.198.144.205.133; NumAd=-1; s_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; fcP=C=133&T=1137020088512&V=1137020102487; NXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF; RMFD=011FiFmA; RMID=c690cd854329f1d0; T3CK=TANT%3D1%7CTANO%3D0; s_cc=true; s_sq=%5B%5BB%5D%5D; JSESSIONID=8870E2C3BE344A492CCC1DCCDE4036AC; PATHWAY=3 Pragma: no-cache Cache-Control: no-cache  HTTP/1.x 200 OK Date: Tue, 23 May 2006 20:22:31 GMT Server: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d mod_jk/1.2.15 Etag: W/'26797-1148335021000' Content-Length: 26797 Expires: Wed, 24 May 2006 00:22:31 GMT Content-Type: image/jpeg Last-Modified: Mon, 22 May 2006 21:57:01 GMT Keep-Alive: timeout=5, max=99 Connection: Keep-Alive  The next time the image is requested, the server returns the context-type as 'text/html', which causes the browser to try to render the image as if it where html.  GET /res/img/content/liferaft.jpg HTTP/1.1 Host: nuked.greatschools.net User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3) Gecko/20060426 Firefox/1.5.0.3 Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5 Accept-Language: en-us,en;q=0.5 Accept-Encoding: gzip,deflate Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7 Keep-Alive: 300 Connection: keep-alive Cookie: TRNO=1127250133.198.144.205.133; NumAd=-1; s_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; fcP=C=133&T=1137020088512&V=1137020102487; NXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF; RMFD=011FiFmA; RMID=c690cd854329f1d0; T3CK=TANT%3D1%7CTANO%3D0; s_cc=true; s_sq=%5B%5BB%5D%5D; JSESSIONID=8870E2C3BE344A492CCC1DCCDE4036AC; PATHWAY=3 Pragma: no-cache Cache-Control: no-cache  HTTP/1.x 200 OK Date: Tue, 23 May 2006 20:22:32 GMT Server: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d mod_jk/1.2.15 Etag: W/'26797-1148335021000' Content-Length: 26797 Expires: Wed, 24 May 2006 00:22:32 GMT Content-Type: text/html Last-Modified: Mon, 22 May 2006 21:57:01 GMT Keep-Alive: timeout=5, max=98 Connection: Keep-Alive  Here's another data point:  If the browser requests content that is not being served by mod_jk, then it will work correctly every time.  For example, if the browser requests images/reportcard.jpg, which is being served directly by the backend web server, it will always send a content type of image/jpeg.  GET /images/reportcard.jpg HTTP/1.1 Host: nuked.greatschools.net User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3) Gecko/20060426 Firefox/1.5.0.3 Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5 Accept-Language: en-us,en;q=0.5 Accept-Encoding: gzip,deflate Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7 Keep-Alive: 300 Connection: keep-alive Cookie: TRNO=1127250133.198.144.205.133; NumAd=-1; s_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; fcP=C=133&T=1137020088512&V=1137020102487; NXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF; RMFD=011FiFmA; RMID=c690cd854329f1d0; T3CK=TANT%3D1%7CTANO%3D0; s_cc=true; s_sq=%5B%5BB%5D%5D; JSESSIONID=8870E2C3BE344A492CCC1DCCDE4036AC; PATHWAY=3 Pragma: no-cache Cache-Control: no-cache  HTTP/1.x 200 OK Date: Tue, 23 May 2006 20:30:24 GMT Server: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d mod_jk/1.2.15 Cache-Control: max-age=21600 Expires: Wed, 24 May 2006 02:30:24 GMT Etag: '1fae43-4487-3f4e92c4' Accept-Ranges: bytes Content-Length: 17543 Last-Modified: Thu, 28 Aug 2003 23:39:48 GMT Keep-Alive: timeout=5, max=89 Connection: Keep-Alive Content-Type: image/jpeg	Please post your cache and proxy configuration here. Furthermore please set the loglevel to debug on the proxy server and post the error_log of two subsequent requests where the first one is served directly and the second one is served by the cache with the wrong content-type. Thank you for the follow up.  Here's some more information:  --- httpd.conf --- ServerRoot '/usr/local' Listen 80  LoadModule authn_file_module libexec/apache22/mod_authn_file.so LoadModule authn_dbm_module libexec/apache22/mod_authn_dbm.so LoadModule authn_anon_module libexec/apache22/mod_authn_anon.so LoadModule authn_default_module libexec/apache22/mod_authn_default.so LoadModule authz_host_module libexec/apache22/mod_authz_host.so LoadModule authz_groupfile_module libexec/apache22/mod_authz_groupfile.so LoadModule authz_user_module libexec/apache22/mod_authz_user.so LoadModule authz_dbm_module libexec/apache22/mod_authz_dbm.so LoadModule authz_owner_module libexec/apache22/mod_authz_owner.so LoadModule authz_default_module libexec/apache22/mod_authz_default.so LoadModule auth_basic_module libexec/apache22/mod_auth_basic.so LoadModule auth_digest_module libexec/apache22/mod_auth_digest.so LoadModule file_cache_module libexec/apache22/mod_file_cache.so LoadModule cache_module libexec/apache22/mod_cache.so LoadModule disk_cache_module libexec/apache22/mod_disk_cache.so LoadModule mem_cache_module libexec/apache22/mod_mem_cache.so LoadModule include_module libexec/apache22/mod_include.so LoadModule filter_module libexec/apache22/mod_filter.so LoadModule charset_lite_module libexec/apache22/mod_charset_lite.so LoadModule deflate_module libexec/apache22/mod_deflate.so LoadModule log_config_module libexec/apache22/mod_log_config.so LoadModule logio_module libexec/apache22/mod_logio.so LoadModule env_module libexec/apache22/mod_env.so LoadModule mime_magic_module libexec/apache22/mod_mime_magic.so LoadModule cern_meta_module libexec/apache22/mod_cern_meta.so LoadModule expires_module libexec/apache22/mod_expires.so LoadModule headers_module libexec/apache22/mod_headers.so LoadModule usertrack_module libexec/apache22/mod_usertrack.so LoadModule unique_id_module libexec/apache22/mod_unique_id.so LoadModule setenvif_module libexec/apache22/mod_setenvif.so LoadModule version_module libexec/apache22/mod_version.so LoadModule proxy_module libexec/apache22/mod_proxy.so LoadModule proxy_connect_module libexec/apache22/mod_proxy_connect.so LoadModule proxy_ftp_module libexec/apache22/mod_proxy_ftp.so LoadModule proxy_http_module libexec/apache22/mod_proxy_http.so LoadModule proxy_ajp_module libexec/apache22/mod_proxy_ajp.so LoadModule proxy_balancer_module libexec/apache22/mod_proxy_balancer.so LoadModule ssl_module libexec/apache22/mod_ssl.so LoadModule mime_module libexec/apache22/mod_mime.so LoadModule dav_module libexec/apache22/mod_dav.so LoadModule status_module libexec/apache22/mod_status.so LoadModule autoindex_module libexec/apache22/mod_autoindex.so LoadModule asis_module libexec/apache22/mod_asis.so LoadModule info_module libexec/apache22/mod_info.so LoadModule cgi_module libexec/apache22/mod_cgi.so LoadModule dav_fs_module libexec/apache22/mod_dav_fs.so LoadModule vhost_alias_module libexec/apache22/mod_vhost_alias.so LoadModule negotiation_module libexec/apache22/mod_negotiation.so LoadModule dir_module libexec/apache22/mod_dir.so LoadModule imagemap_module libexec/apache22/mod_imagemap.so LoadModule actions_module libexec/apache22/mod_actions.so LoadModule speling_module libexec/apache22/mod_speling.so LoadModule userdir_module libexec/apache22/mod_userdir.so LoadModule alias_module libexec/apache22/mod_alias.so LoadModule rewrite_module libexec/apache22/mod_rewrite.so  User www Group www  ServerAdmin sysadmin@greatschools.net  <Directory />   AllowOverride None   Order deny,allow   Deny from all </Directory>  TypesConfig /usr/local/etc/apache22/mime.types  ErrorLog /var/log/httpd-error.log LogLevel debug  # simulated proxy log LogFormat '%h %u %X %t /'%r/' %s %b /'%{Referer}i/' /'%{User-Agent}i/' /'%{Cookie}i/'' proxylog customlog /var/log/apache/proxy.log proxylog  # proxy-level rewrites RewriteEngine on  # return 403 forbidden if no user-agent specified # but don't block our load balancers since they don't specify a user-agent RewriteCond %{HTTP_USER_AGENT} ='' ReWriteCond %{REMOTE_ADDR} !207.33.22.13[34] ReWriteRule ^/* / [L,F]  # cache MCacheRemovalAlgorithm GDSF  MCacheSize 786432 MCacheMaxObjectSize  256000 MCacheMaxObjectCount 65535 CacheDefaultExpire 14400 CacheEnable mem /  # proxy ProxyRequests Off ProxyPreserveHost on ProxyPass / http://dev.greatschools.net/  <Proxy *>   Order deny,allow   Allow from all </Proxy>  # mod_deflate <Location />   SetOutputFilter DEFLATE   SetEnvIfNoCase Request_URI /.(?:gif|jpe?g|png)$ no-gzip dont-vary   Header append Vary User-Agent env=!dont-vary </Location>  --- Here's the relevent log for the working request:   [Tue May 23 14:23:20 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /res/img/content/liferaft.jpg [Tue May 23 14:23:20 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /res/img/content/liferaft.jpg [Tue May 23 14:23:20 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1378): [client 198.144.205.133] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/res/img/content/liferaft.jpg [Tue May 23 14:23:20 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Tue May 23 14:23:20 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/res/img/content/liferaft.jpg [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80 [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1951): proxy: connected /res/img/content/liferaft.jpg to dev.greatschools.net:80 [Tue May 23 14:23:20 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket created to connect to dev.greatschools.net [Tue May 23 14:23:20 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Tue May 23 14:23:20 2006] [debug] mod_proxy_http.c(1448): proxy: start body send [Tue May 23 14:23:20 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Tue May 23 14:23:20 2006] [debug] mod_cache.c(602): cache: Caching url: /res/img/content/liferaft.jpg [Tue May 23 14:23:20 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Tue May 23 14:23:20 2006] [info] mem_cache: Cached url: http://nuked.greatschools.net:80/res/img/content/liferaft.jpg? [Tue May 23 14:23:20 2006] [debug] mod_proxy_http.c(1537): proxy: end body send [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net) [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 0 in child 63574 for worker http://dev.greatschools.net/ [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1644): proxy: worker http://dev.greatschools.net/ already initialized [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 0 in child 63574 for (dev.greatschools.net) [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 1 in child 63574 for worker proxy:reverse [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1644): proxy: worker proxy:reverse already initialized [Tue May 23 14:23:20 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 1 in child 63574 for (*)  Here's the relevent log for the non-working request:  [Tue May 23 14:23:24 2006] [debug] cache_storage.c(261): Cached response for /res/img/content/liferaft.jpg isn't fresh.  Adding/replacing conditional request headers. [Tue May 23 14:23:24 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1378): [client 198.144.205.133] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80 [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1951): proxy: connected /res/img/content/liferaft.jpg to dev.greatschools.net:80 [Tue May 23 14:23:24 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(1541): proxy: header only [Tue May 23 14:23:24 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Tue May 23 14:23:24 2006] [debug] mod_cache.c(602): cache: Caching url: /res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net) [Tue May 23 14:23:24 2006] [debug] cache_storage.c(261): Cached response for /res/img/content/liferaft.jpg isn't fresh.  Adding/replacing conditional request headers. [Tue May 23 14:23:24 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1378): [client 198.144.205.133] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80 [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1951): proxy: connected /res/img/content/liferaft.jpg to dev.greatschools.net:80 [Tue May 23 14:23:24 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(1541): proxy: header only [Tue May 23 14:23:24 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Tue May 23 14:23:24 2006] [debug] mod_cache.c(602): cache: Caching url: /res/img/content/liferaft.jpg [Tue May 23 14:23:24 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Tue May 23 14:23:24 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net)   Heres some data from the log when fetching a stand-alone image, one not served via mod_jk.  Interestingly I noticed when mem_cache cached the content, it added a '?' at the end of the URI.  I added a '?' to the end of /res/img/content/liferaft.jpg and it looks like it sent the headers correctly every time.   [Tue May 23 15:15:20 2006] [info] mod_unique_id: using ip addr 198.144.205.144 [Tue May 23 15:15:21 2006] [info] Init: Seeding PRNG with 0 bytes of entropy [Tue May 23 15:15:21 2006] [info] Init: Generating temporary RSA private keys (512/1024 bits) [Tue May 23 15:15:21 2006] [info] Init: Generating temporary DH parameters (512/1024 bits) [Tue May 23 15:15:21 2006] [warn] Init: Session Cache is not configured [hint: SSLSessionCache] [Tue May 23 15:15:21 2006] [info] Init: Initializing (virtual) servers for SSL [Tue May 23 15:15:21 2006] [info] Server: Apache/2.2.2, Interface: mod_ssl/2.2.2, Library: OpenSSL/0.9.7e-p1 [Tue May 23 15:15:21 2006] [info] mod_unique_id: using ip addr 198.144.205.144 [Tue May 23 15:15:22 2006] [info] Init: Seeding PRNG with 0 bytes of entropy [Tue May 23 15:15:22 2006] [info] Init: Generating temporary RSA private keys (512/1024 bits) [Tue May 23 15:15:23 2006] [info] Init: Generating temporary DH parameters (512/1024 bits) [Tue May 23 15:15:23 2006] [info] Init: Initializing (virtual) servers for SSL [Tue May 23 15:15:23 2006] [info] Server: Apache/2.2.2, Interface: mod_ssl/2.2.2, Library: OpenSSL/0.9.7e-p1 [Tue May 23 15:15:23 2006] [notice] Digest: generating secret for digest authentication ... [Tue May 23 15:15:23 2006] [notice] Digest: done [Tue May 23 15:15:23 2006] [notice] Apache/2.2.2 (FreeBSD) mod_ssl/2.2.2 OpenSSL/0.9.7e-p1 DAV/2 configured -- resuming normal operations [Tue May 23 15:15:23 2006] [info] Server built: May 23 2006 12:40:34 [Tue May 23 15:15:23 2006] [debug] prefork.c(991): AcceptMutex: flock (default: flock) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 0 in child 63711 for worker http://dev.greatschools.net/ [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 0 in child 63711 for (dev.greatschools.net) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 1 in child 63711 for worker proxy:reverse [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 1 in child 63711 for (*) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 0 in child 63712 for worker http://dev.greatschools.net/ [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker http://dev.greatschools.net/ already initialized [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 0 in child 63712 for (dev.greatschools.net) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 1 in child 63712 for worker proxy:reverse [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker proxy:reverse already initialized [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 1 in child 63712 for (*) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 0 in child 63715 for worker http://dev.greatschools.net/ [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker http://dev.greatschools.net/ already initialized [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 0 in child 63715 for (dev.greatschools.net) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 1 in child 63715 for worker proxy:reverse [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker proxy:reverse already initialized [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 1 in child 63715 for (*) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 0 in child 63713 for worker http://dev.greatschools.net/ [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker http://dev.greatschools.net/ already initialized [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 0 in child 63713 for (dev.greatschools.net) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 1 in child 63713 for worker proxy:reverse [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker proxy:reverse already initialized [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 1 in child 63713 for (*) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 0 in child 63714 for worker http://dev.greatschools.net/ [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker http://dev.greatschools.net/ already initialized [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 0 in child 63714 for (dev.greatschools.net) [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 1 in child 63714 for worker proxy:reverse [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker proxy:reverse already initialized [Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 1 in child 63714 for (*) [Tue May 23 15:16:25 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /images/reportcard.jpg [Tue May 23 15:16:25 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /images/reportcard.jpg [Tue May 23 15:16:25 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/images/reportcard.jpg [Tue May 23 15:16:25 2006] [debug] proxy_util.c(1378): [client 198.144.205.133] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/images/reportcard.jpg [Tue May 23 15:16:25 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Tue May 23 15:16:25 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/images/reportcard.jpg [Tue May 23 15:16:25 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Tue May 23 15:16:25 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80 [Tue May 23 15:16:25 2006] [debug] proxy_util.c(1951): proxy: connected /images/reportcard.jpg to dev.greatschools.net:80 [Tue May 23 15:16:25 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket created to connect to dev.greatschools.net [Tue May 23 15:16:25 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Tue May 23 15:16:25 2006] [debug] mod_proxy_http.c(1448): proxy: start body send [Tue May 23 15:16:25 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Tue May 23 15:16:25 2006] [debug] mod_cache.c(602): cache: Caching url: /images/reportcard.jpg [Tue May 23 15:16:25 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Tue May 23 15:16:25 2006] [info] mem_cache: Cached url: http://nuked.greatschools.net:80/images/reportcard.jpg? [Tue May 23 15:16:25 2006] [debug] mod_proxy_http.c(1537): proxy: end body send [Tue May 23 15:16:25 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net) [Tue May 23 15:16:26 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 0 in child 63719 for worker http://dev.greatschools.net/ [Tue May 23 15:16:26 2006] [debug] proxy_util.c(1644): proxy: worker http://dev.greatschools.net/ already initialized [Tue May 23 15:16:26 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 0 in child 63719 for (dev.greatschools.net) [Tue May 23 15:16:26 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard slot 1 in child 63719 for worker proxy:reverse [Tue May 23 15:16:26 2006] [debug] proxy_util.c(1644): proxy: worker proxy:reverse already initialized [Tue May 23 15:16:26 2006] [debug] proxy_util.c(1724): proxy: initialized single connection worker 1 in child 63719 for (*) [Tue May 23 15:16:41 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /images/reportcard.jpg [Tue May 23 15:16:41 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /images/reportcard.jpg [Tue May 23 15:16:41 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/images/reportcard.jpg [Tue May 23 15:16:41 2006] [debug] proxy_util.c(1378): [client 198.144.205.133] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/images/reportcard.jpg [Tue May 23 15:16:41 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Tue May 23 15:16:41 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/images/reportcard.jpg [Tue May 23 15:16:41 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Tue May 23 15:16:41 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80 [Tue May 23 15:16:41 2006] [debug] proxy_util.c(1951): proxy: connected /images/reportcard.jpg to dev.greatschools.net:80 [Tue May 23 15:16:41 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket created to connect to dev.greatschools.net [Tue May 23 15:16:41 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Tue May 23 15:16:41 2006] [debug] mod_proxy_http.c(1448): proxy: start body send [Tue May 23 15:16:41 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Tue May 23 15:16:41 2006] [debug] mod_cache.c(602): cache: Caching url: /images/reportcard.jpg [Tue May 23 15:16:41 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Tue May 23 15:16:41 2006] [info] mem_cache: Cached url: http://nuked.greatschools.net:80/images/reportcard.jpg? [Tue May 23 15:16:41 2006] [debug] mod_proxy_http.c(1537): proxy: end body send [Tue May 23 15:16:41 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net)   Here's an interesting data point.  I was tinkering with this issue a bit more today and discovered that I could hit the cached image that was origionally served via mod_jk using wget all I want, and it would always return image/jpeg as the content-type.  Once I loaded up firefox and hit ctrl+F5 (force refresh) mod_cache started to return text/html as the content type.  So for some reason, the act of force refreshing in firefox seems to be a trigger.  You are correct that this has something to do with doing a refresh in Firefox. Requesting a refresh in Firefox requires the cache to revalidate the cached entity on the back end server. Something seems to go wrong during this process. Currently I cannot decide if this is because something is wrong in the cache code or because the backend delivers a bad response. So it would be most helpful if you could sniff the network traffic between your proxy httpd and your backend httpd, do a non working refresh request with Firefox and attach the results of your sniffing to this report. Thank you for the followup.  Here's some investigation with tcpdump and ethereal from the proxy server.  The client is 198.144.205.133, the reverse proxy server is 198.144.205.144 and the backend web server is 198.144.205.152.  Here is the client making the inital request for /res/img/content/liferaft.jpg. 13:39:20.748596 IP 198.144.205.133.3180 > 198.144.205.144.80: S 3335533019:3335533019(0) win 65535 <mss 1460,nop,nop,sackOK>  13:39:20.748697 IP 198.144.205.144.80 > 198.144.205.133.3180: S 876667792:876667792(0) ack 3335533020 win 65535 <mss 1460,sackOK,eol>  13:39:20.748824 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 1 win 65535  13:39:20.749129 IP 198.144.205.133.3180 > 198.144.205.144.80: P 1:834(833) ack 1 win 65535   Here are the headers the client sent to the proxy server.  GET /res/img/content/liferaft.jpg HTTP/1.1 Host: nuked.greatschools.net User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3) Gecko/20060426 Firefox/1.5.0.3 Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5 Accept-Language: en-us,en;q=0.5 Accept-Encoding: gzip,deflate Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7 Keep-Alive: 300 Connection: keep-alive Cookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487; s_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0; RMFD=011Fiz3b; NXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF; TRNO=1127250133.198.144.205.133  Next, the proxy server makes a connection to the backend web server to fufill the request:  13:39:20.751945 IP 198.144.205.144.55524 > 198.144.205.152.80: S 1402262641:1402262641(0) win 65535 <mss 1460,nop,wscale 1,nop,nop,timestamp 4082124725 0,sackOK,eol> 13:39:20.752099 IP 198.144.205.152.80 > 198.144.205.144.55524: S 2054288495:2054288495(0) ack 1402262642 win 57344 <mss 1460,nop,wscale 0,nop,nop,timestamp 1733763502 4082124725> 13:39:20.752170 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 1 win 33304 <nop,nop,timestamp 4082124725 1733763502> 13:39:20.752735 IP 198.144.205.144.55524 > 198.144.205.152.80: P 1:956(955) ack 1 win 33304 <nop,nop,timestamp 4082124726 1733763502> 13:39:20.757824 IP 198.144.205.152.80 > 198.144.205.144.55524: . 1:1449(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726> 13:39:20.757934 IP 198.144.205.152.80 > 198.144.205.144.55524: . 1449:2897(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726> 13:39:20.757977 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 2897 win 32580 <nop,nop,timestamp 4082124731 1733763503> 13:39:20.758057 IP 198.144.205.152.80 > 198.144.205.144.55524: . 2897:4345(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726> 13:39:20.758179 IP 198.144.205.152.80 > 198.144.205.144.55524: . 4345:5793(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726> 13:39:20.758211 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 5793 win 31132 <nop,nop,timestamp 4082124731 1733763503> 13:39:20.758313 IP 198.144.205.152.80 > 198.144.205.144.55524: . 5793:7241(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726> 13:39:20.758426 IP 198.144.205.152.80 > 198.144.205.144.55524: . 7241:8689(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731> 13:39:20.758462 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 8689 win 29684 <nop,nop,timestamp 4082124732 1733763503> 13:39:20.758549 IP 198.144.205.152.80 > 198.144.205.144.55524: . 8689:10137(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731> 13:39:20.758675 IP 198.144.205.152.80 > 198.144.205.144.55524: . 10137:11585(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731> 13:39:20.758715 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 11585 win 28236 <nop,nop,timestamp 4082124732 1733763503> 13:39:20.758796 IP 198.144.205.152.80 > 198.144.205.144.55524: . 11585:13033(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731> 13:39:20.758918 IP 198.144.205.152.80 > 198.144.205.144.55524: . 13033:14481(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731> 13:39:20.758953 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 14481 win 26788 <nop,nop,timestamp 4082124732 1733763503> 13:39:20.759041 IP 198.144.205.152.80 > 198.144.205.144.55524: . 14481:15929(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731> 13:39:20.759168 IP 198.144.205.152.80 > 198.144.205.144.55524: . 15929:17377(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732> 13:39:20.759211 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 17377 win 25340 <nop,nop,timestamp 4082124732 1733763503> 13:39:20.759288 IP 198.144.205.152.80 > 198.144.205.144.55524: . 17377:18825(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732> 13:39:20.759411 IP 198.144.205.152.80 > 198.144.205.144.55524: . 18825:20273(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732> 13:39:20.759448 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 20273 win 23892 <nop,nop,timestamp 4082124733 1733763503> 13:39:20.759536 IP 198.144.205.152.80 > 198.144.205.144.55524: . 20273:21721(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732> 13:39:20.759656 IP 198.144.205.152.80 > 198.144.205.144.55524: . 21721:23169(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732> 13:39:20.759697 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 23169 win 22444 <nop,nop,timestamp 4082124733 1733763503> 13:39:20.759780 IP 198.144.205.152.80 > 198.144.205.144.55524: . 23169:24617(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732> 13:39:20.759903 IP 198.144.205.152.80 > 198.144.205.144.55524: . 24617:26065(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732> 13:39:20.759940 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 26065 win 20996 <nop,nop,timestamp 4082124733 1733763503> 13:39:20.759994 IP 198.144.205.152.80 > 198.144.205.144.55524: P 26065:27126(1061) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732> 13:39:20.760244 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 27126 win 24465 <nop,nop,timestamp 4082124733 1733763503> 13:39:20.761346 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 27126 win 28465 <nop,nop,timestamp 4082124735 1733763503> 13:39:20.762105 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 27126 win 32465 <nop,nop,timestamp 4082124735 1733763503> 13:39:37.395766 IP 198.144.205.152.80 > 198.144.205.144.55524: F 27126:27126(0) ack 956 win 57920 <nop,nop,timestamp 1733765167 4082124735> 13:39:37.395864 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 27127 win 33304 <nop,nop,timestamp 4082141370 1733765167> 13:40:46.519437 IP 198.144.205.144.55524 > 198.144.205.152.80: F 956:956(0) ack 27127 win 33304 <nop,nop,timestamp 4082210495 1733765167> 13:40:46.519586 IP 198.144.205.152.80 > 198.144.205.144.55524: . ack 957 win 57920 <nop,nop,timestamp 1733772078 4082210495>  Here are the headers that the proxy server sends to the backend for the request:  GET /res/img/content/liferaft.jpg HTTP/1.1 Host: nuked.greatschools.net User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3) Gecko/20060426 Firefox/1.5.0.3 Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5 Accept-Language: en-us,en;q=0.5 Accept-Encoding: gzip,deflate Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7 Cookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487; s_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0; RMFD=011Fiz3b; NXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF; TRNO=1127250133.198.144.205.133 Max-Forwards: 10 X-Forwarded-For: 198.144.205.133 X-Forwarded-Host: nuked.greatschools.net X-Forwarded-Server: nuked.greatschools.net. Connection: Keep-Alive  Here are the headers the backend responds with:  HTTP/1.1 200 OK Date: Thu, 25 May 2006 20:39:20 GMT Server: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d mod_jk/1.2.15 ETag: W/'26797-1148506126000' Last-Modified: Wed, 24 May 2006 21:28:46 GMT Content-Length: 26797 Keep-Alive: timeout=15, max=1000 Connection: Keep-Alive Content-Type: image/jpeg   Then the proxy server responds to the client's request:  13:39:20.760358 IP 198.144.205.144.80 > 198.144.205.133.3180: . 1:1461(1460) ack 834 win 65535 13:39:20.760894 IP 198.144.205.144.80 > 198.144.205.133.3180: . 1461:2921(1460) ack 834 win 65535 13:39:20.760919 IP 198.144.205.144.80 > 198.144.205.133.3180: . 2921:4381(1460) ack 834 win 65535 13:39:20.760932 IP 198.144.205.144.80 > 198.144.205.133.3180: . 4381:5841(1460) ack 834 win 65535 13:39:20.761507 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 2921 win 65535 13:39:20.761607 IP 198.144.205.144.80 > 198.144.205.133.3180: . 5841:7301(1460) ack 834 win 65535 13:39:20.761621 IP 198.144.205.144.80 > 198.144.205.133.3180: . 7301:8761(1460) ack 834 win 65535 13:39:20.761635 IP 198.144.205.144.80 > 198.144.205.133.3180: . 8761:10221(1460) ack 834 win 65535 13:39:20.761719 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 5841 win 65535 13:39:20.761748 IP 198.144.205.144.80 > 198.144.205.133.3180: . 10221:11681(1460) ack 834 win 65535 13:39:20.761763 IP 198.144.205.144.80 > 198.144.205.133.3180: . 11681:13141(1460) ack 834 win 65535 13:39:20.761778 IP 198.144.205.144.80 > 198.144.205.133.3180: . 13141:14601(1460) ack 834 win 65535 13:39:20.763225 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 8761 win 65535 13:39:20.763468 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 11681 win 65535 13:39:20.763526 IP 198.144.205.144.80 > 198.144.205.133.3180: . 14601:16061(1460) ack 834 win 65535 13:39:20.763544 IP 198.144.205.144.80 > 198.144.205.133.3180: . 16061:17521(1460) ack 834 win 65535 13:39:20.763712 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 14601 win 65535 13:39:20.763735 IP 198.144.205.144.80 > 198.144.205.133.3180: . 17521:18981(1460) ack 834 win 65535 13:39:20.763748 IP 198.144.205.144.80 > 198.144.205.133.3180: . 18981:20441(1460) ack 834 win 65535 13:39:20.764661 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 17521 win 65535 13:39:20.764691 IP 198.144.205.144.80 > 198.144.205.133.3180: . 20441:21901(1460) ack 834 win 65535 13:39:20.764703 IP 198.144.205.144.80 > 198.144.205.133.3180: . 21901:23361(1460) ack 834 win 65535 13:39:20.764904 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 20441 win 65535 13:39:20.764924 IP 198.144.205.144.80 > 198.144.205.133.3180: . 23361:24821(1460) ack 834 win 65535 13:39:20.764937 IP 198.144.205.144.80 > 198.144.205.133.3180: . 24821:26281(1460) ack 834 win 65535 13:39:20.765177 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 23361 win 65535 13:39:20.765197 IP 198.144.205.144.80 > 198.144.205.133.3180: P 26281:27164(883) ack 834 win 65535 13:39:20.765423 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 26281 win 65535 13:39:20.941506 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 27164 win 64652 13:39:25.763406 IP 198.144.205.144.80 > 198.144.205.133.3180: F 27164:27164(0) ack 834 win 65535 13:39:25.763601 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 27165 win 64652 13:39:27.958133 IP 198.144.205.133.3180 > 198.144.205.144.80: F 834:834(0) ack 27165 win 64652 13:39:27.958237 IP 198.144.205.144.80 > 198.144.205.133.3180: . ack 835 win 65534  Here are the headers the proxy responds with:  HTTP/1.1 200 OK Date: Thu, 25 May 2006 20:39:20 GMT Server: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d mod_jk/1.2.15 ETag: W/'26797-1148506126000' Last-Modified: Wed, 24 May 2006 21:28:46 GMT Content-Length: 26797 Content-Type: image/jpeg Expires: Thu, 25 May 2006 22:58:23 GMT Keep-Alive: timeout=5, max=100 Connection: Keep-Alive  That transaction worked okay.  Here's one that didn't work:  13:41:01.094260 IP 198.144.205.133.3187 > 198.144.205.144.80: S 1953506917:1953506917(0) win 65535 <mss 1460,nop,nop,sackOK> 13:41:01.094354 IP 198.144.205.144.80 > 198.144.205.133.3187: S 1632330321:1632330321(0) ack 1953506918 win 65535 <mss 1460,sackOK,eol> 13:41:01.094490 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 1 win 65535 13:41:01.094805 IP 198.144.205.133.3187 > 198.144.205.144.80: P 1:877(876) ack 1 win 65535 13:41:01.102707 IP 198.144.205.144.80 > 198.144.205.133.3187: . 1:1461(1460) ack 877 win 65535 13:41:01.102733 IP 198.144.205.144.80 > 198.144.205.133.3187: . 1461:2921(1460) ack 877 win 65535 13:41:01.103237 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 2921 win 65535 13:41:01.103328 IP 198.144.205.144.80 > 198.144.205.133.3187: . 2921:4381(1460) ack 877 win 65535 13:41:01.103340 IP 198.144.205.144.80 > 198.144.205.133.3187: . 4381:5841(1460) ack 877 win 65535 13:41:01.103354 IP 198.144.205.144.80 > 198.144.205.133.3187: . 5841:7301(1460) ack 877 win 65535 13:41:01.103824 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 5841 win 65535 13:41:01.103847 IP 198.144.205.144.80 > 198.144.205.133.3187: . 7301:8761(1460) ack 877 win 65535 13:41:01.103858 IP 198.144.205.144.80 > 198.144.205.133.3187: . 8761:10221(1460) ack 877 win 65535 13:41:01.103870 IP 198.144.205.144.80 > 198.144.205.133.3187: . 10221:11681(1460) ack 877 win 65535 13:41:01.104210 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 8761 win 65535 13:41:01.104234 IP 198.144.205.144.80 > 198.144.205.133.3187: . 11681:13141(1460) ack 877 win 65535 13:41:01.104246 IP 198.144.205.144.80 > 198.144.205.133.3187: . 13141:14601(1460) ack 877 win 65535 13:41:01.104258 IP 198.144.205.144.80 > 198.144.205.133.3187: . 14601:16061(1460) ack 877 win 65535 13:41:01.104457 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 11681 win 65535 13:41:01.104481 IP 198.144.205.144.80 > 198.144.205.133.3187: . 16061:17521(1460) ack 877 win 65535 13:41:01.104495 IP 198.144.205.144.80 > 198.144.205.133.3187: . 17521:18981(1460) ack 877 win 65535 13:41:01.104507 IP 198.144.205.144.80 > 198.144.205.133.3187: . 18981:20441(1460) ack 877 win 65535 13:41:01.104724 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 14601 win 65535 13:41:01.104745 IP 198.144.205.144.80 > 198.144.205.133.3187: . 20441:21901(1460) ack 877 win 65535 13:41:01.104758 IP 198.144.205.144.80 > 198.144.205.133.3187: . 21901:23361(1460) ack 877 win 65535 13:41:01.104771 IP 198.144.205.144.80 > 198.144.205.133.3187: . 23361:24821(1460) ack 877 win 65535 13:41:01.104966 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 17521 win 65535 13:41:01.104985 IP 198.144.205.144.80 > 198.144.205.133.3187: . 24821:26281(1460) ack 877 win 65535 13:41:01.105004 IP 198.144.205.144.80 > 198.144.205.133.3187: P 26281:27164(883) ack 877 win 65535 13:41:01.105213 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 20441 win 65535 13:41:01.105461 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 23361 win 65535 13:41:01.105706 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 26281 win 65535 13:41:01.237467 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 27164 win 64652 13:41:05.312399 IP 198.144.205.133.3187 > 198.144.205.144.80: P 877:1753(876) ack 27164 win 64652 13:41:05.316143 IP 198.144.205.144.80 > 198.144.205.133.3187: . 27164:28624(1460) ack 1753 win 65535 13:41:05.316167 IP 198.144.205.144.80 > 198.144.205.133.3187: . 28624:30084(1460) ack 1753 win 65535 13:41:05.316187 IP 198.144.205.144.80 > 198.144.205.133.3187: . 30084:31544(1460) ack 1753 win 65535 13:41:05.316197 IP 198.144.205.144.80 > 198.144.205.133.3187: . 31544:33004(1460) ack 1753 win 65535 13:41:05.316217 IP 198.144.205.144.80 > 198.144.205.133.3187: . 33004:34464(1460) ack 1753 win 65535 13:41:05.316233 IP 198.144.205.144.80 > 198.144.205.133.3187: . 34464:35924(1460) ack 1753 win 65535 13:41:05.316242 IP 198.144.205.144.80 > 198.144.205.133.3187: . 35924:37384(1460) ack 1753 win 65535 13:41:05.316261 IP 198.144.205.144.80 > 198.144.205.133.3187: . 37384:38844(1460) ack 1753 win 65535 13:41:05.316278 IP 198.144.205.144.80 > 198.144.205.133.3187: . 38844:40304(1460) ack 1753 win 65535 13:41:05.316293 IP 198.144.205.144.80 > 198.144.205.133.3187: . 40304:41764(1460) ack 1753 win 65535 13:41:05.316302 IP 198.144.205.144.80 > 198.144.205.133.3187: . 41764:43224(1460) ack 1753 win 65535 13:41:05.316323 IP 198.144.205.144.80 > 198.144.205.133.3187: . 43224:44684(1460) ack 1753 win 65535 13:41:05.316679 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 30084 win 65535 13:41:05.316774 IP 198.144.205.144.80 > 198.144.205.133.3187: . 44684:46144(1460) ack 1753 win 65535 13:41:05.316785 IP 198.144.205.144.80 > 198.144.205.133.3187: . 46144:47604(1460) ack 1753 win 65535 13:41:05.316795 IP 198.144.205.144.80 > 198.144.205.133.3187: . 47604:49064(1460) ack 1753 win 65535 13:41:05.316874 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 33004 win 65535 13:41:05.316897 IP 198.144.205.144.80 > 198.144.205.133.3187: . 49064:50524(1460) ack 1753 win 65535 13:41:05.316910 IP 198.144.205.144.80 > 198.144.205.133.3187: . 50524:51984(1460) ack 1753 win 65535 13:41:05.316922 IP 198.144.205.144.80 > 198.144.205.133.3187: . 51984:53444(1460) ack 1753 win 65535 13:41:05.317132 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 35924 win 65535 13:41:05.317153 IP 198.144.205.144.80 > 198.144.205.133.3187: P 53444:54325(881) ack 1753 win 65535 13:41:05.317382 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 38844 win 65535 13:41:05.317626 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 41764 win 65535 13:41:05.317868 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 44684 win 65535 13:41:05.318118 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 47604 win 65535 13:41:05.318363 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 50524 win 65535 13:41:05.318610 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 53444 win 65535 13:41:05.503052 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 54325 win 64654 13:41:05.629138 IP 198.144.205.133.3187 > 198.144.205.144.80: P 1753:2489(736) ack 54325 win 64654 13:41:05.633724 IP 198.144.205.144.80 > 198.144.205.133.3187: P 54325:54883(558) ack 2489 win 65535 13:41:05.831178 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 54883 win 64096 13:41:10.634808 IP 198.144.205.144.80 > 198.144.205.133.3187: F 54883:54883(0) ack 2489 win 65535 13:41:10.634969 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 54884 win 64096 13:41:24.506079 IP 198.144.205.133.3187 > 198.144.205.144.80: F 2489:2489(0) ack 54884 win 64096 13:41:24.506191 IP 198.144.205.144.80 > 198.144.205.133.3187: . ack 2490 win 65534  This is actually two requests over a single tcp connection.  I assume firefox is recycling a still connected keep alive session if the user hits ctrl+F5 fast enough.  The client / server headers:  GET /res/img/content/liferaft.jpg HTTP/1.1 Host: nuked.greatschools.net User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3) Gecko/20060426 Firefox/1.5.0.3 Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5 Accept-Language: en-us,en;q=0.5 Accept-Encoding: gzip,deflate Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7 Keep-Alive: 300 Connection: keep-alive Cookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487; s_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0; RMFD=011Fiz3b; NXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF; TRNO=1127250133.198.144.205.133 Pragma: no-cache Cache-Control: no-cache  HTTP/1.1 200 OK Date: Thu, 25 May 2006 20:41:01 GMT Server: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d mod_jk/1.2.15 ETag: W/'26797-1148506126000' Content-Length: 26797 Expires: Fri, 26 May 2006 00:41:01 GMT Content-Type: image/jpeg Last-Modified: Wed, 24 May 2006 21:28:46 GMT Keep-Alive: timeout=5, max=100 Connection: Keep-Alive  GET /res/img/content/liferaft.jpg HTTP/1.1 Host: nuked.greatschools.net User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3) Gecko/20060426 Firefox/1.5.0.3 Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5 Accept-Language: en-us,en;q=0.5 Accept-Encoding: gzip,deflate Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7 Keep-Alive: 300 Connection: keep-alive Cookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487; s_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0; RMFD=011Fiz3b; NXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF; TRNO=1127250133.198.144.205.133 Pragma: no-cache Cache-Control: no-cache  HTTP/1.1 200 OK Date: Thu, 25 May 2006 20:41:05 GMT Server: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d mod_jk/1.2.15 ETag: W/'26797-1148506126000' Content-Length: 26797 Expires: Fri, 26 May 2006 00:41:05 GMT Content-Type: text/html Last-Modified: Wed, 24 May 2006 21:28:46 GMT Keep-Alive: timeout=5, max=99 Connection: Keep-Alive   The first request worked, but the second one was returned as text/html.  Meanwhile, the proxy server is making requests to the backend to handle the client's request.  13:40:46.519646 IP 198.144.205.144.64919 > 198.144.205.152.80: S 755704577:755704577(0) win 65535 <mss 1460,nop,wscale 1,nop,nop,timestamp 4082210496 0,sackOK,eol> 13:40:46.519763 IP 198.144.205.152.80 > 198.144.205.144.64919: S 2886095240:2886095240(0) ack 755704578 win 57344 <mss 1460,nop,wscale 0,nop,nop,timestamp 1733772078 4082210496> 13:40:46.519805 IP 198.144.205.144.64919 > 198.144.205.152.80: . ack 1 win 33304 <nop,nop,timestamp 4082210496 1733772078> 13:40:46.520087 IP 198.144.205.144.64919 > 198.144.205.152.80: P 1:1089(1088) ack 1 win 33304 <nop,nop,timestamp 4082210496 1733772078> 13:40:46.524652 IP 198.144.205.152.80 > 198.144.205.144.64919: P 1:257(256) ack 1089 win 57920 <nop,nop,timestamp 1733772079 4082210496> 13:40:46.624500 IP 198.144.205.144.64919 > 198.144.205.152.80: . ack 257 win 33304 <nop,nop,timestamp 4082210601 1733772079> 13:41:01.097038 IP 198.144.205.144.63148 > 198.144.205.152.80: F 999:999(0) ack 27127 win 33304 <nop,nop,timestamp 4082225073 1733765874> 13:41:01.097158 IP 198.144.205.152.80 > 198.144.205.144.63148: . ack 1000 win 57920 <nop,nop,timestamp 1733773536 4082225073> 13:41:01.097278 IP 198.144.205.144.55877 > 198.144.205.152.80: S 3660931143:3660931143(0) win 65535 <mss 1460,nop,wscale 1,nop,nop,timestamp 4082225074 0,sackOK,eol> 13:41:01.097392 IP 198.144.205.152.80 > 198.144.205.144.55877: S 1545466721:1545466721(0) ack 3660931144 win 57344 <mss 1460,nop,wscale 0,nop,nop,timestamp 1733773536 4082225074> 13:41:01.097431 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 1 win 33304 <nop,nop,timestamp 4082225074 1733773536> 13:41:01.097709 IP 198.144.205.144.55877 > 198.144.205.152.80: P 1:1089(1088) ack 1 win 33304 <nop,nop,timestamp 4082225074 1733773536> 13:41:01.102080 IP 198.144.205.152.80 > 198.144.205.144.55877: P 1:257(256) ack 1089 win 57920 <nop,nop,timestamp 1733773536 4082225074> 13:41:01.202018 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 257 win 33304 <nop,nop,timestamp 4082225179 1733773536> 13:41:03.254784 IP 198.144.205.152.80 > 198.144.205.144.64919: F 257:257(0) ack 1089 win 57920 <nop,nop,timestamp 1733773752 4082210601> 13:41:03.254877 IP 198.144.205.144.64919 > 198.144.205.152.80: . ack 258 win 33304 <nop,nop,timestamp 4082227231 1733773752> 13:41:05.313389 IP 198.144.205.144.55877 > 198.144.205.152.80: P 1089:2177(1088) ack 257 win 33304 <nop,nop,timestamp 4082229290 1733773536> 13:41:05.315555 IP 198.144.205.152.80 > 198.144.205.144.55877: P 257:512(255) ack 2177 win 57920 <nop,nop,timestamp 1733773958 4082229290> 13:41:05.414874 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 512 win 33304 <nop,nop,timestamp 4082229392 1733773958> 13:41:05.629992 IP 198.144.205.144.55877 > 198.144.205.152.80: P 2177:3035(858) ack 512 win 33304 <nop,nop,timestamp 4082229607 1733773958> 13:41:05.631281 IP 198.144.205.152.80 > 198.144.205.144.55877: P 512:1753(1241) ack 3035 win 57920 <nop,nop,timestamp 1733773989 4082229607> 13:41:05.730896 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 1753 win 33304 <nop,nop,timestamp 4082229708 1733773989> 13:41:22.446789 IP 198.144.205.152.80 > 198.144.205.144.55877: F 1753:1753(0) ack 3035 win 57920 <nop,nop,timestamp 1733775671 4082229708> 13:41:22.446885 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 1754 win 33304 <nop,nop,timestamp 4082246424 1733775671>  Here are the headers from the proxy -> backend conversation.  GET /res/img/content/liferaft.jpg HTTP/1.1 Host: nuked.greatschools.net User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3) Gecko/20060426 Firefox/1.5.0.3 Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5 Accept-Language: en-us,en;q=0.5 Accept-Encoding: gzip,deflate Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7 Cookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487; s_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0; RMFD=011Fiz3b; NXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF; TRNO=1127250133.198.144.205.133 Pragma: no-cache Cache-Control: no-cache If-None-Match: W/'26797-1148506126000' If-Modified-Since: Wed, 24 May 2006 21:28:46 GMT Max-Forwards: 10 X-Forwarded-For: 198.144.205.133 X-Forwarded-Host: nuked.greatschools.net X-Forwarded-Server: nuked.greatschools.net. Connection: Keep-Alive  HTTP/1.1 304 Not Modified Date: Thu, 25 May 2006 20:41:01 GMT Server: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d mod_jk/1.2.15 Content-Length: 0 Keep-Alive: timeout=15, max=1000 Connection: Keep-Alive Content-Type: text/html  It looks like the backend is responding with http status code 304.  I'm wondering if the text/html content-type from the 304 code is being erroniously cached in this case?  I have the tcpdump capture file here.  If I can provide any more information or perhaps put the capture file somewhere for download please don't hesitate to ask.  I just ran some tcpdump sniffing while pulling an image served directly by httpd on the backend, not going through mod_jk.  It does not set the conent-type header when it returns a 304 http status code.  Here are the headers from the proxy -> backend conversation:  GET /images/reportcard.jpg HTTP/1.1 Host: nuked.greatschools.net User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3) Gecko/20060426 Firefox/1.5.0.3 Accept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5 Accept-Language: en-us,en;q=0.5 Accept-Encoding: gzip,deflate Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7 Cookie: TRNO=1127250133.198.144.205.133; NXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF; RMFD=011Fiz3b; NumAd=-1; RMID=c690cd854329f1d0; s_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487 Pragma: no-cache Cache-Control: no-cache If-None-Match: '1fae43-4487-3f4e92c4' If-Modified-Since: Thu, 28 Aug 2003 23:39:48 GMT Max-Forwards: 10 X-Forwarded-For: 198.144.205.133 X-Forwarded-Host: nuked.greatschools.net X-Forwarded-Server: nuked.greatschools.net. Connection: Keep-Alive   HTTP/1.1 304 Not Modified Date: Thu, 25 May 2006 23:56:23 GMT Server: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d mod_jk/1.2.15 Connection: Keep-Alive, Keep-Alive Keep-Alive: timeout=15, max=998 ETag: '1fae43-4487-3f4e92c4' Expires: Fri, 26 May 2006 05:56:23 GMT Cache-Control: max-age=21600   Created an attachment (id=18353) Patch for additional Debug messages against 2.2.x  Thanks for the update. I think we are getting closer. Can you please apply the attached patch, run a non working request and post the according error log? The patch is only temporary and does not fix anything, but it should help me to understand the problem better. Here you go.  I applied the patch, and also the patch found in bug 39266.  Here is a snipit from the debug log.  [Fri May 26 11:15:05 2006] [debug] cache_storage.c(261): Cached response for /res/img/content/liferaft.jpg isn't fresh.  Adding/replacing conditional request headers. [Fri May 26 11:15:05 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /res/img/content/liferaft.jpg [Fri May 26 11:15:05 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /res/img/content/liferaft.jpg [Fri May 26 11:15:05 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg [Fri May 26 11:15:05 2006] [debug] proxy_util.c(1378): [client 64.85.232.3] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/res/img/content/liferaft.jpg [Fri May 26 11:15:05 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Fri May 26 11:15:05 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/res/img/content/liferaft.jpg [Fri May 26 11:15:05 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Fri May 26 11:15:05 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80 [Fri May 26 11:15:05 2006] [debug] proxy_util.c(1951): proxy: connected /res/img/content/liferaft.jpg to dev.greatschools.net:80 [Fri May 26 11:15:05 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket created to connect to dev.greatschools.net [Fri May 26 11:15:05 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Fri May 26 11:15:05 2006] [debug] mod_proxy_http.c(1541): proxy: header only [Fri May 26 11:15:05 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Fri May 26 11:15:05 2006] [debug] mod_cache.c(602): cache: Caching url: /res/img/content/liferaft.jpg [Fri May 26 11:15:05 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri May 26 11:15:05 2006] [debug] mod_cache.c(726): cache: Content-Type text/html text/html [Fri May 26 11:15:05 2006] [debug] mod_cache.c(738): cache: Content-Type text/html image/jpeg [Fri May 26 11:15:05 2006] [debug] http_filters.c(990): http_filter: Content-Type text/html image/jpeg [Fri May 26 11:15:05 2006] [debug] http_filters.c(995): http_filter: Content-Type image/jpeg image/jpeg [Fri May 26 11:15:05 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net) [Fri May 26 11:15:06 2006] [debug] cache_storage.c(261): Cached response for /res/img/content/liferaft.jpg isn't fresh.  Adding/replacing conditional request headers. [Fri May 26 11:15:06 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /res/img/content/liferaft.jpg [Fri May 26 11:15:06 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /res/img/content/liferaft.jpg [Fri May 26 11:15:06 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg [Fri May 26 11:15:06 2006] [debug] proxy_util.c(1378): [client 64.85.232.3] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/res/img/content/liferaft.jpg [Fri May 26 11:15:06 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Fri May 26 11:15:06 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/res/img/content/liferaft.jpg [Fri May 26 11:15:06 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Fri May 26 11:15:06 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80 [Fri May 26 11:15:06 2006] [debug] proxy_util.c(1951): proxy: connected /res/img/content/liferaft.jpg to dev.greatschools.net:80 [Fri May 26 11:15:06 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Fri May 26 11:15:06 2006] [debug] mod_proxy_http.c(1541): proxy: header only [Fri May 26 11:15:06 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Fri May 26 11:15:06 2006] [debug] mod_cache.c(602): cache: Caching url: /res/img/content/liferaft.jpg [Fri May 26 11:15:06 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri May 26 11:15:06 2006] [debug] mod_cache.c(726): cache: Content-Type text/html text/html [Fri May 26 11:15:06 2006] [debug] mod_cache.c(738): cache: Content-Type text/html text/html [Fri May 26 11:15:06 2006] [debug] http_filters.c(990): http_filter: Content-Type text/html text/html [Fri May 26 11:15:06 2006] [debug] http_filters.c(995): http_filter: Content-Type text/html text/html [Fri May 26 11:15:06 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net)  This is two requests over the same tcp keepalive connection from firefox.  The first request seemed to work, the second one firefix tried to render the jpeg as if it was html.  Just for comparison's sake, here is some debug log output while force-refreshing an image being served directly by the backend httpd server, not through mod_jk.  [Fri May 26 11:20:28 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /images/reportcard.jpg [Fri May 26 11:20:28 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /images/reportcard.jpg [Fri May 26 11:20:28 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:28 2006] [debug] proxy_util.c(1378): [client 64.85.232.3] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:28 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Fri May 26 11:20:28 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:28 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Fri May 26 11:20:28 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:28 2006] [debug] proxy_util.c(1951): proxy: connected /images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:28 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket created to connect to dev.greatschools.net [Fri May 26 11:20:28 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Fri May 26 11:20:29 2006] [debug] mod_proxy_http.c(1448): proxy: start body send [Fri May 26 11:20:29 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Fri May 26 11:20:29 2006] [debug] mod_cache.c(602): cache: Caching url: /images/reportcard.jpg [Fri May 26 11:20:29 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri May 26 11:20:29 2006] [debug] http_filters.c(990): http_filter: Content-Type image/jpeg image/jpeg [Fri May 26 11:20:29 2006] [debug] http_filters.c(995): http_filter: Content-Type image/jpeg image/jpeg [Fri May 26 11:20:29 2006] [info] mem_cache: Cached url: http://nuked.greatschools.net:80/images/reportcard.jpg? [Fri May 26 11:20:29 2006] [debug] mod_proxy_http.c(1537): proxy: end body send [Fri May 26 11:20:29 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net) [Fri May 26 11:20:38 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /images/reportcard.jpg [Fri May 26 11:20:38 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /images/reportcard.jpg [Fri May 26 11:20:38 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:38 2006] [debug] proxy_util.c(1378): [client 64.85.232.3] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:38 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Fri May 26 11:20:38 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:38 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Fri May 26 11:20:38 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:38 2006] [debug] proxy_util.c(1951): proxy: connected /images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:38 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket created to connect to dev.greatschools.net [Fri May 26 11:20:38 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Fri May 26 11:20:38 2006] [debug] mod_proxy_http.c(1448): proxy: start body send [Fri May 26 11:20:38 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Fri May 26 11:20:38 2006] [debug] mod_cache.c(602): cache: Caching url: /images/reportcard.jpg [Fri May 26 11:20:38 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri May 26 11:20:38 2006] [debug] http_filters.c(990): http_filter: Content-Type image/jpeg image/jpeg [Fri May 26 11:20:38 2006] [debug] http_filters.c(995): http_filter: Content-Type image/jpeg image/jpeg [Fri May 26 11:20:38 2006] [info] mem_cache: Cached url: http://nuked.greatschools.net:80/images/reportcard.jpg? [Fri May 26 11:20:38 2006] [debug] mod_proxy_http.c(1537): proxy: end body send [Fri May 26 11:20:38 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net) [Fri May 26 11:20:39 2006] [debug] cache_storage.c(261): Cached response for /images/reportcard.jpg isn't fresh.  Adding/replacing conditional request headers. [Fri May 26 11:20:39 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /images/reportcard.jpg [Fri May 26 11:20:39 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /images/reportcard.jpg [Fri May 26 11:20:39 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:39 2006] [debug] proxy_util.c(1378): [client 64.85.232.3] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:39 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Fri May 26 11:20:39 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:39 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Fri May 26 11:20:39 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:39 2006] [debug] proxy_util.c(1951): proxy: connected /images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:39 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Fri May 26 11:20:39 2006] [debug] mod_proxy_http.c(1541): proxy: header only [Fri May 26 11:20:39 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Fri May 26 11:20:39 2006] [debug] mod_cache.c(602): cache: Caching url: /images/reportcard.jpg [Fri May 26 11:20:39 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri May 26 11:20:39 2006] [debug] mod_cache.c(726): cache: Content-Type (null) image/jpeg [Fri May 26 11:20:39 2006] [debug] mod_cache.c(738): cache: Content-Type (null) image/jpeg [Fri May 26 11:20:39 2006] [debug] http_filters.c(990): http_filter: Content-Type (null) image/jpeg [Fri May 26 11:20:39 2006] [debug] http_filters.c(995): http_filter: Content-Type image/jpeg image/jpeg [Fri May 26 11:20:39 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net) [Fri May 26 11:20:40 2006] [debug] cache_storage.c(261): Cached response for /images/reportcard.jpg isn't fresh.  Adding/replacing conditional request headers. [Fri May 26 11:20:40 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /images/reportcard.jpg [Fri May 26 11:20:40 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /images/reportcard.jpg [Fri May 26 11:20:40 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:40 2006] [debug] proxy_util.c(1378): [client 64.85.232.3] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:40 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Fri May 26 11:20:40 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:40 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Fri May 26 11:20:40 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:40 2006] [debug] proxy_util.c(1951): proxy: connected /images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:40 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Fri May 26 11:20:40 2006] [debug] mod_proxy_http.c(1541): proxy: header only [Fri May 26 11:20:40 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Fri May 26 11:20:40 2006] [debug] mod_cache.c(602): cache: Caching url: /images/reportcard.jpg [Fri May 26 11:20:40 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri May 26 11:20:40 2006] [debug] mod_cache.c(726): cache: Content-Type (null) image/jpeg [Fri May 26 11:20:40 2006] [debug] mod_cache.c(738): cache: Content-Type (null) image/jpeg [Fri May 26 11:20:40 2006] [debug] http_filters.c(990): http_filter: Content-Type (null) image/jpeg [Fri May 26 11:20:40 2006] [debug] http_filters.c(995): http_filter: Content-Type image/jpeg image/jpeg [Fri May 26 11:20:40 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net) [Fri May 26 11:20:41 2006] [debug] cache_storage.c(261): Cached response for /images/reportcard.jpg isn't fresh.  Adding/replacing conditional request headers. [Fri May 26 11:20:41 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1378): [client 64.85.232.3] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1951): proxy: connected /images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:41 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(1541): proxy: header only [Fri May 26 11:20:41 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Fri May 26 11:20:41 2006] [debug] mod_cache.c(602): cache: Caching url: /images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri May 26 11:20:41 2006] [debug] mod_cache.c(726): cache: Content-Type (null) image/jpeg [Fri May 26 11:20:41 2006] [debug] mod_cache.c(738): cache: Content-Type (null) image/jpeg [Fri May 26 11:20:41 2006] [debug] http_filters.c(990): http_filter: Content-Type (null) image/jpeg [Fri May 26 11:20:41 2006] [debug] http_filters.c(995): http_filter: Content-Type image/jpeg image/jpeg [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net) [Fri May 26 11:20:41 2006] [debug] cache_storage.c(261): Cached response for /images/reportcard.jpg isn't fresh.  Adding/replacing conditional request headers. [Fri May 26 11:20:41 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(54): proxy: HTTP: canonicalising URL //dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1378): [client 64.85.232.3] proxy: http: found worker http://dev.greatschools.net/ for http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] mod_proxy.c(756): Running scheme http handler (attempt 0) [Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving URL http://dev.greatschools.net/images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired connection for (dev.greatschools.net) [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1858): proxy: connecting http://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1951): proxy: connected /images/reportcard.jpg to dev.greatschools.net:80 [Fri May 26 11:20:41 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection complete to 198.144.205.152:80 (dev.greatschools.net) [Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(1541): proxy: header only [Fri May 26 11:20:41 2006] [debug] mod_headers.c(612): headers: ap_headers_output_filter() [Fri May 26 11:20:41 2006] [debug] mod_cache.c(602): cache: Caching url: /images/reportcard.jpg [Fri May 26 11:20:41 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri May 26 11:20:41 2006] [debug] mod_cache.c(726): cache: Content-Type (null) image/jpeg [Fri May 26 11:20:41 2006] [debug] mod_cache.c(738): cache: Content-Type (null) image/jpeg [Fri May 26 11:20:41 2006] [debug] http_filters.c(990): http_filter: Content-Type (null) image/jpeg [Fri May 26 11:20:41 2006] [debug] http_filters.c(995): http_filter: Content-Type image/jpeg image/jpeg [Fri May 26 11:20:41 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released connection for (dev.greatschools.net)  Created an attachment (id=18357) Patch against trunk  I think I got it know. The attached patch should fix your problem. So could you please do the following:  1. Start with clean sources (at least without the debug patch I sent earlier) 2. Apply the patch for 39266 3. Apply the attached patch 4. Compile 5. Test 6. Let me know the results :-). Created an attachment (id=18358) Patch against mod_jk.c (1.3 Version) of mod_jk 1.2.15  Apart from the patch against 2.2.x I am pretty much sure that the behaviour of the backend (sending Content-Length and Content-Type for a 304 response) is not compliant with RFC 2616.   10.3.5 in RFC 2616 states:  The 304 response MUST NOT contain a message-body, and thus is always terminated by the first empty line after the header fields.  I read this as Content-Length and Content-Type header MUST NOT be sent with 304 responses and the behaviour of httpd 2.2.x and the http connector of Tomcat not doing this seem to support this view. From my limited point of view on httpd 1.3 this should be fixed inside mod_jk. I  think that the attached patch, which is untested due to my lack of an available httpd 1.3, does this without breaking other things. So, if you like you can give the attached patch a try to make your backend RFC 2616 compliant again :-). Hi there.  Thanks for your help on this issue.  The patch modules/cache/cache_storage.c seems to do the trick!  I'll try out the patch to mod_jk too.  I agree, it seems like mod_jk is breaking RFC 2616, I'll try out the patch on the backend web server and make sure it doesn't break anything else.   Committed to trunk as r410370 (http://svn.apache.org/viewvc?rev=410370&view=rev). FYI I've been running the patch against mod_jk.c for about two weeks now with no ill effects.  Backported to 2.2.x as r425725 (http://svn.apache.org/viewvc?rev=425725&view=rev). The resolution to this bug breaks a MUST-level requirement of RFC2616. From <http://www.w3.org/ Protocols/rfc2616/rfc2616-sec13.html#sec13.5.3>;  [[[ The end-to-end headers stored in the cache entry are used for the constructed response, except that [...]       - any end-to-end headers provided in the 304 or 206 response MUST         replace the corresponding headers from the cache entry. Unless the cache decides to remove the cache entry, it MUST also replace the end-to-end headers  stored with the cache entry with corresponding headers received in the incoming response, except for  Warning headers as described immediately above. If a header field- name in the incoming response  matches more than one header in the cache entry, all such old headers MUST be replaced.  In other words, the set of end-to-end headers received in the incoming response overrides all  corresponding end-to-end headers stored with the cache entry (except for stored Warning headers with  warn-code 1xx, which are deleted even if not overridden). ]]]  The correct resolution was to fix mod_jk, which the reporter said worked for them.  Please back this patch out. I respectfully disagree here. According to 10.3.5 the response must not / should not contain any entity headers (depending on the validator type). Furthermore 10.3.5 states that this should prevent inconsistencies between the cached entity body and the updated header. Content-type is an entity header and changing the Content-type clearly would create inconsistencies between the cached entity body and the updated header. So we are generous in what we acccept. If you still disagree please continue this discussion on the dev@httpd.apache.org list. 10.3.5 says:   [[[ If the conditional GET used a strong cache validator (see section 13.3.3), the response SHOULD NOT  include other entity-headers. Otherwise (i.e., the conditional GET used a weak validator), the response  MUST NOT include other entity-headers; this prevents inconsistencies between cached entity-bodies  and updated headers. ]]]  That applies to the responses; it doesn't specify the behaviour of the cache when it receives such  responses.  10.3.5 goes on to say   [[[ If a cache uses a received 304 response to update a cache entry, the cache MUST update the entry to  reflect any new field values given in the response. ]]]  However, your reading does make sense. Rather than try and second-guess an apparent inconsistency  in the spec, I'll follow up with the HTTP-WG list. 			Christopher Shumway	Mark Nottingham	Ruediger Pluem
39672	null	RESOLVED		Benjamin Tomos Lewis	1148899620000	1148904443000		Adding non-existant filter providers to filter chain causes  segfault If a filter provider which does not exist is added to the filter chain, the apache child dies with signal 11  Reproduce: FilterChain +NotARealFilter  Backtrace:  Program received signal SIGSEGV, Segmentation fault. [Switching to Thread -1379832912 (LWP 19849)] add_any_filter_handle (frec=0x0, ctx=0x0, r=0x99cfdf0, c=0x99cbf90,     r_filters=0x99cff78, p_filters=0x99cff80, c_filters=0x99cbfd8)     at util_filter.c:286 286         if (frec->ftype < AP_FTYPE_PROTOCOL) { (gdb) bt #0  add_any_filter_handle (frec=0x0, ctx=0x0, r=0x99cfdf0, c=0x99cbf90,     r_filters=0x99cff78, p_filters=0x99cff80, c_filters=0x99cbfd8)     at util_filter.c:286 #1  0x08083e80 in filter_insert (r=0x99cfdf0) at mod_filter.c:758 #2  0x080737e2 in ap_run_insert_filter (r=0x99cfdf0) at request.c:80 #3  0x08077b7c in ap_invoke_handler (r=0x99cfdf0) at config.c:338 #4  0x080ab34d in ap_process_request (r=0x99cfdf0) at http_request.c:258 #5  0x080a8ee9 in ap_process_http_connection (c=0x99cbf90) at http_core.c:172 #6  0x0807d1e6 in ap_run_process_connection (c=0x99cbf90) at connection.c:43 #7  0x080b4473 in worker_thread (thd=0x9536f48, dummy=0x9889e80)     at worker.c:531 #8  0x00211c24 in dummy_worker (opaque=0x9536f48)     at threadproc/unix/thread.c:138 #9  0x00b289b3 in start_thread () from /lib/libpthread.so.0 #10 0x00921d0e in clone () from /lib/libc.so.6   Interestingly, removing non-existant ones does not cause any error?!?	Fixed in trunk and proposed for backport http://svn.apache.org/viewvc?view=rev&revision=410079			Nick Kew
39710	null	RESOLVED		Paul Querna	1149286920000	1184895081000		mod_cgi truncates error replies A 500 ISE page is not send to clients with mod_cgi, which there is an invalid CGI.  With mod_cgid the correct output is generated.  To repo: echo 'foo' > foo.cgi  With mod_cgi the output to a client is: % curl -is --compressed http://example.com/foo.cgi  HTTP/1.1 500 Internal Server Error Date: Fri, 02 Jun 2006 22:21:49 GMT Server: Apache/2.2.2 (Unix) mod_ssl/2.2.2 OpenSSL/0.9.7a Content-Length: 0 Connection: close Content-Type: text/plain  A zero byte reply. However, just swap the LoadModule to mod_cgid, and restart, and the reply is this: HTTP/1.1 500 Internal Server Error Date: Fri, 02 Jun 2006 22:18:36 GMT Server: Apache/2.2.2 (Unix) mod_ssl/2.2.2 OpenSSL/0.9.7a Vary: Accept-Encoding Content-Length: 653 Connection: close Content-Type: text/html; charset=iso-8859-1  <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>500 Internal Server Error</title> </head><body> <h1>Internal Server Error</h1> <p>The server encountered an internal error or misconfiguration and was unable to complete your request.</p> .... etc.	Looks like this is caused by the changes in r231167: http://svn.apache.org/viewvc?view=rev&revision=231167  mod_cgid was not modified to be kept in sync with mod_cgi.  They both have nearly the same code path after the ap_scan_script_header_err... *** Bug 37938 has been marked as a duplicate of this bug. *** this bug is still in 2.2.4, if you have mod_deflate enabled, you get the gz-output instead of a text-file Created an attachment (id=19513) don't truncate error replies  Attached patch has been running in production since this bug was opened.  If you run into this problem, can you try patching your mod_cgi.c? I can confirm the patch works on Apache2.2.4 with mod_deflate configured as  well. Anything I can do to help get this bug fixed?  Is testing the patch all that stands in the way of getting it folded into the trunk? (In reply to comment #7) > Anything I can do to help get this bug fixed?  Is testing the patch all that > stands in the way of getting it folded into the trunk?  Hello?  Anybody home?  What's next? *** Bug 42525 has been marked as a duplicate of this bug. *** Why should bug 42525 be a duplicate of this one?  My setup runs with the Worker MPM, that means with mod_cgid.c. But the patch here touches only mod_cgi.c and so can't possibly change anything in 'my' bug.  Nick, could you explain that to me? Please don't add other people to an error report!  (In reply to comment #10) > Why should bug 42525 be a duplicate of this one?  It certainly looks like it.  Is your CGI script   (a) crashing,   (b) generating an error response, or   (c) generating a malformed response?  > My setup runs with the Worker MPM, that means with mod_cgid.c. But the patch > here touches only mod_cgi.c and so can't possibly change anything in 'my' bug.  what does 'httpd -M' tell you? (In reply to comment #11) > Please don't add other people to an error report!  I obviously wanted to make sure you get my comment. I assume now that you get these comments otherwise, too. Do you know a smart way how to find that out? - Who added me to this bug here?  > (In reply to comment #10) > > Why should bug 42525 be a duplicate of this one? >  > It certainly looks like it.  Is your CGI script >   (a) crashing, >   (b) generating an error response, or >   (c) generating a malformed response?  If you refer to the script I mention in 'my' bug, it prints a 'hello' and exits. I think that is what you refer to with (c). - But what is (a) exactly?  I first noticed the problem with a script that should generated a conforming 200 OK response, but it didn't because of errors in it. You could say it 'crashed', but doing so, it generated a malformed response...  > > My setup runs with the Worker MPM, that means with mod_cgid.c. But the patch > > here touches only mod_cgi.c and so can't possibly change anything in 'my' bug. >  > what does 'httpd -M' tell you?  siemer@polar:~$ /usr/sbin/apache2 -M Loaded Modules:  core_module (static)  log_config_module (static)  logio_module (static)  mpm_worker_module (static)  http_module (static)  so_module (static)  actions_module (shared)  alias_module (shared)  auth_basic_module (shared)  authn_file_module (shared)  authz_default_module (shared)  authz_groupfile_module (shared)  authz_host_module (shared)  authz_user_module (shared)  autoindex_module (shared)  cache_module (shared)  cgi_module (shared)  cgid_module (shared)  dir_module (shared)  disk_cache_module (shared)  env_module (shared)  include_module (shared)  info_module (shared)  mime_module (shared)  negotiation_module (shared)  rewrite_module (shared)  setenvif_module (shared)  speling_module (shared)  status_module (shared)  suexec_module (shared)  userdir_module (shared) Syntax OK   The documentation at http://httpd.apache.org/docs/2.2/mod/mod_cgid.html says that a threaded MPM uses mod_cgid. And the server-info handler on my site reports the Worker MPM with 'threaded: yes'. - Are there setups that use both!??  Regards (In reply to comment #12)  >  cgi_module (shared)  Remove mod_cgi, and I expect your bug will go away. (In reply to comment #13) > (In reply to comment #12) >  > >  cgi_module (shared) >  > Remove mod_cgi, and I expect your bug will go away.  I removed the mod_cgi and the bug went away. Thank you, Nick.  That makes now the link between the mpm and the two cgi(d) modules unclear to me. And if loading both modules makes no sense, it could raise an error or warning...  Regards, R (In reply to comment #14)  >  > That makes now the link between the mpm and the two cgi(d) modules unclear to  See the second paragraph of the summary of   http://httpd.apache.org/docs/2.2/en/mod/mod_cgid.html  for why mod_cgid exists. If forks of multi threaded processes are not expensive on your OS you can use mod_cgi with a threaded MPM as well (you can even do so if they are expensive but then you may pay a huge performance penalty). (In reply to comment #15) > ...  > If forks of multi threaded processes are not expensive > on your OS you can use mod_cgi with a threaded MPM as well (you can even do so > if they are expensive but then you may pay a huge performance penalty).  What I draw out of that: you can use mod_cgid or mod_cgi with whatever MPM. And the one you load first gets used.  That opens a new question: Why says the doc '[mod_cgid] is used by default instead of mod_cgi whenever a multi-threaded MPM is selected' when there is no such default? 			Bob Kline	Nick Kew	Paul Querna	Robert Siemer	Ruediger Pluem	Sven Strickroth	Vincent Jong
39722	null	RESOLVED		Bartek Zdanowski	1149502920000	1193638921000		If DocumentRoot directive in config file has a non existent drive letter httpd crashes. Try to set  DocumentRoot directive to path with nonexistent drive letter, ex. DocumentRoot g:/somepath  During httpd start (both command line called and as a service) httpd will crash.	Just a footnote that we need to determine if the fault occurs in apr, or as a result of a bad call to apr. I have traced this to line 1176 in server/core.c:      arg = ap_server_root_relative(cmd->pool, arg);  which returns a NULL if a directory does not exist.  When line 1178 in server/core.c is reached, this NULL is passed to ap_is_directory as a parameter:      if (apr_filepath_merge((char**)&conf->ap_document_root, NULL, arg,                            APR_FILEPATH_TRUENAME, cmd->pool) != APR_SUCCESS         || !ap_is_directory(cmd->pool, arg)) {  which causes the crash. Looks convincing to me.  Committing an additional check - r589177.  Thanks for the diagnosis.fix possible crash at startup in case of nonexistent DocumentRoot. Fixed in r589618			Adrian Buckley	Nick Kew	Will Rowe
39726	null	RESOLVED		Luis Parravicini	1149521160000	1149575264000		typo in documentation In the first paragraph of 'A Brief Guide to Conditional Requests' appears 'Aoache' instead of 'Apache'.	(In reply to comment #0) > In the first paragraph of 'A Brief Guide to Conditional Requests' appears > 'Aoache' instead of 'Apache'.  Thanks for this, change has been committed. 			Jason Lingohr
39727	null	RESOLVED		Henrik Nordstrom	1149550980000	1204087752000		Incorrect ETag on gzip:ed content Entities gzip:ed by mod_deflate still carries the same ETag as the plain entiy, causing inconsistency in ETag aware proxy caches.  It is very important each unique entity carries unique ETag:s as these identify the specific entity variant of the URL. Each negotiated variant (where Accept-Encoding is just one negotioantio parameter) needs to have unique ETag:s. For mod_deflate it's as simple as adding the encoding to the already computed ETag.  This has implications on at least the following HTTP directives:     If-None-Match  used in Vary negotiation from ETag aware caches    If-Range       ranges in gzip:ed entity obviously not the same as ranges in the plain entity    If-Match       mainly conditional PUT requests   Example HTTP responses from an Apache-2.2.2 mod_deflate enabled server (irrelevant headers pruned):  Plain request     Server: Apache/2.2.2 (Fedora)    ETag: '76e23-1835-4156af5e53ac0'    Content-Length: 6197    Vary: Accept-Encoding,User-Agent      Same request with 'Accept-Encoding: gzip':     Server: Apache/2.2.2 (Fedora)    ETag: '76e23-1835-4156af5e53ac0'    Vary: Accept-Encoding,User-Agent    Content-Encoding: gzip    Content-Length: 1829    Implications of this:    * Clients may be given the incorrect response. In effect the first cached response is given to all clients as If-None-Match indicates the entitiy is OK for all clients..  (same ETag used in both responses -> Same If-None-Match request so mod_deflate can not tell if the If-None-Match condition is on a compressed or plain entity..)    * Clients doing range requests with If-Range may end up with corrupted objects containing part compressed part plain content.   Squid-2.6 and later is ETag aware and will make this problem quite visible. Release date for Squid-2.6 is 1/7 (i.e. in less than a month).	Created an attachment (id=18407) patch that'll cause mod_filter to unset the etag - see util_filter.h  This needs more discussion before committing this or any other patch. Some references  My ETag notes:  http://devel.squid-cache.org/  Old dev discussions: http://mail-archives.apache.org/mod_mbox/httpd-dev/200311.mbox/%3C3FB2E075.5010705@modperlcookbook.org%3E http://mail-archives.apache.org/mod_mbox/httpd-dev/200311.mbox/%3C3FB2C0CB.30401@sun.com%3E http://mail-archives.apache.org/mod_mbox/httpd-dev/200206.mbox/%3C00b801c20daf$736dd190$c000000a@KOJ%3E (In reply to comment #1) > Created an attachment (id=18407) [edit] > patch that'll cause mod_filter to unset the etag - see util_filter.h >  > This needs more discussion before committing this or any other patch.  Sorry for my confusion, but this will only work if mod_deflate is used via mod_filter, right? It will not work if mod_deflate is used without mod_filter. I guess for this case it is needed to unset the ETag header inside mod_deflate. So something like the following:  Index: mod_deflate.c =================================================================== --- mod_deflate.c       (Revision 411469) +++ mod_deflate.c       (Arbeitskopie) @@ -389,6 +389,7 @@              apr_table_mergen(r->headers_out, 'Content-Encoding', 'gzip');          }          apr_table_unset(r->headers_out, 'Content-Length'); +        apr_table_unset(r->headers_out, 'ETag');           /* initialize deflate output buffer */          ctx->stream.next_out = ctx->buffer; (In reply to comment #3)  > Sorry for my confusion, but this will only work if mod_deflate is used via > mod_filter, right?  Yes.  I mentioned that to the reporter in IRC, but not here,  >          apr_table_unset(r->headers_out, 'Content-Length'); > +        apr_table_unset(r->headers_out, 'ETag');  Ugh.  That way every filter has to reinvent protocol handling.  A fertile  breeding ground for bugs (and we have a history to prove it).  mod_filter is  designed to centralise that, so we only need to get the protocol right once. (In reply to comment #4) > >          apr_table_unset(r->headers_out, 'Content-Length'); > > +        apr_table_unset(r->headers_out, 'ETag'); >  > Ugh.  That way every filter has to reinvent protocol handling.  A fertile  > breeding ground for bugs (and we have a history to prove it).  mod_filter is  Yes, and I am pretty sure we have this history :-), BUT mod_filter is not mandatory to use.   > designed to centralise that, so we only need to get the protocol right once.  Agreed, but then we must make the use of mod_filter (or at least the usage of these parts) mandatory or must incorporate them into the core filter routines. From a protocol perspective removing the ETag is sufficient to make you compliant. If conditionals (If-xxx) anyway doesn't work right on transformed responses there is not much benefit of sending an ETag out.  But if you can it's better if you send an ETag. As I said initially you don't need  to compute a new etag, just adding some extra detail to the tag is fine.  I.e. '638f3e-6-1b6d6340-gzip' or similar for a gzip:ed entity where the base entity had the etag '638f3e-6-1b6d6340'.  To HTTP the etag is just a string with the only requirement that it must be unique for each entity variants of the same URL.  Actually I think adding details to the ETag may simplify many things for you as the core routines then can make quick asssssments of conditionals if it's possible to infer information about how the object had been processed from looking at the entity tag. Any progress on getting this patch (or another reasonable alternative) into the mod_deflate tree? (In reply to comment #7) > Any progress on getting this patch (or another reasonable alternative) into the > mod_deflate tree?  It needs raising on dev@ so we can reach a consensus solution.  Bugzilla has only proved that we have  more than one competing solution. This needs to be fixed by mod_deflate producing a new etag.  How we do that is going to take some investigation, since it doesn't do any good to produce the etag unless we can also check it on conditional requests.  My suggestion is to simply extend the existing etag with a gzip marker, for example adding ;gzip at the end or something like that.  I.e. if the original reply had  ETag: '6bf1f7-6-1b6d6340'  Then make mod-gzip translate this to  ETag: '6bf1f7-6-1b6d6340;gzip'  This should allows for easy bidirectional mapping, simplifying most conditionals as no transformation of the entity body is needed to find the etag, and the simple format makes it easier to trace should any misunderstandings occur. Pinging dev@ one more time.. Just committed a fix to make any ETag weak if we transform the entity.  Hopefully this should fix protocol compliance (and our users) without being controversial.  Not sufficient. The two versions is not semantically equivalen as one can not be exchanged for the other without breaking the protocol. In the context of If-None-Match the weak comparator is used in HTTP and there a strong ETag is equal to a weak ETag. Can you elaborate in more detail why you think that the two versions are not semantically equivalent? I read 13.3.3 in a way that they are. Because you can not exchange the gzip:ed variant with the identity encoded variant wihout causing breakage. The two do not mean the same thing to a recipient who do not know how to handle gzip.  The two is only semantically equivalent for a recipient capable of handling gzip, but not to HTTP in general as HTTP do not guarantee clients can handle gzip.  If they were semantically equivalent then there would be no need for conditional mod_gzip compression, or the use of Vary, at least not other than to reduce the load on the server under peak load... What you can do is to either  a) Drop the ETag completely. This is not opimal but works..  b) Or modify the ETag value in some manner. For example adding a constant string infront or after the original ETag.  In 'b', if the compression is not deterministic and always resulting in the same encoding then the ETag should additionally be made weak, to make sure no one attemtps merging partial responses down the line..    The main downside of 'a' is that ETag aware caches will then cache multiple copies of the same object, one per each slight varance of Vary indicated headers. For Apache itself it's not so big difference until conditional requests works proper in precense of filters like mod_deflate (i.e. If-None-Match). (In reply to comment #15) > Because you can not exchange the gzip:ed variant with the identity encoded > variant wihout causing breakage. The two do not mean the same thing to a > recipient who do not know how to handle gzip.  Bugzilla is the wrong place for this discussion.  Should be on dev@httpd.  Only a recipient that can handle gzip will be served the gzipped version.  > The two is only semantically equivalent for a recipient capable of handling > gzip, but not to HTTP in general as HTTP do not guarantee clients can handle gzip.  HTTP provides a separate mechanism for negotiating that.  >  > If they were semantically equivalent then there would be no need for conditional > mod_gzip compression, or the use of Vary, at least not other than to reduce the > load on the server under peak load...  Huh?  Those exist precisely because we need to cater for different clients. (In reply to comment #17)  > Only a recipient that can handle gzip will be served the gzipped version.  Which isn't true due to this bug. If there is a ETag aware cache between the client and Apache the client will be given whatever the previous client could handle.  > Huh?  Those exist precisely because we need to cater for different clients.  Exactly. (In reply to comment #18) > (In reply to comment #17) >  > > Only a recipient that can handle gzip will be served the gzipped version. >  > Which isn't true due to this bug. If there is a ETag aware cache between the > client and Apache the client will be given whatever the previous client could > handle.  The intermediate got a weak ETag.  So the intermediate has been told that the entity is equivalent but not byte-by-byte identical, and may be subject to negotiated transformation.  Therefore the intermediate is responsible for dealing with content-negotiated properties.  Do you have a particular intermediate in mind, when you propose something that treats a weak ETag as strong? 2.2 r608849 http://svn.apache.org/viewvc?view=rev&revision=608849 http://svn.apache.org/viewvc?view=rev&revision=581198 http://svn.apache.org/viewvc?view=rev&revision=607219			Henrik Nordstrom	Nick Kew	Roy T. Fielding	Ruediger Pluem	Takashi Sato
39761	null	RESOLVED		Justo Alonso	1149816240000	1149851771000		DBD: driver not available Hi!!     I compile apr-1.2.7, apr-util-1.2.7 with mysql support. Compile httpd-2.2.2. All on a Suse Enterprise server 9     When I start the server a message: [Fri Jun 09 03:14:28 2006] [notice] Apache/2.2.2 (Unix) mod_ssl/2.2.2 OpenSSL/0.9.7d DAV/2 configured -- resuming normal operations [Fri Jun 09 03:14:28 2006] [crit] (70023)This function has not been implemented on this platform: DBD: driver for  not available [Fri Jun 09 03:14:28 2006] [crit] (70023)This function has not been implemented on this platform: DBD: failed to initialise [Fri Jun 09 03:14:28 2006] [crit] (70023)This function has not been implemented on this platform: DBD: driver for  not available [Fri Jun 09 03:14:28 2006] [crit] (70023)This function has not been implemented on this platform: DBD: failed to initialise  Note that the name of the driver is missing (double space on driver_for__not_available)!!  I probe the dbd with the test ./dbd mysql [params]all work fine (all success) I probe with apache worker and prefork mpm style. I recompile apr-util to support pgsql and it's the same that with mysql.  Any idea ??. Maybe a bug getting parameter from apache and calling DBD with it ??  thanks, in advance	Good catch!  It's all working to spec, but just giving you a misleading error  message when you've forgotten to configure DBDriver.  Just fixed: http://svn.apache.org/viewvc?view=rev&revision=413015			Nick Kew
39806	null	RESOLVED		Brian	1150234260000	1151341746000		Add env vars to mod_proxy_balancer to allow more control Hello,  Here is a very simple patch to add some env vars to mod_proxy_balancer.  This allows you to figure out where the request was routed from the reverse proxy.  I needed this to add sticky session cookies to the response because I could not modify the backend app.  So, you can do something like this on the reverse proxy:  SetEnvIf ^Cookie$ 'MYCOOKIE=([^ ;]*)' MYCOOKIE=$1 Header append Set-Cookie 'MYCOOKIE=%{UNIQUE_ID}e.%{BALANCER_WORKER_ROUTE}e; path=/' env=!MYCOOKIE  RewriteRule ^/+(.*) balancer://test/$1 [P] ProxyPassReverse / balancer://test/  <Proxy balancer://test>   BalancerMember http://host1 route=host1   BalancerMember http://host2 route=host2 </Proxy> ProxySet balancer://test stickysession=MYCOOKIE nofailover=On	Created an attachment (id=18457) patch  quick patch to add env vars to mod_proxy_balancer Nice tool.  If you want to log this, use %{BALANCER_foo}e in the access log.  I don't see the need for the debug-level error log messages.  Other opinions from the crowd? Created an attachment (id=18467) mod_proxy_balancer-trunk.patch  Cleaned up patch, added patch to docs, against trunk. Created an attachment (id=18468) mod_proxy_balancer-trunk.patch  Let's try that again w/o the tab characters ;) ok, removed the debug stuff (not needed).  I also went against trunk and added a patch to the docs as well. Committed to trunk as r417238 (http://svn.apache.org/viewvc?rev=417238&view=rev). Thanks.			Brian	Jeff Trawick	Ruediger Pluem
39843	null	RESOLVED		Brian	1150817940000	1151694314000		 is unsupported Hello,  I was playing with some odd configs today and noticed that using RewriteRule in a Location block is matching on the full filesystem path and not the URL path (minuse the prefix) as expected.  I have not used this before, but so I am not sure here, but the docs for mod_rewrite seem to state that the RE should match on the URL path minus the Location prefix.  So given physical path '/path/to/docs/foo/bar', DocumentRoot 'path/to/docs' and Request 'http://big.com/foo/baz/boo.html'  <Location /foo>   RewriteEngine On   RewriteRule ^baz/(.*) /bar/$1 [R,L] </Location>  The above does not match as per the docs, but instead against '/path/to/docs/foo/baz/boo.html' and fails.  RewriteLog (3) Output: [perdir /foo/] add path info postfix: /path/to/docs/foo/baz -> /path/to/docs/foo/baz/boo.html [perdir /foo/] applying pattern '^baz/(.*)' to uri '/path/to/docs/foo/baz/boo.html'   Here is the complete httpd.conf I used (sanitized):  ### httpd.conf LoadModule rewrite_module modules/mod_rewrite.so  PidFile /path/to/logs/httpd.pid ErrorLog /path/to/logs/error_log LogLevel Debug RewriteLog '/path/to/logs/rewrite_log' RewriteLogLevel 3  Listen 80 ServerName localhost DocumentRoot '/path/to/docs'  <Location /foo>   RewriteEngine On   RewriteRule ^baz/(.*) /bar/$1 [R,L] </Location>	heh, and before I get corrected on this, I meant to type:   RewriteRule ^baz/(.*) bar/$1 [R,L] not    RewriteRule ^baz/(.*) /bar/$1 [R,L]  so that it redirects from /foo/baz to /foo/bar.  But, that does not really matter for the issue at hand. Where do you see docs implying the prefix will be stripped?  In general, using mod_rewrite directives inside <Location> is almost never necessary and can produce unpredictable results.  It should probably just be documented as unsupported. I agree, not that useful really.  But it *is* documented to work in mod_rewrite docs.  http://httpd.apache.org/docs/2.2/mod/mod_rewrite.html#rewriterule  Along with many examples at the end of RewriteRule section, there is also a note stating:  'Note: Pattern matching in per-directory context  Never forget that Pattern is applied to a complete URL in per-server configuration files. However, in per-directory configuration files, the per-directory prefix (which always is the same for a specific directory) is automatically removed for the pattern matching and automatically added after the substitution has been done. This feature is essential for many sorts of rewriting - without this, you would always have to match the parent directory, which is not always possible.  There is one exception: If a substitution string starts with ""http://'', then the directory prefix will not be added ,and an external redirect (or proxy throughput, if using flag P) is forced!'    Aslo note that that note states *one* exception, but the examples show that it is only added back if there is no leading '/'.  So, the exception is actually the rule in most cases. There's your confusion: When the docs refer to per-directory configuration, they mean <Directory> sections and .htaccess files, not <Location> sections.  Unless someone can see a good reason for using RewriteRule in <Location>, I'll change this to a doc bug and suggest just noting that it is unsupported. I've now clarified this somewhat in the docs.			Brian	Joshua Slive
39854	null	RESOLVED		Nick Kew	1150931520000	1166536038000		INFLATE output filter chokes on flush buckets There's a chunk of bogus code in the inflate output filter: I think it was  originally cut&paste (by me) from the inflate input filter.  Since 2.2 we're  getting flush buckets in real life, and they're tickling the bug causing it to  die with 'Inflate error -5 on flush'.  The apache-modules post I've referenced explains it.	Fixed in trunk: revision 416165 Proposed a patch for backport as r437674 (http://svn.apache.org/viewvc?rev=437674&view=rev). Backported to 2.2.x as r488817 (http://svn.apache.org/viewvc?rev=488817&view=rev).			Nick Kew	Ruediger Pluem
39915	null	RESOLVED		Andrew Pimlott	1151470140000	1151577246000		seg fault with SSLProxyMachineCertificateFile In some configurations, SSLProxyMachineCertificateFile causes Apache to seg-fault on startup.  The following small configuration works as expected:      Listen 80     Listen 443      LoadModule proxy_module modules/mod_proxy.so     LoadModule proxy_http_module modules/mod_proxy_http.so     LoadModule ssl_module modules/mod_ssl.so      User nobody     Group #-1     TypesConfig conf/mime.types      #<VirtualHost *>     #</VirtualHost>     <VirtualHost _default_:443>     SSLEngine on     SSLCertificateFile server.cert     </VirtualHost>      SSLProxyEngine on     SSLProxyMachineCertificateFile server.cert      ProxyPass /foo https://www2.metnet.navy.mil/  Requests for /foo on either 80 or 443 will be reverse-proxied to an HTTPS server, using a client cert.  However, if you uncomment the commented VirtualHost lines, Apache seg-faults on startup.  I haven't investigated the reason.  This does not seem to be related to bug 24030 (which should be fixed in apache 2.0.55).	Oh, server.cert is just a dummy self-signed cert plus key.  For ease of reproducing, here it is:  -----BEGIN RSA PRIVATE KEY----- MIICXwIBAAKBgQCsxmVAUyU3wCtyCE75p2imqRkv2t43Nw6jTe+me2sCAUYoE+ls n39/WnUGk299Yg30W1DQDixD1Q15Kv9qlvL+2FylQqH3teS21MDjWYWi2zwS/u53 ShhrUkKJ98Oj1Cqo26wijLCA3+eEpQO+ydj0uk+m2We4HkNnWXAyOq+OGQIDAQAB AoGBAIUOeRVzstrfhNXZ7jA3q9GFsp73GGE/Zmd/csssivlNT+E3jHGZ18+VM0Cw NJFD/WktFexUreRDZI/m/DLzMwip4Cq3ySkzIXsOAaMOtz9KGET/K9LcRpYh1byO FCV+z+43L7Q+Uh8TeKe/Hj+Sh9kA79JamYPtcMKUfUeBbWB9AkEA3hYrwBUf5/xP pWwc17YtChAox1e/hCE07rAiW5CxtJNI4z2QEFysISGBtFzHSaiIFQEhrJnOI+9p MYLtyP/ACwJBAMcoh8NdFUIDNsC7o8QBonS48UPqRwcKPH0bKj4HmcvFTb7P2aIw knAqY71Lx65UOfr8z3NRqtLojEDAQF4VTOsCQQDZ4nSP4enIpsDZMaVmeMPdUJdB Y7RwhEezOTisDtxZpfpnf1mcw97YLlBbTH70pBTGTrLj7I3SsarJuYNipI+bAkEA vSnaCc3X6yNyVg3jtsB2tbcUMhXL8PvgCFRNAy3k/o8hESQK6uqHrNIWei4IM6T8 jVCjGj1vq3QGA1qXyMUikQJBAMn5Yj6xh2piPSEvfFifLlerpqNbrKrhMov1oTWN boMMQpjW3tnXiqd04nTXjQCxN+4CWNcIdCfuO4OqCfQ5Lrs= -----END RSA PRIVATE KEY----- -----BEGIN CERTIFICATE----- MIICJTCCAY4CCQDEZpgxQTJ07DANBgkqhkiG9w0BAQUFADBXMQswCQYDVQQGEwJV UzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8GA1UEBxMITW9udGVyZXkxDzANBgNV BAoTBkFuZHJldzEPMA0GA1UEAxMGQW5kcmV3MB4XDTA2MDYyODA0NDUxMFoXDTA2 MDcyODA0NDUxMFowVzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWEx ETAPBgNVBAcTCE1vbnRlcmV5MQ8wDQYDVQQKEwZBbmRyZXcxDzANBgNVBAMTBkFu ZHJldzCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEArMZlQFMlN8ArcghO+ado pqkZL9reNzcOo03vpntrAgFGKBPpbJ9/f1p1BpNvfWIN9FtQ0A4sQ9UNeSr/apby /thcpUKh97XkttTA41mFots8Ev7ud0oYa1JCiffDo9QqqNusIoywgN/nhKUDvsnY 9LpPptlnuB5DZ1lwMjqvjhkCAwEAATANBgkqhkiG9w0BAQUFAAOBgQCKe9Mjaeut lA6cM6vxhfOsbtc1L1Lz2fA3arXM9dv15jAQGpCDAPzC81ortnQpfohJv1wymIN4 VSDjmbsZi4R6AqK5Pjh/JoCKppdtHmBUaA2EFAkld9CDJAa02vfQAQfupqurN9zf A+kd+smwWefqu0Ea/I6WAX6wad7omNiKBQ== -----END CERTIFICATE-----  You should be able to run my config (from the initial report) with something like  apache2 -X -d $PWD -f httpd.conf  if you put the config in httpd.conf and the cert in server.cert in the same directory.  You'll have to create a few other files, but you're smart, you'll figure it out. Can you get a backtrace?  gdb /path/to/httpd ... (gdb) run -X ... (gdb) bt  Hmm, I didn't realize I'd get a reasonable backtrace without recompiling everything with debugging.  Here it is:  #0  0xa7e19c61 in CRYPTO_add_lock () from /usr/lib/i686/cmov/libcrypto.so.0.9.8 #1  0xa7e9dcae in X509_INFO_free () from /usr/lib/i686/cmov/libcrypto.so.0.9.8 #2  0xa7e83660 in sk_pop_free () from /usr/lib/i686/cmov/libcrypto.so.0.9.8 #3  0xa7989008 in ssl_init_ModuleKill () from /home/andrew/u/modules/mod_ssl.so #4  0xa7c7ee4d in apr_pool_tag () from /usr/lib/libapr-0.so.0 #5  0xa7c7fd27 in apr_pool_clear () from /usr/lib/libapr-0.so.0 #6  0x0807e64d in main () That doesn't ring any bells.  What version of OpenSSL, what distribution? Is this reproducible with 2.2.2?  What is the error_log output with 'LogLevel debug'? Never mind, I can reproduce this. Fixed on the trunk:    http://svn.apache.org/viewvc?view=rev&revision=417988  and will propose for 2.2.x.  Thanks for the report.  Thanks so much for figuring this out.  Sorry for forgetting all my version details; somehow the mind just goes when filing bug reports.			Andrew Pimlott	Joe Orton
39939	null	RESOLVED		Luis Parravicini	1151681700000	1151682508000		Error in documentation There's an error in the document 'Apache performance tuning', section 'HostnameLookups and other DNS considerations'.  It says '...the logresolve program that comes with Apache, on one of the numerous log reporting...' where it should read '...the logresolve program that comes with Apache, or one of the numerous log reporting...'. Changing 'on' by 'or'.	Fixed in svn - should appear on site soon - thanks.			Nick Kew
39992	null	RESOLVED		Darryl Miles	1152349860000	1152462363000		[PATH] improve error message usefulness Please accept this minor patch to make the error report a little more useful when you are using Include directive from multiple configuration files.	Created an attachment (id=18576) Trivial patch  Apart from the fact that you attached the reverse patch :-), I committed it to the  trunk as r420307 (http://svn.apache.org/viewvc?rev=420307&view=rev).			Darryl Miles	Ruediger Pluem
40004	null	RESOLVED		PFudd	1152573600000	1185968978000		t seem to end rewriting I have two rules:     RewriteBase /db/     RewriteRule ^experiment-1 experiment-2 [L]     RewriteRule ^experiment-2 experiment-3  The url http://localhost/db/experiment-1 should be rewritten to experiment-2, and that should be the last rewriting to be done.  However, the actual file retrieved is experiment-3.  The output of rewritelog (at level 2) is: 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa45668/initial] (2) init rewrite engine with requested uri /db/experiment-1 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa45668/initial] (1) pass through /db/experiment-1 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa45668/initial] (2) [perdir /var/www/html/db/] rewrite 'experiment-1' -> 'experiment-2' 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa45668/initial] (2) [perdir /var/www/html/db/] trying to replace prefix /var/www/html/db/ with /db/ 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa45668/initial] (1) [perdir /var/www/html/db/] internal redirect with /db/experiment-2 [INTERNAL REDIRECT] 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa4a040/initial/redir#1] (2) init rewrite engine with requested uri /db/experiment-2 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa4a040/initial/redir#1] (1) pass through /db/experiment-2 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa4a040/initial/redir#1] (2) [perdir /var/www/html/db/] rewrite 'experiment-2' -> 'experiment-3' 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa4a040/initial/redir#1] (2) [perdir /var/www/html/db/] trying to replace prefix /var/www/html/db/ with /db/ 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa4a040/initial/redir#1] (1) [perdir /var/www/html/db/] internal redirect with /db/experiment-3 [INTERNAL REDIRECT] 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa4bcb8/initial/redir#2] (2) init rewrite engine with requested uri /db/experiment-3 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa4bcb8/initial/redir#2] (1) pass through /db/experiment-3 127.0.0.1 - - [10/Jul/2006:16:07:25 --0700] [localhost/sid#989a608][rid#aa4bcb8/initial/redir#2] (1) [perdir /var/www/html/db/] pass through /var/www/html/db/experiment-3  I don't know what [L] is supposed to do, if this is correct behaviour.	These rules are inside a <Directory /var/www/html/db> section, if that helps. Yes. That was obvious from the description and the rewrite log. ;-)  The [L] flag works as expected (finishing the Ruleset). What you probably didn't expect was that the internal redirect finds the whole ruleset again and again. That's a different issue and a side effect of RewriteRules in the directory context.  -> invalid. Well, as my teacher used to say, it's either a bug in the program or a bug in the documentation.  This behaviour isn't documented; who do I send requests like this to?  Thanks! If someone updates the RewriteEngine documentation, some of the points from http://www.sitepoint.com/print/mod_rewrite-no-endless-loops would be good to include. It's kinda documented, but too implicit and so quite bad. The place for such requests is here ;) You can also place patches here or enter the docs list (http://httpd.apache.org/docs-project/) :-) I'd love to supply a patch, but I don't know enough about what's going on to write one for this.  I'd be supplying some 'G' for the GIGO process. The new rewrite flags documentation (httpd.apache.org/docs/rewrite/flags.html) will be providing more detail on things like this. I'll be certain to cover this particular annoyance there. Thanks for the reminder. The more I think about it, the more I think this is a misfeature.  If '[L]' doesn't stop further rewriting (in directory rules), then it doesn't serve a purpose (in directory rules).  Is there a workaround? (In reply to comment #8) > The more I think about it, the more I think this is a misfeature.  If '[L]' > doesn't stop further rewriting (in directory rules), then it doesn't serve a > purpose (in directory rules).  Well, as  Andr?? said, it stops processing in that round of processing. The internal redirect is nearly a new request (well, not everything is being re-processed). The L-Flag is usefull in per-dir context, just think about 20 rules and the first did match. With out the L-flag everything below would be tested in that round of processing, too. That saves processing. I don't think that writing something like 'don't apply rewrite rules any more' into request_rec is a solution, think about the situation rewriting /a to /b while there are rewriteRules in palce fpr <directory /var/www/b>.  > Is there a workaround?  Either use THE_REQUEST or ENV:REDIRECT_STATUS      RewriteBase /db/     RewriteRule ^experiment-1 experiment-2 [L]     RewriteCond %{ENV:REDIRECT_STATUS} =''     RewriteRule ^experiment-2 experiment-3  or      RewriteBase /db/     RewriteRule ^experiment-1 experiment-2 [L]     RewriteCond %{THE_REQUEST} experiment-2     RewriteRule ^experiment-2 experiment-3  > The new rewrite flags documentation (httpd.apache.org/docs/rewrite/flags.html)  There is a small mistake: RewriteRule %{REQUEST_URI} /.(png|gif|jpg) - [E=image:1]  should be  RewriteRule /.(png|gif|jpg) - [E=image:1] (In reply to comment #9)  > There is a small mistake: > RewriteRule %{REQUEST_URI} /.(png|gif|jpg) - [E=image:1] >  > should be >  > RewriteRule /.(png|gif|jpg) - [E=image:1]  Thanks. Fixed in r559494 in trunk. Will fix in 2.2 also. Fixed on trunk to note the reinjection possibility in the docs for the L flag.			Andr?? Malo	Bob Ionescu	Joshua Slive	PFudd	Penelope Fudd	Rich Bowen
40030	null	RESOLVED		Darryl Miles	1152730020000	1156266364000		) The documentaiton page at http://httpd.apache.org/docs/2.2/mod/mod_dav.html  Has:  <LimitExcept GET OPTIONS>   require user admin </LimitExcept>   This example does not seem the best general purpose case since it omits the HEAD and POST options, which would allow to standard URL access to occur but correctly limit methods employed by DAV.  <LimitExcept GET HEAD OPTIONS POST>   require user admin </LimitExcept>	As the <Limit> directive doc says, HEAD is implied by GET.  I'm neutral about POST.  Being more restrictive in the examples is usually better than less restrictive. If I may clarify my thoughts.  Someone adding DAV to their website wants to restricts the additional DAV operations but retain the existing web-application operations, so their web-application continues to work like it did before.  If they wanted to restrict the POST operation they would already have configured a rule for that outside of the additional configuration required for DAV.   Are you saying that DAV utilizes the POST method for any operation and in doing so that optation may modify data or expose extra data to an anonymous website user; that the anonymous website user wouldn't be able to have done otherwise.  So summarize that question 'Can a privilege escalation via the POST method occur for an anonymous website user ?'  When I audited the example configuration changes myself by researching into the commands I was adding this exact concern immediatly came to mind.  After 5 mins looking over the code for what DAV does via the POST method I could not see any active component.  I'm trying to spare someone else less technical than me this headache that the suggestion of <LimitExcept GET OPTIONS> implies, in that DAV maybe unsafe for any website utilizing the POST method for its everyday operations so we dont recommend <LimitExcept GET OPTIONS POST>.   Point taken on the HEAD issue but again <LimitExcept GET HEAD OPTIONS POST> is much clearer to understand than <LimitExcept GET OPTIONS POST>, it means I dont have the headache of finding out why HEAD wasn't included.  If they are equal and one way is clearer than the other, use the clearer way in the documentation.  Is your neurtal stance due to being unsure of the effects of DAV+POST ?  Maybe a DAV guru will notice this and contribute their wizdom.  I'm now thinking if there are side effects these should be documented.  Either way I'm just trying to remove the concern that a potential user may get after reading the current documentation.  I don't have any objection to adding POST.  In general, people should only open up the methods they use, which frequently will not include POST.  But I agree with you that in the context of DAV, it may make sense to address the methods that are not affected by 'Dav On'.  I would certainly object to adding HEAD.  It would lead to people thinking they could restrict HEAD and GET independently, resulting in more confusion, not less.   In fact, the server should probably issue a warning if HEAD is present in a <Limit(except)>.  Understood your objections noted.  How abouts adding a comment line above the LimitExcept clause:  ... # HEAD not required explicitly, GET implies HEAD <LimitExcept GET OPTIONS POST> ...  That would make things very clear and keep us both happy. I've added POST to the trunk version of the docs.  It is unlikely to get backported, so it won't be seen in a release for a while.  Thanks for your suggestion.			Darryl Miles	Joshua Slive
40046	null	RESOLVED		Ian Abel	1152886800000	1185885903000		mod_rewrite PT (Pass Through) option has L side effect a rule with the PT option behaves like a rule with the L option. This is either  a bug in the behaviour or a bug in the documentation given it is only clear  that this occurs by reading the source.	And how does your RewriteRule with the corresponding RewriteLog with loglevel 5 look like? This is not determined from any rewrite rule that i can post but from this code  snippet from the latest release of apache 2.2.2.  httpd-2.2.2/modules/mappers/mod_rewrite.c , line 3939 and following             if (p->flags & RULEFLAG_PASSTHROUGH) {                 rewritelog((r, 2, perdir, 'forcing '%s' to get passed through '                            'to next API URI-to-filename handler', r->filename));                 r->filename = apr_pstrcat(r->pool, 'passthrough:',                                          r->filename, NULL);                 changed = ACTION_NORMAL;                 break;             }  The break statement causes the loop over rewrite rules to be exited from. A  rewrite rule that exhibits this behaviour is for example:  RewriteCond %{QUERY_STRING}  !moose=1 RewriteRule /(.*) /$1?moose=0 [PT,QSA]  RewriteRule /(.*) /$1 [E=TEST:1]  Which doesn't result in TEST being set if moose=1 is not present in the query  string. This is non-documented non-obvious behaviour. (Yes there are many other  ways of rewriting the rules to avoid this, if you consider this behaviour to be  correct / to spec, please document it). I think the behaviour is correct, but of course this should be documented. So I change the component to Documentation. This behavior bit me, too. Working around it resulted in a somewhat ugly solution. Perhaps add an option that disables the current [L]-like behavior. And obviously, this needs to be documented. The fact that PT implies L has been documented on trunk.			Bob Ionescu	Ian Abel	Joshua Slive	Ruediger Pluem	Samuli K
40051	null	RESOLVED		Andy Wang	1152917700000	1153923985000		multiple AuthnProviderAliases causes segfault of apache child process I have the following configuration in my httpd.conf file: <AuthnProviderAlias ldap ldap>   AuthLDAPURL ldap://[insert your ldap server] </AuthnProviderAlias>   <AuthnProviderAlias ldap padl>   AuthLDAPURL ldap://[insert your ldap server] </AuthnProviderAlias>  <Location /dir1>   AuthzLDAPAuthoritative off   AuthName 'MyRealm'   AuthType Basic   AuthBasicProvider padl ldap   require valid-user </Location>  <Location /dir2>   AuthzLDAPAuthoritative off   AuthName 'MyRealm'   AuthType Basic   AuthBasicProvider ldap   require valid-user </Location>   When I hit /dir1, my apache child process segfaults.  Based on the gdb stack trace, it looks like an endless loop of some sort is entered:  Program received signal SIGSEGV, Segmentation fault. [Switching to Thread -1223992400 (LWP 31027)] find_entry (ht=0x80e8a60, key=0x8187b50, klen=-1, val=0x0) at apr_hash.c:256 256     { (gdb) where #0  find_entry (ht=0x80e8a60, key=0x8187b50, klen=-1, val=0x0)     at apr_hash.c:256 #1  0xb7c9243d in apr_hash_get (ht=0xb68b6040, key=0x80e8a60, klen=-1)     at apr_hash.c:330 #2  0xb7eea9fb in authn_alias_check_password (r=0x8193e68,     user=0xb68b6040 '????????', password=0xb68b6040 '????????') at mod_authn_alias.c:59 #3  0xb7eeaa3e in authn_alias_check_password (r=0x8193e68,     user=0xb68b6040 '????????', password=0xb68b6040 '????????') at mod_authn_alias.c:68 #4  0xb7eeaa3e in authn_alias_check_password (r=0x8193e68,     user=0xb68b6040 '????????', password=0xb68b6040 '????????') at mod_authn_alias.c:68 #5  0xb7eeaa3e in authn_alias_check_password (r=0x8193e68,     user=0xb68b6040 '????????', password=0xb68b6040 '????????') at mod_authn_alias.c:68 #6  0xb7eeaa3e in authn_alias_check_password (r=0x8193e68,     user=0xb68b6040 '????????', password=0xb68b6040 '????????') at mod_authn_alias.c:68 #7  0xb7eeaa3e in authn_alias_check_password (r=0x8193e68,     user=0xb68b6040 '????????', password=0xb68b6040 '????????') at mod_authn_alias.c:68 #8  0xb7eeaa3e in authn_alias_check_password (r=0x8193e68,     user=0xb68b6040 '????????', password=0xb68b6040 '????????') at mod_authn_alias.c:68 #9  0xb7eeaa3e in authn_alias_check_password (r=0x8193e68,     user=0xb68b6040 '????????', password=0xb68b6040 '????????') at mod_authn_alias.c:68 #10 0xb7eeaa3e in authn_alias_check_password (r=0x8193e68,     user=0xb68b6040 '????????', password=0xb68b6040 '????????') at mod_authn_alias.c:68  This goes on for tends of thousands of calls and actually eventually segfaults gdb if I try to get to the beginning of the stack.  If I reverse the order of the AuthnProviderAlias declarations and put padl before ldap, the problem goes away.  If I pick different aliases, I have to guess at the right order to do this.	By the way, this bug has been reproduced on both Windows and Linux, though we didn't manage to capture the stack on Windows. Isn't the problem that you have the provider alias being aliased to itself?  You can't do that: pick another name for the first alias besides 'ldap'.  The code may technically permit it, but I expect that's the root cause as they share the same provider namespace and if you get into a recursive definition, funny things may happen. Ahh. I guess the documentation for mod_auth_alias wasn't very clear as to what the baseProvider and aliasName were referring to.  This makes sense.  Seems rather ugly that such a misconfiguration could cause apache to go into an endless loop.  But, at least now we know how to make this do the right thing. Thanks. Created an attachment (id=18636) Add a check to make sure that the base provider and the alias names are different and also that the alias has not been registered before  This patch as been checked into trunk and proposed for backport Backported to 2.2.x as r425740 (http://svn.apache.org/viewvc?rev=425740&view=rev).			Andy Wang	Brad Nicholes	Jess Holle	Justin Erenkrantz	Ruediger Pluem
40064	null	RESOLVED		Ross Heritage	1153220220000	1173687352000		Problem with ETags between 32-bit and 64-bit architectures. The last modified date stored in r->mtime is of type apr_int64_t.   When this is used to build up the ETag in modules/http/http_protocol.c (in  ap_make_etag), this variable is cast to an unsigned long prior to the  converion to hex.  next = etag_ulong_to_hex(next, (unsigned long)r->mtime);  On a 32-bit architecture, this loses the first 32-bits of the number, so the  resulting hex string is only 8 characters long, and does not accuratly reflect  the last-modified time.  On a 64-bit architecture, the cast retains all 64 bits (or more likely its  casting a 128-bit number down to 64-bits), so the resulting hex value is  correct.  This is a big problem for us at the BBC as we now have a mixture of 32-bit and  64-bit machines (AMD Opteron vs. Intel Xeon).  The problem also seems to exist in the latest Apache 2.2 build, although the  ETag code has been extracted to the file modules/http/http_etag.c  Suggested fix:  Change the etag_ulong_to_hex function so that it only ever pushes the last 8  hex characters on to *next. This is not ideal, as the resulting hex is not  representative of the last-modified date, but I would be surprised if this  were to bite anyone.	Changing etag_ulong_to_hex() to use an apr_uint64_t and dropping the casts would be a better fix, I think. Either way, I've ran into this myself before.  Don't suppose anyone wants to write a patch :) ? Created an attachment (id=18635) patch to use apr_uint64_t for etags  Here's a quick patch to always use 64-bit integers in etag generation.\tTested only to compile and produce etags on x86_64, not tried a 32-bit platform or anything more thorough. *** Bug 41095 has been marked as a duplicate of this bug. *** Committed: http://svn.apache.org/viewvc?view=rev&rev=517238 - thanks for the report.  I'm not sure whether it would be a good idea to merge this into 2.2.x; it could break working 32-bit-only shops by having different 2.2.x releases generate different etags across a server farm. Note that the patch attached here was incomplete; the subsequent fix is also needed:  http://svn.apache.org/viewvc?view=rev&rev=517654 Backported to 2.2.x as r602503 (http://svn.apache.org/viewvc?rev=602503&view=rev).			Joe Orton	Paul Querna	Ruediger Pluem
40137	null	RESOLVED		Olaf van der Spek	1154132700000	1198326979000		Unwanted Instance Manager Startup Shortcut Hi,  The installer installs a shortcut to the instance manager in the startup group  without asking. Could an option to disable this be added to the installer? And even better, could that option be disabled by default?	shortcuts can be trivially deleted, and when you give someone the option to 'exit' the taskbar app, they need a way to get back in. > they need a way to get back in.  Yes, but there's no reason for that shortcut to be in the startup group. A regular shortcut would work fine for that. Now we're talking, you suggest promoting into the regular Apache shortcut group, instead of nesting in the control subgroup, right?  I'll tweak that for 2.2.7, thanks for the suggestion.  Actually I had trouble finding it burried in there when I fixed it (the shortcut had been broken for a release or two). No, I mean the Instance Manager, that sits in the tray. A shortcut for it used to be installed in the Startup dir of the start menu, such that it got started automatically after each login. However, I just did a fresh install of 2.2.6 and can't find any shortcut to the instance manager. 'I just did a fresh install of 2.2.6 and can't find any shortcut to the instance manager.'  Those are called taskbar icon applications, and the shortcut to it was broken in 2.2.6 and sometime earlier (I mentioned it was broken).  I've restored it, and placed it under the Apache HTTP Server 2.2.7 shortcut group instead of burring it under Apache HTTP Server 2.2.7 -> Control Services.  > Those are called taskbar icon applications,  AFAIK the icons are in the (system) tray.  > I've restored it, and placed it under the Apache HTTP Server 2.2.7 shortcut group instead of burring it under Apache HTTP Server 2.2.7 -> Control Services.  Does that mean it doesn't start automatically anymore? Ok - so to clarify, all the shortcuts were broken, you would see the apachemonitor upon installation, and never after.  I totally agree that such can be annoying.  This is why the startup group  is chosen over the HKxx/Software/Microsoft/Windows/CurrentVersion/Run, which is much more insidious.  It will again create these shortcuts.  However, it is not a 'key' resource. If you remove this shortcut, the installer should not believe the package has been broken.  Since this is certainly not a common request, but a very minority opinion, we'll leave things be.  Decided you are right in that the ApacheMonitor is a seperate element of the package...  custom install will let you optionally omit this in 2.2.7 - entirely (none of the shortcuts that bothered you, and no ApacheMonitor.exe either). Thanks. Still wondering though, what's the advantage of Apache Monitor compared to the standard Windows Services interface? Very little difference if you are conversant with the SCM (service control manager), although it lets you watch multiple machines at once.  Because some users are 'starting out', it's a handy tool (I use it often to manage some 15 test installations of various flavors of httpd in development.)  I sort of disagree with it's 'coloring scheme' (I think one dead 'automatic' service is too many, while a dead 'manual' service is never bad), and it's just a little slow on the uptake about reporting services in transition (it won't tell you as clearly about starting/stopping).  In full-view mode it provides some extra context about problems starting the service, which is handy.  I should finally point out that with this change, it's actually possible to install /only/ the ApacheMonitor (although why someone needs to do this is sort of beyond me ;-)			Olaf van der Spek	Will Rowe
40299	null	RESOLVED		Dave Hodder	1156277940000	1201599787000		ECMAScript and JavaScript media types in mime.types file Please add the MIME type for ECMAScript, and change the JavaScript MIME type from 'application/x-javascript' to 'application/javascript'.      application/ecmascript\t\tes     application/javascript\t\tjs  Many thanks,  Dave   Unified diff:  --- mime.types\t2006-08-22 19:43:00.687500000 +0100 +++ mime.types\t2006-08-22 19:46:12.718750000 +0100 @@ -28,6 +28,7 @@  application/edifact  application/edi-x12  application/eshop +application/ecmascript\t\tes  application/font-tdpfr  application/http  application/hyperstudio @@ -199,6 +200,7 @@  application/vnd.japannet-setstore-wakeup  application/vnd.japannet-verification  application/vnd.japannet-verification-wakeup +application/javascript\t\tjs  application/vnd.jisp  application/vnd.kde.karbon  application/vnd.kde.kchart @@ -354,7 +356,6 @@  application/x-gtar\t\tgtar  application/x-gzip  application/x-hdf\t\thdf -application/x-javascript\tjs  application/x-koan\t\tskp skd skt skm  application/x-latex\t\tlatex  application/x-netcdf\t\tnc cdf	Created an attachment (id=18743) mime.types patch  When does this bug get fixed in Apache? Please let make the patch proposed above into the trunk as soon as possible. All major browser vendors (except Microsoft) did do their homework and did adjust the new MIMEType for JavaScript/ECMAScript. The extension .es conflicts with existing language extension for Spanish. We will use .ecma instead. (In reply to comment #3) > The extension .es conflicts with existing language extension for Spanish. > We will use .ecma instead.  The extension .pl for perl files also conflicts with existing file extension for polish, .pl. Other existing conflicts may exist. We deal with such conflicts since years...  My question is: why does this conflict seem to be a problem *now*, but the other existing conflicts (e.g. .pl file extension vs. polish language extension) don't? Why using .ecma instead of the RFC-proposed .es and leave the other conflicts untouched?  Is there a possibility to let check apache, if the last file extension is one for content negotiation or the 'normal' file extension? If such a possibility theoretically exists or could exist, I propose, it should be implemented into apache to avoid such conflict situations in the future. What's your opinion about that issue?   Reopened this bug to get an answer to comment #4. You ask why new conflicts are problems but not existing ones.  The other conflicts are problems too. But when you have a conflict you need to make a decision about which type wins. Absent a very compelling argument otherwise, it is clear that an existing type/language should win out over a new one to prevent breaking sites that rely on the existing extension.  A very compelling argument would be, for example, concrete evidence showing that .es is very-widely used for your type and almost never used for the language.			Dave Hodder	Joshua Slive	Roy T. Fielding	Sierk Bornemann
40310	null	RESOLVED		Ian Abel	1156436100000	1187356078000		Ajp Connection handling causes unexpected results. With an apahce proxying requests over ajp to a backend tomcat, the following  sequence of events is possible:  User1 requests /badger, and sends headers. Request hits apache, filters into ap_proxy_ajp_request in mod_proxy_ajp.c User1 terminates connection with extreme prejudice. Apache sends headers to tomcat. Tomcat takes it's time. Apache tries to read the rest of the request body with ap_get_brigade,  mod_proxy_ajp.c:174. This fails as the underlying socket cannot recv any more. So ap_proxy_ajp_request returns 500 immediatly. conn->close++ is not called so  the connection is not touched, merely put back in the available connections. Apache now fails int he output filters trying to send the status 500 error  message.  Now user2 connects, requests /moose, apache takes the above connection from the  pool and sends the headers down the pipe to the tomcat. The tomcat now returns /badger, as that's finally finished processing.  Apache in ajp_read_header reads the SEND_BODY_CHUNK message, and processes it.  Then repeats reading messages until the END_RESPONSE message.  Whereupon apache has successfully served /badger to someone who requested / moose.   Needless to say this is a critical flaw with the ajp connection handling.	Created an attachment (id=18750) Patch that attempts to fix the bug  This patch _should_, if my understanding of the bug is correct , fix it.  Well spotted! Committed to trunk as r434483 (http://svn.apache.org/viewvc?view=rev&revision=434483). Thanks for the patch. Proposed for backport to 2.2.x as r434488 http://svn.apache.org/viewvc?view=rev&revision=434488). I'd like to add that in our shop we witnessed this exact same problem with Apache 2.2.3 and mod_jk 1.2.19, not mod_proxy_ajp.  Will the fix being applied cure this problem when using mod_jk or is a seperate patch going to be applied to that module as well?  Thanks. No this will not cure mod_jk. Bugs for mod_jk should not be further handled in this report. Please open a new report with Product: Tomcat 5 and Component: Native:JK. BTW: The fix for the original bug will be part of 2.2.4 as it has been backported. The problem is still not fixed correctly in 2.2.4 (the worker is marked errored and connection retried but that is wrong): +++ Fri Mar 16 08:27:06 2007] [error] [client 71.140.198.6] proxy: error processing body, referer: https://xxx.yyy.zzz/site/checkout/ship_method.html [Fri Mar 16 08:27:06 2007] [error] proxy: got bad response (5) from 64.85.80.16:8009 (app4) [Fri Mar 16 08:27:06 2007] [error] proxy: BALANCER: (balancer://appservers). All workers are in error state for route (app4-engine1) +++ I have fixed it in trunk. Created an attachment (id=19772) patch for 2.2.x  I will commit it in the 2.2.x branch if noone complains. Fix backported to 2.2.x as r553593 (http://svn.apache.org/viewvc?view=rev&revision=553593)			Ian Abel	Ruediger Pluem	Russell Hatfield	jfclere
40323	null	CLOSED		Richard Crawford	1156518780000	1157368248000		mod_ext_filter"s ExtFilterDefine exhibits problems with case Standard httpd.conf directives added for mod_ext_filter:   ExtFilterDefine myfilterZ cmd='/scriptpath/scriptname.pl' <Location /home>   SetOutputFilter myfilterZ </Location>   Apache config test passes, but on making a request that should hit the filter, the following error is logged:  [Fri Aug 25 10:07:42 2006] [error] [client 192.168.56.15] couldn't find definition of filter 'myfilterz'   Workaround was to change mod configuration parameters and location directive to all lowercase.  ExtFilterDefine myfilterz cmd='/scriptpath/scriptname.pl' <Location /home>   SetOutputFilter myfilterz </Location>	ahh, mod_ext_filter isn't aware that the core server will normalize the case by changing it to lower case; mod_ext_filter has already added the filtername to a hash table using your mixed case and later tries to do a lookup using the normalized name  Please try this patch and report back.  Index: modules/filters/mod_ext_filter.c =================================================================== --- modules/filters/mod_ext_filter.c\t(revision 431472) +++ modules/filters/mod_ext_filter.c\t(working copy) @@ -203,6 +203,7 @@                                               &ext_filter_module);      const char *token;      const char *name; +    char *normalized_name;      ef_filter_t *filter;        name = ap_getword_white(cmd->pool, &args); @@ -210,7 +211,16 @@          return 'Filter name not found';      }   -    if (apr_hash_get(conf->h, name, APR_HASH_KEY_STRING)) { +    /* During request processing, we find information about the filter +     * by looking up the filter name provided by core server in our +     * hash table.  But the core server has normalized the filter +     * name by converting it to lower case.  Thus, when adding the +     * filter to our hash table we have to use lower case as well. +     */ +    normalized_name = apr_pstrdup(cmd->pool, name); +    ap_str_tolower(normalized_name); + +    if (apr_hash_get(conf->h, normalized_name, APR_HASH_KEY_STRING)) {          return apr_psprintf(cmd->pool, 'ExtFilter %s is already defined',                              name);      } @@ -219,7 +229,7 @@      filter->name = name;      filter->mode = OUTPUT_FILTER;      filter->ftype = AP_FTYPE_RESOURCE; -    apr_hash_set(conf->h, name, APR_HASH_KEY_STRING, filter); +    apr_hash_set(conf->h, normalized_name, APR_HASH_KEY_STRING, filter);        while (*args) {          while (apr_isspace(*args)) {  Hi Jeff.  Have re-built 2.0.55 with the provided mod_ext_filter patch and can confirm it fixes the problem.  Many thanks for your help. Thanks for your testing.  The fix is now in trunk and proposed for backport to 2.2.x branch.  If approved for 2.2.x branch I'll propose it for backport to 2.0.x branch as well. 			Jeff Trawick	Richard Crawford
40379	null	RESOLVED		Peter Bierman	1157045040000	1188472050000		Please add application/vnd.apple.installer+xml to mime.types Please update the mime.types file to include the IANA registered MIME type for Apple installer documents.  http://www.iana.org/assignments/media-types/application/vnd.apple.installer+xml  application/vnd.apple.installer+xml     dist distz pkg mpkg  (cross reference to Apple's patch for next Mac OS X: <radar:4704702>)	We only use the .mpkg suffix.  Using generic extension names causes existing sites to change.  Apple should always use .mpkg at this point. Committed to trunk.  Is there a registered type for disk images (.dmg)? 			Roy T. Fielding
40400	null	RESOLVED		Tomokazu Harada	1157258400000	1162979063000		a route value specified by stickysession is invalid In stickyseession mode, a route value is extracted from request line parameters  or cookies. The route value from request line is invalid when many parameters  is in a request line. For example, if a request line is   http://www.examples.com/foo?bar=abc.01&baz=xyz.02 and stickyseession is 'bar', the extracted route value is '01&baz=xyz.02'. But  supposed (and hoped) route value is '01'.  This is caused by the parameter separator is '?'. The right separator is '&'. A  simple patch is available.	Created an attachment (id=18810) a patch for mod_proxy_balancer  Your patch would break session stickyness for other backends (e.g. java backends) which encode the session id differently into the URL like www.someplace.com/somewhere/;jsessionid=gggfgdufdfoef.server?parameter=value. Please give the attached patch a try. It accepts ? and & as separators. Created an attachment (id=18812) patch to filter out sticky session from url given as parameter  I tried the above patch. It's OK. Will the patch be merged to 2.2.x line?  Thanks for testing. First of all I need to commit the patch to the trunk. I just did that as r440160 (http://svn.apache.org/viewvc?view=rev&rev=440160). If there are no further comments by other developers I will propose this patch for backport to 2.2.x. Proposed for backport to 2.2.x as r440643 (http://svn.apache.org/viewvc?view=rev&rev=440643). in 2.2.4-dev and trunk			Jim Jagielski	Ruediger Pluem	Tomokazu Harada
40432	null	RESOLVED		Egmont Koblinger	1157629380000	1185886162000		Charset of date on error pages The error text (e.g. 'Objekt nicht gefunden' and its longer explanation) is  presented in the language the client requests. Its character set is defined for  every language by the error templates Apache provides.  However, in the footer, the date is shown in the language and charset  corresponding to the locale on the server side, with no character set  conversion.  As a result, if these two character sets do not match, the date will be shown  with wrong accented characters.  For example, suppose Apache runs with LC_ALL=fr_FR.UTF-8 and the client  requests French language. The header of the returned page will define the ISO- 8859-1 charset (taken from the error templates), but the date will be put there  with UTF-8, hence it appears as 'double UTF-8'. Stranger results (even invalid  byte sequences) can occur with other combination of the two languages (e.g. the  server may run with hu_HU while the client requests Japanese...)  Suggested solutions:  - [I'd prefer this one] Convert all error templates to UTF-8, and modify Apache  to convert the date string received from libc (strftime() I guess) from the  current locale to UTF-8.  or  - Modify Apache to convert the date string received from libc from the current  locale to &#num; html entities so that they work with any character set. [I  hate html entities anyway and I see no reason not to use bare UTF-8.]	For both this and bug 40431 the problem is basically the same: the locale is a process-global setting which cannot be changed per-request, and changing it to match an Accept-Language/Charset-supplied values would probably be a nightmare anyway.  I think the right fix for this is to simply remove the date from the error pages.  It's not particularly useful and this complaint is not unreasonable.  [in glibc there are locale-specific interfaces which can use non-global locale context but being able to use these in httpd would be nearly impossible without designing a set of essentially glibc-specific interfaces] *** Bug 40431 has been marked as a duplicate of this bug. *** Well, instead of removing the date, you could perhaps format it using numbers  only (e.g. 2006/09/07 14:15 +0200) or format in English using a built-in table  of English month and weekday names (hence not using libc's localized names).  I know about this newlocale()/uselocale()/*_l() stuff, but that's really glibc- specific and requires a quite recent glibc, too. So it'd really be a bad  approach for apache. I didn't realize when submitting the bug that apache is a  multi-thread app so using setlocale() around strftime() isn't safe.  The date has been removed from the error pages.			Egmont Koblinger	Joe Orton	Joshua Slive
40447	null	RESOLVED		Luis Parravicini	1157729880000	1181420550000		typo When the parameters for ProxyPass are described, in the description for min, it says 'Minumum' instead of 'Minimum'.	Thanks for this, change committed (submitted by Tony Stevenson). 			Jason Lingohr
40454	null	RESOLVED		Takashi Sato	1157829060000	1185459648000		 EventMPM typo new_features_2_2.xml line 99  >Event MPM >The event MPM uses a seperate thread to handle  seperate -> separate	Patch applied, page updated: http://svn.apache.org/viewvc?view=rev&rev=559984 Should be visible within a few hours.  Cheers, Tony			Tony Stevenson
40470	null	RESOLVED		Taniya Pirapokin	1157998380000	1167836580000		isapi return wrong status when use ServerSupportFunction When use ServerSupportFunction function with HSE_REQ_SEND_RESPONSE_HEADER or HSE_REQ_SEND_RESPONSE_HEADER_EX and supply valid headers, HTTP status become 0 ( access log recorded as - ) and the HTTP response status is 500 in Apache 2.2.3. On Apache 2.0.54, the HTTP return status is 200 OK but the access log also recorded - as return status code.  (I do the debug on 2.2.3 src) This seems to be because of the return value of ap_scan_script_header_err_core and ap_scan_script_header_err_strs functions (in server/util_script.c) or incorrectly replace HTTP response status code in send_response_header (arch/win32/mod_isapi.c).  server/util_script.c ap_scan_script_header_err_core -> the function does look for Status in the headers and set the r->status if it exist. The function then return OK (which is define as 0). Shouldn't this function return HTTP_OK if status is not define in the header or the status that is provided in the header?  ap_scan_script_header_err_strs -> return the result from ap_scan_script_header_err_core  arch/win32/mod_isapi.c send_response_header -> Call ap_scan_script_header_err_strs then assign the return value to cid->r->status.  From line 712     if (stat) {         cid->r->status = ap_scan_script_header_err_strs(cid->r, NULL,                                         &termch, &termarg, stat, head, NULL);         cid->ecb->dwHttpStatusCode = cid->r->status;     }     else {         cid->r->status = ap_scan_script_header_err_strs(cid->r, NULL,                                         &termch, &termarg, head, NULL);   .....  In both case cid->r->status get set to 0 (with valid header) when it should be 200 (HTTP_OK) or other status which may be set from ap_scan_script_header_err_core.  I call ServerSupportFunction by: 1) strTemp.Format('Content-Type: text/html/r/nContent-Length: %d/r/n/r/n', strResult.GetLength()); dw = strTemp.GetLength(); pECB->ServerSupportFunction( pECB->ConnID, HSE_REQ_SEND_RESPONSE_HEADER, \t\t\t\tNULL,  \t\t\t\t&dw,  \t\t\t\t(DWORD *)(LPCTSTR) strTemp) 2) strTemp.Format('Content-Type: text/html/r/nContent-Length: %d/r/n/r/n', strResult.GetLength()); dw = strTemp.GetLength(); pECB->ServerSupportFunction( pECB->ConnID, HSE_REQ_SEND_RESPONSE_HEADER, \t\t\t\t'200 OK',  \t\t\t\t&dw,  \t\t\t\t(DWORD *)(LPCTSTR) strTemp) 3) With HSE_REQ_SEND_RESPONSE_HEADER_EX putting the same info in HSE_URL_MAPEX_INFO  for the second param.  Let me know if you need more info. TP	I believe you will find this solved in the dev branch, and I've prepared the backport in source and binary form for you to test against 2.0 or 2.2.  Please grab http://people.apache.org/~wrowe/mod_isapi-416293.zip - replace your mod_isapi.so (or the sources of mod_isapi.c/.h if you compile your own apache server) and report back.  The new mod_isapi-416293 still have problem with ServerSupportFunction at least on HSE_REQ_SEND_RESPONSE_HEADER  For HSE_REQ_SEND_RESPONSE_HEADER, after send_response_header call, no handling of ate == headlen.           if (ate < 0) {             apr_set_os_error(APR_FROM_OS_ERROR(ERROR_INVALID_PARAMETER));             return 0;         }         else if ((apr_size_t)ate < headlen) {             apr_bucket_brigade *bb;             apr_bucket *b;             bb = apr_brigade_create(cid->r->pool, c->bucket_alloc);             b = apr_bucket_transient_create((char*) data_type + ate,                                            headlen - ate, c->bucket_alloc);             APR_BRIGADE_INSERT_TAIL(bb, b);             b = apr_bucket_flush_create(c->bucket_alloc);             APR_BRIGADE_INSERT_TAIL(bb, b);             rv = ap_pass_brigade(cid->r->output_filters, bb);             cid->response_sent = 1;             return (rv == APR_SUCCESS);         }     }  From looking at the code for case HSE_REQ_SEND_RESPONSE_HEADER_EX, the return 'return (rv == APR_SUCCESS);', rv may not be initialized.  In my test with Apache 2.2.3, now I get status log as 1 on the access log, and get real Internal Error from apache. I test with HSE_REQ_SEND_RESPONSE_HEADER case and get ate == headlen (Is that suppose to be the normal correct case?)  Thanks, TP Good catch, thank you.  When there is a new update, I'll point you at it, or feel free to offer the patch you believe will fix it. Created an attachment (id=19151) Don't fail when sent is the length of the headers  Here's a suggested patch that retains the ability to incrementally add headers,  and won't send them until some of the body is ready.  Feedback please, I plan to commit in the next day if possible. From your last change: - server response with correct status code (200 OK) - apache log response code as 1 on the isapi handled request (shouldn't it be 200) - PROBLEM - The response has  <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>200 OK</title> </head><body> <h1>OK</h1> <p>The server encountered an internal error or misconfiguration and was unable to complete your request.</p> <p>Please contact the server administrator,  root@localhost and inform them of the time the error occurred, and anything you might have done that may have caused the error.</p> <p>More information about this error may be available in the server error log.</p> </body></html>  append to the end of it.  I change the code from the last patch mod_isapi-416293 you direct to me.  Thanks   (In reply to comment #4) > Created an attachment (id=19151) [edit] > Don't fail when sent is the length of the headers >  > Here's a suggested patch that retains the ability to incrementally add headers, >  > and won't send them until some of the body is ready. >  > Feedback please, I plan to commit in the next day if possible. Created an attachment (id=19256) 2.0 isapi workaround  The problem in the last comment is caused with persistent connections. Apply this patch to work around this problem (reverting to old behavior for this return code).  Created an attachment (id=19257) Patch to record non-APR_SUCCESS results (do not apply with the hack)  Obviously if ap_pass_brigade fails, we should -not- return OK.  What rv are we seeing here?  Are we getting (invalid) http result codes from ap_pass_brigade?  or another error?  It seems an error emit would be appropriate here.  See patch. Well the problem is that (rv == APR_SUCCESS) is 1. OK is 0.  So I am not sure if the right solution is:  return ((rv == APR_SUCCESS) ? OK : HTTP_INTERNAL_SERVER_ERROR);  http://svn.apache.org/viewvc?view=rev&revision=492333  Patch committed, thanks to all who provided feedback, and to Matt for the pointer to OK results from the handler. *** Bug 40698 has been marked as a duplicate of this bug. *** *** Bug 40549 has been marked as a duplicate of this bug. *** An unreleased build of this module including the last several patches is now  available for testing against httpd-2.0 and 2.2 from     http://people.apache.org/~wrowe/mod_isapi-r492341-win32.zip  It's not a release; if you test, report back 1) here, at 2) dev@httpd.a.o, or at users@httpd.a.o.  Thank you.			Matt Eaton	Taniya Pirapokin	Will Rowe
40476	null	RESOLVED		Amichai	1158014100000	1161674275000		warn message is mistakenly written to access log In the server's access log, there is one line that is not an access record that shows up a few times:  [Thu Sep 07 03:09:06 2006] [warn] pid file C:/XXX/logs/httpd.pid overwritten -- Unclean shutdown of previous Apache run?  it looks like it's being written to the wrong log file - it should be in the error log along with the other warnings and errors, not the access log.	Oops... this happens in version 2.2.3, which is missing from the dropdown menu... dunno if it's in 2.3 HEAD as well. Created an attachment (id=18888) ap_open_logs does not store new stderr -   ap_open_logs in server/log.c does not store the new stderr in the static variable stderr_log.  The old handle is closed, or might even be re-used for a different file (which is probably what happened to this guy). I don't really follow that patch: stderr_log is a global variable which is initialized once at startup.  It doesn't really matter *which* apr_file_t * that dup2 happens against; fd 2 ends up the same anyway.   Do you have a repro case for this, Tom? Is it possible that stderr is not fd 2 on Windows? During my investigations for PR40651 I saw a comment in the APR documentation about this (http://apr.apache.org/docs/apr/group__apr__file__io.html#ga10). So this maybe a Windows specific problem. For Unix systems I agree with your analysis. as u probably discerened from my original post, this indeed occured on a Windows (XP) system. If there's some test u'd like me to run to recreate/diagnose this, I'd be glad to help.  There is no 'fd' vis-a-vis unix.  Handles are arbitrarilly assigned.  It absolutely must be applied for non-pure-posix portability. This looks like a good solution but I don't have a platform to apply to at this instant. Yes, the problem happens on Windows.  The stderr filehandle is not 2, as in Unix, and a dup() of stderr produces a new (arbitrary) filehandle value.  For a quick repro: If you start Apache 2.2.3 on Windows with a pre-existing httpd.pid - no 'Unclean shutdown' message appears in the error log (the write is attempted to a closed filehandle).  If you repeat this after applying the patch, the message correctly appears in the error log.  I cannot repro the case where the message appears in the wrong file.  It is just conjecture that a previously closed stderr handle got re-used for an access log in Amichai's installation. Well it seems like an obviously-correct cleanup anyway, so be it:  http://svn.apache.org/viewvc?view=rev&rev=467338 Note this was surplanted by a new two-pool approach, maintaining the old stderr log pool during the creation of the new stderr log pool, then on success tearing down the old one.  That solution required significant refactoring in apr, lest Tom's issue pop up, all over again.			Amichai	Joe Orton	Ruediger Pluem	Tom Donovan	Will Rowe
40573	null	RESOLVED		Matt Eaton	1158863760000	1167836974000		SERVER_PORT_SECURE not set correctly The current code in 2.0/2.2/trunk does not set the SERVER_PORT_SECURE correctly.  When HTTPS is set to 'on' then the mod_isapi code is supposed to set SERVER_PORT_SECURE to 1. However, the code does not compare the string correctly.	Created an attachment (id=18896) Patch against 2.0.59  Trivial fix I concur... http://svn.apache.org/viewvc?view=rev&revision=492341  Thanks for the submission!			Matt Eaton	Will Rowe
40576	null	RESOLVED		Xuekun Hu	1158911760000	1188891717000		mod_mem_cache: signal Floating point exception (8) When caching zero byte file with GDSF removal algorithm and 0  MCacheMinObjectSize in mod_mem_cache, Apache will get ???[notice] child pid 2230  exit signal Floating point exception (8)???.     Solutions could be   1.  diff -ru httpd-2.2.2/modules/cache/mod_mem_cache.c httpd- 2.2.2.new/modules/cache/mod_mem_cache.c  --- httpd-2.2.2/modules/cache/mod_mem_cache.c   2006-04-22 09:53:06.000000000  +0800  +++ httpd-2.2.2.new/modules/cache/mod_mem_cache.c       2006-09-01  13:12:56.594483296 +0800  @@ -199,7 +199,7 @@       cache_object_t *obj = (cache_object_t *)a;       mem_cache_object_t *mobj = obj->vobj;     -    if (mobj->priority == 0)  +    if (mobj->priority == 0 && mobj->m_len != 0)           mobj->priority = queue_clock -                              (long)(mobj->total_refs*1000 / mobj->m_len);     2. Or set MCacheMinObjectSize greater than 0  diff -ru httpd-2.2.2/modules/cache/mod_mem_cache.c httpd- 2.2.2.new/modules/cache/mod_mem_cache.c  --- httpd-2.2.2/modules/cache/mod_mem_cache.c   2006-04-22 09:53:06.000000000  +0800  +++ httpd-2.2.2.new/modules/cache/mod_mem_cache.c       2006-09-01  13:49:08.233344008 +0800  @@ -98,7 +98,7 @@   static mem_cache_conf *sconf;      #define DEFAULT_MAX_CACHE_SIZE 100*1024  -#define DEFAULT_MIN_CACHE_OBJECT_SIZE 0  +#define DEFAULT_MIN_CACHE_OBJECT_SIZE 1   #define DEFAULT_MAX_CACHE_OBJECT_SIZE 10000   #define DEFAULT_MAX_OBJECT_CNT 1009   #define DEFAULT_MAX_STREAMING_BUFFER_SIZE 100000  @@ -964,7 +964,8 @@       if (sscanf(arg, '%' APR_SIZE_T_FMT, &val) != 1) {           return 'MCacheMinObjectSize value must be an integer (bytes)';       }  -    sconf->min_cache_object_size = val;  +    if (val > 0)  +       sconf->min_cache_object_size = val;       return NULL;   }   static const char     Which one is better? Any comments?	(In reply to comment #0) Hi, All  I knew you are all very busy and probaly are busying working on  mod_disk_cache :-)  I really hope someone could give me some comments since I'm a newbie on  learning/reading Apache source code.   Thx, Xuekun From a first glance 2) seems to be more reasonable to me as I currently cannot see a reason to cache objects of size 0 :-). Regarding your check of the value set by MCacheMinObjectSize you should return an error is the value is invalid. (In reply to comment #2) > From a first glance 2) seems to be more reasonable to me as I currently cannot > see a reason to cache objects of size 0 :-). Regarding your check of the value > set by MCacheMinObjectSize you should return an error is the value is invalid.  Thanks for comments. I also think 2) is more reasonable :-) Based on your comments, I added the error return value.   diff -ru httpd-2.2.2/modules/cache/mod_mem_cache.c httpd- 2.2.2.new/modules/cache/mod_mem_cache.c --- httpd-2.2.2/modules/cache/mod_mem_cache.c   2006-04-22 09:53:06.000000000  +0800 +++ httpd-2.2.2.new/modules/cache/mod_mem_cache.c       2006-09-01  13:49:08.233344008 +0800 @@ -98,7 +98,7 @@  static mem_cache_conf *sconf;   #define DEFAULT_MAX_CACHE_SIZE 100*1024 -#define DEFAULT_MIN_CACHE_OBJECT_SIZE 0 +#define DEFAULT_MIN_CACHE_OBJECT_SIZE 1  #define DEFAULT_MAX_CACHE_OBJECT_SIZE 10000  #define DEFAULT_MAX_OBJECT_CNT 1009  #define DEFAULT_MAX_STREAMING_BUFFER_SIZE 100000 @@ -964,7 +964,8 @@      if (sscanf(arg, '%' APR_SIZE_T_FMT, &val) != 1) {          return 'MCacheMinObjectSize value must be an integer (bytes)';      } -    sconf->min_cache_object_size = val; +    if (val > 0) +       sconf->min_cache_object_size = val; +    else +       return  'MCacheMinObjectSize value must be an positive integer (bytes)';      return NULL;  }  static const char  Committed to trunk as r469895 (http://svn.apache.org/viewvc?view=rev&rev=469895). Thanks. *** Bug 41417 has been marked as a duplicate of this bug. *** Proposed for backport as r571936 (http://svn.apache.org/viewvc?rev=571936&view=rev). Backported to 2.2.x as r572628 (http://svn.apache.org/viewvc?rev=572628&view=rev).			Ruediger Pluem	Xuekun Hu
40640	null	RESOLVED		Julien Nadeau	1159543560000	1165493610000		SSLCryptoDevice requirements refer to -DSSL_ENGINE_EXPERIMENTAL For the SSLCryptoDevice directive, the documentations mentions:  Compatibility:\tAvailable if mod_ssl is built using -DSSL_ENGINE_EXPERIMENTAL  But the define no longer exists. Apache just looks for the OpenSSL engine headers.	That's correct, it's a historical curiosity that should be purged from the docs.  If engine support is installed from OpenSSL, we can use it unconditionally without any build time defines. Resolved in r483641			Rich Bowen	Will Rowe
40651	null	RESOLVED		Rainer Jung	1159706940000	1165584003000		Orphaned piped logger process after graceful restart I use Apache 2.2.3 on Solaris. All Logfiles are configured to use rotatelogs. Whenever I restart Apache either with 'restart' or with 'graceful' The first piped logger, which cares about the global error log, is left over in the process table. To be more precise: For all loggers new processes get started, and all apart from the described old one terminate. The problem is this unnecessary old process that doesn't die.  One description of a reason is, that Apache 2.2 uses APR to do the fork and APR uses '/bin/sh -c' to do that. Unfortunately /bin/sh on Solaris doesn an additional fork when called with '-c' and we end up with a process tree of depth three: Apache-/bin/sh-rotatelogs. It looks like the termination mechanism and the signal handling of Apache is not made for this situation.  I described a related problem in Bugzilla   http://issues.apache.org/bugzilla/show_bug.cgi?id=38989  I didn't really trace the signal problem down to the details for Apache 2.2/APR but again the same solution does work: If I use another Shell in SHELL_PATH, which does not fork for '-c', the problem goes away.  Changing the SHELL_PATH in apr_arch_threadproc.h from '/bin/sh' to '/usr/xpg4/bin/sh' worked. That's a XPG4 compliant shell which exists on Solaris since Solaris 2.5, so for about 10 years.  The shell is similar to ksh (see 'man ksh') and does *not* fork when called with '-c'.  It would be nice to at least document the behaviour. Really nice would be to make SHELL_PATH changeable via configure and to be able to change it via Apaches configure (and if that would be documented).  If it's really necessary, I could pin down, why the problem only applies for the first error logger. On the other hand, I also would like to get rid of the additional /bin/sh processes, so using another shell would solve both problems.	(In reply to comment #0) > I use Apache 2.2.3 on Solaris. All Logfiles are configured to use rotatelogs. > Whenever I restart Apache either with 'restart' or with 'graceful' The first > piped logger, which cares about the global error log, is left over in the > process table. To be more precise: For all loggers new processes get started, > and all apart from the described old one terminate. The problem is this > unnecessary old process that doesn't die.  Some questions:  1. Does the respective /bin/sh -c die? 2. Does a new rotatelog process get forked after the restart? 3. What is the parent process of the hanging logrotate process 4. What version of Solaris do you use? 5. Could you please truss /bin/sh -c and logrotate during the restart with    options -faedl -vall -rall -wall?  > It would be nice to at least document the behaviour. Really nice would be to > make SHELL_PATH changeable via configure and to be able to change it via Apaches > configure (and if that would be documented).  Sounds reasonable to me. Hi R??diger,  Some questions:  1. Does the respective /bin/sh -c die?  Yes. All of them die.  2. Does a new rotatelog process get forked after the restart?  Yes. All needed new ones get started.  3. What is the parent process of the hanging logrotate process  PID 1  4. What version of Solaris do you use?  The behaviour was observed on SunOS 5.9 Generic_118558-05 sun4u sparc. I could try with Solaris 8 and 10 to, but that would have to wait until tuesday.  5. Could you please truss /bin/sh -c and logrotate during the restart with    options -faedl -vall -rall -wall?  Yes, I'll attach them in a minute. I didn't do the 'rall', because I don't want the whole config to be in the truss. I'm confident, that the reads are not that important. Otherwise I need to redo the thing with a test configuration.  Also I'll attach three ps excerpts, one directly after start, the second after graceful and the third after restart. The processes I'm talking about are:  ps1.out:    root 11820 11818  0 22:58:45 ?        0:00 /bin/sh -c /usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 8 ps1.out:    root 11822 11820  0 22:58:45 ?        0:00 /usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400  !ps2.out:    root 11822     1  0 22:58:45 ?        0:00 /usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400 ps2.out:    root 11926 11818  0 22:59:32 ?        0:00 /bin/sh -c /usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 8 ps2.out:    root 11929 11926  0 22:59:32 ?        0:00 /usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400  !ps3.out:    root 11822     1  0 22:58:45 ?        0:00 /usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400 !ps3.out:    root 11929     1  0 22:59:32 ?        0:00 /usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400 ps3.out:    root 12034 11818  0 23:00:04 ?        0:00 /bin/sh -c /usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 8 ps3.out:    root 12037 12034  0 23:00:04 ?        0:00 /usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400   Created an attachment (id=18944) gzipped truss  Created an attachment (id=18945) Process table after start  Created an attachment (id=18946) Process table after apachectl graceful  Created an attachment (id=18947) Process table after apachectl restart  Hi Rainer,  many thanks for the quick feedback. I think I know why this problem only happens to the main error logrotater:  httpd closes the writing side of the pipe to the logrotater. This auses the logrotater to exit and thus /bin/sh -c to exit. There is no need to send a SIGTERM to either /bin/sh -c or logrotate in this case. This does not work this way with the main error logrotater since the writing side fd has been previously copied (dup2ed) to stderr. After a start of the new main error log logrotater its wrting side should be dup2ed again to stderr. This should cause the old stderr file descriptor to be closed and thus causing the logrotator to exit as this is the last open writing side of the pipe. This does not seem to work on Solaris (libc on Solaris seems to do a fcntl(13, F_DUP2FD, 0x00000002) instead of dup2(13,2)). I did not have the time to do further tests on this issue. As you may notice the logrotater dies after the main httpd process has died as the OS does now seem to close the file descriptor correctly.  Since I personally do not use logrotation on the main error log file for years (and this works perfectly if you do everything else in virtual hosts and nothing in the main server) I am not quite sure anymore, but I think I stopped logrotating the main error log file because log messages did not arrive there during restart / graceful restart.  Nevertheless it makes still sense to me to stop hardcoding /bin/sh in APR. Additionally to be able to set SHELL_PATH via configure it might be even better if you can set the shell path via some APR function and APR only uses SHELL_PATH if nothing was set. Hi R??diger,  I'm impressed! I had a look at the truss output to, but got stuck exactly around the dup2 fcntl.  You comments about main error logger are interesting. In fact it would be better not to pipe that one to be sure, that errors can be written at any time. And usually everything else happens in vhosts, so not rotating that one is not a huge problem.  But nevertheless, freeing up half of the log child processes by using another shell to invoke still would be nice. The process table looks a lot cleaner after dropping the '/bin/sh -c' processes.  I'm not very experienced with the auto(conf|make|header) stuff, although I did some changes to the configure process in mod_jk. If time permits, I could have a look at it for APR next sunday, but if you or anyone else knows easily how to include this feature I would be happy.  Created an attachment (id=18949) Small test program for dup2  Attached a small quick and dirty test program. If dup2 really does not work on Solaris it should print out:   Child: Hello World!  and NOT return to shell. If it returns to the shell dup2 works as expected. On my Solaris 9 testbox dup2 seems to work as expected. Odd!  If it turns out not to be a Solaris bug with dup2, can you please do the following:  1. Do a truss again as previously (-vall -wall -faedl). 2. Do a graceful restart. 3. Issue pfiles <pid of remaining logrotater> 4. Issue pfiles <pid of httpd main process> 5. Attach outputs of pfiles and truss and let me know the pids of the httpd main    process and the remaining logrotater.  This is reproducible on Linux by using, e.g.:  ErrorLog '| true; /path/to/rotatelogs etc'  which forces the sh process to hang around. This is a fun bug!  After the graceful restart, the *new* piped logger for the main error log is running with its fd 2 pointing to the pipe to the *old* piped logger which it is replacing.  That is the only place that fd is left open, and it's what is preventing the old piped logger from exiting.  The use of the 'sh' process is just what is needed to make this problem apparent.  Otherwise the rotatelogs will get SIGTERMed by the parent directly on restart.  (courtesy of piped_log_cleanup)  Created an attachment (id=18950) proof-of-concept fix  This should prevent the orphaned piped loggers, not sure if this is the optimal solution though. Re-assigning this to httpd. (In reply to comment #12) > This is a fun bug!  Indeed yes  >  > After the graceful restart, the *new* piped logger for the main error log is > running with its fd 2 pointing to the pipe to the *old* piped logger which it is > replacing.  That is the only place that fd is left open, and it's what is > preventing the old piped logger from exiting.  Excellent analysis many thanks. (In reply to comment #13) > Created an attachment (id=18950) [edit] > proof-of-concept fix >  > This should prevent the orphaned piped loggers, not sure if this is the optimal > solution though.  I am a little worried that nobody reads at the other end of the pipe. What if the logger writes a huge amount of data to its stderr? Wouldn't it get blocked? What about using the stdout of the main process (should be /dev/null) for the logger? I modified your patch to do this. A quick test shows that it works. Comments welcome.    Created an attachment (id=18952) Adjust proof-of-concept fix to use stdout of main process  Hi Rainer,  as your specific problem has to be fixed inside of httpd I propose that you open a new report for the enhancement of APR's configure to make SHELL_PATH configurable. This raises a deeper question though.  Should a graceful restart even recycle the logger processes in httpd?  Or should they be persistent and continue to run (short circuit the open logs to keep the existing files *and processes* around?)     Created an attachment (id=18954) Updated version of the stdout version of the fix, which fixes a fd leak  Thanks Ruediger, that's definitely a better approach.  I've tweaked that, and also realised that this needs to be done *only* for the logger for the main server.  Piped loggers for vhosts should continue to inherit stderr from the main server as before.  Committed as http://svn.apache.org/viewvc?view=rev&revision=452431 (In reply to comment #21) > Thanks Ruediger, that's definitely a better approach. >  > I've tweaked that, and also realised that this needs to be done *only* for the  Thanks for tweaking and committing.  > logger for the main server.  Piped loggers for vhosts should continue to  inherit > stderr from the main server as before.  Just for my clarification: This works because the error log of the main server is the first logger that gets 'restarted' during a graceful / restart, right? So the other loggers inherit a stderr that is the writing side of the pipe to the *restarted* main server error logger, correct? Yes, exactly correct. ap_open_logs handles it: opens the main server log, does the dup2-to-stderr trick, then loops through all the vhosts and opens their logs.  (In reply to comment #23) > Yes, exactly correct. ap_open_logs handles it: opens the main server log, does > the dup2-to-stderr trick, then loops through all the vhosts and opens their logs.   Thanks for clarification. Proposed for backport to 2.2.x as r452457 (http://svn.apache.org/viewvc?view=rev&rev=452457). The error log still spawns the process using   rc = apr_procattr_cmdtype_set(procattr,                                         APR_SHELLCMD_ENV)) == APR_SUCCESS)  instead of   rc = apr_procattr_cmdtype_set(procattr,                                         APR_PROGRAM_ENV)) == APR_SUCCESS)  as documented http://issues.apache.org/bugzilla/show_bug.cgi?id=16761  Typically this is an issue with Windows env . Any chance if the same patch  proposal from 16761 can be applied here as well?    Backported to 2.2.4 (In reply to comment #25)  >  > Typically this is an issue with Windows env . Any chance if the same patch   Have you really checked that there is an issue on windows? Anyway the original bug described here is now fixed thus I will close the report again. Feel free to open a new one if there is really a problem on windows with this.			Joe Orton	Rainer Jung	Ruediger Pluem	Will Rowe	toadie
40653	null	RESOLVED		Larry Stefani	1159771080000	1168397561000		apxs dependency on httpd breaks cross-compilation of other packages With proper environment variables, --host= and --target options, Apache 2.2.3  can be cross-compiled successfully.  However, the bin/apxs PERL script has an  implicit dependency on bin/httpd, which causes a problem when building other  modules.  For example, when adding PHP 5.1.6 to Apache 2.2.3, the --with-apxs2= option  is used on the PHP configure line to point to apxs.  PHP needs to run apxs to  determine the include paths, CFLAGS, etc. used to build Apache.  This fails on  a cross-compiled environment when apxs tries to execute httpd on the host  system.  apxs should become truly platform-independent and not rely on binaries that  cannot be run on the build system.	More information.  PHP developers consider this issue a problem with apxs.  From http://bugs.php.net/bug.php?id=38997&edit=2      [2 Oct 3:19pm UTC] tony2001@php.net      If you want apxs utility to be enhanced - please report it as a feature     request to Apache developers.     There is nothing PHP can do about it.  Feel free to contribute an alternative build tool.  You'll have to deal with  the dependencies too, of course.  And bear in mind that apxs is designed to  work in packages, where you don't have all the build debris lying around.  Anyway, cross-compiling PHP sounds to me like a *much* bigger job than this. >>Feel free to contribute an alternative build tool.  You'll have to deal with  >>the dependencies too, of course.  And bear in mind that apxs is designed to  >>work in packages, where you don't have all the build debris lying around.  That may explain the need to run httpd from apxs.  It appeared that since apxs  is created dynamically, it could at least contain all of the CFLAGS, include  paths, etc. that would be required by a fairly popular external module (PHP),  without reading other files.  >>Anyway, cross-compiling PHP sounds to me like a *much* bigger job than this.  I'm not so sure.  PHP configure supports the same --host= and --target=  options as Apache configure.  I was able to configure and cross-compile PHP  successfully, that is, until I added the --with-apxs2= option.  I didn't  realize that without it, the loadable module that Apache needs isn't built.  Now I'm left with a cross-compiled httpd daemon that loads and runs just fine  on my target platform, but with no PHP support.  I appreciate the feedback.  I'll probably need to revert to installing the GCC  toolchain and software packages on my target platform and rerun the  configure/make steps in 'native' mode.  I was hoping for any workaround that  would allow me to avoid that.  Just wanted to note a workaround for this problem.  By editing the PHP  configure script to replace appropriate $APXS -q calls with explicit  directories and filenames, I was able to avoid executing apxs during the  configure step.  What was necessary was to perform the apxs -q queries on the  target platform (where the apxs can run httpd properly), then take the result  and enter it into the PHP configure script, run configure, then cross-compile  PHP accordingly.  The alternative would be to edit apxs to *not* invoke httpd on simple -q  queries, which can be easily determined when apxs is created.  Created an attachment (id=19384) Fixes apxs for cross-compilation  The attached patch removes the need for apxs to invoke httpd.    With this patch, the value of enable_so is saved into config_vars.mk.  apxs then looks up this value instead of invoking httpd. Great patch David, thanks, that code has annoyed me forever.  I tweaked it slightly and committed it to the trunk:  http://svn.apache.org/viewvc?view=rev&revision=494781			David M. Lee	Joe Orton	Larry Stefani	Nick Kew
40656	null	RESOLVED		Larry Cipriani	1159782600000	1159855301000		mod_mime_magic.c precedence problem near line 938 httpd-2.2.3/modules/metadata/mod_mime_magic.c: comparison takes precedence over assignment near line 938      if ((result = apr_file_open(&f, fname, APR_READ | APR_BUFFERED,                                 APR_OS_DEFAULT, p) != APR_SUCCESS)) { probably should be:      if ((result = apr_file_open(&f, fname, APR_READ | APR_BUFFERED,                                 APR_OS_DEFAULT, p)) != APR_SUCCESS) {	Thanks for the report. Fixed in trunk as r452212 (http://svn.apache.org/viewvc?view=rev&rev=452212). Proposed for backport to 2.2.x as r452218 (http://svn.apache.org/viewvc?view=rev&rev=452218). Backport to 2.2.x as r452459 (http://svn.apache.org/viewvc?view=rev&rev=452459).			Ruediger Pluem
40658	null	RESOLVED		Larry Cipriani	1159782840000	1159855337000		mod_echo.c precedence problem on line 67 httpd-2.2.3/modules/echo/mod_echo.c: comparison takes precedence over assignment near line 67          if ((rv = ap_get_brigade(c->input_filters, bb, AP_MODE_GETLINE,                                  APR_BLOCK_READ, 0) != APR_SUCCESS ||              APR_BRIGADE_EMPTY(bb))) {             apr_brigade_destroy(bb);             break;         }  probably should be:          if ((rv = ap_get_brigade(c->input_filters, bb, AP_MODE_GETLINE,                                  APR_BLOCK_READ, 0)) != APR_SUCCESS ||              APR_BRIGADE_EMPTY(bb)) {             apr_brigade_destroy(bb);             break;         }	Thanks for the report. Fixed in trunk as r452213 (http://svn.apache.org/viewvc?view=rev&rev=452213). Proposed for backport to 2.2.x as r452218 (http://svn.apache.org/viewvc?view=rev&rev=452218). Backported to 2.2.x as r452462 (http://svn.apache.org/viewvc?view=rev&rev=452462).			Ruediger Pluem
40756	null	RESOLVED		Trevin Beattie	1160740680000	1189258315000		Segmentation fault in ap_proxy_checkproxyblock When an Apache config file contains any ProxyBlock directive, if a remote client attempts to proxy through the server (using CONNECT) to a target host which does not have a DNS entry, httpd will segfault.  ap_proxy_connect_handler does a DNS lookup of uri.hostname in proxy_connect.c:127 and stores the result in uri_addr.  However, it does not check for an error until line 174.  On line 144, it calls ap_proxy_checkproxyblock with the uri_addr variable, which can be NULL if the DNS lookup failed.  When ap_proxy_checkproxyblock tries to dereference uri_addr (in proxy_util.c:961 or 965), it accesses invalid memory.  There are a couple of possible solutions to this.  uri_addr is only dereferenced in the call to ap_log_error.  So ap_proxy_checkproxyblock could test uri_addr before calling ap_log_error.  The other solution is to move the check for DNS lookup failure in proxy_connect.c up from line 174 to around 129 (immediately following the call to apr_sockaddr_info_get).	Created an attachment (id=19005) Fix to check the result of apr_sockaddr_info_get before passing uri_addr to ap_proxy_checkproxyblock  Is this ever going to be addressed.  I guess my users like requesting pages that aren't in dns because I'm seeing it all over the place.  But I can only reproduce it with ProxyRemote as well as ProxyBlock.  If I have ProxyRemote off then it works just fine. As soon as I sent that, I realized that I probably sounded snippity.  Totally not intended.  Thank you for the wonderful web server and for all of your hard work.  Dude I'm a dork some times. Reviewing after far too long, it appears your CONNECT patch may still be needed, but the FTP patch appears unnecessary, as the current code makes the check before using the addr.  Is that a fair summary of 2.2? After reviewing the code for httpd-2.2.0, it appears your assessment is correct.  The patch I made applies to version 2.0.x. Fixed in 2.2.6			Kelly	Nick Kew	Trevin Beattie
40805	null	RESOLVED		Noah Robin	1161351900000	1178526940000		mod_cache fails to retrieve objects cached for URLs which have been rewritten to target URLs with a query string Environment:  OSX & Linux Apache 2.2.3  Problem:  Using mod_rewrite in conjunction with mod_cache, when a requested object is cached, the path to the cache object is calculated by hashing on the requested URL (http://localhost/real). However, when retrieval of the object is attempted on subsequent requests, the path to the cache object is calculated by hashing on the requested URL *plus* the query string in the target of the RewriteRule.   Details: ========  httpd config is the default config, plus:  LogLevel debug ExpiresActive on ExpiresDefault A86400   rewrite config:  RewriteEngine on RewriteRule ^/real /index.html?foo=bar  cache config:  CacheEnable disk / CacheRoot /tmp/CACHE  Request:  ab -c 1 -n 1 'http://localhost:8000/real'   Request #1 [Fri Oct 20 16:33:00 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /real [Fri Oct 20 16:33:00 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /real [Fri Oct 20 16:33:00 2006] [debug] mod_cache.c(602): cache: Caching url: /real [Fri Oct 20 16:33:00 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri Oct 20 16:33:00 2006] [debug] mod_cache.c(651): cache: Added date header [Fri Oct 20 16:33:00 2006] [debug] mod_disk_cache.c(954): disk_cache: Stored headers for URL http://localhost:8000/real?foo=bar [Fri Oct 20 16:33:00 2006] [debug] mod_disk_cache.c(1043): disk_cache: Body for URL http://localhost:8000/real?foo=bar cached.  Request #2  [Fri Oct 20 16:33:06 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /real [Fri Oct 20 16:33:06 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /real [Fri Oct 20 16:33:06 2006] [debug] mod_cache.c(602): cache: Caching url: /real [Fri Oct 20 16:33:06 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri Oct 20 16:33:06 2006] [debug] mod_cache.c(651): cache: Added date header [Fri Oct 20 16:33:06 2006] [debug] mod_disk_cache.c(954): disk_cache: Stored headers for URL http://localhost:8000/real?foo=bar [Fri Oct 20 16:33:06 2006] [debug] mod_disk_cache.c(1043): disk_cache: Body for URL http://localhost:8000/real?foo=bar cached.  (note that the object is re-cached, rather than being served from cache)  If I remove the query string from the RHS of the rewrite rule:  rewrite config #2:  RewriteEngine on RewriteRule ^/real /index.html  I see this:  Request: ab -c 1 -n 1 'http://localhost:8000/real'  Request #1:  [Fri Oct 20 16:38:12 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /real [Fri Oct 20 16:38:12 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /real [Fri Oct 20 16:38:12 2006] [debug] mod_cache.c(602): cache: Caching url: /real [Fri Oct 20 16:38:12 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri Oct 20 16:38:12 2006] [debug] mod_cache.c(651): cache: Added date header [Fri Oct 20 16:38:12 2006] [debug] mod_disk_cache.c(954): disk_cache: Stored headers for URL http://localhost:8000/real? [Fri Oct 20 16:38:12 2006] [debug] mod_disk_cache.c(1043): disk_cache: Body for URL http://localhost:8000/real? cached.  Request #2:  [Fri Oct 20 16:38:17 2006] [debug] mod_disk_cache.c(477): disk_cache: Recalled cached URL info header http://localhost:8000/real? [Fri Oct 20 16:38:17 2006] [debug] mod_disk_cache.c(750): disk_cache: Recalled headers for URL http://localhost:8000/real? [Fri Oct 20 16:38:17 2006] [debug] mod_cache.c(261): cache: running CACHE_OUT filter [Fri Oct 20 16:38:17 2006] [debug] mod_cache.c(275): cache: serving /real  This time, the object is served from cache.  Finally, if I place the query string *back* into the RewriteRule:   rewrite config #3:  RewriteEngine on RewriteRule ^/real /index.html?foo=bar  And issue a request which appends the query string on the RHS of the RewriteRule to the URI on the LHS of the RewriteRule:  Request: ab -c 1 -n 1 'http://localhost:8000/real?foo=bar'  Request #1:  [Fri Oct 20 16:42:49 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /real [Fri Oct 20 16:42:49 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /real [Fri Oct 20 16:42:49 2006] [debug] mod_cache.c(602): cache: Caching url: /real?foo=bar [Fri Oct 20 16:42:49 2006] [debug] mod_cache.c(608): cache: Removing CACHE_REMOVE_URL filter. [Fri Oct 20 16:42:49 2006] [debug] mod_cache.c(651): cache: Added date header [Fri Oct 20 16:42:49 2006] [debug] mod_disk_cache.c(954): disk_cache: Stored headers for URL http://localhost:8000/real?foo=bar [Fri Oct 20 16:42:49 2006] [debug] mod_disk_cache.c(1043): disk_cache: Body for URL http://localhost:8000/real?foo=bar cached.  Request #2:  [Fri Oct 20 16:42:51 2006] [debug] mod_disk_cache.c(477): disk_cache: Recalled cached URL info header http://localhost:8000/real?foo=bar [Fri Oct 20 16:42:51 2006] [debug] mod_disk_cache.c(750): disk_cache: Recalled headers for URL http://localhost:8000/real?foo=bar [Fri Oct 20 16:42:51 2006] [debug] mod_cache.c(261): cache: running CACHE_OUT filter [Fri Oct 20 16:42:51 2006] [debug] mod_cache.c(275): cache: serving /real  Again, served correctly from cache.  Requested behavior:  For mod_rewrite URLs where the RHS contains a query string, mod_cache should both store and retrieve the cached object from the same path.	Can you please try the attached patch? Created an attachment (id=19038) Patch against trunk  Yep, that works. Is this patch going to be applied against the 2.2 branch? I need to commit this to trunk first and propose it for backport to 2.2.x. Please bug me here if you see no update on this here within the next week. Thanks. Committed to trunk as r476625 (http://svn.apache.org/viewvc?view=rev&rev=476625). Any update on getting this backported to 2.2? Proposed for backport to 2.2.x as r488411 (http://svn.apache.org/viewvc?view=rev&rev=488411). Thanks for the reminder. What are the chances of this making it into 2.2.5? Backported to 2.2.x as r535903 (http://svn.apache.org/viewvc?view=rev&rev=535903). Hello,  excuse my poor english, I'm french.  Can someone explain to me how to apply this patch, please ? I have the 2.2.4 version of Apache. I need to apply the patch on a linux and on a Windows plateform.  Thanks. Go to the directory from where the patch is being created e.g Apache root directory in this patch and run the command. $ patch -p 0 -u -i <patchfile>			Basant Kumar Kukreja	Noah Robin	Ruediger Pluem	portalez
40865	null	RESOLVED		Andrew Rucker Jones	1162380240000	1188697613000		Missing assignment in error checking I was going through the Apache source code looking for another bug, and some code jumped out at me as being obviously wrong. Here's the (really short) patch:  --- proxy_util.c.orig   2006-11-01 20:05:21.000000000 +0100 +++ proxy_util.c        2006-11-01 20:05:56.000000000 +0100 @@ -955,7 +955,7 @@                  *eos = 1;              }              else { -                if (APR_SUCCESS != apr_bucket_read(e, (const char **)&response, &len, APR_BLOCK_READ)) { +                if (APR_SUCCESS != (rv = apr_bucket_read(e, (const char **)&response, &len, APR_BLOCK_READ))) {                      return rv;                  }                  /*   The same code is used a few lines earlier with the assignment i added in the above patch, which convinces me that it really was an unintentional omission.	Thanks for the patch. Committed to trunk as r470076 (http://svn.apache.org/viewvc?view=rev&rev=470076). Backported to 2.2.x as r571929 (http://svn.apache.org/viewvc?view=rev&rev=571929).			Ruediger Pluem
40878	null	VERIFIED		Rob Baily	1162458480000	1162990117000		For LDAP authentication against Windows Active Directory ldap_simple_bind_s fails after a period This is really more an enhance,ent request then a bug.  Here is the situation:  We set up Apache 2.2.3 on a Linux server and set up Subversion 1.4.0 to be handled by it.  We set up authentication to use LDAP to authenticate users.  We are authenticating to a Windows 2003 server through its LDAP service (using Global Catalog).  Here is the basic configuration.  I mangled some of the entries here as to not expose anything.  <Location />     AuthName 'SVN'     AuthType Basic     AuthBasicProvider file ldap     AuthzLDAPAuthoritative Off     AuthLDAPURL ldap://machinename:3268/dc=Company,dc=com?sAMAccountName?sub     AuthLDAPBindDN 'user@domain.com'     AuthLDAPBindPassword 'xxxxx'     AuthUserFile /var/subversion/conf/svn-auth-users     Require valid-user </Location>  So what happens is that generally it works fine.  But then if a user is inactive for a while (appears to be between 1 and 2 hours) and then tries to perform another operation they get a 500 internal error and a message similar to this is logged in the log file.  [Wed Nov 01 11:50:40 2006] [warn] [client 10.1.2.47] [3994] auth_ldap authenticate: user rbaily authentication failed; URI /svn/projects/candyland/trunk [LDAP: ldap_simple_bind_s() failed][Can't contact LDAP server]  If they attempt to rety the operation then usually between 2 to 5 times it comes back with no problem.  So this was becoming a major headache and causing our developers some pain in getting code checked in or getting updates.  Also it was causing some problems with a continuous build server.  I am not certain about the exact time period or the inactivity but indications pointed to this.  So I looked at the code in modules/ldap/util_ldap.c and changed it slightly.  There is a section of code that attempts to do ldap_simple_bind_s and repeats 10 times if it is getting a LDAP_SERVER_DOWN code.  What I noticed about this is that the connection is not truly being reset everytime.  It basically starts with the current state and tries to bind again.  So I moved out the code that was in the upper part of the uldap_connection_open into a function called uldap_connection_init.  Then in the failures loop if we get halfway (5 tries) then I changed it to unbind and then init it before trying to bind again.  This has worked well for us as we are no longer getting this.  So I realize this may be a Windows only issue and people may not be too keen on corecting it but it seems like it could happen on other types of LDAP servers as well.  I also think the design is a little better having the init stuff put out in a separate function rather than in the open function.  Also I changed some of the other places that had multiple statements for the unbind to call uldap_connection_unbind which handles it.  I think ideally it would be better if we could configure the 10 and 5 numbers through the configuration file but I wasn't really sure how to handle that.  I'll attach a patch to this shortly.	Created an attachment (id=19076) Proposed patch for the enhancement.  Ideally I think the 10 and 5 in the failures loop would be configrable with some defaults like the numbers that are currently used.  However I wasn't really sure about the best way to put that in so I did not do that. Changing severity to enhancement.  Although some people may think it is a bug since it eventually fails the LDAP authentication. Checked into trunk and proposed for backport to 2.2 In our environment we're running Apache 2.2.3 on a Solaris 10 box authenticating against a Windows 2003 LDAP server. This issue also appeared when our developers started porting applications over to Apache from IIS. In our situation, it would sometimes appear even upon an initial connection from a user after attempting to authenticate against LDAP. This was after the web server daemon was online for a few hours (four). The end user, if they entered their username/password correctly (or perhaps incorrectly too) would immediately get a 500 Internal Server error message, and an entry like this would be logged:  [Mon Apr 23 12:05:36 2007] [warn] [client 101.10.115.53] [21514] auth_ldap authenticate: user tracy authentication failed; URI /em/gs [LDAP: ldap_simple_bind_s() failed][Can't contact LDAP server]  			Brad Nicholes	John Tracy	Rob Baily
40910	null	RESOLVED		Markus Lind	1162796400000	1188828079000		configuration problem with more than 1 balancer When defining more than 1 proxy balancers the system sometimes ignores configurations and takes the first balancer for all requests. ErrorLog and configtest say everything is ok, the effect seems to be depending of the order of configuration  The following configuration doesn't work  <VirtualHost xxx.xxx.xxx.xxx>     <Proxy balancer://cluster1>         BalancerMember http://10.x.x.x loadfactor=20 retry=60         BalancerMember http://10.x.x.y loadfactor=10 retry=60     </Proxy>     <Proxy balancer://cluster2>         BalancerMember http://10.x.x.x:8080 loadfactor=20 retry=60         BalancerMember http://10.x.x.y:8080 loadfactor=10 retry=60     </Proxy>      RewriteEngine on      RewriteRule ^/specialpath/(.*)$ balancer://cluster2/specialpath/$1 [NC,P,L]      RewriteRule ^/(.*)$ balancer://cluster1/$1 [P,L] </VirtualHost>  Every request to specialpath is routed to the webs linked in cluster1 If I change the sequence of the 2 balancers it works  <VirtualHost xxx.xxx.xxx.xxx>     <Proxy balancer://cluster2>         BalancerMember http://10.x.x.x:8080 loadfactor=20 retry=60         BalancerMember http://10.x.x.y:8080 loadfactor=10 retry=60     </Proxy>     <Proxy balancer://cluster1>         BalancerMember http://10.x.x.x loadfactor=20 retry=60         BalancerMember http://10.x.x.y loadfactor=10 retry=60     </Proxy>      RewriteEngine on      RewriteRule ^/specialpath/(.*)$ balancer://cluster2/specialpath/$1 [NC,P,L]      RewriteRule ^/(.*)$ balancer://cluster1/$1 [P,L] </VirtualHost>  Balancer Manager Webpage shows both clusters, but in case 1 the ports of cluster 2 are 'lost', in case 2 it is shown correctly with port 8080  With 3 or more backend clusters this issue would be even more complicated to test	Could you please give the attached patch a try? It should fix your problem. Created an attachment (id=19092) Patch against trunk  Thanks, the Patch fixes the problem   Committed to trunk as r481901 (http://svn.apache.org/viewvc?view=rev&rev=481901). Proposed for backport as r571936 (http://svn.apache.org/viewvc?rev=571936&view=rev). Backported to 2.2.x as r572420 (http://svn.apache.org/viewvc?rev=572420&view=rev).			Markus Lind	Ruediger Pluem
40932	null	RESOLVED		Jeff Robbins	1163014860000	1199050786000		1 event handle leak in mpm_winnt.c on Restart In the Restart case the parent process (properly) does not wait for the child  to exit because a new child will field web requests so there's no reason to  pend waiting on the old child.  But....  The parent doesn't free the 'child_exit_event' which was duplicated for the  child so a reference is held by the parent and must be free'd or the handle  leaks.  I added the free in mpm_winnt.c line 937 like so:      else if (cld == RESTART_HANDLE) {         /* Received a restart event. Prepare the restart_event to be reused          * then signal the child process to exit.          */ \t\trestart_pending = 1;         ap_log_error(APLOG_MARK, APLOG_NOTICE, 0, s,                      'Parent: Received restart signal -- Restarting the  server.');         if (ResetEvent(restart_event) == 0) {             ap_log_error(APLOG_MARK, APLOG_ERR, apr_get_os_error(), s,                          'Parent: ResetEvent(restart_event) failed.');         }         if (SetEvent(child_exit_event) == 0) {             ap_log_error(APLOG_MARK, APLOG_ERR, apr_get_os_error(), s,                          'Parent: SetEvent for child process %d failed.',                          event_handles[CHILD_HANDLE]);         }         /* Don't wait to verify that the child process really exits,          * just move on with the restart.          */          // JSR         CloseHandle(child_exit_event);          CloseHandle(event_handles[CHILD_HANDLE]);         event_handles[CHILD_HANDLE] = NULL;	You are correct.  Although we have to close it before the return because we are about to signal it in the shutdown case further down.  So the most sensible patch is to close it immediate before the two return cases.  Although that's just my minor tweak - fantastic catch and assigning you full credit for the repair, thanks! 			Will Rowe
40950	null	RESOLVED		Thijs Kinkhorst	1163303700000	1166277774000		add note to manpage that htpasswd/htdigest is not safe for setuid/sudo Hi,  The source code for htpasswd/htdigest contains the following note:  > 'NOTE! This program is not safe as a setuid executable!  Do not make it > setuid!'  Since many users won't be browsing the source code, this should be added to the 'security considerations' of the respective man pages for those programs.  Thanks.	Created an attachment (id=19115) adjust xml text  Fixed in /trunk/ and 2.2.x - thanks 			Nick Kew	Thijs Kinkhorst
41035	null	RESOLVED		bugmenot	1164335700000	1188471769000		Wrong default content-type for icons, use image/vnd.microsoft.icon in mime.types instead of image/x-icon mime.types should have image/vnd.microsoft.icon ico instead of image/x-icon.	Committed to trunk in rev 571260. 			Roy T. Fielding
41056	null	RESOLVED		Jim Jagielski	1164706440000	1197183343000		Chunk filtering broken in httpd-2.2 and -trunk Resulting from PR 19954, a bug in chunk filtering is exposed. Due to all non blocking reads are converted  to blocking reads, chunks with flushes are broken	Created an attachment (id=19183) From PR 19954  Patch committed to trunk. Not yet in 2.2.x Proposed for backport as r600652 (http://svn.apache.org/viewcvs.cgi?rev=600652&view=rev). Backported to 2.2.x as r602679 (http://svn.apache.org/viewvc?rev=602679&view=rev).			Jim Jagielski	Ruediger Pluem
41097	null	RESOLVED		Dan Harkless	1164990060000	1185887433000		X-Forwarded-For, X-Forwarded-Host, and X-Forwarded-Server header addition by mod_proxy_http undocumented It's not documented that mod_proxy_http (starting in httpd 2.0.15) adds X-Forwarded-For, X-Forwarded-Host, and X-Forwarded-Server HTTP headers.  These are very useful to know about so that if you utilize a reverse proxy you'll know how to modify the LogFormat on your destination webserver to log actual client IPs rather than just the IP address of the proxy.  (And so you'll know that with recent versions of httpd, you don't need to install the third-party mod_proxy_add_forward module, as much advice online says to do.)  In the documentation it would be good to note that if traffic has an existing X-Forwarded-For: header, it will be overwritten by the Apache reverse proxy with its IP, rather than appending its IP to the value of that header as some other proxies do.  You might even give the configuration code from http://groups.google.com/group/alt.apache.configuration/msg/6f0ecadabc20623f as an example of how to always log the client IP in the first field, regardless of whether the particular connection went through the reverse proxy.  If you do that, though, you should probably add a note that malicious parties not going through the reverse proxy could hide their IP addresses from the logs by adding their own X-Forwarded-For headers, so for security it's better to log *both* the  value of %h and %{X-Forwarded-For}i.	IME Apache 2.2.0 used as a reverse proxy *does* append to an existing X-Forwarded-For header.  When I access a private server at work from my home machine, I connect via a forward proxy (Squid 2.6) on my home machine, an authenticating reverse proxy (Apache 2.2.0) on the remote firewall, and a reverse proxy (Apache 2.2.0) on the remote DMZ machine.  The server (running under Tomcat 5.5) has a facility for reporting the headers in the request it receives, and the X-Forwarded-For: header contains the private IP address of my home machine (added by Squid), the public IP address of my home machine (added by the firewall Apache), and the DMZ IP address of the remote firewall (added by the DMZ Apache).  As I would expect. These headers are now somewhat documented on trunk. Thanks.			Dave Sparks	Joshua Slive
41123	null	RESOLVED		Michal Prochazka	1165470420000	1196307774000		Support of OCSP in mod_ssl (rewritten patch from bug #31383) This patch is only rewritten patch from bug #31383 to be able to fit Apache 2.2.x version.	Created an attachment (id=19224) OCSP Patch  Created an attachment (id=19386) New version of OCSP patch containg missing file ssl_ocsp.c  In previous bug I forgot to add ssl_ocsp.c file. Created an attachment (id=19390) New version of OCSP patch generalising validation check, and including ssl_ocsp.c file in Visual C++ project  This implements the following validation workflow:  1. if (useOCSP)    => check OCSP    => if ( OCSP validation possible ) return status 2. Other online validation checks in the future (LDAP, etc.)    => check new protocol    => if ( validation possible ) return status 3. if (crl)    => check CRL    => If ( CRL validation possible ) return status 4. If ( forceValidation ) return !ok 5. return ok Created an attachment (id=19391) Corrected a #include  Created an attachment (id=19392) Corrected a #include  Created an attachment (id=19399) Port to 2.2.4  Created an attachment (id=19445) Documentation patch  Created an attachment (id=19446) Validation schema  Schema describing the certificates validation mechanism From review of attachment in comment 6:  A couple of things which make this code hard to review: - many code style issues with this code; tabs, many indenting problems, whitespace around if statements, see:  http://httpd.apache.org/dev/styleguide.html and be familiar with existing httpd code  - don't use C++-style comments - lots of stretches of code have been commented out rather than just deleted.  If they aren't needed, delete them.  General review: - don't log anything in the ssl_cmd_* functions, this doesn't add much - don't invent macros for logging in ssl_ocsp.c, just use ap_log_* directly - when and where is NO_OCSP supposed to be defined?  this needs an autoconf check presumably; call the define MODSSL_something - if it's useful for users to be able configure a proxy make it properly configurable, otherwise remove the debugging code - X509_Int2Str() should be static and have a name outside a namespace owned by OpenSSL.  Use of the static result buffer inside is not thread-safe. - use pools not malloc - using pools, and pool cleanups, or just better function structure, should be able to eliminate the excessive use of goto in VerifyOCSP - GetExtensionValue looks scary.  Why is this not looking up extensions by NID, can X509_get_ext_d2i not be used here? - also a bit scared about using the toy HTTP/1.0 client in OpenSSL :( I modified and cleaned up the code as requested; I will upload a new patch.  Some questions:  1. I used the connection pool for memory allocation: c->pool from ssl_callback_SSLVerify_Validity(). Is that correct ? I did not use any pool cleanup, as this will be closed at the end of the connection.  2. I originally added the #ifdef NOOCSP in case you want a version that is compiled with this code. Is this really needed ? Can I remove it ?  3. Should I replace the HTTP connection by some calls to some Apache API ? Which API is available ?  4. Probably dependent to the previous question, is there any global setting defining a proxy to call when opening an outgoing HTTP(S) connection ? I could define it for the OCSP call only, but some other code (even external modules) could also need it; this would lead to the same info being defined several time. Should I implement it only for my code ? Or can I assume that the server will always have a direct access to the OCSP server ?  Is it possible to use mod_proxy connection pools ? This would make sense, although the outgoing connection pool should go out from mod_proxy to a separate module in order to be reusable by every module ... This would maybe be the future best track, but it sounds a bit heavy to reimplement all mod_proxy connection pool handling just for the OCSP connection. Can we leave this as a future improvement and currently use the OpenSSL connection (which works well in practice in several very big eGov sites) ? (In reply to comment #10) > I modified and cleaned up the code as requested; I will upload a new patch.   > > 3. Should I replace the HTTP connection by some calls to some Apache API ? Which > API is available ? >  > 4. Probably dependent to the previous question, is there any global setting > defining a proxy to call when opening an outgoing HTTP(S) connection ? I could > define it for the OCSP call only, but some other code (even external modules) > could also need it; this would lead to the same info being defined several time. > Should I implement it only for my code ? Or can I assume that the server will > always have a direct access to the OCSP server ? >   Probably not well thought out, but how about a sub request to the proxy_handler provided by mod_proxy? > how about a sub request to the proxy_handler provided by mod_proxy?  Is there any documentation on how to do that ? Would it be acceptable to oblige loading mod_proxy for OCSP validation ? (In reply to comment #13) > > how about a sub request to the proxy_handler provided by mod_proxy? >  > Is there any documentation on how to do that ?  Not as far as I know. But having a look into mod_include for subrequest inclusion and at mod_rewrite for preparing a request to go to the proxy could be helpful.  > Would it be acceptable to oblige loading mod_proxy for OCSP validation ?  I think this should be discussed on dev@httpd.apache.org and not here. Created an attachment (id=19667) Code following recommandations  I followed all recommandations, except the connection that is still established by OpenSSL calls - using mod_proxy was too complex. Note that the OpenSSL connection works very well in big production environments. I've been working on a cleanup of this patch - we need a CLA on file for all the contributors before anything can be committed, since it's a contribution of new code; I'm not sure who out of the following that means:  1) Marc Stern [no CLA] 2) Matthieu Estrade [CLA on file] has worked on this previously 3) Michal Prochazka [no CLA] wrote the initial port to 2.2 attached here.  Marc, can you confirm the lineage of the patch most recently attached?  http://issues.apache.org/bugzilla/attachment.cgi?id=19667  Joe,  I submitted the CLA some time ago. Michal did only port the patch to the new version, no new code was added. Matthieu could provide a CLA if needed (don't know if need for apache.org members).  Can you acknowledge that everything is OK.  Thanks (In reply to comment #17) > Joe, >  > I submitted the CLA some time ago.  Your iCLA has been registered a while ago (May 7th, see http://people.apache.org/~jim/committers.html and search for Marc Stern). So this is fine.  > Michal did only port the patch to the new version, no new code was added.  Not quite sure if an iCLA is needed in this case. Joe?  > Matthieu could provide a CLA if needed (don't know if need for apache.org members).  His iCLA is already on file. So this is fine too. In ssl_ocsp.c, function ap_ocsp_verify_ocsp:  ----- start -----    if (rc == SSL_OCSP_OK) {         /* Get issuer */         ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Get Issuer');         rc = X509_STORE_CTX_get1_issuer(&issuer, ctx, cert);         if (rc != 1) {             ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,                          'Cannot get issuer of '%s'. rc=%d', X509_SUBJ_NAME(cert), rc);             rc = SSL_OCSP_ERROR_INTERNAL;         }     }      if (rc == SSL_OCSP_OK) { ----- end -----  This can't work. If there's no issuer rc is set to SSL_OCSP_ERROR_INTERNAL. If there is one, rc stays '1'. However, SSL_OCSP_OK is 0, 1 means SSL_OCSP_ERROR_PARSE_URL   Created an attachment (id=20958) Small corrections in error handling and OCSp response logging  (From update of attachment 20958) diff -uaEbwNp orig/ssl_ocsp.c ./ssl_ocsp.c --- orig/ssl_ocsp.c\t1970-01-01 01:00:00.000000000 +0100 +++ ./ssl_ocsp.c\t2007-10-11 16:37:20.866178500 +0200 @@ -0,0 +1,441 @@ +/* Licensed to the Apache Software Foundation (ASF) under one or more + * contributor license agreements.  See the NOTICE file distributed with + * this work for additional information regarding copyright ownership. + * The ASF licenses this file to You under the Apache License, Version 2.0 + * (the 'License'); you may not use this file except in compliance with + * the License.  You may obtain a copy of the License at + * + *\thttp://www.apache.org/licenses/LICENSE-2.0 + * + * Unless required by applicable law or agreed to in writing, software + * distributed under the License is distributed on an 'AS IS' BASIS, + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. + * See the License for the specific language governing permissions and + * limitations under the License. + */ +     +/*\t\t\t _\t       _ + *  _ __ ___\t___   __| |    ___ ___| |  mod_ssl + * | '_ " _ / / _ / / _" |   / __/ __| |  Apache Interface to OpenSSL + * | | | | | | (_) | (_| |   /__ /__ / | + * |_| |_| |_|/___/ /__,_|___|___/___/_| + *\t\t\t |_____| + *  ssl_ocsp.c + *  The SSL OCSP checking + * + *  Developed by Marc Stern, for Approach Belgium / CSC / Belgian Government + *\t      based on code developed by Zetes Pass + * + *  This code was added to support the Belgian Electronic Identity Card + * + *  The OCSP responder URL is read from the certificate itself + * + */  +    /* ""When the only tool you own is a hammer, +\t  every problem begins to resemble a nail.???? +     */  +     +#include 'mod_ssl.h' +#include 'ssl_private.h' +#include 'apr_base64.h' + +#define X509_NAME2STR(name_)\t     X509_NAME_oneline(name_, NULL, 0) +#define X509_SUBJ_NAME(cert_)\t     X509_NAME2STR(X509_get_subject_name(cert_)) +#define X509_ISSUER_NAME(cert_)     X509_NAME2STR(X509_get_issuer_name(cert_)) + + +static char *ap_ocsp_ASN1_Int2Str(ASN1_INTEGER *data, apr_pool_t *pool) +{ +    char *result = (char *)apr_palloc(pool, 100); /* 100 should be enough */ +    char *buf = NULL; +    BIGNUM *bn = ASN1_INTEGER_to_BN(data, NULL); + +    *result = 0; +    if (bn && !BN_is_zero(bn)) { +\t buf = BN_bn2hex(bn); +\t if (buf) { +\t     strncpy(result, buf, sizeof(result) - 1); +\t     result[sizeof(result) - 1 ] = 0; +\t } +    } + +    if (bn) BN_free(bn); +    if (buf) OPENSSL_free(buf); +    return result; +} + +static char *ap_ocsp_get_ocsp_uri(X509 *cert, apr_pool_t *pool) +{ +    int crit, j; +    STACK_OF(ACCESS_DESCRIPTION) *values = +\t (STACK_OF(ACCESS_DESCRIPTION) *) +\t\tX509_get_ext_d2i(cert, NID_info_access, &crit, NULL); +    if (! values) return NULL; + +    for (j = 0; j < sk_ACCESS_DESCRIPTION_num(values); j++) { +\t ACCESS_DESCRIPTION *value = sk_ACCESS_DESCRIPTION_value(values, j); +\t if(OBJ_obj2nid(value->method) == NID_ad_OCSP) { +\t     /* Name found in extension */ +\t\t\tchar *result; +\t\t\t +\t\t\t/* Check that it is a URI */ +\t\t\tif (value->location->type != GEN_URI) +\t\t\t\tcontinue; + +\t     result = apr_pstrdup(pool, +\t\t\t      (char *)value->location->d.uniformResourceIdentifier->data); +\t\t\t AUTHORITY_INFO_ACCESS_free(values); +\t     return result; +\t } +    } + +\tsk_ACCESS_DESCRIPTION_free(values); +\t//AUTHORITY_INFO_ACCESS_free(values); +    return NULL; +} + + +static BIO *ap_ocsp_connect(const char *host, int port)  +{ +    BIO *connection = BIO_new_connect((char *)host); +    if (!connection) return 0; + +    BIO_set_conn_int_port(connection, &port); +    if (BIO_do_connect(connection) <= 0) { +\t /* Not needed - default: BIO_set_close(connection, BIO_CLOSE); */ +\t BIO_free_all(connection); +\t return NULL; +    } + +    return connection; + +} + + +static OCSP_RESPONSE *ap_ocsp_sendreq(const char *ocspHost, const char *ocspPort, const char *ocspPath, OCSP_REQUEST *request, server_rec *s)  +{ +    BIO *bio = NULL; +    OCSP_RESPONSE *response = NULL; + +    /* establish a connection to the OCSP responder */  +    ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t 'Connect to OCSP responder '%s:%s'', ocspHost, ocspPort); +    bio = ap_ocsp_connect(ocspHost, atoi(ocspPort)); +    if (!bio) { +\t ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t 'Cannot connect to OCSP responder '%s:%s'', ocspHost, ocspPort); +\t return NULL; +    } +     +    /* send the request and get a response */  +    ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, +\t\t 'sending request to OCSP responder'); +    response = OCSP_sendreq_bio(bio, (char *)ocspPath, request); +    if (!response) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t\t 'Cannot send request to OCSP responder '%s'', ocspHost); +\t } + +    BIO_free_all(bio); + +    return response; +} + + +static int ap_ocsp_verify_ocsp(X509 *cert, X509_STORE_CTX *ctx, server_rec *s, +\t\t\t\tint *ocspStatus, apr_pool_t *pool)  +{ +    int rc = SSL_OCSP_OK; +    X509 *issuer = NULL; +    char *ocspUrl = NULL, *ocspHost = NULL, *ocspPort = NULL, *ocspPath = NULL; +    BIO * bio = NULL; +    OCSP_RESPONSE * response = NULL; +    OCSP_BASICRESP * basicResponse = NULL; +    OCSP_REQUEST * request = NULL; +    OCSP_CERTID * certID = NULL; +    int ssl = 0; +    SSLSrvConfigRec *sc = mySrvConfig(s); +\tchar *subj_name = X509_SUBJ_NAME(cert); +\tchar *issuer_name = X509_ISSUER_NAME(cert); + +    *ocspStatus = V_OCSP_CERTSTATUS_UNKNOWN; +    X509_STORE_CTX_set_error(ctx, X509_V_ERR_APPLICATION_VERIFICATION); +    ap_log_error(APLOG_MARK, APLOG_INFO, 0, s, +\t 'OCSP check - cert='%s', issuer='%s'', subj_name, issuer_name); +    +     +    /* First look if we force the responder url*/ +    if (sc->server->OCSPForceResponderURL) { +\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, +\t\t 'Force the url of responder to: %s', sc->server->OCSPForceResponderURL); +\t ocspUrl = sc->server->OCSPForceResponderURL; +    } +    /* if not, look inside the certificate if we have one */ +    else { +\t  /* Get OCSP Responder URI (only first one) */ +\t ocspUrl = ap_ocsp_get_ocsp_uri(cert, pool);  +\t if (ocspUrl) +\t     ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, +\t\t 'OCSP responder from certificate: %s', ocspUrl); +    } + +    if (!ocspUrl && sc->server->OCSPDefaultResponderURL) { +\t ap_log_error(APLOG_MARK, APLOG_INFO, 0, s, +\t     'No Responder URL in certificate - using default: %s', +\t     sc->server->OCSPDefaultResponderURL); +\t ocspUrl = sc->server->OCSPDefaultResponderURL; +    } + +    if (!ocspUrl) { +\t ap_log_error(APLOG_MARK, APLOG_WARNING, 0, s, +\t  'Cannot get OCSP responder URL from '%s' and no default URL Responder', +\t  subj_name); +\t rc = SSL_OCSP_ERROR_PARSE_URL; +    } +     +    if (rc == SSL_OCSP_OK) { +\t if (!OCSP_parse_url(ocspUrl, &ocspHost, &ocspPort, &ocspPath, &ssl)) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t 'Cannot parse OCSP responder URL from '%s'', +\t\t\t\tsubj_name); +\t     rc = SSL_OCSP_ERROR_PARSE_URL; +\t } +    } +     + +    if (rc == SSL_OCSP_OK) { +\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Create new OCSP request'); +\t request = OCSP_REQUEST_new(); +\t if (!request) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t\t 'Cannot create new OCSP request'); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } +     +    if (rc == SSL_OCSP_OK) { +\t /* Get issuer */ +\t\tint r; +\t\t/* Enhancement: ctx->chain is already ordered -> extract 2nd ? */ +\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Get Issuer'); +\t r = X509_STORE_CTX_get1_issuer(&issuer, ctx, cert); +\t if (r != 1) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t\t 'Cannot get issuer of '%s'. rc=%d', subj_name, rc); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } + +    if (rc == SSL_OCSP_OK) { +\t certID = OCSP_cert_to_id(0, cert, issuer); +\t if (!certID || !OCSP_request_add0_id(request, certID)) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s +\t\t\t, 'Cannot get certificate id from '%s'', subj_name); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } + +    if (rc == SSL_OCSP_OK) { +\t OCSP_request_add1_nonce(request, 0, -1); + +\t /*  To use a proxy, do the following +\t       - ocspHost = proxyHost; +\t       - ocspPort = proxyPort; +\t       - ocspPath = ocspUrl; +\t  */ +     +\t /* establish a connection to the OCSP responder */  +\t response = ap_ocsp_sendreq(ocspHost, ocspPort, ocspPath, request, s); +\t if (!response) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t     'Cannot send request to OCSP responder '%s'', ocspHost); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } + + +    if ( (rc == SSL_OCSP_OK) && (s->loglevel >= APLOG_DEBUG) ) { +\t /* Log OCSP answer (complete OpenSSL buffer) */ +\t char *buf = apr_palloc(pool, +\t\t apr_base64_encode_len(response->responseBytes->response->length) + 1); +\t if (buf) { +\t     apr_base64_encode(buf, +\t\t\t (const char*)response->responseBytes->response->data, +\t\t\t response->responseBytes->response->length); +\t     ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, +\t\t\t 'OCSP response (OpenSSL bufer): serial=%s | dn=%s | %s', +\t\t\t  ap_ocsp_ASN1_Int2Str(X509_get_serialNumber(cert), pool), +\t\t\t   X509_SUBJ_NAME(cert), buf); +\t } +\t else { +\t    ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, 'Cannot allocate buffer'); +\t } +    } + +    if (rc == SSL_OCSP_OK) { +\t\tint r; +\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, +\t\t 'Analyse OCSP request answer'); +\t r = OCSP_response_status(response); +\t if (r != OCSP_RESPONSE_STATUS_SUCCESSFUL) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t\t 'Bad OCSP responder answer. rc=%d', rc); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } +     +    if ( (rc == SSL_OCSP_OK) && (s->loglevel >= APLOG_DEBUG) ) { +\t /* Log OCSP answer (only the 'bare' response) */ +\t int len = i2d_OCSP_RESPONSE(response, NULL); +\t if (len <= 0) +\t    rc = SSL_OCSP_ERROR_INTERNAL; +\t else { +\t\t\tunsigned char *buf1, *buf2; +\t     buf1 = buf2 = (unsigned char *)apr_palloc(pool, len); +\t     if (!buf1) { +\t\t\t\tap_log_error(APLOG_MARK, APLOG_ERR, 0, s, 'Out of memory'); +\t\t rc = SSL_OCSP_ERROR_INTERNAL; +\t     } +\t     else { +\t\tif (i2d_OCSP_RESPONSE(response, &buf1) != len)  +\t\t\t       rc = SSL_OCSP_ERROR_INTERNAL; +\t\telse { +\t\t     /* contents is in buf2, because buf1 is now pointing +\t\t\tto the end of the structure */ +\t\t     char h[] = 'OCSP response : '; +\t\t     int len64 = apr_base64_encode_len(len); +\t\t     char *msg = (char *)apr_palloc(pool, len64 + strlen(h) + 1); +\t\t     if (msg) { +\t\t\t strcpy(msg, h); +\t\t\t apr_base64_encode(msg + strlen(h), buf2, len); +\t\t\t msg[strlen(h) + len64 + 1] = 0; +\t\t\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, msg); +\t\t     } +\t\t} +\t    } +\t} +    } + +    if (rc == SSL_OCSP_OK) { +\t basicResponse = OCSP_response_get1_basic(response); +\t if (!basicResponse) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t\t 'Bad OCSP responder answer'); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } + +    if (rc == SSL_OCSP_OK) { +\t if (OCSP_check_nonce(request, basicResponse) <= 0) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t\t 'Bad OCSP responder answer (bad nonce)'); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } +\t  +    if (rc == SSL_OCSP_OK) { +\t if (OCSP_basic_verify(basicResponse, 0, ctx->ctx, +\t\t sc->server->OCSPResponderVerifyFlag) <= 0) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t\t 'Error verifying OCSP responder answer'); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } +     +    if (rc == SSL_OCSP_OK) { +\t int ocspReason = -1; +\t ASN1_GENERALIZEDTIME * ocspProducedAt, *ocspThisUpdate, +\t     *ocspNextUpdate; +\t rc = OCSP_resp_find_status(basicResponse, certID, ocspStatus, +\t\t       &ocspReason, &ocspProducedAt, +\t\t       &ocspThisUpdate, &ocspNextUpdate); +\t if (rc == 0) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, 'Bad OCSP status'); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t 'OCSP validation completed: status=%d', *ocspStatus); +    rc = SSL_OCSP_OK; +    } + +    ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Cleanup OCSP code'); +\tif (issuer) X509_free(issuer); +\tif (subj_name)\t OPENSSL_free(subj_name); +\tif (issuer_name) OPENSSL_free(issuer_name); +    if (request)  OCSP_REQUEST_free(request); +    if (response) OCSP_RESPONSE_free(response); +    if (basicResponse) OCSP_BASICRESP_free(basicResponse); +\tif (ocspHost) OPENSSL_free(ocspHost); +\tif (ocspPort) OPENSSL_free(ocspPort); +\tif (ocspPath) OPENSSL_free(ocspPath); +    /* certID is just a pointer, nothing to free */  + +    ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Ending cleanup OCSP code'); +    return rc; +} + +int ssl_cmd_VerifyOCSP(X509_STORE_CTX *ctx, server_rec *s, int *ocspStatus, + apr_pool_t *pool)  +{ +    int rc = SSL_OCSP_OK, i; +    X509 *cert = X509_STORE_CTX_get_current_cert(ctx); +    X509_STORE_CTX *ocspCtx = NULL; +    X509_STORE *store = NULL; +    SSLSrvConfigRec *sc = mySrvConfig(s); +\tchar *subj_name = X509_SUBJ_NAME(cert); +\tchar *issuer_name = X509_ISSUER_NAME(cert); + +    ap_log_error(APLOG_MARK, APLOG_INFO, 0, s, +\t 'Validating certificate '%s', issuer: '%s'', +\t    subj_name, issuer_name); +     +    /* Store certif chain in a store */  +    if (!ctx->chain) { +\t ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, 'No certificate chain'); +\t return SSL_OCSP_ERROR_INTERNAL; +    } + +    /* +    ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, +\t 'certificates chain length: %d', ctx->chain->num); +    */  + +    store = X509_STORE_new(); +    if (!store) { +\t ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t 'Cannot create a new X509 store'); +\t return SSL_OCSP_ERROR_INTERNAL; +    } +     +    for (i = 0; i < ctx->chain->num; i++) +    if (!X509_STORE_add_cert(store, sk_X509_value(ctx->chain, i))) { +\t ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t 'Cannot add certificate to X509 store'); +\t rc = SSL_OCSP_ERROR_INTERNAL; +    } + +    if (rc == SSL_OCSP_OK) { +\t ocspCtx = X509_STORE_CTX_new(); +\t if (!ocspCtx) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t     'Cannot create a new X509 context'); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } +    if (rc == SSL_OCSP_OK) { +\t if (X509_STORE_CTX_init(ocspCtx, store, cert, 0) != 1) { +\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, +\t\t\t 'Cannot initialise the new X509 context'); +\t     rc = SSL_OCSP_ERROR_INTERNAL; +\t } +    } + +    if (rc == SSL_OCSP_OK) +\t rc = ap_ocsp_verify_ocsp(cert, ocspCtx, s, ocspStatus, pool); + +\t if (subj_name)   OPENSSL_free(subj_name); +\t if (issuer_name) OPENSSL_free(issuer_name); +    if (store)   X509_STORE_free(store); +    if (ocspCtx) X509_STORE_CTX_free(ocspCtx); +    return rc; +}  I've been looking into updating the patch to use mod_proxy and the sub request mechanism for OCSP queries. Unfortunately the request_rec structure is not set in SSL_get_app_exdata2() at the time it is needed and there doesn't appear to be an easy way to obtain it. This may be because the requested page is unknown at this time because the SSL handshake is in progress and no HTTP headers have been sent. Does this make sub requests a non starter for OCSP or is it possible to use an alternative technique? *** Bug 31383 has been marked as a duplicate of this bug. *** Yes it doesn't look like use of mod_proxy subrequests will be possible unfortunately, per discussion on dev@.  I've got a heavily cleaned up version of the latest patch which I will attach shortly.  I notice the latest patches have a comment 'based on code developed by Zetes Pass' which scares me again.   It is important to understand that we cannot include code in the ASF repository unless the copyright status is clear.  So again, Marc; is this an original contribution to which you entirely own the copyright?  If some other party wrote half the code then we need a CLA from them too since this is a substantial contribution of new code. > I notice the latest patches have a comment 'based on code developed by Zetes > Pass' which scares me again. > is this an original contribution to which you entirely own the > copyright? You can remove the copyright, as 1. the code I mentionned was developped for the same project (Belgian Government) 2. Nothing exists anymore from the original code, I rewrote everything This was a kind of 'recognition' (In reply to comment #24) > I've got a heavily cleaned up version of the latest patch which I will attach > shortly. 1. Just to notice that ocsp.c must also be added to config.m4, but I guess you discovered this. 2. I also noticed that, in order to compile it with the latest Microsoft SDK (from Visual C++ 2008), we need to include 'openssl/ocsp.h' at the very beginning of ssl_ocsp.h & ssl_engine_kernel.c. 3. I am also planning to move the directives (SSLUseOCSP, etc.) to a location level, to offer more flexibility. Do you want to tackle this at the same time, or do you prefer I do it ? 4. For which version did you plan to rework the patch ? 2.2.4, 2.2.6, Head ? Created an attachment (id=21130) attempt 1 of refactored OCSP support  This is the cleaned up version of Marc's OCSP patch, diff relative to the trunk.\t  Relative changes:  - moves OCSP code to ssl_engine_ocsp.c - heavily refactors, cleans up, simplifies code style etc in the above - tones down the debugging a lot.  some common helper functions are needed in ssl_engine_log.c to log cert subject name etc, if desired - updates config.m4 - removed error handling for OpenSSL functions which can only fail on OOM - removed poorly-named SSLOCSPResponderVerify (can be added back separately) - removed addition of SSLForceValidation, which is orthogonal to basic OCSP support (likewise add separately later) - reworked the config options to be:      SSLOCSPEnable <bool>     SSLOCSPOverrideResponder <bool>     SSLOCSPDefaultResponder <URL>    rather than redundantly having two directives to supply a URL. - simplify unnecessarily complex status/error handling for OCSP code   This is untested since my OCSP test setup is broken currently, so it probably doesn't actually work. (In reply to comment #26) > 1. Just to notice that ocsp.c must also be added to config.m4, but I guess you > discovered this.  Yup :)  > 2. I also noticed that, in order to compile it with the latest Microsoft SDK > (from Visual C++ 2008), we need to include 'openssl/ocsp.h' at the very > beginning of ssl_ocsp.h & ssl_engine_kernel.c.  Why, what's the failure otherwise?  The #include in ssl_toolkit_compat.h should be sufficient.  > 3. I am also planning to move the directives (SSLUseOCSP, etc.) to a location > level, to offer more flexibility. Do you want to tackle this at the same time, > or do you prefer I do it ?  Sounds useful, let's get the basic functionality committed first then deal with stuff like that incrementally.  > 4. For which version did you plan to rework the patch ? 2.2.4, 2.2.6, Head ?  trunk.  > > In order to compile it with the latest Microsoft SDK > > (from Visual C++ 2008), we need to include 'openssl/ocsp.h' at the very > > beginning of ssl_ocsp.h & ssl_engine_kernel.c. >  > Why, what's the failure otherwise?  The #include in ssl_toolkit_compat.h > should be sufficient. Some general Apache include files end up in including standard MS SDK. In latest SDK, MS defines some types if they are not defined yet. These types are defined by OpenSSL, so they have to be included before SDK .h, so before Apache .h. This could also be done in ssl_private.h: either include 'openssl/ocsp.h' before Apache files, or 'ssl_toolkit_compat.h', or all 'ssl*.h' files. (In reply to comment #27) > - removed addition of SSLForceValidation, which is orthogonal to basic OCSP This is a very important feature (also for other validation mechanisms, like CRL or, maybe in the future LDAP). Without that, the administrator cannot decide what to do when no validation mechanism is available (OCSp responder not available, or CRL files not up to date). Depending on the server security level, the implementation will either be seen as conatining a security hole (the cert is accepted although it is invalid),  or it will be considered as too strict (blocking valid users because of third party infrastsucture problems). This is a feature that we see as crucial for most of the application owners. (In reply to comment #30) > (In reply to comment #27) > > - removed addition of SSLForceValidation, which is orthogonal to basic OCSP > This is a very important feature (also for other validation mechanisms, like   Yes, that's fine, but it's also orthogonal to getting basic OCSP support working, so it can be added afterwards.  Removing the intrusive changes to the verification callback makes the basic code easier to review and test. Some comments on the latest patch.  1. The function extract_responder_uri() has a memory leak. It should call:  AUTHORITY_INFO_ACCESS_free(values);  instead of:  sk_ACCESS_DESCRIPTION_free(values);  2. After the call to apr_uri_parse() shouldn't we check the scheme is really 'http'? I've heard of some responders which use 'https'. There is also the possibility that the URL will be split up into a path and query string which should be concatenated when passed to OpenSSL.  3. The OCSP query code doesn't include a timeout. This is a problem with the OpenSSL's rather simplistic OCSP handler and the fact that there is no generalized socket timeout code in OpenSSL. There are several ways to work around this. The easiest is to use APR sockets with a timeout. See my OCSP query code in Bug 43822  4. The code unconditionally uses an OCSP nonce. Some responders do not sign every request but just server pre-cached responses. As a result the nonce value can't be honoured and an error will occur when attempting to use such responders. The most notable example is VeriSign's OCSP responder but there are others.  Created an attachment (id=21193) updated patch  Changes in second patch:  1) fixed to check URI scheme, and correctly free 'values' stack per Steve's comment  2) drop the duplicate X509_STORE_CTX & X509_STORE creation.  I can't see why this is necessary; Marc, can you explain what that was for?  OCSP_basic_verify() creates its own X509_STORE_CTX anyway in which to do the verify the response signature, so it was never used directly.  Dropping this doesn't seem to make any difference to result in testing, either.  Was this just here to allow for future customisation of how the response signature is verified?  3) simplified some more logging/debugging.  Uses the new ssl_log_cxerror() function added on the trunk to log cert details as context.  Steve, thanks for a lot for the review - agree with your points (3) and (4) but would like to address these later. [adding CC] >  > 2) drop the duplicate X509_STORE_CTX & X509_STORE creation.  I can't see why > this is necessary; Marc, can you explain what that was for?    I haven't tested it explicitly but I think the extra X509_STORE and ctx was intended to extract the issuer certificate from the client certificate in a reliable way.  Note that X509_STORE_CTX_get1_issuer() will only retrieve the issuer certificate if it is trusted, hence the extra store to make all certificates trusted. To see why suppose you have this situation:  Root->Intermediate->Cert  Where Root only is trusted. The client would send Cert and Intermediate. The OpenSSL validation logic would then build the whole chain.  A call to X509_STORE_CTX_get1_issuer() would fail because Intermediate is not in the trusted store.  In actual fact it isn't necessary to create a separate store because the certificate chain has already been built and validated. All you should need to do is to extract the second member of the validated chain like this....  issuer = sk_X509_value(X509_STORE_CTX_get_chain(ctx), 1); if (issuer == NULL) /* Error */  Since issuer is an internal pointer it shouldn't be freed as it will be freed up when the ctx is cleaned up.  Oh and btw you do need to free up certID.  OK, but the SSLVerify callback (and hence this OCSP validation code) is invoked for each and (necessarily) every cert from the root CA down to the peer's certificate, to verify the complete chain - so:  1) we must always be able to assume that the issuer of the X509_STORE_CTX_get_current_cert() cert is trusted, since otherwise we wouldn't get this far?  2) sk_X509_value(X509_STORE_CTX_get_chain(ctx), 1) is not necessarily the issuer of the current cert - it might *be* the current cert?  ...right?  Or am I missing something fundamental?  On the CERTID front, if I add       if (certID) OCSP_CERTID_free(certID);  it crashes on that line:  #0  0x0000003800e75edb in free () from /lib64/libc.so.6 #1  0x00000038094572fd in CRYPTO_free () from /lib64/libcrypto.so.6 #2  0x00000038094bcc37 in ASN1_STRING_free () from /lib64/libcrypto.so.6 ... Created an attachment (id=21201) final patch  Final patch before committing to trunk.  Changes:  1) factors out the HTTP client into ssl_util_ocsp, and re-implements using APR functions directly; fixing I/O timeout handling, server address handling, and adding response memory use constraints rather than streaming into RAM indefinitely (!) as the OpenSSL code does.  Also allows this code to be easily switched out for a Real HTTP Client (TM) later.  2) removes the debugging code which dumps base64-encoded which seems overkill; tcpdump/wireshark works for such case.  3) use a temporary pool to constrain connection pool memory use  >  > 1) we must always be able to assume that the issuer of the > X509_STORE_CTX_get_current_cert() cert is trusted, since otherwise we wouldn't > get this far? >   I'll check the current patch. As things stand I suspect if the server just trusts a root CA and the client sends root->intermediate->EE it will fail to find the intermediate CA because it isn't in the store.  > 2) sk_X509_value(X509_STORE_CTX_get_chain(ctx), 1) is not necessarily the issuer > of the current cert - it might *be* the current cert? >  > ...right?  Or am I missing something fundamental? >   I was missing something. I was assuming the OCSP calls were being made *after* the chain is validated instead of inside the verification callback.  If you make OCSP calls inside the verification callback the chain may not be fully trusted when you make the OCSP requests. This would allow a carefully constructed certificate chain to persuade a server to make arbitrary OCSP requests to any URL. Some would regard this as undesirable.  > On the CERTID front, if I add  >  >     if (certID) OCSP_CERTID_free(certID); >  > it crashes on that line: >   Yes, I missed that, sorry. It will be freed when the request is freed.   (In reply to comment #39) > I was missing something. I was assuming the OCSP calls were being made *after* > the chain is validated instead of inside the verification callback. >  > If you make OCSP calls inside the verification callback the chain may not be > fully trusted when you make the OCSP requests. This would allow a carefully > constructed certificate chain to persuade a server to make arbitrary OCSP > requests to any URL. Some would regard this as undesirable.  If the cert being verified is not trusted the SSLVerify callback will get invoked with ok=0 though surely? (the OCSP code won't get invoked in that case, only if the cert *is* trusted)   But I did find this confusing, anyway.  Is it at all desirable to be doing OCSP validation of every cert in the chain, including whatever root CA?  Marc, was the code written like this deliberately?  It would be simple enough to only do the OCSP validation for the actual peer cert. It wasn't quite as bad as I originally though. The final verification step is the signature validation of each cert in the chain. So if that is successful the callback is called ok==1 for each cert in the chain.   I thought that the chain went leaf to root which would have allowed arbitrary URIs from a bogus chain.  Instead it goes root to leaf which isn't as bad but would allow a bogus EE cert to trigger chain validation because it isn't checked until the end.  As things stand the current_issuer field of X509_STORE_CTX can be used to obtain the issuer cert. Think that was first added in OpenSSL 0.9.7.  The only other case is when ok is set to 1 because it tolerates an earlier error. That could end up doing an OCSP (and CRL) check twice AFAICS.    Committed to trunk:  http://svn.apache.org/viewvc?view=rev&revision=599385  thanks to all for the patches, review, and patience to those who have worked on this.  Further work:  * add config options to configure whether CRL-and/or-OCSP validation is mandatory as in the 'ForceValidation' config option, whether a nonce is used, what verification flags are passed to OCSP_basic_verify()  * move verification to per-location context?  patches welcome for all the above!  Marking this fixed; for issues with the committed code please file new bugs or mail dev@httpd, likewise for discussion of above future work.  (and as always, patches welcome!) (In reply to comment #40) > Is it at all desirable to be doing OCSP validation of every cert in the chain, > including whatever root CA? > It would be simple enough to only do the OCSP validation for the actual peer > cert. If you compromise the intermediate certificate, you could create a fake OCSP server, with responses that will be accepted by Apache. The only way to ensure the OCSP response is valid is to validate its certificate, and the same up to the root.			Dr Stephen Henson	Joe Orton	Marc Stern	Michal Prochazka	Ruediger Pluem	Wolfram Joost
41144	null	RESOLVED		Davi Arnaut	1165763640000	1186552641000		A especially crafted Date header may cause the ap_proxy_date_canon function to read past the end of a buffer A especially crafted Date header may cause the ap_proxy_date_canon function to read past the end of a  buffer because no bounds checking is performed.  Since the function is badly indented and broken, I diceded to take it out entirely.	Created an attachment (id=19240) patch against the 2.2.x branch  ap_proxy_date_canon is called for the fowling headers:  'Date', 'Expires', 'Last-Modified'  Header example:  'Date: Monday, oops'    A simpler fix would just be to check strlen of the date at the top of the function, wouldn't it? (In reply to comment #3) > A simpler fix would just be to check strlen of the date at the top of the > function, wouldn't it?  Not quite, because the length varies per date format. Well, let's make it less likely to bite us later.  Created an attachment (id=19299) proxy canon date gmt  The first patch version incorrectly converted the time in local timezone instead of GMT. Both your patches are identical - but they're more sensible than the original code.  I'm updating it to use gmt as you intended, and made the tiny optimisation of avoiding a copy. Created an attachment (id=19301) updated patch on 2.2  Should've mentioned: my patch relies on Davi's patch to have got the format right:-)  More importantly, this needs to be applied to trunk ahead of 2.2.x. I double checked, the patches are not identical. Anyway, your patch is better. Thanks. Committed to trunk in revision 561616:  http://svn.apache.org/viewvc?view=rev&rev=561616  Backported to 2.2.x in revision 563198:  http://svn.apache.org/viewvc?view=rev&rev=563198  Backported to 2.0.x in revision 563329:  http://svn.apache.org/viewvc?view=rev&rev=563329			Davi Arnaut	Nick Kew
41148	null	RESOLVED		Luke Kenneth Casson Leighton	1165812660000	1185888084000		no startup option to keep a foreground process a very important command-line startup option is missing: the ability to send all logging to stdout/stderr plus having the main process in foreground whilst all other child processes/threads are running - in production mode.  the reason why this is important is because it is a standard way to run daemons.  and - i am not kidding - apache is the _only_ major free software service, out of fifty or so that i've come across - that do not have this option.  there is a specific reason why i need this option: it's because of depinit.  the use of depinit does away completely with the need for stupid /var/run/*.pid files (it keeps an eye on the main process and automatically restarts it if that main process dies), and with the need for opening up separate log files (it can read from stdout and stderr and send those to another service, for it to process via optional filter programs and ultimately on to a destination service e.g. syslogd)  in a few simple lines of c-code depinit replaces all the cruft that is duplicated in every single service.  and apache is literally the _only_ major free software service that cannot be 'managed' by depinit.  the reason why it cannot be managed by depinit is because apache forks as a daemon, closing stdin-out-err etc. etc.  so, it has to be treated as a 'legacy' service, and therefore any paralllel dependencies on  apache cannot be properly managed.  also, depinit cannot give apache a chance to exit properly: it can only run /etc/init.d/apache2 stop and leave it at that.  there's no chance to find out if that succeeded or failed: after a few seconds, any remaining processes are terminated with extreme prejudice.  if the option was added to run in foreground, in production mode, then depinit could send signals to the main apache process to get it to shut down gracefully, then wait until that main process exited.	What is missing that -DNO_DETACH (prevent the parent from forking) and  -DFOREGROUND (prevent the parent from calling setsid() et al) do not provide?  Use of some hack like -C 'ErrorLog '|cat'' can force error logging to stderr, possibly some easier way with -E and /proc/*/fd. joe, hi,  thanks for pointing that out!  i'll try it out.  funny.  been looking for this for nearly 18 months, and richard's been looking for it for probably three years.  i'll boot up my laptop with depinit on it and let you know, straight away, if it works.  ok: yes, that works as expected.  so the question becomes, really, how come two experienced linux developers could not find that option, easily, by looking in every place that they could think of?  man pages, online, documentation - nothing mentions -DFOREGROUND in any of the kinds of prominent places in which you'd expect to find advice on how to run the world's most popular web server in a mode which dramatically changes how it operates.  bizarre!   Obligatory 'use the source, Luke' jokes aside, no answers... changing to Docs bug. Added to the docs for httpd -D in trunk.			Joe Orton	Joshua Slive	Luke Kenneth Casson Leighton
41193	null	CLOSED		Davi Arnaut	1166354280000	1166943177000		Remove useless call Remove useless calls to apr_os_sock_get	Created an attachment (id=19272) Remove useless calls to apr_os_sock_get  thanks for the patch committed to trunk			Davi Arnaut	Jeff Trawick
41231	null	RESOLVED		Michael Stapelberg	1166738340000	1194332608000		SSL: using connection: upgrade leaves plaintext from PHP in reply I'm issuing a request:  GET /index.php HTTP/1.1 Host: localhost Upgrade: TLS/1.0 Connection: upgrade  And my client crashes because it can't parse the plaintext given back by  index.php (which contains <?php for ($i = 0; $i < 10; $i++) echo 'foobar'; ?>).  In strace it's clearly visible: [pid 16349] recv(8, '/24/3/1/0/1/1/26/3/1/0000f/212W/335/273/16L/352/357/3054/32/204/311/376 /264a4l/3670/17/303e/224/202/370!/361/271/311/320/360/356/210ZN/255w/314 ~/351/377=}/250irfoobarfoobarfoobarfoobarfoobarfoobarfoobarfoobarfoobarfoobar', 2048, 0) = 119  If an OPTION * HTTP/1.1-request is sent before, it correctly switches and  processes the next request.  You can reproduce it by using tlsupgrade.c: Get http://people.apache.org/~bnicholes/tlsupgrade/tlsupgrade.c Compile it with gcc -lssl -o tlsupgrade tlsupgrade.c Run it using: strace -s 2048 ./tlsupgrade http://localhost/index.php SSLEngine needs to be set to optional for the vhost (on port 80).	Apparantly the APR_BUCKET_IS_EOC is true for some reason, so  ssl_filter_io_shutdown is called and the result is not filtered via SSL  anymore. Before APR_BUCKET_IS_EOC is true, ssl_filter_write (which is called  when APR_BUCKET_IS_EOC is not true) is called two times with NULL as data- pointer.   I don't know if this is normal behaviour and i'm not very into debugging  apache, but maybe it gives a hint to the developers. Fixed on trunk:  http://svn.apache.org/viewvc?view=rev&revision=592446			Joe Orton	Michael Stapelberg
41475	null	RESOLVED		Lars Uffmann	1169792820000	1179411611000		mod_cache does not serve (CACHE_OUT) URLs which are url-escaped Max OS X, Linux, Solaris Apache: 2.2.4  When an object is cached who's URL is url-escaped (containg spaces, etc), mod_cache will never serve the cached file because the key-lookup to locate the cached file is performed using the escaped URL. Instead the file is cached over and over again, using the unescaped URL as the key.  PS: I added the ap_log_error to cache_generate_key_default() in cache_storage.c  Test-config:  <Location /tmc/>   ExpiresActive On   ExpiresDefault A31536000 </Location> CacheEnable disk /tmc/ ...  # mkdir -p htpdocs/tmc # cp /etc/hosts htdocs/tmc/bla.txt  # cp /etc/hosts htdocs/tmc/foo/ bar.txt  This problem is quite similar in effect to #40805.  # curl -D - -o /dev/null 'http://localhost/tmc/foo%20bar.txt'  request #1  Fri Jan 26 14:41:16 2007] [debug] cache_storage.c(432): cache_generate_key_default(): key is 'http:// localhost:80/tmc/foo%20bar.txt?' [Fri Jan 26 14:41:16 2007] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /tmc/foo% 20bar.txt [Fri Jan 26 14:41:16 2007] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /tmc/foo% 20bar.txt [Fri Jan 26 14:41:16 2007] [debug] cache_storage.c(432): cache_generate_key_default(): key is 'http:// localhost:80/tmc/foo bar.txt?' [Fri Jan 26 14:41:16 2007] [debug] mod_cache.c(609): cache: Caching url: /tmc/foo%20bar.txt [Fri Jan 26 14:41:16 2007] [debug] mod_cache.c(615): cache: Removing CACHE_REMOVE_URL filter. [Fri Jan 26 14:41:16 2007] [debug] mod_cache.c(658): cache: Added date header [Fri Jan 26 14:41:16 2007] [debug] mod_disk_cache.c(954): disk_cache: Stored headers for URL http:// localhost:80/tmc/foo bar.txt? [Fri Jan 26 14:41:16 2007] [debug] mod_disk_cache.c(1043): disk_cache: Body for URL http://localhost: 80/tmc/foo bar.txt? cached.   request #2  [Fri Jan 26 14:41:44 2007] [debug] cache_storage.c(432): cache_generate_key_default(): key is 'http:// localhost:80/tmc/foo%20bar.txt?' [Fri Jan 26 14:41:44 2007] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /tmc/foo% 20bar.txt [Fri Jan 26 14:41:44 2007] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /tmc/foo% 20bar.txt [Fri Jan 26 14:41:44 2007] [debug] cache_storage.c(432): cache_generate_key_default(): key is 'http:// localhost:80/tmc/foo bar.txt?' [Fri Jan 26 14:41:44 2007] [debug] mod_cache.c(609): cache: Caching url: /tmc/foo%20bar.txt [Fri Jan 26 14:41:44 2007] [debug] mod_cache.c(615): cache: Removing CACHE_REMOVE_URL filter. [Fri Jan 26 14:41:44 2007] [debug] mod_cache.c(658): cache: Added date header [Fri Jan 26 14:41:44 2007] [debug] mod_disk_cache.c(954): disk_cache: Stored headers for URL http:// localhost:80/tmc/foo bar.txt? [Fri Jan 26 14:41:44 2007] [debug] mod_disk_cache.c(1043): disk_cache: Body for URL http://localhost: 80/tmc/foo bar.txt? cached.   # curl -D - -o /dev/null 'http://localhost/tmc/bla.txt'   request #1 [Fri Jan 26 14:44:21 2007] [debug] cache_storage.c(432): cache_generate_key_default(): key is 'http:// localhost:80/tmc/bla.txt?' [Fri Jan 26 14:44:21 2007] [debug] mod_cache.c(129): Adding CACHE_SAVE filter for /tmc/bla.txt [Fri Jan 26 14:44:21 2007] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL filter for /tmc/ bla.txt [Fri Jan 26 14:44:21 2007] [debug] cache_storage.c(432): cache_generate_key_default(): key is 'http:// localhost:80/tmc/bla.txt?' [Fri Jan 26 14:44:21 2007] [debug] mod_cache.c(609): cache: Caching url: /tmc/bla.txt [Fri Jan 26 14:44:21 2007] [debug] mod_cache.c(615): cache: Removing CACHE_REMOVE_URL filter. [Fri Jan 26 14:44:21 2007] [debug] mod_cache.c(658): cache: Added date header [Fri Jan 26 14:44:21 2007] [debug] mod_disk_cache.c(954): disk_cache: Stored headers for URL http:// localhost:80/tmc/bla.txt? [Fri Jan 26 14:44:21 2007] [debug] mod_disk_cache.c(1043): disk_cache: Body for URL http://localhost: 80/tmc/bla.txt? cached.  request #2 [Fri Jan 26 14:44:43 2007] [debug] cache_storage.c(432): cache_generate_key_default(): key is 'http:// localhost:80/tmc/bla.txt?' [Fri Jan 26 14:44:43 2007] [debug] mod_disk_cache.c(477): disk_cache: Recalled cached URL info  header http://localhost:80/tmc/bla.txt? [Fri Jan 26 14:44:43 2007] [debug] mod_disk_cache.c(750): disk_cache: Recalled headers for URL  http://localhost:80/tmc/bla.txt? [Fri Jan 26 14:44:43 2007] [info] Incoming request is asking for a uncached version of /tmc/bla.txt, but  we know better and are ignoring it [Fri Jan 26 14:44:43 2007] [debug] mod_cache.c(263): cache: running CACHE_OUT filter [Fri Jan 26 14:44:43 2007] [debug] mod_cache.c(277): cache: serving /tmc/bla.txt	*** Bug 41516 has been marked as a duplicate of this bug. *** Could you please give the attached patch a try and report back whether it solves your problem? Created an attachment (id=19529) Patch against trunk  (In reply to comment #2) > Could you please give the attached patch a try and report back whether it solves > your problem?  I applied your patch against 2.2.4.  The testcase I used to report the problem (see above) worked for me. (In reply to comment #4) > (In reply to comment #2) > > Could you please give the attached patch a try and report back whether it solves > > your problem? >  > I applied your patch against 2.2.4. >  > The testcase I used to report the problem (see above) worked for me.  Confirming that this solved my problems also (duplicate reported bug 41516), when applied to 2.2.4. Thanks for the feedback. Committed to trunk as r506621 (http://svn.apache.org/viewvc?view=rev&revision=506621). Backported to 2.2.x as r539112 (http://svn.apache.org/viewvc?view=rev&rev=539112).			Dean Scothern	Lars Uffmann	Ruediger Pluem
41484	null	RESOLVED		Fredrik Widlund	1169988720000	1179411626000		Suggest adding CacheIgnoreQueryString option to mod_cache Hi,  I have a need to use caching to improve performance when delivering for example banners. Since query-string parameters are used to associate unique meta-information to each request mod_cache will treat each request as a new request. Since mod_cache is run as a quick handler it is not possible to use mod_rewrite to remove the query-string part of the request.  I believe this should be considered a relevant scenario, and that an option to disable this behaviour is motivated.  I am including a patch for this below.  Kind regards, Fredrik Widlund  --- cache_storage.c.orig        Sun Jan 28 20:12:51 2007 +++ cache_storage.c     Sun Jan 28 20:25:01 2007 @@ -331,10 +331,16 @@  apr_status_t cache_generate_key_default(request_rec *r, apr_pool_t* p,                                          char**key)  { +    cache_server_conf *conf;      char *port_str, *hn, *lcs;      const char *hostname, *scheme;      int i;   +    /* Get the module configuration. We need this for the CacheIgnoreQueryString +     * below */ +    conf = (cache_server_conf *) ap_get_module_config(r->server->module_config, +                                                     &cache_module); +      /*       * Use the canonical name to improve cache hit rate, but only if this is       * not a proxy request or if this is a reverse proxy request. @@ -424,10 +430,14 @@          /* Use the server port */          port_str = apr_psprintf(p, ':%u', ap_get_server_port(r));      } - -    /* Key format is a URI */ -    *key = apr_pstrcat(p, scheme, '://', hostname, port_str, -                       r->parsed_uri.path, '?', r->args, NULL); +     +    /* Key format is a URI, optionally without the query-string */ +    if (conf->ignorequerystring) +       *key = apr_pstrcat(p, scheme, '://', hostname, port_str, +                          r->parsed_uri.path, '?', NULL); +    else +       *key = apr_pstrcat(p, scheme, '://', hostname, port_str, +                          r->parsed_uri.path, '?', r->args, NULL);        return APR_SUCCESS;  } --- mod_cache.c.orig    Sun Jan 28 20:32:48 2007 +++ mod_cache.c Sun Jan 28 20:32:32 2007 @@ -433,7 +433,8 @@          /* if a Expires header is in the past, don't cache it */          reason = 'Expires header already expired, not cacheable';      } -    else if (r->args && exps == NULL) { +    else if (!conf->ignorequerystring && +            r->parsed_uri.query && exps == NULL) {          /* if query string present but no expiration time, don't cache it           * (RFC 2616/13.9)           */ @@ -889,6 +890,8 @@      ps->no_last_mod_ignore = 0;      ps->ignorecachecontrol = 0;      ps->ignorecachecontrol_set = 0; +    ps->ignorequerystring = 0; +    ps->ignorequerystring_set = 0;      ps->store_private = 0;      ps->store_private_set = 0;      ps->store_nostore = 0; @@ -929,6 +932,10 @@          (overrides->ignorecachecontrol_set == 0)          ? base->ignorecachecontrol          : overrides->ignorecachecontrol; +    ps->ignorequerystring  = +       (overrides->ignorequerystring_set == 0) +       ? base->ignorequerystring +       : overrides->ignorequerystring;      ps->store_private  =          (overrides->store_private_set == 0)          ? base->store_private @@ -970,6 +977,19 @@      return NULL;  }   +static const char *set_cache_ignore_querystring(cmd_parms *parms, +                                               void *dummy, int flag) +{ +    cache_server_conf *conf; +     +    conf = +       (cache_server_conf *)ap_get_module_config(parms->server->module_config, +                                                 &cache_module); +    conf->ignorequerystring = flag; +    conf->ignorequerystring_set = 1; +    return NULL; +} +  static const char *set_cache_store_private(cmd_parms *parms, void *dummy,                                             int flag)  { @@ -1159,6 +1179,9 @@      AP_INIT_FLAG('CacheIgnoreCacheControl', set_cache_ignore_cachecontrol,                   NULL, RSRC_CONF,                   'Ignore requests from the client for uncached content'), +    AP_INIT_FLAG('CacheIgnoreQueryString', set_cache_ignore_querystring, +                NULL, RSRC_CONF, +                'Ignore query-string when caching'),      AP_INIT_FLAG('CacheStorePrivate', set_cache_store_private,                   NULL, RSRC_CONF,                   'Ignore 'Cache-Control: private' and store private content'), --- mod_cache.h.orig    Sun Jan 28 20:26:16 2007 +++ mod_cache.h Sun Jan 28 20:27:29 2007 @@ -138,6 +138,9 @@      /** ignore client's requests for uncached responses */      int ignorecachecontrol;      int ignorecachecontrol_set; +    /** ignore query-string when caching */ +    int ignorequerystring; +    int ignorequerystring_set;      /** ignore Cache-Control: private header from server */      int store_private;      int store_private_set;	Created an attachment (id=19473) Patch to add CacheIgnoreQueryString option  The patch looks good in general. Please fix the following things such that it can be appplied:  1. Provide a version of this patch against trunk. 2. Provide a patch for the documentation (docs/manual/mod/mod_cache.xml) to    document the new directive. 3. Provide the diff files in unix format (only LF at the end) if possible.    Otherwise just mention that they are in DOS format (CR-LF). Forgot one thing:  Please put  int ignorequerystring; int ignorequerystring_set;  at the end of the cache_server_conf struct to avoid binary incompatibility and thus the need for a major bump. A patch that creates binary incompatibility cannot be backported to 2.2.x. Putting them to the end of the structure only requires a minor bump which can be backported (include/ap_mmn.h). Created an attachment (id=19527) Patch against trunk adding IgnoreQueryString directive  Created an attachment (id=19528) Patch against trunk adding documentation for IgnoreQueryString  1/2/3: Done  Kind regards, Fredrik Widlund Committed with some minor style fixes as r504183 (http://svn.apache.org/viewvc?view=rev&revision=504183) to trunk. For future patches please ensure that they follow the style guide (http://httpd.apache.org/dev/styleguide.html) (especially no tabs). Thanks for submitting the patch. Proposed for backport to 2.2.x as r535911 (http://svn.apache.org/viewvc?view=rev&rev=535911). Backported to 2.2.x as r539111 (http://svn.apache.org/viewvc?view=rev&rev=539111). I am pretty sure this was not committed to the 2.2.4 release. Is this version set correctly?			Fredrik Widlund	Ruediger Pluem	Thomas Van de Velde
41551	null	RESOLVED		Xuekun Hu	1170804120000	1188190080000		mod_mem_cache cache incorrect header Hi,  I'm using Apache2.2.4 (worker+mod_mem_cache). I just used mod_mem_cache to  cache some little files. However after run severl minutes, I found the file  content sent by mod_mem_cache are incorrect!!   I captured the response package. And I found those error packages are sending   the wrong http headers, like including several headers, wrong ETag value. Seems  like memory overflow!! For example, one response are: -----------------------------------------------------------------------  HTTP/1.1 200 OK Date: Thu, 25 Jan 2007 11:30:51 GMT Server: Apache/2.2.4 (Unix) mod_jk/1.2.15 Last-Modified: Thu, 01 Jan 1970 00:00:00 GMT ETag: 2<uwJU@x@)IzNFELwphctT&^r^MvqY kP/k'gZ@Zrs3a-_S+'A@z%49o[9nyUX^-eR9j1*(lp9B4A3)R]J2?yi:sbVxZJV ?('9e@tFn$>.cokt;ao/V|^tXj/UIo-|Xz6YX(nXE9:y/OcK5Yl7]%D3"#s=+;o cZci>tNQ+|UUp5RETf>f72<{b*0ICP*gz0>'|2UAY'4VeIfL;?4S>*0t9:V9B|B hML1)p?]grrJ/ku4"h/'N(H63PEi@$qfiP<;f,$7a<Ogy7<[rR]!TMZf{c1($]M -a_Sb,W"09|)D|NnaD"jHrd*h4ck6]W&xy?sv)]uVZ#u?d!^q/TBM1sD/&.'SM/ Ad.W1[2)(2RgwQO.2^wQ|/s?^9np7MiN:9/A|V.xki1C8u164bo6pD,#>Jl2IX, ZdOG;b4>ET>|%2[6Sv;vE_eLhtFhj/jlyA@QQKj"k3/ONE='7j'Ty.73"w&a-DE l%@X&H:T*,x/@BbVPST!)Tbfjh0RS+yUI@',{sMP/I'z:M?_'dQadTN;'ob&_w" EE[)/wj{'r:&]J|H%%j#W8>)0bZrJzlHH4:vLw[xyrtC]IY9%_pH-R8l(3?V#-N fqo,?$R'<aE6aa1N7iU,,(>,Bv2zk<Z+Gqg''O/nFxV/Zpz3I(_Z|hYi26f!n'X tp"fyb!iqrBV7e6(h?6'zKL@PGc$bJsgc1$ZkrHL<tYJ1OFb,_h'5]!$XrMB^]! 94/>=OObnMgS33U'bg+Uf26dC:!4"8h_n>'w>U0/!mqc6-9yD#gN%.pV3DeJHsE KNfI+wCCH]BPin<sChB21XKr1+pgDuWLzHGOkg>Jg0F'q,_I|M^$cnVbi7cU-T$ =eFc;h(8jov[Adbcy#>-n7G3l!DU!>f!zDx.#q42T1i-Z)H'4e*M6."jhLnj0P' +.H[yP'n?b7=KmoTwGCg,@rbV1Qf5n[4rRn/$7yB^/"zu?='@v3h$RdG7wJQY)K 1e/&zO5y-w5q('?NQmuPa'PAi.;-Os0NN>Nx/8Qk(kEb/0pILMbRd!Dd>3s80D/ o1s3@'#iSV0!'CJlDuDKlkmh41_s+>$*K?F{-i@Uz(+16t#xlqF''/SZ!-)miPG U[PkYIO!Yfuz'tlGNb|"6[983jtwyB?F?A8Xmr*[@+^F|AuW!/o9k:50d)T)Twq "f'n(?ou;(*ZBL-3=9Ue)/]Y[p1nNEI'lf2lNF3KS4BI()6smg1?q(bc'.0[b&O F;=?q=V'&Lyq+_VGke@H*"$32/d[@3W<DS'[bV0^-c/wVX'+F(@#)r*/{5'LAxH IJI#(SXmlmak6+]4n+p-F;]5V&00er+JQ[;hU]GR4+eXJ_]T;Cx*LS!|:m$#3G8 |vgF]TA_/d!G#Z,5-sTV,^J4UurZ['?,v$5/IDRcV(]"dN?.H"1@5ll1n7pq7([ '/eoDI1&R0#R*"VS8Mjy[q&{q&h<h=1x{CD[w'(5]SQ*)"uty*|(41&:n3%*dRq RD9s:61RDRK3XO?n/TIF-dmK]1c0#Vgo@#0XLM1{x4s/w;M':j#GU=.ubloj@N# Y=fI-2c{{^_?/tOIr$5jq&xpAaT_hc0XqE.Hbge6{76^h@ek/GH@Hi>TBob(;c+ i,8OS2aTS_dv5j*e^VCE"+UIU&y@S7huO!Xj?mTmz#Z,Ca0W-z2X%HysN[NxO{g TDSvcaFVVz_3ms5*uV)bdA^K52p"UKO[HZ<WzVFUUECIcJjD2cIKxxW?{a?Sa/M P;kma")4q#*?'xjO1L-*BUuUjwDOHcUEFE1;oGwzQl!lzko2x5]@62$P{aRY*'3 o.m'1oT/q93&{(#M<g)!c^h$F--,Nnk|<.#Q:7L+$e(*@S3xJiFTJuYZ@Wf^/Q( s4GQ#arbPmAg5T{70$KnVbbTsyc4fe'_*xf6W?$ExHU6_;>b4;$oKOX"4j*aApl K#?s[/PwP6DkqxZB"Z:j?:Kdt;'^{wCLh|662k_k<pbm|&QbVBlt/LWjeBLKDVS {kHTiH@w(1TIxwp'T2*5u){aMWoOsif4J5?lT'@C,vAKX!>^,wl"I58FBY3#e@& +%1t&m@m4.m6L>q^5l3V',J?FPhC-_$:X,>t#yB'0!UgEHG.>eVJIzu)K|gJh'? hmXf%bz3pHTzGHQ'A[9:vW-y_Fkunqalva%pu0vo8RBZE*{G1e=c(c-."N,<J_T D'$7I2XJpxgxT&h4mH-t+yr"DGK.8N]_=?ZB)V-84U(L7XrA+'MC|;,k*][XY0L !::f@Zm]xAlQo"?FFJ)=>3Sp5Y,FDJLfp;(WST{U]MK$'Z0PbfrE&gk1grzC.l* 27<X%nau9%&]<IYA+.sA"9C|KLf@o^S2FAgB+]U8MkG_]G5?eg4&{2P#iLKenxT fq(1LM,rn1@33.9]xp6;@FJPPFQYD'@>ED'D%nfkj;-qEK1[d^wV:i,'NLuylTN /E(82(nsb,a"8')I=$jP6?8Z.4IH7NE@@$4l:79J/dCU@"=37bT(Opd'"n;(dk& p6*F-#x!W<no$;Di2%s_]SmXlYgfhEiyTcv"0'PB"[[SP@cl:HM5B*[jvAkUvra ff=fCE0?P2DqySbc{W5E@[-Bj3-S3,TT_o&=ek:sY(8a_HubaCTX+,,3PFL5.Ap wWU%^Ohf!9WnizXy|sd.t[qftGmF(.&_fEF6/s"dvRfAg+R8q(Hv'9</pre> </body> </html>  Accept-Ranges: bytes Content-Length: 2170 Expires: Fri, 26 Jan 2007 11:27:58 GMT Age: 107 Content-Type: text/plain; charset=ISO-8859-1  Accept-Ranges: bytes Content-Length: 90 Expires: Fri, 26 Jan 2007 11:27:11 GMT Age: 158 Content-Type: text/plain; charset=ISO-8859-1 ... ---------------------------------------------------------------------  While I also tested Apache2.2.3+mod_mem_cache, Apache2.2.4 without  mod_mem_cache, Apache2.2.4+mod_disk_cache, all work fine.  So, there must something wrong in mod_mem_cache itself.  I compared with mod_mem_cache in 2.2.3 vs. 2.2.4, the big change is using APR  memory pool to cache http header, instead of malloc. However I had no idea what  the real reason is.   Any thoughts?  Thx, Xuekun	I am seeing the etag blown away on 2.2.4 and trunk as well, running with a single child process and no concurrent connections.  This happens _before_ revalidation based on Expires or Age (on a particular system/config 4th non-conditional request gets the ETag removed in some way (truncated, random garbage)  I was occasionally seeing the Last-Modified time set to 0 as well, but not able to reproduce it as easily. Created an attachment (id=19948) don't use apr_table_copy to store/recall headers  naive patch to deep copy in/out headers before storing/retrieving from cache.  when retrieving, we only bother to do the deep copy to appease pool debugging, who would abort even when the cache pool is longer living, but not an ancester of, the request pool.  (In reply to comment #2) > Created an attachment (id=19948) [edit] > don't use apr_table_copy to store/recall headers > naive patch to deep copy in/out headers before storing/retrieving from cache. > when retrieving, we only bother to do the deep copy to appease pool debugging, > who would abort even when the cache pool is longer living, but not an ancester > of, the request pool.  No. Your patch didn't resolve this issue. The same error still was blown away.  Ouch, that's my fault. I naively believed that apr_table_copy copied the table data. We should revert  revision 484642 ASAP. Created an attachment (id=20064) table copy warning  Created an attachment (id=20065) deep table copy  Could you try the above patch and let me know if you still have these errors? Thanks. (In reply to comment #7) > Could you try the above patch and let me know if you still have these errors?  Thanks.  I tried your patch with several hours run, all seems fine. Thanks    Created an attachment (id=20150) table copy (clone) function for apr  Backported to 2.2.x as r555626 (http://svn.apache.org/viewvc? view=rev&revision=555626).			Davi Arnaut	Eric Covener	Ruediger Pluem	Xuekun Hu
41796	null	RESOLVED		Michael Krieger	1173376140000	1173685807000		Internal Dummy Connection should process effortlessly It's clear that the Internal Dummy Connection requests are needed and it is my understanding that these exist in 2.0 but however are not logged.  My concern is not with them existing or logging, but with the request that is being made. The 'GET /' request used causes dynamic pages to generate- in some cases with tens or hundreds of requests in a matter of a few seconds.  A dynamic page I have shows these Internal dummy connections making tens of database queries to generate and returning 100-200KB of data to the dummy connection.  This should be changed to either:  a) request something else other than 'GET /', such as using 'OPTIONS *', or 'GET /robots.txt' or 'GET /apache_internal_dummy_file.txt' that would not be used or would not incur the massive processing of many of today's Web sites.  -OR- (better yet)  b) be handled specially by the request handler that in the case of a connection from the local IP with that user agent, it should avoid as much advanced processing as possible(rewrite rules, PHP scripts, Perl scripts, SSI, Directory restrictions, htaccess processing, etc), and simply return a very short 'ACK' style request with only the necessary headers to be deemed valid.  When the whole server approaches the request limit near the same time or receives certain commands that dispatch these, it is important that it is not making requests it shouldn't.  Advertisers and users depend on these database requests to count pageviews and other measures that Apache suddenly adds hundreds of throughout a day... which can add up and show a difference in pageviews from what actually is occuring.	My TEMPORARY solution was to create these virtualhosts (apparently it's an IP6 request in my configuration, so I needed the second).  <Virtualhost 127.0.0.1>         ServerName      localhost         DocumentRoot    /var/www </VirtualHost> <Virtualhost [::1]>         ServerName      localhost         DocumentRoot    /var/www </VirtualHost>  At least these I know will return MY dummy file instead of a huge PHP script where the database queries and numbers do matter.  However, this issue needs to be addressed if this method is used to wake up the children.  Making requests blindly and without care to a Web server can throw off numbers in more than the logs in an era where everything is dynamic.  The REQUEST FILE either NEEDS to be configurable, or the HOST NEEDS to be configurable, or the request TYPE needs to be harmless and dealt with internally, or the request needs to be silently handled internally without doing any processing.  Either way really, with the preference being internally handling it, then changing the type.  Agreed, as discussed recently on dev@ - committed in:   http://svn.apache.org/viewvc?view=rev&revision=517233			Joe Orton	Michael Krieger
41798	null	RESOLVED		Mike Cardwell	1173406800000	1206978180000		mod_proxy rewrites url paths badly This is related to bugs 39746 and 38448.  After turning on AllowEncodedSlashes, Apache lets us use percent encoded forward slashes in the path. Eg:  'http://foo/hello%2Fworld'  When using 'ProxyPass / http://bar/'  mod_proxy makes a request for:  'http://bar/hello/world'  That is wrong as I understand it. The forward slash at the end should be encoded still.  RFC-1738, section 3.3 regarding HTTP URLs:  'Within the <path> and <searchpart> components, '/', ';', '?' are reserved. The '/' character may be used within HTTP to designate a hierarchical structure.'  So... The forward slash is a reserved character. Section 2.2 says the following about reserved characters:  'If the character corresponding to an octet is reserved in a scheme, the octet must be encoded.'  So as far as I can see http://foo/hello%2Fworld and http://foo/hello/world are distinctly different HTTP URLs that should be allowed to behave differently. Just because Apache treats them the same when serving local content, doesn't mean that other servers do when you're proxying the request to them, so I don't think the path should be rewritten in the way mod_proxy is doing it...  Perhaps there should be an option called something like 'ProxyPreservePathEncoding' which when turned on, means that *no* encoding/decoding of the path in the url is performed before it is proxied...  If my browser makes a request for 'http://foo/hello%2Fworld' and I have 'ProxyPass / http://bar/' I *expect* it to call 'http://bar/hello%2Fworld' not 'http://bar/hello/world' as it does currently. It *should* be the default behaviour, but that would probably not be backwards compatible.  Mike	*** Bug 35100 has been marked as a duplicate of this bug. *** *** Bug 42592 has been marked as a duplicate of this bug. *** *** Bug 39455 has been marked as a duplicate of this bug. *** Fixed in Trunk in r588791. Fixed in r596712. I have an instance of mod_proxy doing reverse proxying using the 'nocanon' parameter in the ProxyPass directive. The reason I needed this was that I'm dealing with IRIs on the path, and mod_proxy was decoding the characters for me.  In any case, I find that when 'nocanon' is turned on, mod_proxy appends the query twice and sent it to the target host, e.g.:  Original request:  http://mod-proxy-host.com/path?query  The target was sent:  http://localhost:8003/target?query?query   This seems to be due to r->unparsed_uri containing the original query, whereas r->uri doesn't (and other parts of the code appends it to the target.) Created an attachment (id=21743) Proof-of-concept that fixes the issue  This is meant to demonstrate that it fixes the issue. However, I have not checked for security issues or whether it breaks other configurations. Comments 6 and 7 appear to be opening a new report.  Please don't hijack an old report for that.  And if we're to take your NEW report seriously, we'll need more information, such as a configuration and request that trigger the problem with 2.2.8. Sorry for hijacking this report. I've created bug 44730 to track the issue.			Nick Kew	Wil Tan
41826	null	RESOLVED		Tom Payerle	1173715920000	1174983462000		order directive: text and table disagree on no-match case In reference to page http://httpd.apache.org/docs/2.2/mod/mod_authz_host.html#order  Text for order Deny,Allow option states requests not matching any deny or allow statements are DENIED.  Table states that Deny,Allow and no-match => ALLOW (default to second)  Similarly, text for Allow,Deny states non-matching requests defaults to ALLOW, but table shows DENIED.  Same disagreement in 1.3 docs (http://httpd.apache.org/docs/1.3/mod/mod_access.html#order)  2.0 documentation does not have a table, and text supports the tabular version.	*** Bug 41833 has been marked as a duplicate of this bug. *** Fixed. Thanks. *** Bug 41767 has been marked as a duplicate of this bug. *** please backport to 2.0 http://httpd.apache.org/docs/2.0/en/mod/mod_access.html backported http://svn.apache.org/viewvc?view=rev&revision=561438			Joshua Slive	Ruediger Pluem	Takashi Sato
41829	null	RESOLVED		Torsten F	1173748020000	1174901129000		usage of an uninitialized structure member in server/request.c in ap_directory_walk the opts structure represents the currently active options and allowed overrides. In 2.2.0 'AllowOverride Options=...' was introduced and with it a new member of this structure override_opts. Unfortunately this member is not properly initialized from this_dir->override_opts. This prevents maptostorage handlers from inserting additional configuration statements like mod_perls '$r->add_config(['AllowOverride Options'])'. With Apache 2.0.x this has worked but has ceased to since 2.2.0 because opts.override_opts is by chance 0.  This simple patch cures the problem:  --- server/request.c~   2007-03-11 17:20:25.000000000 +0100 +++ server/request.c    2007-03-11 17:50:01.000000000 +0100 @@ -631,6 +631,7 @@          opts.add = this_dir->opts_add;          opts.remove = this_dir->opts_remove;          opts.override = this_dir->override; +        opts.override_opts = this_dir->override_opts;           /* Set aside path_info to merge back onto path_info later.           * If r->filename is a directory, we must remerge the path_info,	Created an attachment (id=19700) it initializes opts.override_opts properly  Fixed as revision 522011, see  http://svn.apache.org/viewvc?view=rev&revision=522011			Torsten F
41835	null	RESOLVED		Ricardo Tavizon	1173801120000	1186120095000		smart filtering not working for some match arguments The provider for smart filtering is not being called when the match matches  the value declared as dispatch for integer and unconditional arguments. ie,  you have next directives in httpd.conf -> SetEnv foo 99                                       FilterProvider include INCLUDES env=foo <100               FilterChain include And the document including the shtml file won't display it. From mod_filter.c in filter_lookup() some changes need to be done. See below an excerpt from the code that i modified         if (!str) {             // if (provider->match_type == DEFINED && provider->match.string)  { /* THIS IS NOT ALWAYS TRUE SINCE match_type MAY BE A DIFFERENT TYPE */                 match = 0;             //}         }         //else if (!provider->match.string) {\t/* IS BETTER TO VERIFY NOT  NULLS BELOW FOR provider->match.string AND provider->match.regex ONLY */         //    match = 0;         //}         else {             /* Now we have no nulls, so we can do string and regexp matching */             switch (provider->match_type) {             case STRING_MATCH:                 if (strcasecmp(str, provider->match.string)) {                     match = 0;                 }                 break;             case STRING_CONTAINS:                 str1 = apr_pstrdup(r->pool, str);                 ap_str_tolower(str1);                 if (!strstr(str1, provider->match.string)) {                     match = 0;                 }                 break;             case REGEX_MATCH:                 if (ap_regexec(provider->match.regex, str, 0, NULL, 0)                     == AP_REG_NOMATCH) {                 match = 0;                 }                 break;             case INT_EQ:                 if (atoi(str) != provider->match.number) {                     match = 0;                 }                 break;             case INT_LT:                 if (atoi(str) >= provider->match.number) { /* IF YOU CONSIDER  match IS SET TO 1 AND ONLY WILL BE SET TO ZERO FOR FAIL CASES THEN INCOMING */ \t\t\t\t\t\t\t   /* INTEGER MUST BE  GREATHER-THAN OR EQUAL TO SPECIFIED NUMBER. IT MAKES SENSE AS YOU SEE BELOW */ \t\t\t\t\t\t\t   /* FOR INT_EQ WHERE  THE CONDITION IS != AND NOT == AND THIS APPLIES TO ALL NUMERIC COMPARISON. */                     match = 0;                 }                 break;             case INT_LE:                 if (atoi(str) > provider->match.number) {  /* REVERSE  CONDITION */                     match = 0;                 }                 break;             case INT_GT:                 if (atoi(str) <= provider->match.number) {  /* REVERSE  CONDITION */                     match = 0;                 }                 break;             case INT_GE:                 if (atoi(str) < provider->match.number) {  /* REVERSE  CONDITION */                     match = 0;                 }                 break;             case DEFINED:        /* we already handled this:-) */                 break;             }         }	This is a bug, but it's actually just some of the comparisons being reversed! In a related bug, integer comparisons to 0 will fail.  Hacking a patch now.			Nick Kew
42005	null	RESOLVED		Christophe JAILLET	1175350260000	1184870690000		Code clean up (in file /modules/cache/cache_cache.c) The function 'cache_find' of /modules/cache/cache_cache.c can be simplified a  bit.	Created an attachment (id=19853) Proposed patch  http://svn.apache.org/viewvc?view=rev&revision=557837 			Christophe JAILLET	Nick Kew
42006	null	RESOLVED		Christophe JAILLET	1175350980000	1184870706000		Code clean up (in file /server/request.c) The function 'ap_sub_req_loo' of /server/request.c can be simplified a bit.  These strcpy + strlen combinaisons really look like an ugly strcat.	Created an attachment (id=19854) Proposed patch  Created an attachment (id=19858) Corrected patch  http://svn.apache.org/viewvc?view=rev&revision=557837 			Christophe JAILLET	Nick Kew
42007	null	RESOLVED		Christophe JAILLET	1175351580000	1184870727000		Code clean up (apr_pcalloc) apr_palloc + memset can be safely be replaced by the equivalent apr_pcalloc  that makes code a bit more compact.  This has already been discussed in this old thread : http://mail-archives.apache.org/mod_mbox/httpd-dev/200511.mbox/% 3c20051126100823.GA31626@redhat.com%3e	Created an attachment (id=19855) Proposed patch  http://svn.apache.org/viewvc?view=rev&revision=557837 			Christophe JAILLET	Nick Kew
42008	null	RESOLVED		Christophe JAILLET	1175352360000	1197095828000		Code clean up (in file /modules/metadata/mod_usertrack.c) Some code can be simplified in function 'make_cookie' of  file 'modules/metadata/mod_usertrack.c' to avoid code duplication.	Created an attachment (id=19856) Proposed patch  http://svn.apache.org/viewvc?view=rev&revision=557837  This patch is not contained in r557837.			Christophe JAILLET	Nick Kew	Ruediger Pluem
42009	null	RESOLVED		Christophe JAILLET	1175352780000	1184870751000		Code clean up (ap_str_tolower) In some cases, we loop with 'apr_tolower' to lower a whole string instead of  using the equivalent 'ap_str_tolower' function which does it all in one.	Created an attachment (id=19857) Proposed patch  http://svn.apache.org/viewvc?view=rev&revision=557837 			Christophe JAILLET	Nick Kew
42031	null	RESOLVED		Takashi Sato	1175568600000	1189463428000		EventMPM child process freeze Child process freezes with many downloading against MaxClients.  How to reproduce:  (1) configuration to httpd.conf  StartServers          1 MaxClients          3 MinSpareThreads      1 MaxSpareThreads      3 ThreadsPerChild      3 MaxRequestsPerChild   0 Timeout 10 KeepAlive On MaxKeepAliveRequests 0 KeepAliveTimeout 5  (2) put a large file 'test.mpg' (about 200MB) on DocumentRoot (3) apachectl start (4) execute many downloading simultaneously. e.g. bash and wget: $ for (( i=0 ; i<20 ; i++ )); do wget -b http://localhost/test.mpg; done;  Then the child process often freezes. If not, try to download more.  (5) terminate downloading e.g. bash and wget: $ killall wget  (6) access to any file from web browser. However long you wait, server won't response.   'apachectl graceful' then in error log [Tue Apr 03 16:41:14 2007] [debug] event.c(1392): the listener thread didn't  exit  'apachectl stop' then in error log [Tue Apr 03 16:48:18 2007] [warn] child process 31077 still did not exit,  sending a SIGTERM [Tue Apr 03 16:48:20 2007] [warn] child process 31077 still did not exit,  sending a SIGTERM [Tue Apr 03 16:48:22 2007] [warn] child process 31077 still did not exit,  sending a SIGTERM [Tue Apr 03 16:48:24 2007] [error] child process 31077 still did not exit,  sending a SIGKILL    OS: Fedora Core 6 kernel: 2.6.20-1.2933.fc6 glibc: 2.5-10.fc6  httpd revision 525116. $ ./httpd -V Server version: Apache/2.3.0-dev (Unix) Server built:   Apr  3 2007 15:49:09 Server's Module Magic Number: 20060905:2 Server loaded:  APR 1.3.0-dev, APR-UTIL 1.3.0-dev Compiled using: APR 1.3.0-dev, APR-UTIL 1.3.0-dev Architecture:   32-bit Server MPM:     Event   threaded:     yes (fixed thread count)     forked:     yes (variable process count) Server compiled with....  -D APACHE_MPM_DIR='server/mpm/experimental/event'  -D APR_HAS_SENDFILE  -D APR_HAS_MMAP  -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)  -D APR_USE_SYSVSEM_SERIALIZE  -D APR_USE_PTHREAD_SERIALIZE  -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT  -D APR_HAS_OTHER_CHILD  -D AP_HAVE_RELIABLE_PIPED_LOGS  -D DYNAMIC_MODULE_LIMIT=128  -D HTTPD_ROOT='/usr/local/apache2'  -D SUEXEC_BIN='/usr/local/apache2/bin/suexec'  -D DEFAULT_SCOREBOARD='logs/apache_runtime_status'  -D DEFAULT_ERRORLOG='logs/error_log'  -D AP_TYPES_CONFIG_FILE='conf/mime.types'  -D SERVER_CONFIG_FILE='conf/httpd.conf'    backtrace of frozen child process:  Thread 5 (Thread -1219343472 (LWP 30355)): #0  0x007b9402 in __kernel_vsyscall () No symbol table info available. #1  0x4bb3998e in __lll_mutex_lock_wait () from /lib/libpthread.so.0 No symbol table info available. #2  0x4bb357fc in _L_mutex_lock_85 () from /lib/libpthread.so.0 No symbol table info available. #3  0x4bb3533d in pthread_mutex_lock () from /lib/libpthread.so.0 No symbol table info available. #4  0x0055a308 in apr_thread_mutex_lock (mutex=0x83c72f8)     at locks/unix/thread_mutex.c:92         rv = 0 #5  0x08091234 in process_socket (p=0x83f3cd0, sock=0x83f3d10, cs=0x83f3eb0,     my_child_num=0, my_thread_num=0) at event.c:656         output_filter = (ap_filter_t *) 0x83f4448         rv = 0         c = (conn_rec *) 0x83f3f08         pt = (listener_poll_type *) 0x83f3ee8         conn_id = 0         rc = 2         sbh = (ap_sb_handle_t *) 0x83f45c8 #6  0x0809215c in worker_thread (thd=0x83b94e0, dummy=0x83e94e0)     at event.c:1194         ti = (proc_info *) 0x83e94e0         process_slot = 0         thread_slot = 0         csd = (apr_socket_t *) 0x83f3d10         cs = (conn_state_t *) 0x83f3eb0         ptrans = (apr_pool_t *) 0x83f3cd0         rv = 0         is_idle = 0 #7  0x00566f70 in dummy_worker (opaque=0x83b94e0)     at threadproc/unix/thread.c:142         thread = (apr_thread_t *) 0x83b94e0 #8  0x4bb333db in start_thread () from /lib/libpthread.so.0 No symbol table info available. #9  0x4ba1726e in clone () from /lib/libc.so.6 No symbol table info available.    Thread 4 (Thread -1229833328 (LWP 30356)): #0  0x007b9402 in __kernel_vsyscall () No symbol table info available. #1  0x4bb3998e in __lll_mutex_lock_wait () from /lib/libpthread.so.0 No symbol table info available. #2  0x4bb357fc in _L_mutex_lock_85 () from /lib/libpthread.so.0 No symbol table info available. #3  0x4bb3533d in pthread_mutex_lock () from /lib/libpthread.so.0 No symbol table info available. #4  0x0055a308 in apr_thread_mutex_lock (mutex=0x83c72f8)     at locks/unix/thread_mutex.c:92         rv = 0 #5  0x08091234 in process_socket (p=0x83e9c38, sock=0x83e9c78, cs=0x83e9e18,     my_child_num=0, my_thread_num=1) at event.c:656         output_filter = (ap_filter_t *) 0x83ea3b0         rv = 0         c = (conn_rec *) 0x83e9e70         pt = (listener_poll_type *) 0x83e9e50         conn_id = 1         rc = 2         sbh = (ap_sb_handle_t *) 0x83ea818 #6  0x0809215c in worker_thread (thd=0x83b9500, dummy=0x83e94f0)     at event.c:1194         ti = (proc_info *) 0x83e94f0         process_slot = 0         thread_slot = 1         csd = (apr_socket_t *) 0x83e9c78         cs = (conn_state_t *) 0x83e9e18         ptrans = (apr_pool_t *) 0x83e9c38         rv = 0         is_idle = 0 #7  0x00566f70 in dummy_worker (opaque=0x83b9500)     at threadproc/unix/thread.c:142         thread = (apr_thread_t *) 0x83b9500 #8  0x4bb333db in start_thread () from /lib/libpthread.so.0 No symbol table info available. #9  0x4ba1726e in clone () from /lib/libc.so.6 No symbol table info available.    #8  0x4bb333db in start_thread () from /lib/libpthread.so.0 No symbol table info available. #9  0x4ba1726e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 3 (Thread -1240323184 (LWP 30357)): #0  0x007b9402 in __kernel_vsyscall () No symbol table info available. #1  0x4bb3998e in __lll_mutex_lock_wait () from /lib/libpthread.so.0 No symbol table info available. #2  0x4bb357fc in _L_mutex_lock_85 () from /lib/libpthread.so.0 No symbol table info available. #3  0x4bb3533d in pthread_mutex_lock () from /lib/libpthread.so.0 No symbol table info available. #4  0x0055a308 in apr_thread_mutex_lock (mutex=0x83c72f8)     at locks/unix/thread_mutex.c:92         rv = 0 #5  0x08091382 in process_socket (p=0x8419eb8, sock=0x8419ef0, cs=0x841a090,     my_child_num=0, my_thread_num=2) at event.c:697         rc = 0         pt = (listener_poll_type *) 0x841a0c8         c = (conn_rec *) 0x841a0e8         pt = (listener_poll_type *) 0x841a0c8         conn_id = 2         rc = -2         sbh = (ap_sb_handle_t *) 0x841a088 #6  0x0809215c in worker_thread (thd=0x83b9520, dummy=0x83e94e0)     at event.c:1194         ti = (proc_info *) 0x83e94e0         process_slot = 0         thread_slot = 2         csd = (apr_socket_t *) 0x8419ef0         cs = (conn_state_t *) 0x0         ptrans = (apr_pool_t *) 0x8419eb8         rv = 0         is_idle = 0 #7  0x00566f70 in dummy_worker (opaque=0x83b9520)     at threadproc/unix/thread.c:142         thread = (apr_thread_t *) 0x83b9520 #8  0x4bb333db in start_thread () from /lib/libpthread.so.0 No symbol table info available. #9  0x4ba1726e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 2 (Thread -1250813040 (LWP 30358)): #0  0x007b9402 in __kernel_vsyscall () No symbol table info available. #1  0x4bb371a6 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/libpthread.so.0 No symbol table info available. #2  0x0055876f in apr_thread_cond_wait (cond=0x83b9478, mutex=0x83b9448)     at locks/unix/thread_cond.c:68         rv = 0 #3  0x08094de4 in ap_queue_info_wait_for_idler (queue_info=0x83b9430)     at fdqueue.c:158         rv = 0         prev_idlers = 0 #4  0x080917bd in get_worker (have_idle_worker_p=0xb5721364) at event.c:855         rc = 1270095860 #5  0x08091dd1 in listener_thread (thd=0x83b9540, dummy=0x83e9500)     at event.c:1063         rc = 0         ti = (proc_info *) 0x83e9500         process_slot = 0         tpool = (apr_pool_t *) 0x83c72c0         csd = (void *) 0x8419ef0         ptrans = (apr_pool_t *) 0x8419eb8         lr = (ap_listen_rec *) 0x832b520         have_idle_worker = 0         cs = (conn_state_t *) 0x83fff50         out_pfd = (const apr_pollfd_t *) 0x83c73ac         num = 0         time_now = 1175583389600457         timeout_interval = 1000000         timeout_time = 1175583389700457         pt = (listener_poll_type *) 0x83c73f0 #6  0x00566f70 in dummy_worker (opaque=0x83b9540)     at threadproc/unix/thread.c:142         thread = (apr_thread_t *) 0x83b9540 #7  0x4bb333db in start_thread () from /lib/libpthread.so.0 No symbol table info available. #8  0x4ba1726e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 1 (Thread -1208617280 (LWP 30353)): #0  0x007b9402 in __kernel_vsyscall () No symbol table info available. #1  0x4bb39d6b in read () from /lib/libpthread.so.0 No symbol table info available. #2  0x08095389 in ap_mpm_pod_check (pod=0x8341640) at pod.c:54         c = 0 '/0'         fd = 5         rc = -1075834592 #3  0x08092bb6 in child_main (child_num_arg=0) at event.c:1553         threads = (apr_thread_t **) 0x83e94d0         rv = 0         ts = (thread_starter *) 0x83b9300         thread_attr = (apr_threadattr_t *) 0x83b9310         start_thread_id = (apr_thread_t *) 0x83b9348 #4  0x08092d3c in make_child (s=0x832ef78, slot=0) at event.c:1639         pid = 0 #5  0x08092dbf in startup_children (number_to_start=1) at event.c:1658         i = 0 #6  0x080934e4 in ap_mpm_run (_pconf=0x832d0a8, plog=0x835d168, s=0x832ef78)     at event.c:1978         remaining_children_to_start = 1 #7  0x08064abb in main (argc=3, argv=0xbfe011a4) at main.c:750         c = 0 '/0'         configtestonly = 0         confname = 0x80a0d7d 'conf/httpd.conf'         def_server_root = 0x80a0d8d '/usr/local/apache2'         temp_error_log = 0x0         error = 0x0         process = (process_rec *) 0x832b128         server_conf = (server_rec *) 0x832ef78         pglobal = (apr_pool_t *) 0x832b0a0         pconf = (apr_pool_t *) 0x832d0a8         plog = (apr_pool_t *) 0x835d168         ptemp = (apr_pool_t *) 0x8361178         pcommands = (apr_pool_t *) 0x832f0b0         opt = (apr_getopt_t *) 0x832f148         rv = 0         mod = (module **) 0x80acc90         optarg = 0x0         signal_server = (     apr_OFN_ap_signal_server_t *) 0x80859a8 <ap_signal_server> #0  0x007b9402 in __kernel_vsyscall ()	I have not have the time to analyse this in more detail, but from first glance I tend to say that the lock aquired in line 1058 of event.c is being held for too long, such that we can run into a deadlock. In the backtrace below thread 2 is holding this lock and preventing all the worker threads from doing their jobs (they need to get hold of this lock). OTH thread 2 waits for a free worker via a conditional wait. BOOOM. Created an attachment (id=20684) 2.2.x deadlock fix  Here is a patch that might fix this issue on 2.2.x.  I haven't been able to locally reproduce it --  can you please try this patch out and let me know if it fixes the issue?  This reorders the locking logic inside the timeout ring iteration, so that we only lock when doing ops on the ring, but once we are ready to push to a child, we are lock free. I've committed a potential fix to trunk with r567852: https://svn.apache.org/viewvc?view=rev&revision=567852  The approach is different form the patch attached here -- it avoids rewriting the loops. > Here is a patch that might fix this issue on 2.2.x.  I haven't been able to > locally reproduce it --  can you please try this patch out and let me know if > it fixes the issue?  I wasn't able to reproduce the bug on 2.2.x. I should've mentioned it. Now I can't reproduce the bug on trunk rev 567852 nor rev 525116. (4) execute many downloading simultaneously, Then child process exit signal Segmentation fault. Why???  gdb output (rev 525116)  (gdb) run -X Starting program: /usr/local/apache2/bin/httpd -X [Thread debugging using libthread_db enabled] [New Thread -1208502592 (LWP 561)] [New Thread -1208738928 (LWP 574)] [New Thread -1219228784 (LWP 575)] [New Thread -1229718640 (LWP 576)] [New Thread -1240208496 (LWP 577)] [New Thread -1250698352 (LWP 578)] [Thread -1208738928 (LWP 574) exited]  Program received signal SIGPIPE, Broken pipe. [Switching to Thread -1240208496 (LWP 577)] 0x00110402 in __kernel_vsyscall () (gdb) thread apply all bt full  Thread 6 (Thread -1250698352 (LWP 578)): #0  0x00110402 in __kernel_vsyscall () No symbol table info available. #1  0x003e2b21 in __lll_mutex_unlock_wake () from /lib/libpthread.so.0 No symbol table info available. #2  0x003df839 in _L_mutex_unlock_99 () from /lib/libpthread.so.0 No symbol table info available. #3  0x003df4b0 in __pthread_mutex_unlock_usercnt () from /lib/libpthread.so.0 No symbol table info available. #4  0x003df830 in pthread_mutex_unlock () from /lib/libpthread.so.0 No symbol table info available. #5  0x0016b37e in apr_thread_mutex_unlock (mutex=0x9a99010)     at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_mutex.c:121 \tstatus = 0 #6  0x0809518f in ap_queue_push (queue=0x9a98ff8, sd=0x9b2bec8, cs=0x0,  p=0x9b2be90)     at /home/user1/httpd-trunk/server/mpm/experimental/event/fdqueue.c:337 \telem = (fd_queue_elem_t *) 0x9a99094 \trv = 0 #7  0x08091cc7 in listener_thread (thd=0x9a991d0, dummy=0x9ac7168)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1027 \trc = 0 \tti = (proc_info *) 0x9ac7168 \tprocess_slot = 0 \ttpool = (apr_pool_t *) 0x9aa2f80 \tcsd = (void *) 0x9b2bec8 \tptrans = (apr_pool_t *) 0x9b2be90 \tlr = (ap_listen_rec *) 0x9a33520 \thave_idle_worker = 1 \tcs = (conn_state_t *) 0x9b0dea0 \tout_pfd = (const apr_pollfd_t *) 0x9aa3080 \tnum = 1 \ttime_now = 1187710557998374 \ttimeout_interval = 1000000 \ttimeout_time = 1187710558098374 \tpt = (listener_poll_type *) 0x9aa30b0 #8  0x00179754 in dummy_worker (opaque=0x9a991d0)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142 \tthread = (apr_thread_t *) 0x9a991d0 #9  0x003dc44b in start_thread () from /lib/libpthread.so.0 No symbol table info available. #10 0x002bd80e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 5 (Thread -1240208496 (LWP 577)): #0  0x00110402 in __kernel_vsyscall () No symbol table info available. #1  0x002b41ee in sendfile64 () from /lib/libc.so.6 No symbol table info available. #2  0x00173b2a in apr_socket_sendfile (sock=0x9b2bec8, file=0x9b2c618,  hdtr=0x17f9f8, offset=0xb613e0e0,      len=0xb613e0dc, flags=0) at /home/user1/httpd- trunk/srclib/apr/network_io/unix/sendrecv.c:329 \trv = 0 \tnbytes = 0 \ttotal_hdrbytes = 0 \ti = 134909576 \tarv = 1569892 \toff = 16384 #3  0x0807a583 in sendfile_nonblocking (s=0x9b2bec8, bucket=0x9b2e0c8,  cumulative_bytes_written=0x9b2c5d0,      c=0x9b2c0c0) at /home/user1/httpd-trunk/server/core_filters.c:774 \tn = 190898180 \tarv = 0 \told_timeout = 10000000 \trv = 0 \tfile_bucket = (apr_bucket_file *) 0x9b2e018 \tfd = (apr_file_t *) 0x9b2c618 \tfile_length = 190898180 \tfile_offset = 16384 \tbytes_written = 0 #4  0x08079ea7 in send_brigade_nonblocking (s=0x9b2bec8, bb=0x9b2c5f8,  bytes_written=0x9b2c5d0, c=0x9b2c0c0)     at /home/user1/httpd-trunk/server/core_filters.c:576 \tfile_bucket = (apr_bucket_file *) 0x9b2e018 \tfd = (apr_file_t *) 0x9b2c618 \tdid_sendfile = 1 \tbucket = (apr_bucket *) 0x9b2e0c8 \tnext = (apr_bucket *) 0x9b2e070 \trv = 162731568 \tvec = {{iov_base = 0x9b31388, iov_len = 0}, {iov_base = 0x9b2c09c,  iov_len = 162717632}, {     iov_base = 0x9b31368, iov_len = 162728960}, {iov_base = 0x9b31488, iov_len  = 0}, {iov_base = 0x0,      iov_len = 162727224}, {iov_base = 0x0, iov_len = 162731128}, {iov_base =  0x9b2dfc0,      iov_len = 162717808}, {iov_base = 0x9b31388, iov_len = 3054756344},  {iov_base = 0x8074626,      iov_len = 162728960}, {iov_base = 0x9b31488, iov_len = 0}, {iov_base =  0x0, iov_len = 190914564}, {     iov_base = 0x0, iov_len = 162717632}, {iov_base = 0x198e18, iov_len =  162103320}, {iov_base = 0x0,      iov_len = 0}, {iov_base = 0x16e525, iov_len = 4129}, {iov_base =  0xffffffff, iov_len = 162031304}} \tnvec = 0 #5  0x08079c97 in ap_core_output_filter (f=0x9b2c568, new_bb=0x9b2c6a0)     at /home/user1/httpd-trunk/server/core_filters.c:488 \trv = 162709608 \tc = (conn_rec *) 0x9b2c0c0 \tnet = (core_net_rec *) 0x9b2c540 \tctx = (core_output_filter_ctx_t *) 0x9b2c5c8 \tbb = (apr_bucket_brigade *) 0x9b2c5f8 \tbucket = (apr_bucket *) 0x9b2c5fc \tnext = (apr_bucket *) 0x9b2c5fc \tbytes_in_brigade = 190898180 \tnon_file_bytes_in_brigade = 0 #6  0x08087609 in ap_pass_brigade (next=0x9b2c568, bb=0x9b2c6a0)     at /home/user1/httpd-trunk/server/util_filter.c:526 \te = (apr_bucket *) 0x9b2dfc0 #7  0x0808b0e5 in ap_process_async_request (r=0x9b2fed8)     at /home/user1/httpd-trunk/modules/http/http_request.c:261 \taccess_status = 0 \tbb = (apr_bucket_brigade *) 0x9b2c6a0 \tb = (apr_bucket *) 0x9b2dfc0 \tc = (conn_rec *) 0x9b2c0c0 #8  0x08087b6a in ap_process_http_async_connection (c=0x9b2c0c0)     at /home/user1/httpd-trunk/modules/http/http_core.c:140 \tr = (request_rec *) 0x9b2fed8 \tcs = (conn_state_t *) 0x9b2c068 #9  0x0808353f in ap_run_process_connection (c=0x9b2c0c0) at /home/user1/httpd- trunk/server/connection.c:43 \tpHook = (ap_LINK_process_connection_t *) 0x9ac1970 \tn = 0 \trv = -2 #10 0x080911eb in process_socket (p=0x9b2be90, sock=0x9b2bec8, cs=0x9b2c068,  my_child_num=0,      my_thread_num=2) at /home/user1/httpd- trunk/server/mpm/experimental/event/event.c:626 \tc = (conn_rec *) 0x9b2c0c0 \tpt = (listener_poll_type *) 0x9b2c0a0 \tconn_id = 2 \trc = -2 \tsbh = (ap_sb_handle_t *) 0x9b2c060 #11 0x080921e8 in worker_thread (thd=0x9a991b0, dummy=0x9ac7158)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194 \tti = (proc_info *) 0x9ac7158 \tprocess_slot = 0 \tthread_slot = 2 \tcsd = (apr_socket_t *) 0x9b2bec8 \tcs = (conn_state_t *) 0x0 \tptrans = (apr_pool_t *) 0x9b2be90 \trv = 0 \tis_idle = 0 #12 0x00179754 in dummy_worker (opaque=0x9a991b0)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142 \tthread = (apr_thread_t *) 0x9a991b0 #13 0x003dc44b in start_thread () from /lib/libpthread.so.0 No symbol table info available. #14 0x002bd80e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 4 (Thread -1229718640 (LWP 576)): #0  0x00110402 in __kernel_vsyscall () No symbol table info available. #1  0x003e0206 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/libpthread.so.0 No symbol table info available. #2  0x0016cf4f in apr_thread_cond_wait (cond=0x9a99040, mutex=0x9a99010)     at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_cond.c:68 \trv = 0 #3  0x08095200 in ap_queue_pop (queue=0x9a98ff8, sd=0xb6b3f38c, cs=0xb6b3f388,  p=0xb6b3f384)     at /home/user1/httpd-trunk/server/mpm/experimental/event/fdqueue.c:363 \telem = (fd_queue_elem_t *) 0x0 \trv = 0 #4  0x08092147 in worker_thread (thd=0x9a99190, dummy=0x9ac7168)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1162 \tti = (proc_info *) 0x9ac7168 \tprocess_slot = 0 \tthread_slot = 1 \tcsd = (apr_socket_t *) 0x9ad1970 \tcs = (conn_state_t *) 0x9ad1b10 \tptrans = (apr_pool_t *) 0x9ad1938 \trv = 0 \tis_idle = 1 #5  0x00179754 in dummy_worker (opaque=0x9a99190)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142 \tthread = (apr_thread_t *) 0x9a99190 #6  0x003dc44b in start_thread () from /lib/libpthread.so.0 No symbol table info available. #7  0x002bd80e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 3 (Thread -1219228784 (LWP 575)): #0  0x00110402 in __kernel_vsyscall () No symbol table info available. #1  0x002b41ee in sendfile64 () from /lib/libc.so.6 No symbol table info available. #2  0x00173b2a in apr_socket_sendfile (sock=0x9ac78d8, file=0x9ac8028,  hdtr=0x17f9f8, offset=0xb7540190,      len=0xb754018c, flags=0) at /home/user1/httpd- trunk/srclib/apr/network_io/unix/sendrecv.c:329 \trv = 0 \tnbytes = 0 \ttotal_hdrbytes = 0 \ti = 0 \tarv = 162676768 \toff = 10301440 #3  0x0807a583 in sendfile_nonblocking (s=0x9ac78d8, bucket=0x9ac9ad8,  cumulative_bytes_written=0x9ac7fe0,      c=0x9ac7ad0) at /home/user1/httpd-trunk/server/core_filters.c:774 \tn = 183644164 \tarv = 0 \told_timeout = 10000000 \trv = 0 \tfile_bucket = (apr_bucket_file *) 0x9ac9a28 \tfd = (apr_file_t *) 0x9ac8028 \tfile_length = 183644164 \tfile_offset = 7270400 \tbytes_written = 0 #4  0x08079ea7 in send_brigade_nonblocking (s=0x9ac78d8, bb=0x9ac80c0,  bytes_written=0x9ac7fe0, c=0x9ac7ad0)     at /home/user1/httpd-trunk/server/core_filters.c:576 \tfile_bucket = (apr_bucket_file *) 0x9ac9a28 \tfd = (apr_file_t *) 0x9ac8028 \tdid_sendfile = 1 \tbucket = (apr_bucket *) 0x9ac9ad8 \tnext = (apr_bucket *) 0x9ac9a80 \trv = 0 \tvec = {{iov_base = 0x9afbc70, iov_len = 162511984}, {iov_base =  0x9afa3d8, iov_len = 162503552}, {     iov_base = 0x0, iov_len = 162505488}, {iov_base = 0x1302f4, iov_len =  3075736136}, {     iov_base = 0x8087564, iov_len = 162505304}, {iov_base = 0x9afa3d8, iov_len  = 2549142}, {     iov_base = 0x17bccc, iov_len = 3075736132}, {iov_base = 0x0, iov_len =  162511752}, {iov_base = 0xb,      iov_len = 0}, {iov_base = 0x46cb065c, iov_len = 457949}, {iov_base =  0x9af9d70, iov_len = 0}, {     iov_base = 0x9af9da4, iov_len = 3075736184}, {iov_base = 0x806ae86,  iov_len = 0}, {iov_base = 0x0,      iov_len = 3075736184}, {iov_base = 0x806ce1f, iov_len = 162512072},  {iov_base = 0x9b23e20,      iov_len = 3075736216}} \tnvec = 0 #5  0x08079ad6 in ap_core_output_filter (f=0x9ac7f78, new_bb=0x0)     at /home/user1/httpd-trunk/server/core_filters.c:423 \trv = 304 \tc = (conn_rec *) 0x9ac7ad0 \tnet = (core_net_rec *) 0x9ac7f50 \tctx = (core_output_filter_ctx_t *) 0x9ac7fd8 \tbb = (apr_bucket_brigade *) 0x9ac80c0 \tbucket = (apr_bucket *) 0x3e2b21 \tnext = (apr_bucket *) 0x9ac8330 \tbytes_in_brigade = 162297992 \tnon_file_bytes_in_brigade = 4112372 #6  0x0809123c in process_socket (p=0x9ac78a0, sock=0x9ac78d8, cs=0x9ac7a78,  my_child_num=0,      my_thread_num=0) at /home/user1/httpd- trunk/server/mpm/experimental/event/event.c:644 \toutput_filter = (ap_filter_t *) 0x9ac7f78 \trv = 0 \tc = (conn_rec *) 0x9ac7ad0 \tpt = (listener_poll_type *) 0x9ac7ab0 \tconn_id = 0 \trc = 2 \tsbh = (ap_sb_handle_t *) 0x9ac8330 #7  0x080921e8 in worker_thread (thd=0x9a99170, dummy=0x9ac7158)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194 \tti = (proc_info *) 0x9ac7158 \tprocess_slot = 0 \tthread_slot = 0 \tcsd = (apr_socket_t *) 0x9ac78d8 \tcs = (conn_state_t *) 0x9ac7a78 \tptrans = (apr_pool_t *) 0x9ac78a0 \trv = 0 \tis_idle = 0 #8  0x00179754 in dummy_worker (opaque=0x9a99170)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142 \tthread = (apr_thread_t *) 0x9a99170 #9  0x003dc44b in start_thread () from /lib/libpthread.so.0 No symbol table info available. #10 0x002bd80e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 1 (Thread -1208502592 (LWP 561)): #0  0x00110402 in __kernel_vsyscall () No symbol table info available. #1  0x003e3f3e in do_sigwait () from /lib/libpthread.so.0 No symbol table info available. #2  0x003e3fdf in sigwait () from /lib/libpthread.so.0 No symbol table info available. #3  0x0017b242 in apr_signal_thread (signal_handler=0x8092279 <check_signal>)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/signals.c:383 \tsignal_received = 4095 \tsig_mask = {__val = {1073340935, 4294967294, 4294967295 <repeats 30  times>}} \tsig_func = (int (*)(int)) 0x8092279 <check_signal> #4  0x08092be4 in child_main (child_num_arg=0)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1520 \tthreads = (apr_thread_t **) 0x9ac7148 \trv = 0 \tts = (thread_starter *) 0x9a98f90 \tthread_attr = (apr_threadattr_t *) 0x9a98fa0 \tstart_thread_id = (apr_thread_t *) 0x9a98fd8 #5  0x08092d42 in make_child (s=0x9a36f78, slot=0)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1602 \tpid = 0 #6  0x08092e4b in startup_children (number_to_start=1)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1658 \ti = 0 #7  0x08093570 in ap_mpm_run (_pconf=0x9a350a8, plog=0x9a65168, s=0x9a36f78)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1978 \tremaining_children_to_start = 1 #8  0x08064aeb in main (argc=2, argv=0xbff4d244) at /home/user1/httpd- trunk/server/main.c:750 \tc = 88 'X' \tconfigtestonly = 0 \tconfname = 0x80a0e3d 'conf/httpd.conf' \tdef_server_root = 0x80a0e4d '/usr/local/apache2' \ttemp_error_log = 0x0 \terror = 0x0 \tprocess = (process_rec *) 0x9a33128 \tserver_conf = (server_rec *) 0x9a36f78 \tpglobal = (apr_pool_t *) 0x9a330a0 \tpconf = (apr_pool_t *) 0x9a350a8 \tplog = (apr_pool_t *) 0x9a65168 \tptemp = (apr_pool_t *) 0x9a69178 \tpcommands = (apr_pool_t *) 0x9a370b0 \topt = (apr_getopt_t *) 0x9a37148 \trv = 0 \tmod = (module **) 0x80ae0b0 \toptarg = 0x0 \tsignal_server = (apr_OFN_ap_signal_server_t *) 0 #0  0x00110402 in __kernel_vsyscall () (gdb) c Continuing.  Program received signal SIGSEGV, Segmentation fault. 0x00117186 in apr_brigade_cleanup (data=0x0)     at /home/user1/httpd-trunk/srclib/apr-util/buckets/apr_brigade.c:42 42\t    while (!APR_BRIGADE_EMPTY(b)) { (gdb) thread apply all bt full  Thread 6 (Thread -1250698352 (LWP 578)): #0  0x00110402 in __kernel_vsyscall () No symbol table info available. #1  0x003e0206 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/libpthread.so.0 No symbol table info available. #2  0x0016cf4f in apr_thread_cond_wait (cond=0x9a99108, mutex=0x9a990d8)     at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_cond.c:68 \trv = 0 #3  0x08094e70 in ap_queue_info_wait_for_idler (queue_info=0x9a990c0)     at /home/user1/httpd-trunk/server/mpm/experimental/event/fdqueue.c:158 \trv = 0 \tprev_idlers = 0 #4  0x08091849 in get_worker (have_idle_worker_p=0xb573d364)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:855 \trc = 4112372 #5  0x08091f10 in listener_thread (thd=0x9a991d0, dummy=0x9ac7168)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1087 \trc = 0 \tti = (proc_info *) 0x9ac7168 \tprocess_slot = 0 \ttpool = (apr_pool_t *) 0x9aa2f80 \tcsd = (void *) 0x9b2bec8 \tptrans = (apr_pool_t *) 0x9b2be90 \tlr = (ap_listen_rec *) 0x9a33520 \thave_idle_worker = 0 \tcs = (conn_state_t *) 0x9ae5c40 \tout_pfd = (const apr_pollfd_t *) 0x9aa3094 \tnum = 0 \ttime_now = 1187710592861859 \ttimeout_interval = 1000000 \ttimeout_time = 1187710592961859 \tpt = (listener_poll_type *) 0x9aa30b0 #6  0x00179754 in dummy_worker (opaque=0x9a991d0)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142 \tthread = (apr_thread_t *) 0x9a991d0 #7  0x003dc44b in start_thread () from /lib/libpthread.so.0 No symbol table info available. #8  0x002bd80e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 5 (Thread -1240208496 (LWP 577)): #0  0x00117186 in apr_brigade_cleanup (data=0x0)     at /home/user1/httpd-trunk/srclib/apr-util/buckets/apr_brigade.c:42 \tb = (apr_bucket_brigade *) 0x0 \te = (apr_bucket *) 0x0 #1  0x08079921 in ap_core_output_filter (f=0x9b2c568, new_bb=0x0)     at /home/user1/httpd-trunk/server/core_filters.c:357 \tc = (conn_rec *) 0x9b2c0c0 \tnet = (core_net_rec *) 0x9b2c540 \tctx = (core_output_filter_ctx_t *) 0x9b2c5c8 \tbb = (apr_bucket_brigade *) 0x808366d \tbucket = (apr_bucket *) 0x0 \tnext = (apr_bucket *) 0x9b2c068 \tbytes_in_brigade = 3054756600 \tnon_file_bytes_in_brigade = 134755647 #2  0x0809123c in process_socket (p=0x9b2be90, sock=0x9b2bec8, cs=0x9b2c068,  my_child_num=0,      my_thread_num=2) at /home/user1/httpd- trunk/server/mpm/experimental/event/event.c:644 \toutput_filter = (ap_filter_t *) 0x9b2c568 \trv = 0 \tc = (conn_rec *) 0x9b2c0c0 \tpt = (listener_poll_type *) 0x9b2c0a0 \tconn_id = 2 \trc = -2 \tsbh = (ap_sb_handle_t *) 0x9b2c060 #3  0x080921e8 in worker_thread (thd=0x9a991b0, dummy=0x9ac7158)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194 \tti = (proc_info *) 0x9ac7158 \tprocess_slot = 0 \tthread_slot = 2 \tcsd = (apr_socket_t *) 0x9b2bec8 \tcs = (conn_state_t *) 0x0 \tptrans = (apr_pool_t *) 0x9b2be90 \trv = 0 \tis_idle = 0 #4  0x00179754 in dummy_worker (opaque=0x9a991b0)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142 \tthread = (apr_thread_t *) 0x9a991b0 #5  0x003dc44b in start_thread () from /lib/libpthread.so.0 No symbol table info available. #6  0x002bd80e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 4 (Thread -1229718640 (LWP 576)): #0  0x00110402 in __kernel_vsyscall () No symbol table info available. #1  0x003e2a0e in __lll_mutex_lock_wait () from /lib/libpthread.so.0 No symbol table info available. #2  0x003de883 in _L_mutex_lock_79 () from /lib/libpthread.so.0 No symbol table info available. #3  0x003de3ad in pthread_mutex_lock () from /lib/libpthread.so.0 No symbol table info available. #4  0x0016b2fc in apr_thread_mutex_lock (mutex=0x9aa2fb8)     at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_mutex.c:92 \trv = 0 #5  0x080912c0 in process_socket (p=0x9b0dcc8, sock=0x9b0dd00, cs=0x9b0dea0,  my_child_num=0,      my_thread_num=1) at /home/user1/httpd- trunk/server/mpm/experimental/event/event.c:656 \toutput_filter = (ap_filter_t *) 0x9b0e3a0 \trv = 0 \tc = (conn_rec *) 0x9b0def8 \tpt = (listener_poll_type *) 0x9b0ded8 \tconn_id = 1 \trc = 2 \tsbh = (ap_sb_handle_t *) 0x9b0e568 #6  0x080921e8 in worker_thread (thd=0x9a99190, dummy=0x9ac7168)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194 \tti = (proc_info *) 0x9ac7168 \tprocess_slot = 0 \tthread_slot = 1 \tcsd = (apr_socket_t *) 0x9b0dd00 \tcs = (conn_state_t *) 0x9b0dea0 \tptrans = (apr_pool_t *) 0x9b0dcc8 \trv = 0 \tis_idle = 0 #7  0x00179754 in dummy_worker (opaque=0x9a99190)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142 \tthread = (apr_thread_t *) 0x9a99190 #8  0x003dc44b in start_thread () from /lib/libpthread.so.0 No symbol table info available. #9  0x002bd80e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 3 (Thread -1219228784 (LWP 575)): #0  0x00110402 in __kernel_vsyscall () No symbol table info available. #1  0x003e2a0e in __lll_mutex_lock_wait () from /lib/libpthread.so.0 No symbol table info available. #2  0x003de883 in _L_mutex_lock_79 () from /lib/libpthread.so.0 No symbol table info available. #3  0x003de3ad in pthread_mutex_lock () from /lib/libpthread.so.0 No symbol table info available. #4  0x0016b2fc in apr_thread_mutex_lock (mutex=0x9aa2fb8)     at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_mutex.c:92 \trv = 0 #5  0x080912c0 in process_socket (p=0x9ac78a0, sock=0x9ac78d8, cs=0x9ac7a78,  my_child_num=0,      my_thread_num=0) at /home/user1/httpd- trunk/server/mpm/experimental/event/event.c:656 \toutput_filter = (ap_filter_t *) 0x9ac7f78 \trv = 0 \tc = (conn_rec *) 0x9ac7ad0 \tpt = (listener_poll_type *) 0x9ac7ab0 \tconn_id = 0 \trc = 2 \tsbh = (ap_sb_handle_t *) 0x9ac8330 #6  0x080921e8 in worker_thread (thd=0x9a99170, dummy=0x9ac7158)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194 \tti = (proc_info *) 0x9ac7158 \tprocess_slot = 0 \tthread_slot = 0 \tcsd = (apr_socket_t *) 0x9ac78d8 \tcs = (conn_state_t *) 0x9ac7a78 \tptrans = (apr_pool_t *) 0x9ac78a0 \trv = 0 \tis_idle = 0 #7  0x00179754 in dummy_worker (opaque=0x9a99170)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142 \tthread = (apr_thread_t *) 0x9a99170 #8  0x003dc44b in start_thread () from /lib/libpthread.so.0 No symbol table info available. #9  0x002bd80e in clone () from /lib/libc.so.6 No symbol table info available.  Thread 1 (Thread -1208502592 (LWP 561)): #0  0x00110402 in __kernel_vsyscall () No symbol table info available. #1  0x003e3f3e in do_sigwait () from /lib/libpthread.so.0 No symbol table info available. #2  0x003e3fdf in sigwait () from /lib/libpthread.so.0 No symbol table info available. #3  0x0017b242 in apr_signal_thread (signal_handler=0x8092279 <check_signal>)     at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/signals.c:383 \tsignal_received = 4095 \tsig_mask = {__val = {1073340935, 4294967294, 4294967295 <repeats 30  times>}} \tsig_func = (int (*)(int)) 0x8092279 <check_signal> #4  0x08092be4 in child_main (child_num_arg=0)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1520 \tthreads = (apr_thread_t **) 0x9ac7148 \trv = 0 \tts = (thread_starter *) 0x9a98f90 \tthread_attr = (apr_threadattr_t *) 0x9a98fa0 \tstart_thread_id = (apr_thread_t *) 0x9a98fd8 #5  0x08092d42 in make_child (s=0x9a36f78, slot=0)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1602 \tpid = 0 #6  0x08092e4b in startup_children (number_to_start=1)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1658 \ti = 0 #7  0x08093570 in ap_mpm_run (_pconf=0x9a350a8, plog=0x9a65168, s=0x9a36f78)     at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1978 \tremaining_children_to_start = 1 #8  0x08064aeb in main (argc=2, argv=0xbff4d244) at /home/user1/httpd- trunk/server/main.c:750 \tc = 88 'X' \tconfigtestonly = 0 \tconfname = 0x80a0e3d 'conf/httpd.conf' \tdef_server_root = 0x80a0e4d '/usr/local/apache2' \ttemp_error_log = 0x0 \terror = 0x0 \tprocess = (process_rec *) 0x9a33128 \tserver_conf = (server_rec *) 0x9a36f78 \tpglobal = (apr_pool_t *) 0x9a330a0 \tpconf = (apr_pool_t *) 0x9a350a8 \tplog = (apr_pool_t *) 0x9a65168 \tptemp = (apr_pool_t *) 0x9a69178 \tpcommands = (apr_pool_t *) 0x9a370b0 \topt = (apr_getopt_t *) 0x9a37148 \trv = 0 \tmod = (module **) 0x80ae0b0 \toptarg = 0x0 \tsignal_server = (apr_OFN_ap_signal_server_t *) 0 0x00117186\t42\t    while (!APR_BRIGADE_EMPTY(b)) { (gdb) c Continuing.  Program terminated with signal SIGSEGV, Segmentation fault. The program no longer exists. (gdb) quit  Your latest backtrace appears to be a separate bug. The crashing thread is crashing in sendfile_nonblocking, which is also new code in trunk. Please update to trunk again, I believe I have fixed the last crash with r568202: https://svn.apache.org/viewvc?view=rev&revision=568202 I tried two source trees: (A)rev 568202 (B)rev 568202 + revert r567852 ( svn merge -r 567852:567851 ./ )  (A) works fine, there seems to be no issues. And I can reproduce the dead lock bug on (B). RESOLVED FIXED?  thanks   sorry, not resolved  On (A), repeat  (4) execute many downloading simultaneously. (5) terminate downloading then child freezes.  Reproducing the deadlock issue on (A) is harder than on (B), so r567852 is effective but not complete, IMHO. I took a bachtrace of a frozen child process. The bt was the same as  bt I have posted in April.  'Reproducing the deadlock issue on (A) is harder than on (B)' was how I felt,  but now seems wrong. I tried 2.2 and reproduced the deadlock, so I tried that patch against 2.2.  Aother error occurs:  [Wed Aug 22 19:51:22 2007] [error] event_loop: unexpected state 2 [Wed Aug 22 19:51:22 2007] [crit] [Wed Aug 22 19:51:22 2007]  file /home/user1/httpd-2.2.x/server/mpm/experimental/event/event.c, line 925,  assertion '0' failed [Wed Aug 22 19:51:23 2007] [notice] child pid 17224 exit signal Aborted (6)  This error occurs when I access a HTML page from browser. Created an attachment (id=20769) for trunk  How about this patch?  now: apr_thread_mutex_lock(timeout_mutex) get_worker(&have_idle_worker) APR_RING_REMOVE(cs, timeout_list) apr_thread_mutex_unlock(timeout_mutex) push2worker(&cs->pfd, event_pollset)  this patch: apr_thread_mutex_lock(timeout_mutex) APR_RING_REMOVE(cs, timeout_list) apr_thread_mutex_unlock(timeout_mutex) get_worker(&have_idle_worker) push2worker(&cs->pfd, event_pollset) I've committed a slightly modified version of your patch in r574462.			Paul Querna	Ruediger Pluem	Takashi Sato
42096	null	RESOLVED		Alexander Koch	1176343080000	1185460188000		 to configuration example Hello,  I suggest to change the configuration example from:  Require valid-user Allow from 192.168.1 Satisfy Any  to something like:  Require valid-user Order deny,allow Allow from 192.168.1 Deny from all Satisfy Any  So, the configuration example will work 'out-of-the-box'.	I think 'Deny from all' is wasteful.  Require valid-user Order allow,deny Allow from 192.168.1 Satisfy Any You are right, if the Order statement is 'Order allow,deny'. So the example could be like yours. Patch applied.  http://svn.apache.org/viewvc?view=rev&rev=559990 Should be visible within a few hours.  Cheers, Tony 			Alexander Koch	Takashi Sato	Tony Stevenson
42186	null	RESOLVED		Issac Goldstand	1177222980000	1186120073000		t merge ! or = correctly mod_filter doesn't handle FilterChain =... or FilterChain ! properly when  merging configs.  Assume you have a setup like this:  FilterProvider a ... FilterProvider b ... FilterProvider c ...  FilterChain a b <Location /foo> FilterChain =c </Location>  <Location /bar> FilterChain ! </Location> <VirtualHost>  The correct behaviour should be for foo to run *only* c, and for bar to run  nothing.  However, currently /foo will run abc and /bar will run ab	Created an attachment (id=20011) Patch to fix bug  Patch committed to /trunk/ in http://svn.apache.org/viewvc?view=rev&revision=559804 http://svn.apache.org/viewvc?view=rev&revision=562441			Issac Goldstand	Nick Kew
42286	null	RESOLVED		Takashi Sato	1177784760000	1178258439000		 linkage in ap_mpm.h ap_mpm.h declares functions without extern 'C'. We must include it with extern 'C' from C++. Other headers seem to use extern 'C' in function declarations.	Which functions ? Meanwhile, this might do the trick:  extern 'C' {     #include 'ap_mpm.h'  } (In reply to comment #1) > Which functions ?  My module written in C++ needs to call ap_mpm_query.  >Meanwhile, this might do the trick: Yes, I'm using it.   Headers files which declare functions with extern 'C' : ap_regex.h ap_regkey.h http_config.h http_connection.h http_core.h http_log.h http_protocol.h http_request.h http_vhost.h httpd.h mpm_common.h scoreboard.h util_ebcdic.h util_filter.h util_md5.h util_mutex.h util_script.h util_time.h util_xml.h  Headers files which declare functions without extern 'C' : ap_listen.h ap_mpm.h ap_provider.h util_cfgtree.h util_ldap.h Created an attachment (id=20092) Add a few missing externs to the headers  Committed to trunk, revision 535169, by Ruediger Pluem. Backported to 2.2.x as r536627 (http://svn.apache.org/viewvc?view=rev&rev=536627)			Davi Arnaut	Ruediger Pluem	Takashi Sato
42549	null	RESOLVED		Eric Covener	1180529940000	1198272069000		win32: httxt2dbm not built/installed in windows build httxt2dbm (convert rewritemap text files to DBM hashes) isn't shipped in Apache 2.2.4 nor built in 2.2.x/trunk via windows build process.	Created an attachment (id=20293) mimic htcacheclean trunk build for httxt2dbm  not sure if there's an EOL issue in patch, working outside of comfort zone all resolved for 2.2.7			Eric Covener	Will Rowe
42572	null	RESOLVED		Marcos Boyington	1180889220000	1192467039000		Server crashes in child_main Have a production server carshing in child_main [child.c]. I believe it may  have something to do with MaxRequestsPerChild, but I have not yet verified  this. I have a DMP and MDMP available if it helps.  Access violation reading  location 0x00000000.  Crash line:  /* Reset the scoreboard entry for the thread we just whacked */         score_idx = apr_hash_get(ht, &child_handles[i], sizeof(HANDLE)); --->    ap_update_child_status_from_indexes(0, *score_idx, SERVER_DEAD, NULL);  Callstack:  >\tlibhttpd.dll!child_main(apr_pool_t * pconf=0x0039dc80)  Line 1139 \tC  \tlibhttpd.dll!ap_mpm_run(apr_pool_t * _pconf=0x0039dc80, apr_pool_t *  plog=0x0087c110, server_rec * s=0x0039fbb0)  Line 1663\tC  \tapache.exe!main(int argc=3, const char * const * argv=0x00392720)   Line 717 + 0xd bytes\tC  \tapache.exe!mainCRTStartup()  Line 398 + 0xe bytes\tC	Created an attachment (id=20311) Fixes NULL pointer deference in the winnt mpm  When creating threads, the index (i) might not be sequential if the scoreboard entry status is not SERVER_GRACEFUL or SERVER_DEAD.  Could you try the patch and let me know if the error still happens? Thanks. (In reply to comment #1) > Created an attachment (id=20311) [edit] > Fixes NULL pointer deference in the winnt mpm  The patch looks right, but should probably also log an error (at EMERG or at least CRIT level if the server has just leaked a whole thread?)  It would be good to know whether Davi's patch at least stops the crashing. Davi's fix does work, tested on the same server, crashing stopped. This got fixed in trunk but missed the changelog.  I guess it wants backporting. Fixed in trunk and for the next 2.2.7 release, thanks for the patch! 			Davi Arnaut	Marcos Boyington	Nick Kew	Will Rowe
42592	null	RESOLVED		Jerry Baker	1181041260000	1195543820000		Proxied URLs are incorrectly unescaped. Running Apache 2.2.2 proxy my clients are unable to use Yahoo Shopping. Searching and browsing product listings works fine, but as soon as they click on a particular item they get a 'Forbidden' error page.  STEPS TO REPRODUCE:  1. Set Apache as your proxy server and try to browse to the above URL.  RESULT: HTTP Forbidden page  Now try browsing to that URL with no proxy.  RESULT: Works fine.	This appears to be an instance of PR #41798.  *** This bug has been marked as a duplicate of 41798 *** This is not in fact a duplicate of PR 41798.  Although the symptoms are the same, the code path and therefore the fix are entirely different.  This is a good report of the forward proxy bug with a testcase I could easily reproduce, so I'm re-opening it with a more generic title, in order to document the bug and its fix. *** Bug 35100 has been marked as a duplicate of this bug. *** *** Bug 39455 has been marked as a duplicate of this bug. *** Fixed in trunk in r583002. Fixed in r596712.			Nick Kew
42757	null	RESOLVED		Joe Orton	1182956940000	1200660616000		abnormal child termination not logged at shutdown/restart Found whilst playing with pid safety patches, noting so I don't forget:  mpm_common.c:reclaim_one_pid() does not do normal logging of children which exit abnormally e.g. with SIGSEGV.  So if a child dies abnormally during shutdown or just before, this isn't logged.  repro e.g.  kill -SEGV <childpid>; apachectl stop	Fixed on trunk, http://svn.apache.org/viewcvs.cgi?rev=613263&view=rev			Joe Orton
42993	null	RESOLVED		Nikolas Coukouma	1185707460000	1186648393000		Inflate filter does not check Content-Encoding completely Right now the inflate filter only checks to see if the Content-Encoding in the headeres table contains gzip. It does not check r->content_encoding. This breaks it with mod_mime. Example below  # All files from this location have been compressed <Location '/zipped'>   AddEncoding gzip .html .txt </Location> # Automatically decompress things for clients that don't support gzip Header add Vary Accept-Encoding FilterDeclare gzip CONTENT_SET FilterProvider gzip inflate req=Accept-Encoding $!gzip FilterChain gzip	Created an attachment (id=20562) Patch against 2.2.4  This moves the code for getting Content-Encoding in deflate_out_filter into a separate (static) function so that inflate_out_filter can use the exact same code. It also updates the clearing of Content-Encoding so it's done a bit later (after triying to initialize zlib, which is when the Content-Length header is removed) and updates both the header table and r->content_encoding. Created an attachment (id=20563) Patch against trunk  This makes the same changes, but against trunk. All that's changed is line numbers, so it applies cleanly. http://svn.apache.org/viewvc?view=rev&rev=563464 Ouch.  I didn't look carefully enough.  This bug is fixed in /trunk/ but still pending for 2.2. In 2.2.5-dev...			Jim Jagielski	Nick Kew	Nikolas Coukouma
43183	null	RESOLVED		Brian Rectanus	1187712240000	1188828466000		Env proxy-sendchunked is coded as proxy-sendchunks (typo) Both docs in trunk/docs/manual/mod/mod_proxy.xml and comments in trunk/modules/proxy/mod_proxy_http.c state to use:  SetEnv proxy-sendchunked 1  to force chunked T-E to the backend, however, the code tests for 'proxy-sendchunks' ('s' not 'ed').  Code needs changed to match docs.  Also needs backports.	Created an attachment (id=20686) patch typo  The attached patch changes the code rather than the docs. Could dev@ confirm that the code rather than  the docs are wrong?  If not I'll fix up the docs. Please fix the docs. Thus we avoid regressions with configurations in the wild that found out this situation and adjusted their config to the code. What about all those that have read the docs, have their configs set as such?  Those people continue to have broken setups if you fix the docs.  Changing the code will at least allow people using the proxy-sendchunked env var to start working in the next release.  I think the chances of someone noticing this in the code and adjusting their configs is much less than someone following the docs and never verifying that it was working.  Look how long this bug has been there as proof of this. If you do decide to fix the docs, please fix the code comments as well. Grepping the (trunk) sources gives:  ./docs/manual/env.html.en:329:   <h3><a name='proxy' id='proxy'>force-proxy-request-1.0, proxy-nokeepalive, proxy- sendchunked, proxy-sendcl</a></h3> ./docs/manual/env.html.ja.euc-jp:321:   <h3><a name='proxy' id='proxy'>force-proxy-request-1.0, proxy-nokeepalive,  proxy-sendchunked, proxy-sendcl</a></h3> ./docs/manual/env.xml:369:   <section id='proxy'><title>force-proxy-request-1.0, proxy-nokeepalive, proxy-sendchunked,  proxy-sendcl</title> ./docs/manual/env.xml.ja:356:   <section id='proxy'><title>force-proxy-request-1.0, proxy-nokeepalive, proxy- sendchunked, proxy-sendcl</title> ./docs/manual/mod/mod_proxy.html.en:289:    <code>proxy-sendchunked</code> minimizes resource usage by using ./docs/manual/mod/mod_proxy.xml:260:    <code>proxy-sendchunked</code> minimizes resource usage by using ./modules/proxy/mod_proxy_http.c:910:     *   not setenv proxy-sendchunked or has set setenv proxy-sendcl ./modules/proxy/mod_proxy_http.c:913:     *   setenv proxy-sendcl, and not setenv proxy-sendchunked ./modules/proxy/mod_proxy_http.c:915:     * If both proxy-sendcl and proxy-sendchunked are set, the ./modules/proxy/mod_proxy_http.c:921:     * To reduce server resource use,   setenv proxy-sendchunked  So it's clear that there's some confusion over the variable name. In fact, there's more references to 'proxy-sendchunked' in the  code comments than there are in the docs.  I was about to commit a sed-style fix to the trunk docs, but I'm holding off in case send-chunked (which seems to me a better  phrase) wins out over send-chunks (which at least has comical value to the English :) My suggestion: Double-check that all docs say 'chunked' instead of 'chunks'. For code in 2.0.x and 2.2.x 'stable' branches, check for 'chunked' like the docs say now, as well as 'chunks' which somebody who read the code might use. For code in trunk, check only 'chunked'.  Created an attachment (id=20699) Check for both -s and -ed variants in 2.2  Check for both sendchunks and sendchunked in 2.2 following from Jeff Trawick's suggestion. Brian's original patch for trunk is also valid. No changes required for the 2.2 docs, or any comments in the C code. Created an attachment (id=20700) Check for -s and -ed variants in 2.0  Again following from Jeff Trawick's suggestion, this time for 2.0. The 2.0 docs don't mention either variant in env.xml, so I guess there's no changes to make there.  Please review the logic of both patches carefully, as I'm not a C coder and not particularly confident that it's right. Sorry, been busy ;)  The patches in comments #8 and #9 look fine.  I have not tested, though (no time) as I applied my patch to our 2.2.x tree.  Thanks Vincent!  -B Backported to 2.2.x as r572421 (http://svn.apache.org/viewvc?rev=572421&view=rev).			Brian Rectanus	Jeff Trawick	Ruediger Pluem	Vincent Bray
43210	null	RESOLVED		Phil Endecott	1187967540000	1206016250000		Please improve mod_dbd error messages mod_dbd uses the error message 'Error looking up %s in database' in three different situations.  It would help debugging if these situations could be distinguished, e.g. to tell the difference between a mistake in a database connection string and a mistake in SQL query syntax.  The patch that I'll attach does this with the following three messages:  'Failed to acquire database connection to look up user %s' 'Query execution error looking up %s in database' 'Error retrieving results while looking up %s in database'  (It would be even better if the error message returned by the database could be included, but I don't think that the apr dbd API allows for this.)	Created an attachment (id=20703) Patch as described  Patch committed to trunk with changes and additional reformatting in r639079.			Chris Darroch	Phil Endecott
43213	null	RESOLVED		Julien Perez	1187985480000	1188194114000		mod_expires.c segfaults when parsing configuration mod_expires.c segfaults when parsing configuration if a line with the directive ExpiresByType is used with a mimetype which doesnt contain any slash.  Bad code:     check = ap_strrchr_c(mime, '/');     if ((strlen(++check) == 1) && (*check == '*')) {         dir_config->wildcards = 1;     }  Patch submitted in attachment which returns an error message when the mimetype is supplied without slash.	Created an attachment (id=20708) Adds an error message when ExpiresByType is supplied with an invalid mimetype, avoids a segfault  Thanks for the report.  Fixed in /trunk/ - r569622. Fixed in r570093.			Julien Perez	Nick Kew
43233	null	RESOLVED		IIDA Yosiaki	1188344640000	1188473978000		possible typos in some files under htdocs/manual/ In files handler.html.ja.jis, index.html.ja.jis and install.html.ja.jis, under  htdocs/manual/ sub-directory of Apache 1.3.37, it reads:   href='misc/api.html' But I see no such files there.  Should it be like:   href='misc/API.html'	Thank you for reporting this problem  I have fixed it for the next release. 			Roy T. Fielding
43310	null	RESOLVED		SunHo Kim	1188967500000	1197113650000		buffer overflow (1 byte) in ap_vrprintf() If entire output size of ap_vrprintf() is multiple of 8192(AP_IOBUFSIZE), then vd.vbuff.curpos is equal to vd.vbuff.curend and null terminator is written over the end of vrprintf_buf[].  In my machine, first byte of vd.vbuff.curpos is cleared to zero, and 3rd  parameter of output_buffer() is calcurated incorrectly.  tested on apache-2.2.4 ======== step to reproduce the problem: 1) make sample module $ apxs -g -n test  2) edit test_handler /* The sample content handler */ static int test_handler(request_rec *r) {     if (strcmp(r->handler, 'test')) {         return DECLINED;     }     r->content_type = 'text/html';      int n = atoi(r->args) ;     char * s = apr_pcalloc(r->pool, n+1) ;     memset(s, '1', n) ;     ap_rprintf(r, '%s', s) ;      return OK; }  3) append to httpd.conf and apachectl start LoadModule test_module modules/mod_test.so <Location /test> SetHandler test </Location>  4) module output size test $ N=8192 ; for ((i=$N-4; i<$N+4; i++)) ; do echo $i "curl -s localhost/test?$i  | wc -c" ; done 8188 8188 8189 8189 8190 8190 8191 8191 8192 8112        <-- expected size is 8192 8193 8193 8194 8194 8195 8195	Created an attachment (id=20774) Patch against httpd-2.2.4  null terminator is not used I reviewed the patch. Patch looks ok to me. Here is the description of the bug :  In ap_vrprintf, vrprintf_buf is a array allocated on stack of 8192 bytes. ap_vrprintf invokes ap_vformatter to format the string.  ap_vformatter prints the data character by character, if buffer is overflowed, then it flushes the data and reset the vdbuf.curpos to beginning of buffer.  If  the size of the output is a multiplication of 8192 then after ap_vformatter returns, vbuff.curpos just passes one byte after the allocated value. (ap_vformatter himself doesn't write beyond the allocated buffer). We can't write NULL to this value as it overflow the buffer.  For a request with /test/?8192, here is the debugger session :  Breakpoint 1, ap_vrprintf (r=0x91f6028, fmt=0xd137af '%s', va=0xb731d218 '(??M/t/005')     at protocol.c:1530 1530        vd.vbuff.curpos = vrprintf_buf; (gdb) n 1531        vd.vbuff.endpos = vrprintf_buf + AP_IOBUFSIZE; (gdb) n 1532        vd.r = r; (gdb) n 1533        vd.buff = vrprintf_buf; (gdb) n 1535        if (r->connection->aborted) (gdb) n 1538        written = apr_vformatter(r_flush, &vd.vbuff, fmt, va); (gdb) n 1541        *(vd.vbuff.curpos) = '/0'; (gdb) p vd.vbuff.curpos - vrprintf_buf $1 = 8192 (gdb) p sizeof(vrprintf_buf) $2 = 8192 (gdb)  This patch deletes the statement which sets the null value. This null value is not used later in the function. buffer_output function flushes rest of the data and it doesn't see the data beyond vdbuff.curpos. Also buffer_output doesn't make any call which assumes NULL character at the end.  Created an attachment (id=20781) Same patch against trunk.  Same patch as submitted by Sunho kim but patch is against trunk.  A patch for this issue was committed in revision 589461:  http://svn.apache.org/viewvc?rev=589461&view=rev a backport proposal (2.2.x) http://svn.apache.org/viewvc?view=rev&revision=589638 In 2.2.7			Basant Kumar Kukreja	Davi Arnaut	Jim Jagielski	SunHo Kim	Takashi Sato
43358	null	RESOLVED		Takashi Sato	1189539480000	1189568114000		documents that have links to Require, AuthName and AuthType (trunk) Require directive was moved from Core to mod_authz_core. AuthName and AuthType directives were moved from Core to mod_authn_core. Some documents that have link(s) to these directives hasn't been modified.	Created an attachment (id=20793)  Patch applied.  http://svn.apache.org/viewvc?rev=574882&view=rev  Thanks again.			Takashi Sato	Vincent Bray
43472	null	RESOLVED		Christian BOITEL	1190712120000	1191735409000		New version socket_is_connected breaks http keep-alive connections I am using a front Apache compiled with worker MPM acting as a reverse proxy  to access back-end http servers  While upgrading to 2.2.6 (from 2.2.4), back-end HTTP connections are no longer  kept alive. While investigating, i found that connections were kept in the  pool but were closed when later being reused.  Found the fix for patch  (http://svn.apache.org/viewvc/httpd/httpd/branches/2.2.x/modules/proxy/proxy_ut il.c?r1=488822&r2=536291&diff_format=h) introduced the wrong behaviour: new  version of is_socket_connected fails and connection is believed to be no  longer usable.  When defining USE_ALTERNATE_IS_CONNECTED to 0 (to revert to old mechanism),  everything is back to normal.  I have using Solaris 2.9 (which defines MSG_PEEK).	Created an attachment (id=20877) Patch proposal against trunk  Can you please check if the attached patch fixes your problem after you set USE_ALTERNATE_IS_CONNECTED back to 1? Thanks. (In reply to comment #1)  Applied patch and perform testes: it fixes problem.  I believe patch should also be backported to 2.2.x branch. Fixed in trunk - r580466 Proposed for backport to  2.2.x as r580625 (http://svn.apache.org/viewcvs.cgi?rev=580466&view=rev). Fix backported in r582620			Christian BOITEL	Nick Kew	Ruediger Pluem
43509	null	RESOLVED		Nick Kew	1190980080000	1191918528000		Proxy MUST parse Connection header and strip headers matching tokens listed Violation of RFC2616 section 14.10, discovered using co-advisor tool.  Proxy correctly parses a single Connection: header and strips headers listed in the Connection.  However, when presented with more than one Connection header, it processes only the first.	Fixed in trunk: r580457 Fixed in r583194.			Nick Kew
43512	null	RESOLVED		Peter Belau	1191004200000	1191158289000		mod_deflate fails to inflate Inflation fails for certain websites. Appears to be caused by lack of validaton bytes where they are expected. Commenting out validation bytes checking in mod_deflate.c does not fix the problem. Size of compressed data is reported as 1 byte in ctx->stream.total_in, uncompressed is 0. Condition can be provoked by requesting:  www.cnn.com www.ebay.com  Probably others as well	Can you please provide the changes that made it work for you as a patch. Even if this is not the solution is would be helpful for analysis of the problem. I just tested both www.cnn.com and www.ebay.com (using my apache as forward proxy and commandline telnet to request uncompressed output), and got the correctly-uncompressed output.  You've been confusing yourself and scaring the rest of us on IRC for rather a long time.  Perhaps it would be a good idea to revert to a clean 2.2.6 install, and work from there. Nick,  In order to duplicate this bug, you need to be using Apache with mod_proxy enabled and mod_deflate in the filter chain set to INFLATE gzip-ed content. I'll be attached an httpd.conf for Apache 2.2.6 that  provokes the buggy behavior. Created an attachment (id=20897) httpd config for  provoking mod_deflate bug  Also, forgot to mention two things:  1. Setting VALIDATON_SIZE to 0 fixes the problem when it pops up 2. Both cnn.com and ebay.com do occasionally send all 8 validation bytes. Please try making the request a few times before you conclude that there's nothing broken   Please set up a testcase for the alleged bug, so I can reproduce it. You can use mod_asis to set exact headers, as well as the gzipped data. I'm working on a test case for you, but the bug is really not at all hard to reproduce. It shows up both with 2.2.6 and TRUNK. Both cnn.com and ebay.com routinely fail more than 50% of the time with both Firefox 1.5 and 2.0. I have been so far unable to reproduce this bug by copying the responses geneated by  by perl IO::Socket to .asis files. In such cases, the files are rendered perfectly through INFLATE. I will continue my attempts at creating a better test case but I'm quite exhausted at this point.  Please note that this really is a bug and not a configuration issue. I would be glad to give someone access to my server if it allows him/her to more expediently identify that this is indeed a bug and not a figment of my imagination.  Hopefully someone can take a look at this thing in earnest; I have not been having a pleasant time trying to fix it myself. Another bit of information:  The log output in error_log is Zlib: Validation bytes not present I was able to reproduce this intermittently (2 requests fail w/ 0 length body, then a success) with:  LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_http_module modules/mod_proxy_http.so LoadModule deflate_module modules/mod_deflate.so  ProxyPass /proxy/  http://www.cnn.com/ LoadModule ext_filter_module modules/mod_ext_filter.so ExtFilterDefine foo mode=output cmd='/usr/bin/perl -p -e 's/^/|/g'' ftype=21 <location /proxy/> ExtFilterOptions debuglevel=999 Setoutputfilter INFLATE;foo;DEFLATE </location>  I sent a request with wget and --header='Accept-Encoding: gzip' Fixed in trunk - r580598.  I expect you'll report back whether this fixes it for you.  Comments: (1) Easy once I could reproduce the problem. (2) This is a problem that has affected many filters that worked fine in 2.0 when moving to 2.2. (3) Sorry about my initial scepticism! Looking good ! I'll do some more testing and try to wrap my head around what you did later (seems like a two line fix, but I didn't immediately understand why it works...)  Good night for now; hope to close out the ticket later. Thanks again.  2.2 r580916 http://svn.apache.org/viewvc?view=rev&revision=580916			Eric Covener	Nick Kew	Peter Belau	Ruediger Pluem	Takashi Sato
43519	null	RESOLVED		Nick Kew	1191166440000	1191821001000		OPTIONS * applies permissions from Document Root An OPTIONS * request will run through check_dir_access.  Since * is not a path, it'll get the permissions of the root directory, and thus be denied in any sane configuration.  This is a core bug, but also affects mod_proxy, as it prevents OPTIONS * requests being proxied.	Not relevant to proxying after all: http://marc.info/?l=apache-httpd-dev&m=119119652229134&w=2  Removing block on PR 43454 OK, I shouldn't be doing this at 2 a.m.  Bah.  OPTIONS * gets the permissions of DocumentRoot, and the test machine I encountered this on had no Allow in its documentroot.  This is IMO still a bug: OPTIONS * shouldn't be mapped to the filesystem, and if any permissions apply it should be <Location /> (which was set to ALLOW in my config). I would propose that only one walk, an explicit <Location '*'> should ever be applied to OPTIONS *.  However, the test must ensure the directive is OPTIONS and deny all other requests for '*' (unless there is some other edge case hiding in RFC2616 or later std/rfc docs).   Created an attachment (id=20902) Simple patch to allow OPTIONS *  OK, the simple fix to this is to patch mod_authz_host.\tI'll do it here, because such a simple fix is n/a in /trunk/. http://svn.apache.org/viewvc/httpd/httpd/trunk/modules/http/http_core.c?r1=581358&r2=581389			Jim Jagielski	Nick Kew	Will Rowe
43534	null	RESOLVED		Tom Donovan	1191298080000	1200743397000		mod_perl and FastCGI fails on Windows The changes in APR 1.2.10+ and Apache 2.2.6 caused mod_perl 2.0.3 to fail on Windows.  mod_perl attempts to save stdin and stdout on entry and restore them on exit.  mod_perl uses POSIX-like int file descriptors - _fileno(stdin) and _fileno(stdout) - for this.  These file descriptors are not updated by setting STD_INPUT_HANDLE and STD_OUTPUT_HANDLE via SetStdHandle(). For example, SetStdHandle(STD_INPUT_HANDLE, newhand) does not change the HANDLE associated with _fileno(stdin). _fileno(stdin) still refers to the original Windows HANDLE  - the pipe handle, regardless of whether it is open or has been closed.  This can be seen by comparing the return value from GetStdHandle(STD_INPUT_HANDLE) to the value from _get_osfhandle(_fileno(stdin)) before and after mpm_winnt.c replaces the stdin handle.  mpm_winnt currently creates a HANDLE to 'NUL' as a replacement stdout when Apache is run as a Windows Service.  Because a console-device HANDLE is not useable (always returns 'invalid handle') when it is inherited by a detached process, this is needed for command-line too.  Attached is a patch to mpm_winnt (2.2.x branch) which:  1. Creates the 'NUL' stdout in the parent for both service and cmd-line execution, rather than just for service. Only single-process mode (-X) retains the original console-device stdout HANDLE.  2. Uses _dup2() in the child to replace the stdin file descriptor with the stdout file descriptor (i.e. to set stdout to 'NUL' except in single-process mode).  Note that this has the side-effect of closing the regular Windows HANDLE to the stdin pipe too, so it must be done after the child is done reading from the parent.  3. Sets the Windows HANDLEs (but not the file descriptors) for stdout and stderr to INVALID_HANDLE_VALUE at child_init for FastCGI modules. See APR bug 43329.  This would allow current Windows FastCGI modules to work with APR 1.2.10+ without requiring APR_NO_FILE flag changes until a major Apache release, while other non-Apache APR programs could still take advantage of the APR process creation changes.  This patch works with mod_fastcgi, mod_fcgid, and mod_perl on Win2k and Vista when built with either VC6 and VS8.	Created an attachment (id=20905) mod_perl and FastCGI patch  Allows mod_perl and FastCGI programs to run with Apache 2.2.6 on Windows Typo in 2. above - I meant:  '(i.e. to set stdin to 'NUL' except in single-process mode)'  Also observed that this patch does not interfere with the new APR behavior re: not leaking unwanted handles.  rotatelogs.exe works as expected with APR 1.2.10+.  Created an attachment (id=21264) new patch for 2.2.x branch 12/12/2007  Updated patch for 2.2.x trunk (revision 603073 - Dec 12, 2007).    Per Bug 43329 - reverting the apr_proc_create behavior fixes the problem for new processes created by mod_fastcgi or mod_fcgid.  STD_OUTPUT_HANDLE and STD_ERROR_HANDLE are now INVALID_HANDLE_VALUE as required.  The Apache child process itself must be created with valid stdout and stdin file descriptors (vs. HANDLEs) for modules which use fd's. It is OK for these to be file descriptors to 'NUL'.  This patch always creates the Apache child with 'NUL' as stdout, which the child later _dup2's to stdin after all the info has been collected from the parent via the stdin pipe.  This leaves the Apache child with acceptable fd's for stdin and stdout to satisfy modules which use fd's instead of HANDLEs (like mod_perl).  I'm reviewing the patch I had already authored (see URL above) which applied to both 2.2.x and 2.0.x branches.  I'll then examine that it meets the requirements of the patch Tom has attached to this incident, because I think it covers all the bases but need to confirm.  If anyone else active in resolving this bug is interested, the current httpd 2.2.x branch from svn, and the 1.2.12 apr[-util] release (or 1.2.x svn branch) can be used to verify the current behavior before release. (In reply to comment #4) > I'm reviewing the patch I had already authored (see URL above) which applied > to both 2.2.x and 2.0.x branches.  Not sure which 'URL above' is meant here.  The current revision of the 2.2.x branch (rev 607543 30-Dec-2007), which includes change 607311 to mpm_winnt.c, will run mod_perl only when Apache is started as a Windows service.  If Apache is started from the command line, the error when mod_perl is invoked is:   Failed to dup STDOUT: Bad file descriptor.  [Sun Dec 30 08:18:22 2007] [notice] Parent: child process exited with status 9 -- Restarting.  It is a welcome improvement that mod_perl errors (like 'Failed to dup') now appear in the error log. Created an attachment (id=21351) Updated patch for 2.2.7  Updated patch to work with Apache 2.2.7 RC.  Only the command-line case needed to be fixed.    mpm_winnt already creates a stdout handle to 'NUL', but only when started as a Windows Service.  This 'NUL' handle is acceptable to mod_perl as both stdin and stdout.  Since console handles don't inherit - when Apache is started from the command-line mod_perl gets an invalid stdout. This patch changes mpm_winnt to *always* create a 'NUL' stdout handle when creating a child process, for both Windows service and command-line startup.  Single-process mode (-X) has always worked with mod_perl.  There is no process creation, therefore no handle inheritance is involved.\tBecause the original (real) console handles are valid, mod_perl runs correctly. Troubles with this patch; it doesn't mirror unix behavior (which is actually right in this case) and it introduces a service regression just as the earlier patch I committed introduced a console regression.  The unix behavior is that the stdout channel should be fixed at the moment that  configure is finished.  This ensures any normal emits from perl, etc are seen in the parent by the user.  I'm working to track down where that happens, it may be at daemonize() and actually embedded in apr, and I'm looking at a best solution to mirror unix.  The regression is that stdio (and stderr and stdin) are third rails in a service that we can't touch before they have been repaired.  The existing location of the stdout substitution can't and won't be changed.  Thanks for the patch and the thorough explanation on dev@httpd, I'm proceeding with the patch that will resolve this without modifying unix nor services.   Here we go;  on Unix, apr_proc_detach(1) causes all of the descriptors to be replaced with the /dev/null handle, and this is precisely the behavior we want.  Today on unix this occurs in pre_config (c.f. worker.c and prefork.c).  However this behavior is a bit borked in the minds of some developers, who are frustrated with the fact that perl emits that showed up in 1.3 no longer show up in 2.0. But I can agree for now that we have to mirror unix, at least our register_hooks and earlier pre_config hooks will mirror unix.  See the revised patch which only modifies normal console-mode operation at;    http://svn.apache.org/viewvc?view=rev&revision=609354  review and let me know if this satisfies your test cases, and I'll backport ASAP.   Corrected patch cited (now that I can take it to win32).  Sorry the initial backport was actually from unix.  http://svn.apache.org/viewvc/httpd/httpd/trunk/server/mpm/winnt/mpm_winnt.c?r1=607677&r2=609366   (In reply to comment #9) r609366 applied to Apache 2.2.7 works as expected.  Windows-service, command-line, and single-process (-X) all run mod_perl OK with this change.  Command-line startup with no console also works OK - e.g. 'START /B httpd.exe' or Apache started via CreateProcess(...DETACHED_PROCESS...).  Backported to both 2.0 and 2.2, I think we can at last tag this FIXED for the forthcoming 2.2.8 and 2.0.63 releases.  Thanks for all of your help Tom! (In reply to comment #11) > Backported to both 2.0 and 2.2, I think we can at last tag this FIXED for the > forthcoming 2.2.8 and 2.0.63 releases.  Thanks for all of your help Tom!  Thanks for the kind words - but you may not want to thank me just yet.  I failed to notice that with the current fix, closing the Apache window does not shut down Apache (presuming a window is displayed) .  Ditto for right-click [Close] on the task-bar icon.  This was not a problem with the previous patch, so somehow the windows console (vs. the child window itself) is not associated with the parent process with this fix.  I see this on Win2k and Steffen reports the same on XP. I regret we didn't catch this quicker. Fixed in 2.2.8.			Ruediger Pluem	Tom Donovan	Will Rowe
43562	null	RESOLVED		Jose Kahan	1191574800000	1208419092000		PR 21059 is not needed anymore and has degraded the use of mod_speling; please suprress Please remove PR 21059 from mod_speling as it has downgraded the behavior of Apache 2.2 and also because bug 21059 was solved by changes elsewhere in the code. The patch I'm submitting effectively deletes PR 21059.  Detailed report:  Way back in 2003, the following dependency was added to mod_speling:check_speling(), as an attempt to fix bug report # 21059 [1] for Apache 2.0.45. This patch was apparently applied only to the 2.2 tree:  [[     /* we default to reject path info (same as core handler) */     if ((r->used_path_info != AP_REQ_ACCEPT_PATH_INFO) &&         r->path_info && *r->path_info) {         return DECLINED;     } ]]  This patch has had a bad side effect on Apache 2.2: use of mod_speling is now conditioned to the use of AcceptPathInfo; it's not possible anymore to use mod_speling without having AcceptPathInfo turned on.  With all due respect, I believe that the correct approach would have rather been to add a directive similar to mod_mime's ModMimeUsePathInfo [2], which is 'is used to combine the filename with the path_info URL component to apply mod_mime's directives to the request.' This requires a deeper code change than what the patch proposed.  This patch has also downgraded the behavior of Apache 2.2; if you were using mod_speling, URIs that returned status 404 under Apache 1.3 are now returning status 200, because you need to enable AcceptPathInfo to be able to use mod_speling.  If we look at bug report 21059, I see that it is describing a standard behavior in Apache 1.3:    1. the client passed a path_info in its request       http://www.abcdatos.com/programas/traductores/   2. mod_negotiation (and not mod_speling), converted the URI to:       http://www.abcdatos.com/programas/traductores/'  The real bug here, according to the report, is that the server returns 404, regardless of the user's enabling of AcceptPathInfo. Up to this moment, mod_speling has not been concerned: there has been no spelling correction.  Let's jump  back to the future and to Apache 2.2. I made the following tests (detailed results here below):  1. Apache 1.3 with mod_speling 2. Apache 2.2.4; mod_speling with PR 21059 and AcceptPathInfo enabled 3. Apache 2.2.4; mod_speling without PR 21059 removed and AcceptPathInfo  disabled 4. Apache 2.2.4; mod_sepling witout PR 21059 and AcceptPathInfo enabled  To summarize the results, removing the patch to mod_speling and disabling AcceptPathInfo gives us the same behavior as with Apache 1.3. Moreover, removing the patch and enabling AcceptPathInfo does pass the path info to the resource, thus showing that the behavior described in bug report 21059 was fixed elsewhere in the code and that PR 21059 is not needed.  There have been other bug reports about the side-effects and nuisance of binding mod_speling with a global AcceptPathInfo (e.g, # 38635 [3] and mailing list posts)).  I would strongly advise to remove this dependency and, when resources are available, add a better integration of AcceptPathInfo processing into mod_speling, such as the one done in mod_mime via ModMimeUsePathInfo.  Cheers,  -jose  [1] http://issues.apache.org/bugzilla/show_bug.cgi?id=21059 [2] http://httpd.apache.org/docs/2.2/mod/mod_mime.html#modmimeusepathinfo [3] http://issues.apache.org/bugzilla/show_bug.cgi?id=38635  --------------- detailed tests  We're requesting http://www.w3.org/INSTALL.html, using different versions of the Apache server and different variations on the URI.  --------------  1. Apache 1.3.37 (gives us our 'standard' behavior)  *** Without '/' after the URI:  http://www.w3.org/INSTALL.html  --> 200  OK  http://www.w3.org/INSTALL  --> 200 OK    Content-Location: INSTALL.html  http://www.w3.org/Install --> 300 Multiple Choices (INSTALL.html) http://www.w3.org/Install.html --> 301 Moved Permanently (INSTALL.html) http://www.w3.org/Install.HTML --> 301 Moved Permanently (INSTALL.html)  ** With '/' after the URI:    --> Content-Location header is not sent anymore  http://www.w3.org/INSTALL/ --> 404 Not Found http://www.w3.org/INSTALL.html/ --> 404 Not Found http://www.w3.org/Install/ --> 300 Multiple Choices (/INSTALL.html/) http://www.w3.org/Install.html/ --> 301 Moved Permanently (INSTALL.html/)    --> Conclusion: They will all end returning  404  ** With '/foo' after the URI:  http://www.w3.org/INSTALL.html/foo --> 404 Not Found http://www.w3.org/INSTALL/foo --> 404 Not Found    --> No redirection http://www.w3.org/Install.html/foo --> 301 Moved Permanently (INSTALL.html/foo) http://www.w3.org/Install/foo --> 300 Multiple Choices (INSTALL.html/foo)     --> Conclusion: They will all end returning  404  Summary:   Only INSTALL returns valid content in the end; all the other variations, INSTALL/ or INSTALL/foo, return 404.  ==============  2. Apache 2.2.4 with AcceptPathInfo enabled; mod_speling contains PR 21059  *** Without '/' after the URI:  http://www.w3.org/INSTALL.html  --> 200  OK  http://www.w3.org/INSTALL  --> 200 OK    Content-Location: INSTALL.html  http://www.w3.org/Install --> 300 Multiple Choices (INSTALL.html) http://www.w3.org/Install.html --> 301 Moved Permanently (INSTALL.html) http://www.w3.org/Install.HTML --> 301 Moved Permanently (INSTALL.html)  ** With '/' after the URI:   http://www.w3.org/INSTALL/ --> 200 OK http://www.w3.org/INSTALL.html/ --> 200 OK http://www.w3.org/Install/ --> 300 Multiple Choices (/INSTALL.html/) http://www.w3.org/Install.html/ --> 301 Moved Permanently (INSTALL.html/)  ** With '/foo' after the URI:  http://www.w3.org/INSTALL/foo --> 200 OK http://www.w3.org/INSTALL.html/foo --> 200 OK http://www.w3.org/Install/foo --> 300 Multiple Choices (/INSTALL.html/foo) http://www.w3.org/Install.html/foo --> 301 Moved Permanently (INSTALL.html/foo)  Summary:   The server always return status code 200 if we want to use mod_speling, because of the biding with AcceptPathInfo on.  There's no way to have the same behavior as under Apache 1.3.  =======  3. Apache 2.2.4 with AcceptPathInfo disabled; mod_speling without PR 21059  *** Without '/' after the URI:  http://www.w3.org/INSTALL.html  --> 200  OK  http://www.w3.org/INSTALL  --> 200 OK    Content-Location: INSTALL.html  http://www.w3.org/Install --> 300 Multiple Choices (INSTALL.html) http://www.w3.org/Install.html --> 301 Moved Permanently (INSTALL.html) http://www.w3.org/Install.HTML --> 301 Moved Permanently (INSTALL.html)  ** With '/' after the URI:   http://www.w3.org/INSTALL/ --> 404 Not Found http://www.w3.org/INSTALL.html/ --> 404 Not Found http://www.w3.org/Install/ --> 300 Multiple Choices (/INSTALL.html/) http://www.w3.org/Install.html/ --> 301 Moved Permanently (INSTALL.html/)  ** With '/foo' after the URI:  http://www.w3.org/INSTALL.html/foo --> 404 Not Found http://www.w3.org/INSTALL/foo --> 404 Not Found http://www.w3.org/Install.html/foo --> 301 Moved Permanently (INSTALL.html/foo) http://www.w3.org/Install/foo --> 300 Multiple Choices (INSTALL.html/foo)  Conclusion:  Removing PR 21059 and disabling AcceptPathInfo gives us the same behavior as under Apache 1.3. mod_speling is not conditioned anymore to the AcceptPathInfo directive.  ==========  4. Apache 2.2.4 with AcceptPathInfo enabled; mod_speling without PR 21059  *** Without '/' after the URI:  http://www.w3.org/INSTALL.html  --> 200  OK  http://www.w3.org/INSTALL  --> 200 OK    Content-Location: INSTALL.html  http://www.w3.org/Install --> 300 Multiple Choices (INSTALL.html) http://www.w3.org/Install.html --> 301 Moved Permanently (INSTALL.html) http://www.w3.org/Install.HTML --> 301 Moved Permanently (INSTALL.html)  ** With '/' after the URI:   http://www.w3.org/INSTALL/ --> 404 Not Found http://www.w3.org/INSTALL.html/ --> 404 Not Found http://www.w3.org/Install/ --> 300 Multiple Choices (/INSTALL.html/) http://www.w3.org/Install.html/ --> 301 Moved Permanently (INSTALL.html/)  ** With '/foo' after the URI:  http://www.w3.org/INSTALL.html/foo --> 200 OK http://www.w3.org/INSTALL/foo --> 200 OK http://www.w3.org/Install.html/foo --> 301 Moved Permanently (INSTALL.html/foo) http://www.w3.org/Install/foo --> 300 Multiple Choices (INSTALL.html/foo)  Conclusion:  Removing PR 21059 and enabling AcceptPathInfo gives us the same behavior as under Apache 1.3, with the addition of being able to pass on the path info to the resource. This shows effectively that bug #21059 was solved elsewhere in the code and that PR 21059 in mod_speling is not related at all.	Created an attachment (id=20923) removes PR 21059 from mod_speling. Patch against 2.2.6  Created an attachment (id=20924) removes PR 21059 from mod_speling. Patch against trunk  One thing to add to this report is a rather serious side effect this mod_speling/pathinfo bug inadvertently introduces, infinitely recursive uris.  Clueless crawlers, which are many, do not notice from the ETAG that they are getting is identical to a resource they already indexed.  When parsing a resource for links they accessed with a trailing / and coming across a relative uri they naturally append the relative path to the uri they already have as a resource to crawl.  For example:  http://www.w3.org/INSTALL.html/Library/src/Library/src/ --> 200 OK  http://www.w3.org/INSTALL.html/Library/src/Library/src/Library/src/ --> 200 OK  ad nauseam  Except as perhaps a teergrube exercise to trap and hold hostage unsuspecting crawlers indefinitely this is generally undesirable.  Regards, fixed in trunk r635953. Will propose for 2.2 backport backported to 2.2 as r649120 http://svn.apache.org/viewvc?view=rev&revision=649120			Jim Jagielski	Jose Kahan	Takashi Sato	Ted Guild
43649	null	RESOLVED		Jose Kahan	1192695060000	1195572496000		mod_autoindex is generating invalid XHTML markup mod_autoindex is generating invalid XHTML markup. The xhtml namespace was  missing in emit_preamble(). I'm including a patch against both 2.2.6 and trunk  that fixes it.  Bug report 34519 is quite similar, but mentions other enhancements (and didn't  include a patch). I decided to make a new bug report as I was not sure if it  was OK to reply to one of the points given in the previous report.	Created an attachment (id=21003) mod_autoindex was not adding the xhtml namespace  Patch against 2.2.6 Created an attachment (id=21004) mod_autoindex was not adding the xhtml namespace  Patch against trunk Committed to trunk as r59381 (http://svn.apache.org/viewvc?rev=593778&view=rev). Thanks for the patch. Proposed for backport as r593818 (http://svn.apache.org/viewvc?rev=593818&view=rev). Here's an idea:  These autoindexes should not only be valid markup but promote open standards (valid markup) by linking back to W3C's Validator.  If you are open to the idea it would be ideal if Apache were to include W3C valid markup logos in the /icons directory so as to distribute load of serving those icons on all the new valid autoindex URIs.  In turn we can promote adoption of Apache 2.2, as apparently many are still 1.3, on the Validator's results page eg    http://validator.w3.org/check?uri=http%3A//www.w3.org/&doctype=Inline&%20outline=  We could give an alternate markup for Apache instances >2.2.N to all users or perhaps just for sites we detect the Server: header as still Apache 1.3 or 2.0    <p>     <a href='http://validator.w3.org/check?uri=referer'><img         src='/icons/valid-xhtml10'         alt='Valid XHTML 1.0 Strict' height='31' width='88' /></a>   </p> I don't like it. to 2.2 as r596675 <http://svn.apache.org/viewvc?view=rev&revision=596675>			Andr?? Malo	Jose Kahan	Ruediger Pluem	Takashi Sato	Ted Guild
43711	null	RESOLVED		Ragini Bisarya	1193407680000	1203698253000		100-continue response when 401 expected General comments -  ---------------- This bug is reproducible.  I have marked it a regression because to works fine in Apache 1.3 but not in Apache 2. Here is the link to the email exchange on users@httpd.apache.org on this issue.  http://www.gossamer-threads.com/lists/apache/users/340314#340314.  Overview Description: --------------------- For PUT requests with a Expect: 100-continue header, Apache 2.2.6 server sends a HTTP/1.1 100 Continue response before checking to see if a 401 or 405 response might need to be sent for the request.   When the resource requires authentication, Apache 2.6 sends a 100 Continue instead of a 401. After the client sends the request body, Apache 2.2.6 returns a 401 and now the client ends up having to send the request body again.  For large request body sending the entire body multiple times defeats the purpose of the continue response stated in the HTTP 1.1 RFC - http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.2.3   When a resource does *not* require authentication Apache 2.2.6 and Apache 1.3 both send a 100 Continue as expected and there are no issues there.   Steps to Reproduce:  ---------------------  1-5 are to setup Apache for this test.  1. Create a directory named 'secret' under htdocs. 2. Create a passwords file with user 'test' and a passwd. 3. Create a .htaccess file in the secret directory  My .htaccess had -  AuthType Basic  AuthName 'secret_access'  AuthBasicProvider file  AuthUserFile /opt/apache226/htdocs/.passwd  Require user test  4. Enable PUT method support by adding 'Script PUT /cgi-bin/put.cgi' to the httpd.conf. 5. I used the put script available at - http://www.apacheweek.com/issues/put1 for this test and copied it to the cgi-bin dir.  6. Send the following PUT request to the Apache 2 server.  PUT /secret/test.html HTTP/1.1 Host: 10.10.10.1:8080 Expect: 100-continue Date: Mon, 15 Oct 2007 20:05:24 GMT Connection: Keep-Alive Content-Length: 49 Content-Type: application/octet-stream    Actual Results : ----------------- HTTP/1.1 100 Continue   Expected Results: ------------------ HTTP/1.1 401 Authorization Required Date: Mon, 15 Oct 2007 20:05:24 GMT Server: Apache/2.2.6 (Unix) WWW-Authenticate: Basic realm='secret_access' Content-Length: 401 Keep-Alive: timeout=5, max=100 Connection: Keep-Alive    With Apache 1.3 the complete exchange was as follows -  PUT /secret/test.html HTTP/1.1 Host: 10.10.10.1:8888 Expect: 100-continue Date: Mon, 15 Oct 2007 22:22:24 GMT Connection: Keep-Alive Content-Length: 49 Content-Type: application/octet-stream   HTTP/1.1 401 Authorization Required Date: Mon, 15 Oct 2007 22:22:24 GMT Server: Apache/1.3.33 (Unix) WWW-Authenticate: Basic realm='secret_access' Content-Length: 401 Connection: close etc...   PUT /secret/test.html HTTP/1.1 Host: 10.10.10.1:8080 Authorization: Basic dGVzdDp0ZXN0 Date: Mon, 15 Oct 2007 22:22:24 GMT Connection: Keep-Alive Content-Length: 49 Content-Type: application/octet-stream  <html><body><h1>Secret works!</h1></body></html>   HTTP/1.1 204	Thanks for entering this as a bug.  The basic problem is that the HTTP protocol input filter (ap_http_filter) actually sends the 100-continue.  That's way too early.  I think the fix should be to remove that code from the protocol filter, and send the 100 response from a fixups hook.  Bug me if I don't get around to doing anything about it. Created an attachment (id=21053) Patch against trunk  Can you please check if the attached patch solves your problem? Thanks for the patch.   I patched in the change to the Apache 2.2.6 source code version. And it did not work as I expected it to. The server sent both a 401 AND a 100 response for the PUT request!  Next I will pull the trunk version of the source code to test this patch and let you know the results.   For 2.2.6 you also need to apply the patch for PR38014 (http://svn.apache.org/viewvc?view=rev&revision=574950) which has been already backported to 2.2.x. Thus it worked for me. Results of testing this using the trunk version of the source code + the patch.  A 401 was returned instead of the 100 continue, so that is good. But when the PUT request with the auth header was sent by the client on that connection, the server's state seemed to be all wrong.  Looking at the hex dump of the 401 response returned by the server, it looks like the last chunk of the response (the 401 response has Transfer-encoding = chunked) with 0 length and the CRLF was not sent by the server so the 401 response sent by the server is actually incomplete.  Test 1 - PUT request for resource that requires authentication - Result is NOT OK  ===> sending the request with out the Auth header PUT /secret/test.html HTTP/1.1 Host: 10.10.10.1:8080 Expect: 100-continue Date: Mon, 15 Oct 2007 20:05:24 GMT Connection: Keep-Alive Content-Length: 49 Content-Type: application/octet-stream   HTTP/1.1 401 Authorization Required Date: Tue, 30 Oct 2007 00:04:18 GMT Server: Apache/2.3.0-dev (Unix) WWW-Authenticate: Basic realm='secret_access' Keep-Alive: timeout=5, max=100 Connection: Keep-Alive Transfer-Encoding: chunked Content-Type: text/html; charset=iso-8859-1  192 <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>401 Authorization Required</title> </head><body> <h1>Authorization Required</h1> <p>This server could not verify that you are authorized to access the document requested.  Either you supplied the wrong credentials (e.g., bad password), or your browser doesn't understand how to supply the credentials required.</p> </body></html>  ===> NOTE - the 0 length chunk was not sent. ===> sending the request WITH the auth header PUT /secret/test.html HTTP/1.1 Host: 10.10.10.1:8080 Authorization: Basic dGVzdDp0ZXN0 Date: Mon, 15 Oct 2007 22:22:24 GMT Connection: Keep-Alive Content-Length: 49 Content-Type: application/octet-stream0  <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>501 Method Not Implemented</title> </head><body> <h1>Method Not Implemented</h1> <p>8080 to /index.html not supported.<br />      ===> the server thinks the new request method is 8080 - the characters halfway through the Host header in the request. </p> </body></html>  Connection closed by foreign host.  Looks like even though a 401 was sent out, the server is in some weird state. If the client sends two CRs at this point this results in the server sending back a 0 length chunk.  Trying a GET request on this server confirmed that this server does send a correct and complete 401 in the case of GET as shown below.  GET /secret/test.html HTTP/1.1 Host: 1.1.1.1  HTTP/1.1 401 Authorization Required Date: Tue, 30 Oct 2007 00:44:15 GMT Server: Apache/2.3.0-dev (Unix) WWW-Authenticate: Basic realm='secret_access' Transfer-Encoding: chunked Content-Type: text/html; charset=iso-8859-1  192 <!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'> <html><head> <title>401 Authorization Required</title> </head><body> <h1>Authorization Required</h1> <p>This server could not verify that you are authorized to access the document requested.  Either you supplied the wrong credentials (e.g., bad password), or your browser doesn't understand how to supply the credentials required.</p> </body></html>   0  Connection closed by foreign host.    Test 2 - PUT request for resource that does not required authentication - OK. Same as before patch.   PUT /test.html HTTP/1.1 Host: 10.10.10.1:8888 Expect: 100-continue Date: Mon, 15 Oct 2007 22:22:24 GMT Connection: Keep-Alive Content-Length: 49 Content-Type: application/octet-stream  HTTP/1.1 100 Continue  <html><body><h1>Secret works!</h1></body></html>  HTTP/1.1 204 No Content Date: Mon, 29 Oct 2007 21:31:13 GMT Server: Apache/2.3.0-dev (Unix) Content-Length: 0 Keep-Alive: timeout=5, max=100 Connection: Keep-Alive Content-Type: text/html  Test results for Apache 2.2.6 + PR38014 patch + patch for this bug are the same as those reported in Comment #6.  The hexdump for the 401 response is as follows -    0     :  48 54 54 50 2F 31 2E 31  20 34 30 31 20 41 75 74   *HTTP/1.1 401 Aut*  16    :  68 6F 72 69 7A 61 74 69  6F 6E 20 52 65 71 75 69   *horization Requi*  32    :  72 65 64 0D 0A 44 61 74  65 3A 20 54 75 65 2C 20   *red..Date: Tue, *  48    :  33 30 20 4F 63 74 20 32  30 30 37 20 30 31 3A 32   *30 Oct 2007 01:2*  64    :  37 3A 35 39 20 47 4D 54  0D 0A 53 65 72 76 65 72   *7:59 GMT..Server*  80    :  3A 20 41 70 61 63 68 65  2F 32 2E 32 2E 36 20 28   *: Apache/2.2.6 (*  96    :  55 6E 69 78 29 0D 0A 57  57 57 2D 41 75 74 68 65   *Unix)..WWW-Authe*  112   :  6E 74 69 63 61 74 65 3A  20 42 61 73 69 63 20 72   *nticate: Basic r*  128   :  65 61 6C 6D 3D 22 6C 65  76 65 6C 5F 31 35 5F 61   *ealm='level_15_a*  144   :  63 63 65 73 73 22 0D 0A  4B 65 65 70 2D 41 6C 69   *ccess'..Keep-Ali*  160   :  76 65 3A 20 74 69 6D 65  6F 75 74 3D 35 2C 20 6D   *ve: timeout=5, m*  176   :  61 78 3D 31 30 30 0D 0A  43 6F 6E 6E 65 63 74 69   *ax=100..Connecti*  192   :  6F 6E 3A 20 4B 65 65 70  2D 41 6C 69 76 65 0D 0A   *on: Keep-Alive..*  208   :  54 72 61 6E 73 66 65 72  2D 45 6E 63 6F 64 69 6E   *Transfer-Encodin*  224   :  67 3A 20 63 68 75 6E 6B  65 64 0D 0A 43 6F 6E 74   *g: chunked..Cont*  240   :  65 6E 74 2D 54 79 70 65  3A 20 74 65 78 74 2F 68   *ent-Type: text/h*  256   :  74 6D 6C 3B 20 63 68 61  72 73 65 74 3D 69 73 6F   *tml; charset=iso*  272   :  2D 38 38 35 39 2D 31 0D  0A 0D 0A 31 39 31 0D 0A   *-8859-1....191..*  288   :  3C 21 44 4F 43 54 59 50  45 20 48 54 4D 4C 20 50   *<!DOCTYPE HTML P*  304   :  55 42 4C 49 43 20 22 2D  2F 2F 49 45 54 46 2F 2F   *UBLIC '-//IETF//*  320   :  44 54 44 20 48 54 4D 4C  20 32 2E 30 2F 2F 45 4E   *DTD HTML 2.0//EN*  336   :  22 3E 0A 3C 68 74 6D 6C  3E 3C 68 65 61 64 3E 0A   *'>.<html><head>.*  352   :  3C 74 69 74 6C 65 3E 34  30 31 20 41 75 74 68 6F   *<title>401 Autho*  368   :  72 69 7A 61 74 69 6F 6E  20 52 65 71 75 69 72 65   *rization Require*  384   :  64 3C 2F 74 69 74 6C 65  3E 0A 3C 2F 68 65 61 64   *d</title>.</head*  400   :  3E 3C 62 6F 64 79 3E 0A  3C 68 31 3E 41 75 74 68   *><body>.<h1>Auth*  416   :  6F 72 69 7A 61 74 69 6F  6E 20 52 65 71 75 69 72   *orization Requir*  432   :  65 64 3C 2F 68 31 3E 0A  3C 70 3E 54 68 69 73 20   *ed</h1>.<p>This *  448   :  73 65 72 76 65 72 20 63  6F 75 6C 64 20 6E 6F 74   *server could not*  464   :  20 76 65 72 69 66 79 20  74 68 61 74 20 79 6F 75   * verify that you*  480   :  0A 61 72 65 20 61 75 74  68 6F 72 69 7A 65 64 20   *.are authorized *  496   :  74 6F 20 61 63 63 65 73  73 20 74 68 65 20 64 6F   *to access the do*  512   :  63 75 6D 65 6E 74 0A 72  65 71 75 65 73 74 65 64   *cument.requested*  528   :  2E 20 20 45 69 74 68 65  72 20 79 6F 75 20 73 75   *.  Either you su*  544   :  70 70 6C 69 65 64 20 74  68 65 20 77 72 6F 6E 67   *pplied the wrong*  560   :  0A 63 72 65 64 65 6E 74  69 61 6C 73 20 28 65 2E   *.credentials (e.*  576   :  67 2E 2C 20 62 61 64 20  70 61 73 73 77 6F 72 64   *g., bad password*  592   :  29 2C 20 6F 72 20 79 6F  75 72 0A 62 72 6F 77 73   *), or your.brows*  608   :  65 72 20 64 6F 65 73 6E  27 74 20 75 6E 64 65 72   *er doesn't under*  624   :  73 74 61 6E 64 20 68 6F  77 20 74 6F 20 73 75 70   *stand how to sup*  640   :  70 6C 79 0A 74 68 65 20  63 72 65 64 65 6E 74 69   *ply.the credenti*  656   :  61 6C 73 20 72 65 71 75  69 72 65 64 2E 3C 2F 70   *als required.</p*  672   :  3E 0A 3C 2F 62 6F 64 79  3E 3C 2F 68 74 6D 6C 3E   *>.</body></html>*  688   :  0A 0D 0A -- -- -- -- --  -- -- -- -- -- -- -- --   *...-------------*  Changing the state of the bug since the required information has been provided. Created an attachment (id=21407) don't send 100 continue if a client error (4xx) occurred  Could you please try this patch (made against apache 2.2.6) and let me know if it fixes your issue.  Thanks Created an attachment (id=21408) don't send 100 continue if a client error (4xx) occurred  Try this instead of the previous patch (again made against 2.2.6) Created an attachment (id=21414) don't send 100 continue if a client error (4xx) occurred - patch against 2.2.8  Patch to fix the issue made against httpd 2.2.8 (In reply to comment #11) > Created an attachment (id=21414) [edit] > don't send 100 continue if a client error (4xx) occurred - patch against 2.2.8 >  > Patch to fix the issue made against httpd 2.2.8  This patch worked perfectly. Thanks for fixing this.  FYI -  Test result for resource that requires authentication -  PUT /secret/test.html HTTP/1.1 Host: 10.10.10.1:8080 Expect: 100-continue Date: Mon, 15 Oct 2007 20:05:24 GMT Connection: Keep-Alive Content-Length: 49 Content-Type: application/octet-stream   HTTP/1.1 401 Authorization Required Date: Fri, 25 Jan 2008 22:52:05 GMT Server: Apache/2.2.8 (Unix) WWW-Authenticate: Basic realm='test' Content-Length: 401 Keep-Alive: timeout=5, max=100 Connection: Keep-Alive Content-Type: text/html; charset=iso-8859-1 etc...  PUT /secret/test.html HTTP/1.1 Host: 10.10.10.1:8080 Authorization: Basic dGVzdDp0ZXN0DQo= Date: Mon, 15 Oct 2007 22:22:24 GMT Connection: Keep-Alive Content-Length: 49 Content-Type: application/octet-stream  <html><body><h1>Secret works!</h1></body></html>  HTTP/1.1 204 No Content Date: Fri, 25 Jan 2008 22:52:10 GMT Server: Apache/2.2.8 (Unix) Content-Length: 0 Keep-Alive: timeout=5, max=99 Connection: Keep-Alive Content-Type: text/html   Fixed in trunk - r628644 Fix backported to 2.2.x in r630366 - will be in 2.2.9. *** Bug 44492 has been marked as a duplicate of this bug. ***			Chetan Reddy	Nick Kew	Ragini Bisarya	Ruediger Pluem
43738	null	CLOSED		Garrett Wollman	1193756220000	1194232817000		Who is hiding my buffered POST data from mod_ssl after renegotiation? These logs show a connection to a FastCGI server in a directory which requires SSL renegotiation.  mod_fastcgi uses the deprecated ap_get_client_block() family  to read POST data from the client, but rewriting it to use the underlying Apache 2 APIs shows identical results.  I've deleted a few lines that aren't relevant to this analysis...  [Tue Oct 30 16:41:47 2007] [info] [client 128.30.28.20] Connection to child 9 established (server courses.csail.mit.edu:443) ... [Tue Oct 30 16:41:47 2007] [debug] ssl_engine_io.c(1478): [client 128.30.28.20] filling buffer [Tue Oct 30 16:41:47 2007] [debug] ssl_engine_io.c(1529): [client 128.30.28.20] total of 525 bytes in buffer, eos=1 ...my analysis concentrates here... [Tue Oct 30 16:42:21 2007] [error] [client 128.30.28.20] FastCGI: comm with server '/usr/bin/php5-cgi' aborted: idle timeout (30 sec), referer: [URI deleted] [Tue Oct 30 16:42:21 2007] [debug] ssl_engine_io.c(1561): [client 128.30.28.20] read from buffered SSL brigade, mode 0, 8192 bytes [Tue Oct 30 16:42:21 2007] [debug] ssl_engine_io.c(1623): [client 128.30.28.20] buffered SSL brigade now exhausted; removing filter  The reason for the timeout is that the FastCGI server is waiting to read POST data from the server which never arrives.  In fact, the server thinks it should be passing client data, but when ap_get_client_block() attempts to read the client data, it gets an EOS.  More interestingly, an examination of the input_filter chain at that point shows 'http_in' followed by 'ssl/tls filter'; I believe the second (or maybe the first) filter here should be 'ssl/tls buffer' instead.  (We know from the two previous lines that the POST content has been successfully buffered.)  The buffer does eventually get read, as the following log entries show -- but not by mod_fastcgi.  The very last thing that ssl_io_buffer_fill() does is add the 'ssl/tls buffer' filter, so I don't understand why it doesn't appear at the head of the input filter list when ap_get_client_block() is running, nor why it does get read (and presumably is in the filter chain) after the request is aborted.	Curious.  Can you get a dump of the r->input_filters in gdb at the point where ap_get_client_block() is called in mod_fastcgi?  source /path/to/httpd-source/.gdbinit dump_filters r->input_filters  Here's what GDB thinks (gdb) b ap_get_client_block Breakpoint 1 at 0x441f60 (gdb) cont Continuing.  Breakpoint 1, 0x0000000000441f60 in ap_get_client_block () (gdb) up #1  0x00002b952d63a703 in do_work (r=0x819238, fr=0x84d0c0)     at mod_fastcgi.c:868 868             if ((countRead = ap_get_client_block(fr->r, end, count)) < 0) (gdb) source /afs/csail.mit.edu/u/w/wollman/public/apache2/apache2-2.2.3/.gdbinit  (gdb) dump_filters fr->r->input_filters http_in(0x826c98): ctx=0x83e990, r=0x819238, c=0x810248 ssl/tls filter(0x81e098): ctx=0x81c048, r=0x0, c=0x810248 log_input_output(0x8109f0): ctx=0x0, r=0x0, c=0x810248 core_in(0x81e140): ctx=0x81e120, r=0x0, c=0x810248 (gdb) p *r $1 = {pool = 0x825088, connection = 0x810248, server = 0x6d0478, next = 0x0,    prev = 0x8250f8, main = 0x0,    the_request = 0x8266b0 'POST /16.410/wiki/index.php?title=Special:Preferences HTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0,    protocol = 0x8267b0 'HTTP/1.1', proto_num = 1001,    hostname = 0x826c78 'more-courses.csail.mit.edu',    request_time = 1193866479991696, status_line = 0x0, status = 200,    method = 0x826700 'POST', method_number = 2, allowed = 0,    allowed_xmethods = 0x0, allowed_methods = 0x84b828, sent_bodyct = 0,    bytes_sent = 0, mtime = 0, chunked = 0, range = 0x0, clength = 0,    remaining = 525, read_length = 0, read_body = 1, read_chunked = 0,    expecting_100 = 0, headers_in = 0x8253d8, headers_out = 0x819af0,    err_headers_out = 0x825d20, subprocess_env = 0x819d38, notes = 0x84b688,    content_type = 0x84a308 'application/x-httpd-fastphp5',    handler = 0x2b952d6428c8 'fastcgi-script', content_encoding = 0x0,    content_languages = 0x0, vlist_validator = 0x0,    user = 0x84d028 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0,    no_local_copy = 0,    unparsed_uri = 0x819518 '/.php5-cgi/16.410/wiki/index.php?title=Special:Preferences', uri = 0x819558 '/.php5-cgi/16.410/wiki/index.php',    filename = 0x84c418 '/usr/bin/php5-cgi',    canonical_filename = 0x84c418 '/usr/bin/php5-cgi',    path_info = 0x84c2f9 '/16.410/wiki/index.php',  ---Type <return> to continue, or q <return> to quit---    args = 0x819580 'title=Special:Preferences', finfo = {pool = 0x825088,      valid = 7598448, protection = 1877, filetype = APR_REG, user = 0,      group = 0, inode = 283762, device = 2049, nlink = 1, size = 5483216,      csize = 8540296, atime = 1193866145000000, mtime = 1183409032000000,      ctime = 1193860247000000, fname = 0x84c418 '/usr/bin/php5-cgi',      name = 0x6bb731 '/.php5-cgi', filehand = 0x7fff808d1370}, parsed_uri = {     scheme = 0x0, hostinfo = 0x0, user = 0x0, password = 0x0, hostname = 0x0,      port_str = 0x0, path = 0x819558 '/.php5-cgi/16.410/wiki/index.php',      query = 0x819580 'title=Special:Preferences', fragment = 0x0,      hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0,      dns_resolved = 0}, used_path_info = 0, per_dir_config = 0x819e60,    request_config = 0x8195a0, htaccess = 0x83cdb0, output_filters = 0x8265d0,    input_filters = 0x826c98, proto_output_filters = 0x8265d0,    proto_input_filters = 0x826c98, eos_sent = 0}  That all looks correct.  The filter chain is correct; r->remaining is 525 which matches the number of bytes the SSL buffer captured.  I can't see why this would fail, and I can't think what else to suggest here other than stepping through the code to see what is happening, or adding a lot of ap_log_rerror() debugging calls in ap_get_client_block()/ap_http_filter().    - is this ap_get_client_block() call happening *before* the timeout? - does ap_get_client_block() fail? - the topmost filter is ap_http_filter - breakpoint on that; does it get invoked?  step through; what does it do?   What makes you say that the filter chain is correct?  I would expect the 'ssl/tls buffer' filter to be at the head to the chain, since that's where all the data is being buffered.  There's no chance that reading from 'ssl/tls filter' will give me any data since its data has already been read and stored in the buffer.  To answer your questions: >- is this ap_get_client_block() call happening *before* the timeout?  Yes, I thought I made that clear in my analysis.  >- does ap_get_client_block() fail?  No, as I said before, it returns end-of-stream (0).  I haven't traced through ap_http_filter; however, in the course of instrumenting ap_get_client_block() before I filed this bug, I made it skip over 'http_in' and read directly from 'ssl/tls filter'.  Same result: end of stream.  (In reply to comment #4) > What makes you say that the filter chain is correct?  I would expect the > 'ssl/tls buffer' filter to be at the head to the chain, since that's where all > the data is being buffered.  There's no chance that reading from 'ssl/tls > filter' will give me any data since its data has already been read and stored in > the buffer.  It is correct. You have to read the whole thing as a stack:   http_in(0x826c98):          HTTP filter: Does dechunking if transfer-encoding of                              the body is chunked or reads up to Content-length                             bytes from the body. ssl/tls filter(0x81e098):   Does decryption of the input stream and deals with                             client certificates. Sometimes this filter buffers                             data. log_input_output(0x8109f0): Counts bytes that came in. core_in(0x81e140):          Core network connection to the raw socket.  >ssl/tls filter(0x81e098):   Does decryption of the input stream and deals with >                            client certificates. Sometimes this filter buffers >                            data.  That's not what the code claims.  See the end of ssl_io_buffer_fill() in ssl_engine_io.c:      /* Insert the filter which will supply the buffered data. */     ap_add_input_filter(ssl_io_buffer, ctx, r, c);      return 0;  The buffered data can only come from the 'ssl/tls buffer' filter, not the 'ssl/tls filter' filter.  As I noted in my original report, we know from the debug logs that the 'ssl/tls buffer' filter's read routine (ssl_io_filter_buffer) is in fact being called, but not until after the 30-second timeout. Created an attachment (id=21077) test fix  Sorry, I read the filter stack wrong; I was only looking to check that http_in was at the top; the second filter down should be the buffering filter not the normal SSL filter (they are separate filters).  I note that r->prev is set here so an internal redirect will have happened.  And that will filters < AP_FTYPE_PROTOCOL, which includes this one... oops.  Can you try this fix? should read: ^And that will kill filters < AP_FTYPE_PROTOCOL Ah, no, that won't work at all.  The buffering filter is AP_FTYPE_PROTOCOL - 1 exactly because it the fill_buffer reads from r->proto_input_filters.  Ick.  I can't see any obvious fix here.  To confirm the diagnosis can you reproduce without whatever triggered the internal redirect? > To confirm the diagnosis can you reproduce without whatever triggered the > internal redirect?  Can you suggest how I might figure out what that was?  For what it's worth, ssl_io_filter_buffer() is eventually called from ap_discard_request_body() after mod_fastcgi gives up.  > To confirm the diagnosis can you reproduce without whatever triggered the > internal redirect?  I think I figured it out.  This problem is not seen by mod_php4 applications, nor by regular CGI applications.  The internal redirect is caused by mod_action, which is used to implement PHP5 under FastCGI.  The configuration looks like this:  FastCgiServer /usr/bin/php5-cgi -processes 5 ScriptAlias /.php5-cgi /usr/bin/php5-cgi <Directory /usr/bin>   Order deny,allow   Deny from all   <Files php5-cgi>     Options ExecCGI     SetHandler fastcgi-script     Order allow,deny     Allow from all   </Files> </Directory> Action php5-script /.php5-cgi Action application/x-httpd-fastphp5 /.php5-cgi  Then in .htaccess, users who want php5 instead of php4 specify:  AddHandler php5-script .php  I don't see how your conf is triggering an internal redirect?  Can you differentiate if this is a fast-internal redirect or a straight redirect?  Is this because the client requests /app/Login instead of requesting /app/Login.php ?  > Can you differentiate if this is a fast-internal redirect or a straight > redirect?  Not sure I know what that means.  Here is what the two request_rec structures look like.  Note that the first one is generated in mod_actions by calling ap_internal_redirect_handler() and the second one is the original request:  (gdb) p *r $2 = {pool = 0x839398, connection = 0x80ba98, server = 0x6ce468, next = 0x0,    prev = 0x839408, main = 0x0,    the_request = 0x83a9c0 'GET /16.410/wiki/index.php?title=Special:Preferences HTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0,    protocol = 0x83aac0 'HTTP/1.1', proto_num = 1001,    hostname = 0x83aeb8 'more-courses.csail.mit.edu',    request_time = 1193938941817986, status_line = 0x44efd3 '200 OK',    status = 200, method = 0x83aa10 'GET', method_number = 0, allowed = 0,    allowed_xmethods = 0x0, allowed_methods = 0x81d928, sent_bodyct = 1,    bytes_sent = 8192, mtime = 0, chunked = 1, range = 0x0, clength = 0,    remaining = 0, read_length = 0, read_body = 1, read_chunked = 0,    expecting_100 = 0, headers_in = 0x8396e8, headers_out = 0x861668,    err_headers_out = 0x83a030, subprocess_env = 0x85af28, notes = 0x81d788,    content_type = 0x861450 'text/html; charset=utf-8',    handler = 0x2b7546f648c8 'fastcgi-script', content_encoding = 0x0,    content_languages = 0x0, vlist_validator = 0x0,    user = 0x840608 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0,    no_local_copy = 0,    unparsed_uri = 0x85a708 '/.php5-cgi/16.410/wiki/index.php?title=Special:Preferences', uri = 0x85a748 '/.php5-cgi/16.410/wiki/index.php',    filename = 0x81e518 '/usr/bin/php5-cgi',    canonical_filename = 0x81e518 '/usr/bin/php5-cgi',    path_info = 0x81e3f9 '/16.410/wiki/index.php',  ---Type <return> to continue, or q <return> to quit---    args = 0x85a770 'title=Special:Preferences', finfo = {pool = 0x839398,      valid = 7598448, protection = 1877, filetype = APR_REG, user = 0,      group = 0, inode = 283762, device = 2049, nlink = 1, size = 5483216,      csize = 8623000, atime = 1193936766000000, mtime = 1183409032000000,      ctime = 1193860247000000, fname = 0x81e518 '/usr/bin/php5-cgi',      name = 0x6b9721 '/.php5-cgi', filehand = 0x7fff66fafa30}, parsed_uri = {     scheme = 0x0, hostinfo = 0x0, user = 0x0, password = 0x0, hostname = 0x0,      port_str = 0x0, path = 0x85a748 '/.php5-cgi/16.410/wiki/index.php',      query = 0x85a770 'title=Special:Preferences', fragment = 0x0,      hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0,      dns_resolved = 0}, used_path_info = 0, per_dir_config = 0x85b050,    request_config = 0x85a790, htaccess = 0x817f00, output_filters = 0x83a908,    input_filters = 0x83aed8, proto_output_filters = 0x83a908,    proto_input_filters = 0x83aed8, eos_sent = 0} (gdb) p r->prev $3 = (request_rec *) 0x839408 (gdb) p *r->prev $4 = {pool = 0x839398, connection = 0x80ba98, server = 0x6ce468,    next = 0x85a428, prev = 0x0, main = 0x0,    the_request = 0x83a9c0 'GET /16.410/wiki/index.php?title=Special:Preferences HTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0,    protocol = 0x83aac0 'HTTP/1.1', proto_num = 1001,    hostname = 0x83aeb8 'more-courses.csail.mit.edu',    request_time = 1193938941817986, status_line = 0x0, status = 200,    method = 0x83aa10 'GET', method_number = 0, allowed = 0,    allowed_xmethods = 0x0, allowed_methods = 0x8396a8, sent_bodyct = 0,    bytes_sent = 0, mtime = 0, chunked = 0, range = 0x0, clength = 0,    remaining = 0, read_length = 0, read_body = 0, read_chunked = 0,    expecting_100 = 0, headers_in = 0x8396e8, headers_out = 0x839de8,    err_headers_out = 0x83a030, subprocess_env = 0x839a68, notes = 0x83a1d0,    content_type = 0x83daf8 'application/x-httpd-fastphp5',    handler = 0x83d980 'php5-script', content_encoding = 0x0,    content_languages = 0x0, vlist_validator = 0x0,    user = 0x819ac0 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0,    no_local_copy = 0,    unparsed_uri = 0x83aa50 '/16.410/wiki/index.php?title=Special:Preferences',    uri = 0x83aa88 '/16.410/wiki/index.php',    filename = 0x83b108 '/afs/csail.mit.edu/proj/courses/data/16.410/wiki/index.php',    canonical_filename = 0x83b108 '/afs/csail.mit.edu/proj/courses/data/16.410/wik---Type <return> to continue, or q <return> to quit--- i/index.php', path_info = 0x83b03a '',    args = 0x83aaa0 'title=Special:Preferences', finfo = {pool = 0x839398,      valid = 7598448, protection = 1604, filetype = APR_REG, user = 12369,      group = 12369, inode = 831797006, device = 18, nlink = 1, size = 3218,      csize = 0, atime = 1183079954000000, mtime = 1183079954000000,      ctime = 1183079954000000,      fname = 0x83b000 '/afs/csail.mit.edu/proj/courses/data/16.410/wiki/index.php', name = 0x0, filehand = 0x0}, parsed_uri = {scheme = 0x0, hostinfo = 0x0,      user = 0x0, password = 0x0, hostname = 0x0, port_str = 0x0,      path = 0x83aa88 '/16.410/wiki/index.php',      query = 0x83aaa0 'title=Special:Preferences', fragment = 0x0,      hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0,      dns_resolved = 0}, used_path_info = 2, per_dir_config = 0x817f58,    request_config = 0x83a370, htaccess = 0x817f00, output_filters = 0x83a8e0,    input_filters = 0x83aed8, proto_output_filters = 0x83a8e0,    proto_input_filters = 0x83aed8, eos_sent = 0}  Oops, I should have noticed that that was a GET request that I tripped over while debugging, rather than the POST requests that are the problem.  I'll try to grab another dump from the right request. Here's a better example:  (gdb) p *r $3 = {pool = 0x817ca8, connection = 0x80ba98, server = 0x6ce468, next = 0x0,    prev = 0x817d18, main = 0x0,    the_request = 0x8192d0 'POST /16.410/wiki/index.php?title=Special:Preferences HTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0,    protocol = 0x8193d0 'HTTP/1.1', proto_num = 1001,    hostname = 0x819898 'more-courses.csail.mit.edu',    request_time = 1193947551567157, status_line = 0x0, status = 200,    method = 0x819320 'POST', method_number = 2, allowed = 0,    allowed_xmethods = 0x0, allowed_methods = 0x84a5b8, sent_bodyct = 0,    bytes_sent = 0, mtime = 0, chunked = 0, range = 0x0, clength = 0,    remaining = 528, read_length = 0, read_body = 1, read_chunked = 0,    expecting_100 = 0, headers_in = 0x817ff8, headers_out = 0x843ea0,    err_headers_out = 0x818940, subprocess_env = 0x8440e8, notes = 0x84a418,    content_type = 0x83daf8 'application/x-httpd-fastphp5',    handler = 0x2b7546f648c8 'fastcgi-script', content_encoding = 0x0,    content_languages = 0x0, vlist_validator = 0x0,    user = 0x840608 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0,    no_local_copy = 0,    unparsed_uri = 0x8438c8 '/.php5-cgi/16.410/wiki/index.php?title=Special:Preferences', uri = 0x843908 '/.php5-cgi/16.410/wiki/index.php',    filename = 0x84b1a8 '/usr/bin/php5-cgi',    canonical_filename = 0x84b1a8 '/usr/bin/php5-cgi',    path_info = 0x84b089 '/16.410/wiki/index.php',  ---Type <return> to continue, or q <return> to quit---    args = 0x843930 'title=Special:Preferences', finfo = {pool = 0x817ca8,      valid = 7598448, protection = 1877, filetype = APR_REG, user = 0,      group = 0, inode = 283762, device = 2049, nlink = 1, size = 5483216,      csize = 8486056, atime = 1193936766000000, mtime = 1183409032000000,      ctime = 1193860247000000, fname = 0x84b1a8 '/usr/bin/php5-cgi',      name = 0x6b9721 '/.php5-cgi', filehand = 0x7fff66fafa30}, parsed_uri = {     scheme = 0x0, hostinfo = 0x0, user = 0x0, password = 0x0, hostname = 0x0,      port_str = 0x0, path = 0x843908 '/.php5-cgi/16.410/wiki/index.php',      query = 0x843930 'title=Special:Preferences', fragment = 0x0,      hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0,      dns_resolved = 0}, used_path_info = 0, per_dir_config = 0x844210,    request_config = 0x843950, htaccess = 0x82c5a0, output_filters = 0x8191f0,    input_filters = 0x8198b8, proto_output_filters = 0x8191f0,    proto_input_filters = 0x8198b8, eos_sent = 0} (gdb) p *r->prev $4 = {pool = 0x817ca8, connection = 0x80ba98, server = 0x6ce468,    next = 0x8435e8, prev = 0x0, main = 0x0,    the_request = 0x8192d0 'POST /16.410/wiki/index.php?title=Special:Preferences HTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0,    protocol = 0x8193d0 'HTTP/1.1', proto_num = 1001,    hostname = 0x819898 'more-courses.csail.mit.edu',    request_time = 1193947551567157, status_line = 0x0, status = 200,    method = 0x819320 'POST', method_number = 2, allowed = 0,    allowed_xmethods = 0x0, allowed_methods = 0x817fb8, sent_bodyct = 0,    bytes_sent = 0, mtime = 0, chunked = 0, range = 0x0, clength = 0,    remaining = 0, read_length = 0, read_body = 0, read_chunked = 0,    expecting_100 = 0, headers_in = 0x817ff8, headers_out = 0x8186f8,    err_headers_out = 0x818940, subprocess_env = 0x818378, notes = 0x818ae0,    content_type = 0x83daf8 'application/x-httpd-fastphp5',    handler = 0x83d980 'php5-script', content_encoding = 0x0,    content_languages = 0x0, vlist_validator = 0x0,    user = 0x82e1d8 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0,    no_local_copy = 0,    unparsed_uri = 0x819360 '/16.410/wiki/index.php?title=Special:Preferences',    uri = 0x819398 '/16.410/wiki/index.php',    filename = 0x819ae8 '/afs/csail.mit.edu/proj/courses/data/16.410/wiki/index.php',    canonical_filename = 0x819ae8 '/afs/csail.mit.edu/proj/courses/data/16.410/wik---Type <return> to continue, or q <return> to quit---  i/index.php', path_info = 0x819a1a '',    args = 0x8193b0 'title=Special:Preferences', finfo = {pool = 0x817ca8,      valid = 7598448, protection = 1604, filetype = APR_REG, user = 12369,      group = 12369, inode = 831797006, device = 18, nlink = 1, size = 3218,      csize = 0, atime = 1183079954000000, mtime = 1183079954000000,      ctime = 1183079954000000,      fname = 0x8199e0 '/afs/csail.mit.edu/proj/courses/data/16.410/wiki/index.php', name = 0x0, filehand = 0x0}, parsed_uri = {scheme = 0x0, hostinfo = 0x0,      user = 0x0, password = 0x0, hostname = 0x0, port_str = 0x0,      path = 0x819398 '/16.410/wiki/index.php',      query = 0x8193b0 'title=Special:Preferences', fragment = 0x0,      hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0,      dns_resolved = 0}, used_path_info = 2, per_dir_config = 0x82c5f8,    request_config = 0x818c80, htaccess = 0x82c5a0, output_filters = 0x8191f0,    input_filters = 0x82e1a0, proto_output_filters = 0x8191f0,    proto_input_filters = 0x8198b8, eos_sent = 0}  And I can now confirm that the head of the input filter chain for the original request is 'ssl/tls buffer':  (gdb) p *r->prev->input_filters $7 = {frec = 0x6333b8, ctx = 0x84b760, next = 0x858e18, r = 0x857278,    c = 0x80ba98} (gdb) p *r->prev->input_filters->frec $8 = {name = 0x628a18 'ssl/tls buffer', filter_func = {     out_func = 0x2b7547f58370 <ssl_io_filter_buffer>,      in_func = 0x2b7547f58370 <ssl_io_filter_buffer>}, filter_init_func = 0,    ftype = 29, next = 0x0, providers = 0x0, debug = 0, proto_flags = 0}  Here's the full filter chain for both requests:  (gdb) dump_filters r->input_filters http_in(0x81e8d8): ctx=0x85b050, r=0x818eb8, c=0x80ba98 ssl/tls filter(0x816ce8): ctx=0x814c98, r=0x0, c=0x80ba98 log_input_output(0x80c240): ctx=0x0, r=0x0, c=0x80ba98 core_in(0x816d90): ctx=0x816d70, r=0x0, c=0x80ba98 (gdb) dump_filters r->prev->input_filters ssl/tls buffer(0x85b070): ctx=0x85b020, r=0x81cd38, c=0x80ba98 http_in(0x81e8d8): ctx=0x85b050, r=0x818eb8, c=0x80ba98 ssl/tls filter(0x816ce8): ctx=0x814c98, r=0x0, c=0x80ba98 log_input_output(0x80c240): ctx=0x0, r=0x0, c=0x80ba98 core_in(0x816d90): ctx=0x816d70, r=0x0, c=0x80ba98  Created an attachment (id=21080) working fix  Here's a tested fix.  Moving the filter to AP_FTYPE_PROTOCOL is the right thing to do; there were a few tricks needed to getting this working though.  Further testing welcome! Fixed on trunk as per attached patch with only comment tweaks:  http://svn.apache.org/viewvc?rev=591393&view=rev  Results from testing still desirable!   It appears to work on my test server.  Great, thanks a lot for the testing and debugging work. Proposed for backport in r608076. Merged for 2.2.x: http://svn.apache.org/viewvc?view=rev&revision=608787			Garrett Wollman	Joe Orton	Ruediger Pluem	Will Rowe
43789	null	RESOLVED		Tom Donovan	1194072840000	1194146472000		Windows build - ap_time_process_request Revision 590122 changed the declaration of ap_time_process_request in scoreboard.h.  This needs to be changed in server/scoreboard.c too, else it breaks the Windows build:   ./server/scoreboard.c(487) : error C2373: 'ap_time_process_request' : redefinition; different type modifiers	Created an attachment (id=21082) scoreboard.c declaration for ap_time_process_request  Committed to trunk as r591760 (http://svn.apache.org/viewvc?rev=591760&view=rev). Thanks for the fix.			Ruediger Pluem	Tom Donovan
43856	null	RESOLVED		Frantisek Sokolovsky	1195018980000	1195022223000		' Bad link ('perldoc perlre') in paragraph:  For more information about regular expressions, have a look at the perl regular  expression manpage ('perldoc perlre'). If you are interested in more detailed  information about regular expressions and their variants (POSIX regex etc.) the  following book is dedicated to this topic  on page:  http://httpd.apache.org/docs/2.0/mod/mod_rewrite.html#rewriterule	also server http://www.perldoc.com/ doesn't working. Only today (14th november  2007)?  Changed the references to perldoc.perl.org. Thanks for your care.			Andr?? Malo	Frantisek Sokolovsky
43882	null	RESOLVED		Bj	1195186200000	1197095725000		Multiple Transfer-Encodings in requests handled improperly Requests using multiple transfer encodings are handled as if they had no  Transfer-Encoding header and no entity body. For example:    POST / HTTP/1.1   Transfer-Encoding: gzip,chunked   [more headers]    [body]  Here Apache would treat [body] as if it was the beginning of a new request.  This is incorrect, RFC 2616 allows requests of this kind and recommends to  respond with Not Implemented if the Transfer-Encoding is not understood; the  alternative would be to treat it as if it had 'Transfer-Encoding: chunked' and  let request handlers remove the other transfer encodings if they so wish though  this would probably require some opt-in feature to avoid feeding garbage to  unsuspecting handlers.  The specific code seems to tbe in http_filters.c ap_http_filter(...) which only goes into BODY_CHUNK mode if 'chunked' is the only encoding. There also  does not seem to be lexical checking performed on the value. RFC 2616 requires  that 'chunk' occurs at most once in the value and if it does, occurs at the end  of the list. Apache should probably respond with Bad Request if that is not the  case (to avoid confusing request handlers taking care of the decoding if that  is made an option).	Fixed in trunk in r595672. From the latest version:              /* RFC2616 allows qualifiers, so use strncasecmp */             if (!strncasecmp(tenc, 'chunked', 7) && !ap_strchr_c(tenc, ',')) {                 ctx->state = BODY_CHUNK;             }             else {                 /* Something that isn't in HTTP, unless some future                  * edition defines new transfer ecodings, is unsupported.                  */  I am a bit worried, I am unsure what 'qualifiers' refers to and the code below  seems to match on 'Transfer-Encoding: chunkedfoo' which it should not. And the  original example 'Transfer-Encoding: gzip,chunked' is 'in HTTP', Apache just  does not support it. So shouldn't this be something like              if (!strcasecmp(tenc, 'chunked')) {                 ctx->state = BODY_CHUNK;             }             else {                 /* Other Transfer-Encodings are not implemented */  Bj??rn, this is turning into discussion, and as such should be on dev@httpd, not bugzilla.  Do you follow that?  1.  Qualifiers come from the BNF-style representation of the header, which means something like Transfer-Encoding: chunked;foo=bar is syntactically valid.  But in practice, no qualifiers are defined.  2.  gzip is a content-encoding, not a transfer-encoding.  The passage in RFC2616 that suggests otherwise is clearly a drafter who'd been staring at it too long, and had a brainfart.  3.  You're right about 'chunkedfoo' - I'll fix it.  If noone shouts, I'll just set it back to strcasecmp, so we don't support any qualifiers.  As it happens, I'd already realised it wasn't right, but just wasn't rushing the job again:-)  Thank you for your attention to detail. Ah you meant parameters, they are indeed allowed, but not knowing what to do  with them they didn't seem to affect the issue. I don't follow the development  list, but I also have nothing to add if you do 3., except to point out that you  are wrong about gzip not being a Transfer-Encoding... Fixed in r602470.			Bj	Nick Kew
43889	null	RESOLVED		Dr Stephen Henson	1195279140000	1195623459000		t log OpenSSL associated error string data When mod_ssl logs OpenSSL errors it doesn't include the associated error string. This string can carry additional data related to the error making the cause easier to locate. In some cases (e.g. the OpenSSL ASN1 library) omitting the error string renders the error output almost useless.  The attached patch fixes this.	Created an attachment (id=21141) Log associated error string  The man page for ERR_get_error_line_data() implies that you have to check for flags&ERR_TXT_MALLOCED and free the 'data' string if true - but the fact that data is passed as const char * somewhat contradicts that - what's correct here? The manual page is a bit confusing in that respect. Almost all applications just call ERR_print_errors() and forget about it, that isn't of course possible here.  The data will be freed internally when the circular buffer is reused (e.g. by more errors or explicitly cleared).  If you free up the data explicitly it wont reset the internal flags and data so you'd end up with the data being freed twice.  Now I've checked the sources in more detail there is a simpler way to achieve the same thing and free up the data properly: peek the error first and call ERR_get_error() afterwards. New patch included. Created an attachment (id=21151) Updated associated error print patch.  Great, thanks.  I also took the opportunity to tweak the log message to delineate the error/data/annotation better; committed to trunk:  http://svn.apache.org/viewvc?view=rev&revision=597077			Dr Stephen Henson	Joe Orton
43890	null	RESOLVED		Bill Salak	1195287060000	1198512350000		path typo in suexec documentation ? The documentation states:   ------ If for example...  and suexec is installed at '/usr/local/apache2/sbin/suexec', you should run:  chgrp webgroup /usr/local/apache2/bin/suexec chmod 4750 /usr/local/apache2/bin/suexec  This will ... ------  Shouldn't that path '/usr/local/apache2/sbin/suexec' be pointing  to .../apache2/bin/... not .../apache2/sbin/... ?	Bill,  Thanks for the heads up here.  I have corrected this is in the trunk branch of  the documentation, and committed it.  These changes should be visible within a  few hours.    For some reason my build tool will not build 2.2, or 2.0 docs at the moment, so  I cannot commit these changes to the older branches.    See here for the SVN commit log:  http://svn.apache.org/ viewvc?view=rev&revision=606748   Bill,  As promised here are the commits for 2.2, and 2.0  2.2 Updated:  http://svn.apache.org/viewvc?rev=606749&view=rev 2.0 Updated:  http://svn.apache.org/viewvc?rev=606750&view=rev   Regards, Tony			Tony Stevenson
43922	null	CLOSED		Basant Kumar Kukreja	1195599660000	1195616867000		CustomLog entry in httpd-vhosts.conf.in is incorrect. CustomLog Entry in httpd-vhosts.conf.in is defined as CustomLog '@rel_logfiledir@/dummy-host.example.com-access_log common'  The correct format is : CustomLog '@rel_logfiledir@/dummy-host.example.com-access_log' common	Created an attachment (id=21170) Patch for the bug  Corrected the CustomLog directive entry in httpd-vhosts.in file.  Fixed in 2.2.x branch; not a problem in trunk; thanks!			Basant Kumar Kukreja	Jeff Trawick
44001	null	RESOLVED		Takashi Sato	1196401560000	1196545522000		AuthDigestEnableQueryStringHack is not needed for IE7 doc says: The Digest authentication implementation in current Internet Explorer for  Windows implementations has known issues,   IE5 and IE6 have this issue, but IE7 doesn't.	http://svn.apache.org/viewvc?view=rev&revision=600245  Docs updated, thanks. The update doesn't include instructions for browser version detection as the hack is  used as a fallback and doesn't get invoked by msie7's correct digest hashing.			Vincent Bray
44014	null	RESOLVED		Victor Stinner	1196664600000	1196683007000		Fix XSS in error page #413 Procheckup just published a bug in Apache 2.2 which is not fixed in Apache 2.2  branch of Subversion: http://procheckup.com/Vulnerability_PR07-37.php  I wrote a small patch to fix it.	Created an attachment (id=21220) Fix the XSS  For a host of reasons, this is generally not exploitable in any usual case, and would represent a very unusual client.  Quoting the 'vulnerability' report;  'This type of attack can result in non-persistent defacement of the target site,  or the redirection of confidential information (i.e. session IDs) to unauthorised  third parties provided that a web browser is tricked to submit a malformed HTTP  method.'  Given that this is nonsense in the context of a web browser, no CVE will be assigned, but thank you for the report, it is a bug worth fixing.  Proposed for backport to 2.2 and 2.0. 			Victor Stinner	Will Rowe
44073	null	RESOLVED		yl	1197529440000	1197679476000		SSL client certificate extensions parsing bug The following code in httpd-2.2.6/modules/ssl/ssl_expr_eval.c assume a nul-terminated string which isn't (always) :  apr_array_header_t *ssl_extlist_by_oid(request_rec *r, const char *oidstr) { <snip>            BIO *bio = BIO_new(BIO_s_mem());             if (X509V3_EXT_print(bio, ext, 0, 0) == 1) {                 BUF_MEM *buf;                 char **new = apr_array_push(val_array);                  BIO_get_mem_ptr(bio, &buf);                  *new = apr_pstrdup(r->pool, buf->data);             } <snip>     if (val_array->nelts == 0)         return NULL;     else         return val_array; }  Neither X509V3_EXT_print() nor BIO_get_mem_ptr() nul-terminate the BIO buffer, so 'buf->data' should be used in the limit of 'buf->length', that is :      *new = apr_pstrndup(r->pool, buf->data, buf->length);  When SSLRequire is used with OIDs, the server can crash (exploitable?), or the certificate extensions requirements can be bypassed since the value may contain arbitrary trailing data.	Sorry, httpd-2.2.6 is concerned by this bug, not the version 2.0.61 which doesn't implement the certificate OIDs requirements.  I want to submit a patch on httpd-2.0.61 for this to be handled, hence my confusion. Proposed patch for inclusion to 2.2.x in r604012 (http://svn.apache.org/viewvc/httpd/httpd/branches/2.2.x/STATUS?r1=604012&r2=604011&pathrev=604012) Ok for the patch in 2.2.x, but the problem is there in trunk too :            *ptr = apr_pstrmemdup(p, buf->data, buf->length); This will not create a nul-terminated string either, while it is supposed to, I suggest to use apr_strndup here too.  Should I open a new ticket for trunk ? Trunk changes in http://svn.apache.org/viewvc?view=rev&revision=289444 has moved the problem described above in httpd-trunk/modules/ssl/ssl_engine_vars.c, function ssl_ext_list() pstrmemdup does NUL-terminate the returned string. Included in 2.2.x per r604403 (http://svn.apache.org/viewvc?rev=604403&view=rev). Sorry, I didn't notice that, the name drove me wrong. Thanks for the patch.			Joe Orton	Ruediger Pluem	yl
44152	null	RESOLVED		Michael Clark	1198904520000	1200743448000		litmus regression: PUT conditional on lock and etag failed Build 2.2.6 from tarball, enable extra/httpd-dav.conf and run litmus 0.11 Build 2.2.7-dev from branches/2.2, enable extra/httpd-dav.conf and run litmus  2 regressions:  --- /tmp/litmus-2.2.6.txt\t2007-12-29 17:50:28.000000000 +0800 +++ /tmp/litmus-2.2.x.txt\t2007-12-29 17:50:54.000000000 +0800 @@ -88,12 +88,12 @@  12. notowner_modify....... pass  13. notowner_lock......... pass  14. copy.................. pass -15. cond_put.............. pass +15. cond_put.............. FAIL (PUT conditional on lock and etag failed: 412 Precondition Failed)  16. fail_cond_put......... pass  17. cond_put_with_not..... pass  18. cond_put_corrupt_token WARNING: PUT failed with 400 not 423      ...................... pass (with 1 warning) -19. complex_cond_put...... pass +19. complex_cond_put...... FAIL (PUT with complex conditional failed: 412 Precondition Failed)  20. fail_complex_cond_put. pass  21. unlock................ pass  22. fail_cond_put_unlocked pass @@ -113,11 +113,6 @@  36. indirect_refresh...... pass  37. unlock................ pass  38. finish................ pass -<- summary for "locks': of 39 tests run: 39 passed, 0 failed. 100.0% +<- summary for "locks': of 39 tests run: 37 passed, 2 failed. 94.9%  -> 1 warning was issued.	Here is the relevant part of the litmus debug log.  2.2.6  Sending request headers: HEAD /uploads/litmus/lockme HTTP/1.1 Host: localhost User-Agent: litmus/0.11 neon/0.26.3 Connection: TE TE: trailers Authorization: Basic bWNsYXJrOnNhZ2kxNzcx X-Litmus: locks: 16 (fail_cond_put)  Sending request-line and headers: Request sent; retry is 1. [status-line] < HTTP/1.1 200 OK [hdr] Date: Sat, 29 Dec 2007 10:09:11 GMT Header Name: [date], Value: [Sat, 29 Dec 2007 10:09:11 GMT] [hdr] Server: Apache/2.2.7-dev (Unix) DAV/2 Header Name: [server], Value: [Apache/2.2.7-dev (Unix) DAV/2] [hdr] Last-Modified: Sat, 29 Dec 2007 10:09:10 GMT Header Name: [last-modified], Value: [Sat, 29 Dec 2007 10:09:10 GMT] [hdr] ETag: 'ec400e-20-4426a008c3d80' Header Name: [etag], Value: ['ec400e-20-4426a008c3d80']   2.2.7-dev  Sending request headers: HEAD /uploads/litmus/lockme HTTP/1.1 Host: localhost User-Agent: litmus/0.11 neon/0.26.3 Connection: TE TE: trailers Authorization: Basic bWNsYXJrOnNhZ2kxNzcx X-Litmus: locks: 15 (cond_put)  Sending request-line and headers: Request sent; retry is 1. [status-line] < HTTP/1.1 200 OK [hdr] Date: Sat, 29 Dec 2007 12:53:31 GMT Header Name: [date], Value: [Sat, 29 Dec 2007 12:53:31 GMT] [hdr] Server: Apache/2.2.7-dev (Unix) DAV/2 Header Name: [server], Value: [Apache/2.2.7-dev (Unix) DAV/2] [hdr] Last-Modified: Sat, 29 Dec 2007 12:53:31 GMT Header Name: [last-modified], Value: [Sat, 29 Dec 2007 12:53:31 GMT] [hdr] ETag: W/'ec400e-20-4426c4c4f28c0' Header Name: [etag], Value: [W/'ec400e-20-4426c4c4f28c0']  Reversing the changes to http_etag.c fixes the problem.  Which I guess is this CHANGES entry:   *) core: Change etag generation to produce identical results on      32-bit and 64-bit platforms.  PR 40064.  [Joe Orton]   Created an attachment (id=21331) http_etags change when reversed solves regression  Just another quick note. From looking at the debug.log with 2.2.6, the last-modified date is 1 second behind the Date header.  With 2.2.7-dev, the dates are equal.  I'm am unsure how the patch effects the dates to cause the Weak ETag in 2.2.7-dev as it does not apparently change any date fields only reads them.  I have run the tests many times to ensure it is not a timing issue.  The date issue and Etag I mentioned is a red herring.  Here the test is succedding on 2.2.7-dev with the 64bit etag patches reversed (Dates are equal and ETag is weak - so not related).  Must be one of the 64 bits casts is putting garbage in the Etag making the condition fail.  This is a successful run on 32bit Linux with the patch reversed.   ******* Running test 15: cond_put ******** ah_create, for WWW-Authenticate Running pre_send hooks auth: Sending 'Basic' response. Sending request headers: HEAD /uploads/litmus/lockme HTTP/1.1 Host: localhost User-Agent: litmus/0.11 neon/0.26.3 Connection: TE TE: trailers Authorization: Basic bWNsYXJrOnNhZ2kxNzcx X-Litmus: locks: 15 (cond_put)  Sending request-line and headers: Request sent; retry is 1. [status-line] < HTTP/1.1 200 OK [hdr] Date: Sat, 29 Dec 2007 13:46:43 GMT Header Name: [date], Value: [Sat, 29 Dec 2007 13:46:43 GMT] [hdr] Server: Apache/2.2.7-dev (Unix) DAV/2 Header Name: [server], Value: [Apache/2.2.7-dev (Unix) DAV/2] [hdr] Last-Modified: Sat, 29 Dec 2007 13:46:43 GMT Header Name: [last-modified], Value: [Sat, 29 Dec 2007 13:46:43 GMT] [hdr] ETag: W/'ec400e-20-a9136c0' Header Name: [etag], Value: [W/'ec400e-20-a9136c0'] [hdr] Accept-Ranges: bytes Header Name: [accept-ranges], Value: [bytes] [hdr] Content-Length: 32 Header Name: [content-length], Value: [32] [hdr] Content-Type: text/plain Header Name: [content-type], Value: [text/plain] [hdr]  End of headers. Running post_send hooks ah_post_send (#0), code is 200 (want 401), WWW-Authenticate is (none) Request ends, status 200 class 2xx, error line: 200 OK Running destroy hooks. Request ends. ah_create, for WWW-Authenticate Running pre_send hooks auth: Sending 'Basic' response. Sending request headers: PUT /uploads/litmus/lockme HTTP/1.1 Host: localhost User-Agent: litmus/0.11 neon/0.26.3 Connection: TE TE: trailers Content-Length: 32 If: (<opaquelocktoken:7da06b5a-b614-11dc-89f6-f543e31a2f21> [W/'ec400e-20-a9136c0']) Authorization: Basic bWNsYXJrOnNhZ2kxNzcx X-Litmus: locks: 15 (cond_put)  Sending request-line and headers: Sending request body: Body block (32 bytes): [This is a test file called foo  ] Request sent; retry is 1. [status-line] < HTTP/1.1 204 No Content [hdr] Date: Sat, 29 Dec 2007 13:46:43 GMT Header Name: [date], Value: [Sat, 29 Dec 2007 13:46:43 GMT] [hdr] Server: Apache/2.2.7-dev (Unix) DAV/2 Header Name: [server], Value: [Apache/2.2.7-dev (Unix) DAV/2] [hdr] Content-Length: 0 Header Name: [content-length], Value: [0] [hdr] Content-Type: text/plain Header Name: [content-type], Value: [text/plain] [hdr]  End of headers. Running post_send hooks ah_post_send (#0), code is 204 (want 401), WWW-Authenticate is (none) Request ends, status 204 class 2xx, error line: 204 No Content Running destroy hooks. Request ends.  It appears the problem is mod_dav:dav_fs_getetag routine not being updating to create 64bit time in the etags.  Please apply this patch so we can avoid this regression in 2.2.7  I will verify if the same issue is present in trunk (I think it is) Created an attachment (id=21332) update to print 64 bit time in the etag  Created an attachment (id=21333) All fields should be 64bit for parity with http_etag implementation  Just verified that the same issue is present in trunk 2.3.0-dev.  Patch applies there with 4 lines offset.  I get no litmus failures with this patch applied on both 2.2.7-dev and 2.3.0-dev  Created an attachment (id=21334) missed mtime only case  Thanks for the patch. Committed a slightly modified version of the patch (r607437, http://svn.apache.org/viewvc?rev=607437&view=rev) plus a warning to the FileETAG documentation that changing the default could cause breakage with conditional WebDAV requests against mod_dav_fs provided backends. Proposed for backport as r607441 (http://svn.apache.org/viewvc?rev=607441&view=rev). Fixed in 2.2.8.			Michael Clark	Ruediger Pluem
44311	null	RESOLVED		Peter Belau	1201503480000	1201879549000		hotels.com broken in 2.2.8 mod_proxy working as a forward proxy in Apache 2.2.8 seems to break www.hotels.com. This would appear to be a regression since 2.2.7. I have confirmed  this issue on 3 servers and 3 seperate Apache builds.  httpd.conf below:  Listen 0.0.0.0:9292 User daemon Group daemon ErrorLog logs/error_log LogLevel debug DefaultType text/html Header unset Accept-Ranges RequestHeader unset Range HostnameLookups off SetEnv proxy-sendcl off SetEnv proxy-sendchunked 1 SetEnv proxy-sendchunks 1 ThreadStackSize 256000 ServerLimit 12 ThreadLimit 512 ThreadsPerChild 512 MaxRequestsPerChild 5000000 MaxClients 6000 KeepAliveTimeout 1 MaxKeepAliveRequests 100 ProxyRequests On	1. There was no 2.2.7 release. Do you talk about the candidate that was published on the dev list for review? 2. How does it break www.hotels.com? (In reply to comment #1) > 1. There was no 2.2.7 release. Do you talk about the candidate that was > published on the dev list for review? > 2. How does it break www.hotels.com?  Sorry, I meant 2.2.6. In Firefox and Opera there is no visible page data. In the logs with debug turned on I'm seeing:  [Mon Jan 28 07:27:21 2008] [debug] mod_proxy_http.c(1822): proxy: HTTP: serving URL http://www.hotels.com/ [Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(1855): proxy: HTTP: has acquired connection for (*) [Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(1916): proxy: connecting http://www.hotels.com/ to www.hotels.com:80 [Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(2015): proxy: connected / to www.hotels.com:80 [Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(2172): proxy: HTTP: fam 2 socket created to connect to * [Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(2269): proxy: HTTP: connection complete to 72.246.51.115:80 (www.hotels.com) [Mon Jan 28 07:27:21 2008] [debug] mod_proxy_http.c(1607): proxy: start body send [Mon Jan 28 07:27:21 2008] [debug] mod_headers.c(665): headers: ap_headers_output_filter() [Mon Jan 28 07:27:21 2008] [info] [client 127.0.0.1] (104)Connection reset by peer: core_output_filter: writing data to the network [Mon Jan 28 07:27:21 2008] [debug] mod_proxy_http.c(1696): proxy: end body send [Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(1873): proxy: HTTP: has released connection for (*) [Mon Jan 28 07:27:21 2008] [info] [client 127.0.0.1] (32)Broken pipe: core_output_filter: writing data to the network     Also, I should not that hotels.com seems to send a redirect depending upon what country you are from. You can perhaps try this link from  Germany:  http://www.hotels.com/?isRedirect=true&js=1&zz=1201533352859  (In reply to comment #1) > 1. There was no 2.2.7 release. Do you talk about the candidate that was > published on the dev list for review? > 2. How does it break www.hotels.com?   Please post your configuration. I tried to use 2.2.8 as forward proxy and I had no hassle reaching www.hotels.com. The messages from the error log indicate that you have a client problem. (In reply to comment #4) > Please post your configuration. I tried to use 2.2.8 as forward proxy and I had > no hassle reaching www.hotels.com. The messages from the error log indicate that > you have a client problem.  My configuration is posted in the body of the original message. I have been able to reproduce this error on 3 different Apache builds running on 3 different networks. The errors occurs both with Firefox and Opera.   I've succeeded to reproduce this IE 7.0 WinXP SP3RC1 If IE setting 'Use HTTP/1.1 for proxy' is turned off, work correct. I guess something happens in chunked encoding. (In reply to comment #3) > Also, I should not that hotels.com seems to send a redirect depending upon what > country you are from. You can perhaps try this link from  Germany: >  > http://www.hotels.com/?isRedirect=true&js=1&zz=1201533352859  Thanks for the link. With the help of the link I was able to reproduce your issue. It is caused by www.hotels.com sending a Connection: Transfer-Encoding header in its response. This is IMHO unusual (Transfer-Encoding is a hop-by-hop header anyway), but allowed. This causes httpd to remove Transfer-Encoding too early during its internal processing and thus disables it from processing the chunked response. Please let me know if the patch I will attach in a second fixes your problem.    Created an attachment (id=21438) Patch against Trunk  Thanks a lot for tackling this issue, but must this patch be strictly applied to trunk ? I tried it against 2.2.8 with no success ...  (In reply to comment #9) > Created an attachment (id=21438) [edit] > Patch against Trunk >    (In reply to comment #10) > Thanks a lot for tackling this issue, but must this patch be strictly applied to > trunk ? I tried it against 2.2.8 with no success ...  No, it should work with 2.2.8. I tested it with the link you provided against 2.2.x (which is currently identical to 2.2.8 with respect to mod_proxy) and afterwards everything was fine.   You are right. In my sleepy state, I incorrectly manually applied the patch. It does indeed fix this issue. Thanks again !  (In reply to comment #11) > (In reply to comment #10) > > Thanks a lot for tackling this issue, but must this patch be strictly applied to > > trunk ? I tried it against 2.2.8 with no success ... >  > No, it should work with 2.2.8. I tested it with the link you provided against > 2.2.x (which is currently identical to 2.2.8 with respect to mod_proxy) and > afterwards everything was fine. >  >    Reopen because no fixes haven't been committed yet Committed a slightly optimized version to trunk as r616517 (http://svn.apache.org/viewvc?rev=616517&view=rev). backported to 2.2 http://svn.apache.org/viewvc?view=rev&revision=617686			Peter Belau	Ruediger Pluem	Takashi Sato
44346	null	RESOLVED		Toralf F	1201941120000	1208418907000		integer overflow in ab If I benchmark a local apache-2.2.8 installation under a stable Gentoo, I used this command  n22 /var/www/localhost/htdocs/public # dd if=/dev/urandom of=urand400K bs=1024 count=400 400+0 records in 400+0 records out 409600 bytes (410 kB) copied, 0.357657 s, 1.1 MB/s  to create a dummy file, after that I used ab to get some results:  n22 /var/www/localhost/htdocs/public # ab -q -n 10000 http://n22/public/urand400K This is ApacheBench, Version 2.0.40-dev <$Revision: 1.146 $> apache-2.0 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Copyright 2006 The Apache Software Foundation, http://www.apache.org/  Benchmarking n22 (be patient).....done   Server Software:        Apache Server Hostname:        n22 Server Port:            80  Document Path:          /public/urand400K Document Length:        409600 bytes  Concurrency Level:      1 Time taken for tests:   12.913905 seconds Complete requests:      10000 Failed requests:        0 Write errors:           0 Total transferred:      -196517296 bytes HTML transferred:       -198967296 bytes Requests per second:    774.36 [#/sec] (mean) Time per request:       1.291 [ms] (mean) Time per request:       1.291 [ms] (mean, across all concurrent requests) Transfer rate:          -14860.80 [Kbytes/sec] received  Connection Times (ms)               min  mean[+/-sd] median   max Connect:        0    0   0.1      0      11 Processing:     0    1   1.8      1      61 Waiting:        0    0   0.1      0       4 Total:          0    1   1.8      1      61  Percentage of the requests served within a certain time (ms)   50%      1   66%      1   75%      1   80%      1   90%      1   95%      1   98%      2   99%      3  100%     61 (longest request)   I'm wondering about the negative values which only happens for a 400 KB file, but not for a 100KB file for 10000 requests. With 40000 requests and a 100 KB dummy file I get negative values too.  Seems to be a simple overflow of an integer, isn't it ?	I agree with this. Does the following patch solve the problem for you? Created an attachment (id=21462) Patch against trunk  (In reply to comment #2) > Created an attachment (id=21462) [edit] > Patch against trunk >  yes, works fine :-) Committed to trunk as r617890 (http://svn.apache.org/viewvc?rev=617890&view=rev). *** Bug 40734 has been marked as a duplicate of this bug. *** I'm wondering why this bug was open such a long time w/o a solution (bug #40734 was opened at 2006-10-11 14:50)  Proposed for backport to 2.2.x as r618229 (http://svn.apache.org/viewvc?rev=618229&view=rev). backported to 2.2 <http://svn.apache.org/viewvc?view=rev&revision=618229> sorry, wrong revision  backported to 2.2 as r649114 http://svn.apache.org/viewvc?view=rev&revision=649114			Ruediger Pluem	Takashi Sato	Toralf F
44360	null	RESOLVED		Rainer Jung	1202229720000	1202298757000		Correct typo in error message and in comment timout -> timeout	Created an attachment (id=21474) Typo correction patch (timout)  Thanks for the patch. Committed to trunk in r619125.			Rainer Jung	Ruediger Pluem
44402	null	RESOLVED		Basant Kumar Kukreja	1202834820000	1204029474000		Worker mpm crashes (SEGV) under stress with static workload I am running specweb99 static content workload with httpd 2.2.6 on Solaris nevada (snv_79).  I am seeing several crashes. Typically crash do reproduce in 10 minutes. Here are the details : Apache version : httpd-2.2.6 Simultaneous connection : 1000 Hardware : X4100 Server (4 core 2.8 GHz) CPU : Only single core is enabled Architecture : x86_64   httpd.conf contains : <IfModule worker.c> ListenBackLog     50000 StartServers         2 ThreadLimit        500 ThreadsPerChild    500 MinSpareThreads    100 MaxSpareThreads    100 ThreadsPerChild    500 MaxClients        1000 MaxRequestsPerChild  0 </IfModule>  Listen 192.168.21.1:80 Listen 192.168.22.1:80  Here is the most common stack trace.   Configure option : CFLAGS='-g -mt -m64 -KPIC ' ./configure --prefix=<prefix_path> --with-mpm=worker --enable-modules=all --with-ssl=/usr/sfw --enable-mods-shared=all --enable-cgi --enable-threads && gmake && gmake install  Crash 1 : (dbx) where current thread: t@76 =>[1] allocator_free(allocator = 0x101f870, node = (nil)), line 331 in 'apr_pools.c'   [2] apr_pool_clear(pool = 0x102fb88), line 710 in 'apr_pools.c'   [3] ap_core_output_filter(f = 0x1020550, b = 0x101f9e8), line 899 in 'core_filters.c'   [4] ap_pass_brigade(next = 0x1020550, bb = 0x101f9e8), line 526 in 'util_filter.c'   [5] logio_out_filter(f = 0x10204e0, bb = 0x101f9e8), line 135 in 'mod_logio.c'   [6] ap_pass_brigade(next = 0x10204e0, bb = 0x101f9e8), line 526 in 'util_filter.c'   [7] ap_flush_conn(c = 0x101fd00), line 84 in 'connection.c'   [8] ap_lingering_close(c = 0x101fd00), line 123 in 'connection.c'   [9] process_socket(p = 0x101f968, sock = 0x101f9e8, my_child_num = 1, my_thread_num = 227, bucket_alloc = 0x1029a88), line 545 in 'worker.c'   [10] worker_thread(thd = 0x5bed38, dummy = 0x6dbac0), line 894 in 'worker.c'   [11] dummy_worker(opaque = 0x5bed38), line 142 in 'thread.c'   [12] _thr_setup(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5d8f7   [13] _lwp_start(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5dba0  Crash 2 : (dbx) where current thread: t@363 =>[1] apr_palloc(pool = 0x21680007952225ff, size = 18446744073323675656U), line 601 in 'apr_pools.c'   [2] apr_sockaddr_ip_get(addr = 0xcda3d0, sockaddr = 0x42d790), line 104 in 'sockaddr.c'   [3] core_create_conn(ptrans = 0xcda2d8, server = 0x4bf600, csd = 0xcda358, id = 360, sbh = 0xcda378, alloc = 0xd147e8), line 3895 in 'core.c'   [4] ap_run_create_connection(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0x45fe03   [5] process_socket(p = 0xcda2d8, sock = 0xcda358, my_child_num = 0, my_thread_num = 360, bucket_alloc = 0xd147e8), line 542 in 'worker.c'   [6] worker_thread(thd = 0x7192f8, dummy = 0x7e45a0), line 894 in 'worker.c'   [7] dummy_worker(opaque = 0x7192f8), line 142 in 'thread.c'   [8] _thr_setup(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5d8f7   [9] _lwp_start(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5dba0  I tried httpd-2.2.8 too but got the similar crash : Crash 3 (with httpd-2.2.8): =>[1] apr_palloc(pool = 0x226800079e7a25ff, size = 18446744073323675656U), line 630 in 'apr_pools.c'   [2] apr_sockaddr_ip_get(addr = 0xc57060, sockaddr = 0x42dab8), line 104 in 'sockaddr.c'   [3] core_create_conn(ptrans = 0xc56f68, server = 0x4c0378, csd = 0xc56fe8, id = 951, sbh = 0xc57008, alloc = 0xc58f78), line 3895 in 'core.c'   [4] ap_run_create_connection(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0x4604e3   [5] process_socket(p = 0xc56f68, sock = 0xc56fe8, my_child_num = 1, my_thread_num = 451, bucket_alloc = 0xc58f78), line 542 in 'worker.c'   [6] worker_thread(thd = 0x870c88, dummy = 0x7e7e30), line 894 in 'worker.c'   [7] dummy_worker(opaque = 0x870c88), line 142 in 'thread.c'   [8] _thr_setup(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5d8f7   [9] _lwp_start(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5dba0  prefork mpm works just fine.	I tried to debug the crash  =>[1] allocator_free(allocator = 0x101f870, node = (nil)), line 331 in 'apr_pools.c'   [2] apr_pool_clear(pool = 0x102fb88), line 710 in 'apr_pools.c'   [3] ap_core_output_filter(f = 0x1020550, b = 0x101f9e8), line 899 in 'core_filters.c'  In ap_core_output_filter, crash is happening when apr_pool_clear is called for deferred_write_pool.             apr_pool_clear(ctx->deferred_write_pool); On further investigation, I found that for ctx->deferred_write_pool, pool->ref points to pool->next i.e pool->ref == &pool->next  Thus in apr_pool_clear :     if (active->next == active)         return;      *active->ref = NULL; // ---> this cause active->next to set to NULL because                          // active->ref points to active->next     allocator_free(pool->allocator, active->next);  The situation doesn't arrive on normal single connection situation. This happens only under stress. Under normal connection active->next == active and function returns from apr_pool_clear (when called for ctx->deferred_write_pool)  Crashes are happening on 32 bit apache too therefore changing the summary. Here is the crash from 32 bit apache : =>[1] allocator_free(allocator = 0x8aae018, node = (nil)), line 331 in 'apr_pools.c'   [2] apr_pool_clear(pool = 0x8b629b8), line 710 in 'apr_pools.c'   [3] ap_core_output_filter(f = 0x8aae870, b = 0x8aae0e0), line 899 in 'core_filters.c'   [4] ap_pass_brigade(next = 0x8aae870, bb = 0x8aae0e0), line 526 in 'util_filter.c'   [5] logio_out_filter(f = 0x8aae830, bb = 0x8aae0e0), line 135 in 'mod_logio.c'   [6] ap_pass_brigade(next = 0x8aae830, bb = 0x8aae0e0), line 526 in 'util_filter.c'   [7] ap_flush_conn(c = 0x8aae390), line 84 in 'connection.c'   [8] ap_lingering_close(c = 0x8aae390), line 123 in 'connection.c'   [9] process_socket(p = 0x8aae0a0, sock = 0x8aae0e0, my_child_num = 1, my_thread_num = 249, bucket_alloc = 0x8b5c9a0), line 545 in 'worker.c'   [10] worker_thread(thd = 0x81a6788, dummy = 0x831f5a0), line 894 in 'worker.c'   [11] dummy_worker(opaque = 0x81a6788), line 142 in 'thread.c'   [12] _thr_setup(0xf004d200), at 0xfec6f282   [13] _lwp_start(0xfee7ddb9, 0xfee7f55e, 0xfffffff6, 0x0, 0x1, 0xfeea1984), at 0xfec6f4e0  Here is the debug information from a crash of 32 bit apache :  t@414 (l@414) terminated by signal SEGV (Segmentation Fault) Current function is apr_sockaddr_ip_get   104       *addr = apr_palloc(sockaddr->pool, sockaddr->addr_str_len); (dbx) where current thread: t@414 =>[1] apr_sockaddr_ip_get(addr = 0x974a3d0, sockaddr = (nil)), line 104 in 'sockaddr.c'   [2] core_create_conn(ptrans = 0x974a348, server = 0x80d9020, csd = 0x974a388, id = 411, sbh = 0x974a398, alloc = 0x9788670), line 3895 in 'core.c'   [3] ap_run_create_connection(0x974a348, 0x80d9020, 0x974a388, 0x19b, 0x974a398, 0x9788670), at 0x8090ae8   [4] process_socket(p = 0x974a348, sock = 0x974a388, my_child_num = 0, my_thread_num = 411, bucket_alloc = 0x9788670), line 542 in 'worker.c'   [5] worker_thread(thd = 0x83a6ff8, dummy = 0x8125e80), line 894 in 'worker.c'   [6] dummy_worker(opaque = 0x83a6ff8), line 142 in 'thread.c'   [7] _thr_setup(0xf008e200), at 0xfec6f282   [8] _lwp_start(0x0, 0xfee8410c, 0xe451bef8, 0xe451bef8, 0x8081a83, 0x974a3d0), at 0xfec6f4e0 (dbx) p sockaddr sockaddr = (nil) (dbx) where current thread: t@414 =>[1] apr_sockaddr_ip_get(addr = 0x974a3d0, sockaddr = (nil)), line 104 in 'sockaddr.c'   [2] core_create_conn(ptrans = 0x974a348, server = 0x80d9020, csd = 0x974a388, id = 411, sbh = 0x974a398, alloc = 0x9788670), line 3895 in 'core.c'   [3] ap_run_create_connection(0x974a348, 0x80d9020, 0x974a388, 0x19b, 0x974a398, 0x9788670), at 0x8090ae8   [4] process_socket(p = 0x974a348, sock = 0x974a388, my_child_num = 0, my_thread_num = 411, bucket_alloc = 0x9788670), line 542 in 'worker.c'   [5] worker_thread(thd = 0x83a6ff8, dummy = 0x8125e80), line 894 in 'worker.c'   [6] dummy_worker(opaque = 0x83a6ff8), line 142 in 'thread.c'   [7] _thr_setup(0xf008e200), at 0xfec6f282   [8] _lwp_start(0x0, 0xfee8410c, 0xe451bef8, 0xe451bef8, 0x8081a83, 0x974a3d0), at 0xfec6f4e0 (dbx) up Current function is core_create_conn  3895       apr_sockaddr_ip_get(&c->local_ip, c->local_addr); (dbx) p *c *c = {     pool                  = 0x974a348     base_server           = (nil)     vhost_lookup_data     = (nil)     local_addr            = (nil)     remote_addr           = (nil)     remote_ip             = (nil)     remote_host           = (nil)     remote_logname        = (nil)     aborted               = 0     keepalive             = AP_CONN_UNKNOWN     double_reverse        = 0     keepalives            = 0     local_ip              = (nil)     local_host            = (nil)     id                    = 0     conn_config           = 0x974a400     notes                 = 0x974a6a0     input_filters         = (nil)     output_filters        = (nil)     sbh                   = 0x974a398     bucket_alloc          = (nil)     cs                    = (nil)     data_in_input_filters = 0 } (dbx) dump alloc = 0x9788670 rv = 0 ptrans = 0x974a348 server = 0x80d9020 sbh = 0x974a398 c = 0x974a3a0 id = 411 csd = 0x974a388 (dbx) _arch_networkio.h"struct apr_socket_t*)csd                              < *((struct apr_socket_t *) csd) = {     pool                    = (nil)     socketdes               = 158893680     type                    = -17726080     protocol                = 134660748     local_addr              = (nil)     remote_addr             = 0x19b     timeout                 = 158638920LL     local_port_unknown      = 0     local_interface_unknown = 0     remote_addr_unknown     = 0     options                 = 0     inherit                 = 0     userdata                = (nil) }  Please let me know if any other information is need.  First guess for your last crash in comment #4 (all line numbers 2.2.8):  lr->accept_func(&csd, lr, ptrans); (line 742 in worker.c) fails with rv != APR_SUCCESS, but with a non NULL value for csd. In contrast to the code in prefork we don't check this situation:  Lines 621 - 631 of prefork.c:          status = lr->accept_func(&csd, lr, ptrans);          SAFE_ACCEPT(accept_mutex_off());      /* unlock after 'accept' */          if (status == APR_EGENERAL) {             /* resource shortage or should-not-occur occured */             clean_child_exit(1);         }         else if (status != APR_SUCCESS) {             continue;         }  Maybe we need to do a continue in the worker case as well or we need to do something like the following:  Index: server/mpm/worker/worker.c =================================================================== --- server/mpm/worker/worker.c  (Revision 627576) +++ server/mpm/worker/worker.c  (Arbeitskopie) @@ -743,6 +743,9 @@              /* later we trash rv and rely on csd to indicate success/failure */              AP_DEBUG_ASSERT(rv == APR_SUCCESS || !csd);  +            if (rv != APR_SUCCESS) { +                csd = NULL; +            }              if (rv == APR_EGENERAL) {                  /* E[NM]FILE, ENOMEM, etc */                  resource_shortage = 1;     I did the stress test with the patch you suggested. After your patch, I still got the 1st crash. If it crashed in second stack trace then I will update the bug.  Here are some more information about 1st crash. * I am able to reproduce the crash on Solaris 10 update 1 (on a different   machine) too. It took around 4 hours of stress before I got the crash on   Solaris 10 while it takes around < 30 minutes to reproduce on Solaris nevada.   It was crash 1 (allocator_free with node = null) (without your patch).  Here is more information of the crash 1 : (dbx) where current thread: t@21 =>[1] allocator_free(allocator = 0x8afe2e0, node = (nil)), line 331 in 'apr_pools.c'   [2] apr_pool_clear(pool = 0xa0d01c0), line 710 in 'apr_pools.c'   [3] ap_core_output_filter(f = 0xa0b28c8, b = 0xa0b2a08), line 899 in 'core_filters.c'   [4] ap_pass_brigade(next = 0xa0b28c8, bb = 0xa0b2a08), line 526 in 'util_filter.c'   [5] logio_out_filter(f = 0xa0b2888, bb = 0xa0b2a08), line 135 in 'mod_logio.c'   [6] ap_pass_brigade(next = 0xa0b2888, bb = 0xa0b2a08), line 526 in 'util_filter.c'   [7] ap_flush_conn(c = 0xa0b23e8), line 84 in 'connection.c'   [8] ap_lingering_close(c = 0xa0b23e8), line 123 in 'connection.c'   [9] process_socket(p = 0x8afe368, sock = 0x8aff660, my_child_num = 1, my_thread_num = 18, bucket_alloc = 0xa0be178), line 545 in 'worker.c'   [10] worker_thread(thd = 0x81487d8, dummy = 0x8117b30), line 894 in 'worker.c'   [11] dummy_worker(opaque = 0x81487d8), line 142 in 'thread.c'   [12] _thr_setup(0xfe244800), at 0xfeccf92e   [13] _lwp_start(), at 0xfeccfc10 (dbx) up Current function is apr_pool_clear   710       allocator_free(pool->allocator, active->next); (dbx) p *active *active = {     next        = (nil)     ref         = 0xa0d01a8     index       = 1U     free_index  = 0     first_avail = 0xa0d01f8 '/xc0^A^M/n/xfc^A^M/n/xfc^A^M/nx/xe1^K/n'     endp        = 0xa0d21a8 '^A ' } (dbx) up Current function is ap_core_output_filter   899               apr_pool_clear(ctx->deferred_write_pool); (dbx) p *ctx *ctx = {     b                   = (nil)     deferred_write_pool = 0xa0d01c0 } (dbx) p *ctx->deferred_write_pool *ctx->deferred_write_pool = {     parent           = 0x8afe368     child            = (nil)     sibling          = 0xa0c6198     ref              = 0x8afe36c     cleanups         = (nil)     free_cleanups    = (nil)     allocator        = 0x8afe2e0     subprocesses     = (nil)     abort_fn         = (nil)     user_data        = (nil)     tag              = 0x80bfd1c 'deferred_write'     active           = 0xa0d01a8     self             = 0xa0d01a8     self_first_avail = 0xa0d01f8 '/xc0^A^M/n/xfc^A^M/n/xfc^A^M/nx/xe1^K/n' } (dbx) p *c *c = {     pool                  = 0x8afe368     base_server           = 0x80e6bf8     vhost_lookup_data     = (nil)     local_addr            = 0x8aff698     remote_addr           = 0x8aff7c0     remote_ip             = 0xa0b2850 '192.168.11.1'     remote_host           = (nil)     remote_logname        = (nil)     aborted               = 0     keepalive             = AP_CONN_KEEPALIVE     double_reverse        = 0     keepalives            = 1     local_ip              = 0xa0b2840 '192.168.11.2'     local_host            = (nil)     id                    = 518     conn_config           = 0xa0b2448     notes                 = 0xa0b26e8     input_filters         = 0xa0b2870     output_filters        = 0xa0b2888     sbh                   = 0xa0b23e0     bucket_alloc          = 0xa0be178     cs                    = (nil)     data_in_input_filters = 0 }  One putting some printfs I figured out the following :  In apr_pool_clear (when invoked for deferred_write_pool)     ...     active = pool->active = pool->self;     active->first_avail = pool->self_first_avail;      if (active->next == active)         return;  active->next should typically be s circular link list. What is happenning some cases is that active->next points to some thing else and active->ref still points to active->next.  I put a printf of active->next before it is set to NULL. For a particular crash, here is my debugging session. I found that active->next was set to 0x20e8810 before it was set to NULL.  (dbx) up Current function is apr_pool_clear   774       allocator_free(pool->allocator, active->next); (dbx) up Current function is ap_core_output_filter   923               apr_pool_clear(ctx->deferred_write_pool); (dbx) p (struct apr_memnode_t*)0x20e8810 -----> This was active->next before set to NULL. (struct apr_memnode_t *) 0x20e8810 = 0x20e8810 (dbx) p *(struct apr_memnode_t*)0x20e8810 *((struct apr_memnode_t *) 0x20e8810) = {     next        = 0x288c5b0     ref         = 0x20e8810     index       = 1U     free_index  = 0     first_avail = 0x20e9eb0 'GET /file_set/dir00104/class1_3 HTTP/1.0'     endp        = 0x20ea810 '^A ' } (dbx) down Current function is apr_pool_clear   774       allocator_free(pool->allocator, active->next); (dbx) p active active = 0x20e27e0 (dbx) p *((struct apr_memnode_t*)0x20e8810)->next *((struct apr_memnode_t *) 0x20e8810)->next = {     next        = 0x20e07d0     ref         = 0x20e07d0     index       = 1U     free_index  = 0     first_avail = 0x288d008 ''     endp        = 0x288e5b0 '^A ' } (dbx) p active active = 0x20e27e0 (dbx) p *(((struct apr_memnode_t*)0x20e8810)->next)->next *((struct apr_memnode_t *) 0x20e8810)->next->next = {     next        = 0x28905d0     ref         = 0x288c5b0     index       = 1U     free_index  = 0     first_avail = 0x20e2738 ''     endp        = 0x20e27d0 '^A ' } (dbx) p *((((struct apr_memnode_t*)0x20e8810)->next)->next)->next *((struct apr_memnode_t *) 0x20e8810)->next->next->next = {     next        = 0x288e5c0     ref         = 0x28905d0     index       = 1U     free_index  = 0     first_avail = 0x2890668 '/xf8^E/x89^B'     endp        = 0x28925d0 '^Q^P' } (dbx) p *(((((struct apr_memnode_t*)0x20e8810)->next)->next)->next)->next *((struct apr_memnode_t *) 0x20e8810)->next->next->next->next = {     next        = (nil)     ref         = (nil)     index       = 1U     free_index  = 0     first_avail = 0x288e5e8 '"^_'     endp        = 0x28905c0 '^A ' }  On further debugging, I figured out that typically ap_core_output_filter is called 4 times for a request. The crash always happen in 4th invocation. It seems to me that it gets corrupted somewhere after the 3rd invocation (after it returns from ap_core_output_filter) and before it enters into ap_core_output_filter 4th time (when ap_lingering_close is in call stack). Also conn->keepalives was always set to 1.  With Ruediger patch, I still got the crash (#2). Here is the debug information :  t@314 (l@314) terminated by signal SEGV (Segmentation Fault) Current function is apr_sockaddr_ip_get   104       *addr = apr_palloc(sockaddr->pool, sockaddr->addr_str_len); (dbx) where current thread: t@314 =>[1] apr_sockaddr_ip_get(addr = 0x1ebb4b0, sockaddr = (nil)), line 104 in 'sockaddr.c'   [2] core_create_conn(ptrans = 0x1ebb3b8, server = 0x4c0200, csd = 0x1ebb728, id = 311, sbh = 0x1ebb458, alloc = 0x2128b58), line 3895 in 'core.c'   [3] ap_run_create_connection(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0x4602c3   [4] process_socket(p = 0x1ebb3b8, sock = 0x1ebb728, my_child_num = 0, my_thread_num = 311, bucket_alloc = 0x2128b58), line 566 in 'worker.c'   [5] worker_thread(thd = 0x7195c8, dummy = 0x6e2310), line 923 in 'worker.c'   [6] dummy_worker(opaque = 0x7195c8), line 142 in 'thread.c'   [7] _thr_setup(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5d8f7   [8] _lwp_start(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5dba0 (dbx) p *addr *addr = (nil) (dbx) up Current function is core_create_conn  3895       apr_sockaddr_ip_get(&c->local_ip, c->local_addr); (dbx) p *c *c = {     pool                  = 0x1ebb3b8     base_server           = (nil)     vhost_lookup_data     = (nil)     local_addr            = (nil)     remote_addr           = (nil)     remote_ip             = (nil)     remote_host           = (nil)     remote_logname        = (nil)     aborted               = 0     keepalive             = AP_CONN_UNKNOWN     double_reverse        = 0     keepalives            = 0     local_ip              = (nil)     local_host            = (nil)     id                    = 0     conn_config           = 0x1ebb508     notes                 = 0x1ebba48     input_filters         = (nil)     output_filters        = (nil)     sbh                   = 0x1ebb458     bucket_alloc          = (nil)     cs                    = (nil)     data_in_input_filters = 0 } (dbx) dump alloc = 0x2128b58 rv = 0 ptrans = 0x1ebb3b8 server = 0x4c0200 sbh = 0x1ebb458 c = 0x1ebb460 id = 311 csd = 0x1ebb728 (dbx) p csd csd = 0x1ebb728 (dbx) p *(struct apr_socket_t*) csd *((struct apr_socket_t *) csd) = {     pool                    = (nil)     socketdes               = 0     type                    = 0     protocol                = 0     local_addr              = (nil)     remote_addr             = (nil)     timeout                 = 0     local_port_unknown      = 0     local_interface_unknown = 0     remote_addr_unknown     = 0     options                 = 0     inherit                 = 0     userdata                = (nil) }    I assume that the ptrans pool somehow gets corrupted. I guess it is used by two threads in parallel which could lead to a corruption since pools as such are not thread safe. So I think a good starting point for further investigations would be   ap_queue_info_wait_for_idler in mpm/worker/fdqueue.c  or the lines 731 - 740 in worker.c:              if (ptrans == NULL) {                 /* we can't use a recycled transaction pool this time.                  * create a new transaction pool */                 apr_allocator_t *allocator;                  apr_allocator_create(&allocator);                 apr_allocator_max_free_set(allocator, ap_max_mem_free);                 apr_pool_create_ex(&ptrans, pconf, NULL, allocator);                 apr_allocator_owner_set(allocator, ptrans);             }   Thanks Ruediger for your suggestion. I will try to explore based on your suggestion.  Meanwhile here is the 3rd type of crash (with your patch).  t@13 (l@13) terminated by signal SEGV (Segmentation Fault) Current function is apr_pool_cleanup_kill  2045       c = p->cleanups; (dbx) where current thread: t@13 =>[1] apr_pool_cleanup_kill(p = 0xa0, data = 0x195b888, cleanup_fn = 0xfffffd7fff223540 = &"libapr-1.so.0.2.11"sockets.c"socket_cleanup(void *sock)), line 2045 in 'apr_pools.c'   [2] apr_pool_cleanup_run(p = 0xa0, data = 0x195b888, cleanup_fn = 0xfffffd7fff223540 = &"libapr-1.so.0.2.11"sockets.c"socket_cleanup(void *sock)), line 2088 in 'apr_pools.c'   [3] apr_socket_close(thesocket = 0x195b888), line 149 in 'sockets.c'   [4] ap_lingering_close(c = 0x17407f0), line 135 in 'connection.c'   [5] process_socket(p = 0x1740748, sock = 0x195b888, my_child_num = 1, my_thread_num = 10, bucket_alloc = 0x195b728), line 569 in 'worker.c'   [6] worker_thread(thd = 0x52bb48, dummy = 0x4f3480), line 951 in 'worker.c'   [7] dummy_worker(opaque = 0x52bb48), line 142 in 'thread.c'   [8] _thr_setup(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5d8f7   [9] _lwp_start(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5dba0 (dbx) up Current function is apr_pool_cleanup_run  2088       apr_pool_cleanup_kill(p, data, cleanup_fn); (dbx) up Current function is apr_socket_close   149       return apr_pool_cleanup_run(thesocket->pool, thesocket, socket_cleanup); (dbx) p *thesocket *thesocket = {     pool                    = 0xa0     socketdes               = 26588968     type                    = 0     protocol                = 26588928     local_addr              = 0x195b7e8     remote_addr             = 0x1741158     timeout                 = 24383832     local_port_unknown      = 4895848     local_interface_unknown = 0     remote_addr_unknown     = 0     options                 = 0     inherit                 = 0     userdata                = (nil) } (dbx) dump thesocket = 0x195b888 (dbx) up Current function is ap_lingering_close   135           apr_socket_close(csd); (dbx) dump timeup = 0 dummybuf = '' c = 0x17407f0 nbytes = 4294967296U csd = 0x195b888 (dbx) p *c *c = {     pool                  = 0x1740748     base_server           = 0x4c0300     vhost_lookup_data     = (nil)     local_addr            = 0x195b8d8     remote_addr           = 0x195ba18     remote_ip             = 0x1740f88 '192.168.22.2'     remote_host           = (nil)     remote_logname        = (nil)     aborted               = 0     keepalive             = AP_CONN_UNKNOWN     double_reverse        = 0     keepalives            = 0     local_ip              = 0x1740f78 '192.168.22.1'     local_host            = (nil)     id                    = 510     conn_config           = 0x1740898     notes                 = 0x1740dd8     input_filters         = 0x1740fa8     output_filters        = 0x1740fd0     sbh                   = 0x17407e8     bucket_alloc          = 0x195b728     cs                    = (nil)     data_in_input_filters = 0 } (dbx) _arch_networkio.h"struct apr_socket_t*)csd                              < *((struct apr_socket_t *) csd) = {     pool                    = 0xa0     socketdes               = 26588968     type                    = 0     protocol                = 26588928     local_addr              = 0x195b7e8     remote_addr             = 0x1741158     timeout                 = 24383832     local_port_unknown      = 4895848     local_interface_unknown = 0     remote_addr_unknown     = 0     options                 = 0     inherit                 = 0     userdata                = (nil) } (dbx) etworkio.h"struct apr_socket_t*)csd->local_addr                         < dbx: can't find field 'local_addr' in '*(csd)' (dbx) p (("srclib/apr/include/arch/unix/apr_arch_networkio.h"struct apr_socke > ((struct apr_socket_t *) csd)->local_addr = 0x195b7e8 (dbx) p *(("srclib/apr/include/arch/unix/apr_arch_networkio.h"struct apr_sock > *((struct apr_socket_t *) csd)->local_addr = {     pool         = 0xa0     hostname     = 0x195b728 'H^Gt^A'     servname     = 0x195b700 ''     port         = 0     family       = 0     salen        = 24383744U     ipaddr_len   = 0     addr_str_len = 24383744     ipaddr_ptr   = 0xfffffd7fff2e8010     next         = (nil)     sa           = {         sin  = {             sin_family = 0             sin_port   = 0             sin_addr   = {                 S_un = {                     S_un_b = {                         s_b1 = '/0'                         s_b2 = '/0'                         s_b3 = '/0'                         s_b4 = '/0'                     }                     S_un_w = {                         s_w1 = 0                         s_w2 = 0                     }                     S_addr = 0                 }             }             sin_zero   = ''         }         sin6 = {             sin6_family   = 0             sin6_port     = 0             sin6_flowinfo = 0             sin6_addr     = {                 _S6_un = {                     _S6_u8     = ''                     _S6_u32    = (0, 0, 4373928U, 0)                     __S6_align = 0                 }             }             sin6_scope_id = 26588968U             __sin6_src_id = 0         }         sas  = {             ss_family = 0             _ss_pad1  = ''             _ss_align = 0.0             _ss_pad2  = 'xxB'         }     } }  As you wrote Solaris on Sun I suppose you mean on SPARC. Have you checked if the crashes happen with the same Solaris version on x86? Background of the question: ap_queue_info_wait_for_idler uses atomics whose implementation depends on the hardware architecture. Non functional atomics could be a source for concurrency problems under load. (In reply to comment #10) > As you wrote Solaris on Sun I suppose you mean on SPARC. Have you checked if the > crashes happen with the same Solaris version on x86? Background of the question:  Oops my fault: You already said that you are using x86. Nevertheless does the same happen on SPARC with the same Solaris version or if you compile with  --enable-nonportable-atomics=no ?  Thanks Ruediger for your pointer. It was really useful.  Regarding the function : ap_queue_info_wait_for_idler (lines 188-196) 188:        struct recycled_pool *first_pool = queue_info->recycled_pools; 189:        if (first_pool == NULL) { 190:            break; 191:        } 192:        if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools), first_pool->next, 193:                              first_pool) == first_pool) { 194:            *recycled_pool = first_pool->pool; 195:            break; 196:        }  I will represent queue_info->receycled_pools as qu->rp to make it make it short.  Inside apr_atomic_casptr we acquire a mutex. So I will write 3 steps : 1. Calcualte first_pool. 2. Calculate first_pool->next and invoke apr_atomic_caspptr 3. Acquire lock on qi->rp (inside apr_atomic_casptr)  There is a very clear race condition between the two statement (line 188 and line 193) and between step 2 & 3. Though I agree that &queue_info->recycled_pool is protected and it is atomically correct but the next pointer (first_pool and first_pool->next) are not protected correctly. There is a very clear race condition between the two. To prove my point, here is an example :  Suppose at a particular moment recycled_pool pool list is  1 --> 2 ---> 3 . Where 1,2,3 are the pool nodes. qi->rp = 1. Now consider the following situation : Thread 1 :     first_pool = 1;     first_pool->next = 2.      Now before step 3 is executed that is before we acquire a lock on qi->rp, context switch happens.  Thread 2 :     Thread 2 pops a node (1) from the list and hence list becomes 2->3.  Thread 3 :     Thread 3 pops another node (2) from the list and hence list becomes 3.  Thread 2 :     push the node back and now list becomes 1->3.  Thread 1:     first->pool->next = 2.  qi->rp is still 1.  Thread acquires a lock &1 and atomically compare and swap with 2. It succeeded because qi->rp was 1 but qi->rp->next was not 3, it becomes 2 and hence queue becomes 2 (or 2-->3).          I believe, I can prove my point with a sample standalone application. So far I used a separate mutex and protected both qi->rp and qi->rp->next both.  I tried with the attached patch. With this patch, I am able to run the stress for more than 10 hour without any crash. Without this patch, crash used to happen in less than 30 minutes. Here is the patch which I tried : ---------------------------------------------------------------------------  --- orghttpd-2.2.6/server/mpm/worker/fdqueue.c\tWed Jul 25 06:13:49 2007 +++ httpd-2.2.6/server/mpm/worker/fdqueue.c\tFri Feb 15 10:57:42 2008 @@ -25,6 +25,7 @@  struct fd_queue_info_t {      apr_uint32_t idlers;      apr_thread_mutex_t *idlers_mutex; +    apr_thread_mutex_t *queue_mutex;      apr_thread_cond_t *wait_for_idler;      int terminated;      int max_idlers; @@ -36,6 +37,7 @@      fd_queue_info_t *qi = data_;      apr_thread_cond_destroy(qi->wait_for_idler);      apr_thread_mutex_destroy(qi->idlers_mutex); +    apr_thread_mutex_destroy(qi->queue_mutex);        /* Clean up any pools in the recycled list */      for (;;) { @@ -65,6 +67,11 @@      if (rv != APR_SUCCESS) {          return rv;      } +    rv = apr_thread_mutex_create(&qi->queue_mutex, APR_THREAD_MUTEX_DEFAULT, +                                 pool); +    if (rv != APR_SUCCESS) { +        return rv; +    }      rv = apr_thread_cond_create(&qi->wait_for_idler, pool);      if (rv != APR_SUCCESS) {          return rv; @@ -93,14 +100,14 @@          new_recycle = (struct recycled_pool *)apr_palloc(pool_to_recycle,                                                           sizeof(*new_recycle));          new_recycle->pool = pool_to_recycle; -        for (;;) { -            new_recycle->next = queue_info->recycled_pools; -            if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools), -                                  new_recycle, new_recycle->next) == -                new_recycle->next) { -                break; -            } -        } +        rv = apr_thread_mutex_lock(queue_info->queue_mutex); +        if (rv != APR_SUCCESS) +            return rv; +        new_recycle->next = queue_info->recycled_pools; +        queue_info->recycled_pools = new_recycle; +        rv = apr_thread_mutex_unlock(queue_info->queue_mutex); +        if (rv != APR_SUCCESS) +            return rv;      }        /* Atomically increment the count of idle workers */ @@ -182,19 +189,18 @@        /* Atomically decrement the idle worker count */      apr_atomic_dec32(&(queue_info->idlers)); - -    /* Atomically pop a pool from the recycled list */ -    for (;;) { +    rv = apr_thread_mutex_lock(queue_info->queue_mutex); +    if (rv != APR_SUCCESS) +        return rv; +    if (queue_info->recycled_pools) {          struct recycled_pool *first_pool = queue_info->recycled_pools; -        if (first_pool == NULL) { -            break; -        } -        if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools), first_pool->next, -                              first_pool) == first_pool) { -            *recycled_pool = first_pool->pool; -            break; -        } +        queue_info->recycled_pools = first_pool->next; +        *recycled_pool = first_pool->pool; +        first_pool->next = NULL;      } +    rv = apr_thread_mutex_unlock(queue_info->queue_mutex); +    if (rv != APR_SUCCESS) +        return rv;        if (queue_info->terminated) {          return APR_EOF; ---------------------------------------------------------------------------  If you agree that there is a clear race condition then to correct this, I have following suggestion : (a) Use a dedicated pool for each worker thread, this will avoid any locking. It will perform better but may require little more memory in those situations when worker threads are not fully used. (b) Use some other technique other than a recycled pool list which avoids race conditions.  I am in favour of option (a) until some good idea for (b) comes to my mind. If you agree with (a) then I can work and generate a patch.  Note : Also I believe that the crash will happen in linux too. I never ran more than 1 hour in linux. I will try that tonight.  (In reply to comment #12)  > If you agree that there is a clear race condition then to correct this, I have > following suggestion : > (a) Use a dedicated pool for each worker thread, this will avoid any locking. > It will perform better but may require little more memory in those situations > when worker threads are not fully used. > (b) Use some other technique other than a recycled pool list which avoids race > conditions. >  > I am in favour of option (a) until some good idea for (b) comes to my mind. > If you agree with (a) then I can work and generate a patch. >  > Note : Also I believe that the crash will happen in linux too. I never ran more > than 1 hour in linux. I will try that tonight. >   Thank you for your thorough investigation. I agree with you that we have the described race conditions here. We have a similar race in the event MPM. Next steps:  1. Bring your patch above into trunk. Currently I see no significant performance     loss over the current code as we are using a mutex there as well. We only    increase the time during which we lock the resource. I don't know right    now when I find the cycles to apply the patch to trunk, but if you could    attach a trunk version of your patch to this report it would be a big help.  2. Move the further discussion regarding options a) or b) to     dev@httpd.apache.org and lets wait for its results to decide how to move     along and improve the situation here in the long run.    I think I have to correct myself in two points.  1. On APR trunk there are better implementations for apr_atomic_casptr which no     longer use a mutex, but native platform processor / OS features. So in     contrast to my first assumption there could be a performance degradation by    your patch on trunk, which would be bad.  2. The race scenario you described cannot happen in this way, because it assumes    that multiple threads pop pools from the list in parallel. This is not the     case as only the listener thread does this. What happens in parallel are:     - Multiple pushes to the list    - (Multiple) pushes to the list and a pop  OTOH I still believe that there is some kind of race scenario as your patch showed that the error goes away if the locking / syncing is changed here. So maybe its only a different scenario (that I haven't figured out so far) or there is a bug in apr_atomic_casptr. Do the same crashes happen with trunk?     Regarding the example given in comments # 12, I need to correct myself. I agree with you that the example is not valid for worker implementation because there is single thread which pop the nodes and multiple threads which pushes the node.  ( ap_queue_info_wait_for_idler is not thread safe but it is not called by multiple threads. It is only invoked by single listener_thread. )  I could not yet think of any race condition in which single popping thread and several pushing thread cause recycle_pool list corruption.  I am still working on it to find the real cause of the crashes.    Few more updates :  * Probably these crashes also exist on Linux (64 bit). But I can't say for sure. I saw 3 crashes so far. Out of 3, I get core dump only once and stack trace from that core dump didn't seem much sense to me so I can't say for sure that the bug reproduces on Linux or not. (Linux is 64 bit Fedora 8 with 64 bit apache).   On Solaris, I tried the following things : * Replaced apr_atomic_casptr with solaris's atomic_casptr. But the result remained the same. I still saw the crashes. This means that this may not be the apr bug. * If I replace apr_atomic_casptr code but keep the for loop then  the crashes disappear. ---------------------------------- ap_queue_info_set_idle-------------             if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools),                                   new_recycle, new_recycle->next) ==                 new_recycle->next) {                 break;             } ---------------------------------- replace with -----------------------             rv = apr_thread_mutex_lock(queue_info->queue_mutex);             if (queue_info->recycled_pools == new_recycle->next) {                 queue_info->recycled_pools = new_recycle;                 success = 1;             }             rv = apr_thread_mutex_unlock(queue_info->queue_mutex);   ---------------------------------- ap_queue_info_wait_for_idler --------------         if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools), first_pool->next,                               first_pool) == first_pool) {             *recycled_pool = first_pool->pool;             break;         } ---------------------------------- replace with ---------------------------         rv = apr_thread_mutex_lock(queue_info->queue_mutex);         if (queue_info->recycled_pools == first_pool) {             queue_info->recycled_pools = next;             success = 1;         }         rv = apr_thread_mutex_unlock(queue_info->queue_mutex); ----------------------------------  Created an attachment (id=21581) Patch for httpd-2.2.8  Eventually I figured out where is the real race condition.  Lines fdqueue.c:96-102 (in httpd-2.2.8) \tfor (;;) { \t    new_recycle->next = queue_info->recycled_pools; \t    if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools), \t\t\t\t  new_recycle, new_recycle->next) == \t\tnew_recycle->next) { \t\tbreak; \t    } \t}  The race condition is between return of apr_atomic_casptr and calculating new_recycle->next.  Let us write the look into three steps (qi->rp is queue_info->recycled_pools): 1. Set new_recycle->next to qi->rp 2. atomically compare and swap qi->rp with new_recycle if matches with     new_recycle->next. 3. Calculate new_recycle->next again. 4. Determine the call apr_atomic_casptr is successful based on the return value and    result of step 3.  The race condition is in between step2 and step3. If apr_atomic_casptr was successful (it means it successfully swapped the value) and If there is a context switch between 2 and 3 then new_recycle->next can point to something else and can also be corrupted. The result of which is that if condition will fail.  I saved the new_recycle->next in a local variable and then used the local variable as shown in the patch and the issue got resolved.  Here is the example how new_recycle->next can be changed by a race condition : Suppose our list is 1-->2-->3, where 1,2,3 are list nodes. Now suppose worker thread 1 wants to add a node 4 to it's head. Here is how it goes :  ----------------------------------------------------------- Worker thread 1 :    new_recycle = 4;    qi->rp = 1;    new_recycle->next = 1;    apr_atomic_casptr successfully compare and swap it with qi->rp that means    qi->rp = 4;     (list now becomes 4-->1-->2-->3)     Now context switch happens :  Listener_thread :     qi->rp is 4 and hence it pops the node 4 and gives it to worker thread 2.    The list becomes 1-->2-->3.     Listener thread pops another node and give it worker thread 3 and now list    becomes 2-->3.  Worker thread 2 :    Returns the node 4 into the list and list becomes 4-->2-->3.  Worker thread 1 :    new_recycle->next now becomes 2 and it compares with 1 and hence comparision fails. -----------------------------------------------------------     Real situations can be little different than what I described because before  worker thread returns node 4 to the list, pool is cleared (line 897 of worker.c, in worker_thread function ) \tapr_pool_clear(ptrans); \tlast_ptrans = ptrans;  which means new_recycle->next will be corrupted and point to a deleted value.  How I figured out this is that if you put a assert statement like : \t    struct recycled_pool *next = queue_info->recycled_pools; \t    new_recycle->next = next; \t    if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools), \t\t\t\t  new_recycle, new_recycle->next) == next) { \t\tap_assert(next == new_recycle->next); \t\tbreak; \t    } then assertion fails under stress situations.  The bug also exist in event mpm too (server/mpm/experimental/event/fdqueue.c).  Ruediger, can you review the patch? The patch is against 2.2.8. Should I submit  patch against trunk?  Since the crash happens on linux too so I am changing the summary. Created an attachment (id=21582) Revised patch  Made small correction in comments of patch. Fixed in trunk in r630335. Great work Basant. Nick beat me to committing your patch, but in the meantime I applied your patch to the event MPM on trunk as well (r630348). *** Bug 44474 has been marked as a duplicate of this bug. *** Backported to 2.2.x as r631362 (http://svn.apache.org/viewvc?rev=631362&view=rev). *** Bug 42086 has been marked as a duplicate of this bug. ***			Basant Kumar Kukreja	Nick Kew	Ruediger Pluem
44511	null	RESOLVED		Eric Suran	1204264620000	1204424001000		mod_cache : no-cache reponses are stored and not revalidated Created an attachment (id=21603) trace between apache and the origin server  Hello,  We use Apache 2.2.6 as a reverse proxy cache with, almong others, mod_cache, mod_disk_cache and mod_proxy (of course). Apache stores response from the origin server despite header 'Cache-Control : no-cache', but it does not revalidate it on subsequent requests, so it serves stalled objects.	Can you check if the following patch fixes your problem:  Index: modules/cache/cache_util.c =================================================================== --- modules/cache/cache_util.c  (revision 632318) +++ modules/cache/cache_util.c  (working copy) @@ -235,6 +235,14 @@      cc_cresp = apr_table_get(h->resp_hdrs, 'Cache-Control');      expstr = apr_table_get(h->resp_hdrs, 'Expires');  +    if (ap_cache_liststr(NULL, cc_cresp, 'no-cache', NULL)) { +        /* +         * The cached entity contained Cache-Control: no-cache, so treat as +         * stale causing revalidation +         */ +        return 0; +    } +      if ((agestr = apr_table_get(h->resp_hdrs, 'Age'))) {          age_c = apr_atoi64(agestr);      }  Created an attachment (id=21604) Patch against trunk   Hello Ruediger,  Your patch works fine. Thank you. Regards,  Eric Committed to trunk as r632749 (http://svn.apache.org/viewvc?rev=632749&view=rev).			Eric Suran	Ruediger Pluem
44699	null	RESOLVED		Takashi Sato	1206657000000	1207132038000		 are garbled Created an attachment (id=21726) screen shot (IE7)  Charset of HTML are different between languages.  de ISO-8859-1 en ISO-8859-1 es ISO-8859-1 fr ISO-8859-1 ja EUC-JP ko EUC-KR pt-br ISO-8859-1 tr UTF-8  Value of title attribute of link tags of Available Languages is from style/lang/(lang).xml language/messages id=nativename. Each style/lang/(lang).xml defines nativename with their own charset. This causes garbled HTML.  For example, EUC-JP (charset for Japanese) doesn't contain alphabet with diacritic.	>Each style/lang/(lang).xml defines nativename with their own charset.  This is not true. For example, style/lang/es.xml defines nativename as Espa&#241;ol.  The input charset is not relevant anyway.  This looks like a bug in IE 7 for me. It doesn't seem to translate the characters correctly to unicode (or fails to select the correct font). For example, the title looks fine in firefox 2 /linux (German locale). (In reply to comment #2) > This looks like a bug in IE 7 for me. It doesn't seem to translate the > characters correctly to unicode (or fails to select the correct font). For > example, the title looks fine in firefox 2 /linux (German locale).  No, this is not an IE bug. Charset of Japanese HTMLs is EUC-JP, but Japanese HTMLs contain ISO-8859-1. I opens them with many text editor, and they are garbled. Firefox actually shows it correctly. I think Firefox has special handler for EUC-JP-ISO-8859-1-mixed text.  I checked Korean file, and found that it contains numeric character references.  <a href='./es/install.html' hreflang='es' rel='alternate' title='Espa&#241;ol'>&nbsp;es&nbsp;</a> | <a href='./fr/install.html' hreflang='fr' rel='alternate' title='Fran&#231;ais'>&nbsp;fr&nbsp;</a> |  Why do XSLT processors convert numeric character references to raw data for Japanese HTML files? I don't have deep knowledge about XML and XSLT... Created an attachment (id=21768) make Japanese HTML UTF-8 against trunk  Japanese character and alphabets with diacritic cannot live together in EUC-JP.  You're right. I'm sure, I saw HTML character references somewhere in ja files. So it seems to be actually java problem then.  I'm gonna take the ja.xml part of your patch, run "build.sh bootstrap" and move the files around.  Thanks for your care. trunk is already synced to the live server, the other branches are coming soon.			Andr?? Malo	Takashi Sato
